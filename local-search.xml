<?xml version="1.0" encoding="utf-8"?>
<search>
  
  
  
  <entry>
    <title>Trusted Memory Zone 介绍</title>
    <link href="/2024/10/08/tmz/"/>
    <url>/2024/10/08/tmz/</url>
    
    <content type="html"><![CDATA[<p>参考：<a href="https://lpc.events/event/9/contributions/630/attachments/703/1300/xdc2020_rayhuang_secure_buffer_with_tmz.pdf">通过可信内存区域（Trusted Memory Zone）支持安全缓冲区</a></p><span id="more"></span><h1 id="背景"><a href="#背景" class="headerlink" title="背景"></a>背景</h1><ul><li>内存加密是一项重要功能，可保护内容不被未经授权的应用程序访问。</li><li>AMD GPU 开发了 TMZ（可信内存区域）来支持视频内存和系统内存加密。</li><li>Linux® 内核、Mesa 和用户空间应用程序正在利用 TMZ 的功能来实现安全缓冲区支持，该支持可用于 Linux® 上的许多其他场景。</li></ul><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><ul><li>可信内存区域 (TMZ) 是一种保护正在写入和从内存读取的内容的方法。</li><li>AMD GPU 平台支持全内存带宽 AES 密码。<ul><li>所有 TMZ 读取和 TMZ 写入在到达内存之前都会经过 AES 密码。</li><li>页表中的 TMZ 位和可信事务提供多重保护。<ul><li>即使 TMZ 位配置错误，内容仍然是安全的，不会暴露。</li></ul></li></ul></li></ul><h1 id="硬件平台支持"><a href="#硬件平台支持" class="headerlink" title="硬件平台支持"></a>硬件平台支持</h1><ul><li>支持的硬件平台：<ul><li>独立 GPU 平台（可加密显存）。</li><li>APU（CPU + GPU）平台（可加密显存和系统内存）。</li></ul></li><li>注意：我们目前仅在 Linux® 上启用了 APU 支持。</li></ul><h1 id="Secure-BO-Buffer-Object"><a href="#Secure-BO-Buffer-Object" class="headerlink" title="Secure BO(Buffer Object)"></a>Secure BO(Buffer Object)</h1><p><img src="/img/gpu/amd/tmz.png" alt="Secure Buffer Object"></p><h1 id="内核和-Mesa-安全缓冲区定义和握手"><a href="#内核和-Mesa-安全缓冲区定义和握手" class="headerlink" title="内核和 Mesa 安全缓冲区定义和握手"></a>内核和 Mesa 安全缓冲区定义和握手</h1><ul><li>在内核驱动程序中初始化 BO 级保护，以便为 gem create ioctl 和 libdrm 提供新标志 AMDGPU_GEM_CREATE_ENCRYPTED，以进行安全缓冲区分配。<ul><li>Mesa 使用分配缓冲区来决定是否安全。</li><li>如果 Mesa 设置了 AMDGPU_GEM_CREATE_ENCRYPTED，则必须设置此缓冲区的整个页表条目的 TMZ 位。</li></ul></li><li>提供 AMDGPU_IB_FLAGS_SECURE 来指示 IB（存储 GPU 命令的间接缓冲区）是否受信任。<ul><li>Mesa 在命令提交上下文的 IB 句柄中使用此标志来通知内核图形引擎是否需要转换为受信任状态。</li></ul></li><li>提供 AMDGPU_IDS_FLAGS_TMZ 来指示 TMZ 功能是否集成。<ul><li>Mesa 使用此信息标志来了解当前 gpu 是否支持 TMZ。</li></ul></li></ul><h1 id="安全策略"><a href="#安全策略" class="headerlink" title="安全策略"></a>安全策略</h1><ul><li><strong>CPU 作为不受信任的域</strong>，无法使用 TMZ 解密安全缓冲区。<ul><li>即使经过 k 映射，用户也无法从 CPU 地址获取原始数据。</li></ul></li><li>只有受信任的硬件块才有能力解密安全缓冲区。<ul><li>所有加密内存只能通过映射 GPUVM 进行解密。</li></ul></li><li>受信任的硬件块<ul><li>GFX</li><li>SDMA</li><li>Video Codec Next (VCN) &#x2F; (JEPG)</li><li>显示引擎</li></ul></li></ul><h1 id="写操作调制表"><a href="#写操作调制表" class="headerlink" title="写操作调制表"></a>写操作调制表</h1><table><thead><tr><th>Transaction Trust State (0:Not trusted, 1:Trusted)</th><th>TMZ bit in GPU table</th><th>Modulation Result</th><th>Encryption State in TMZ</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>Not Encrypted</td><td>OFF</td></tr><tr><td>0</td><td>1</td><td>Encrypted</td><td>ON</td></tr><tr><td>1</td><td>0</td><td>Encrypted</td><td>ON</td></tr><tr><td>1</td><td>1</td><td>Encrypted</td><td>ON</td></tr></tbody></table><h1 id="读操作调制表"><a href="#读操作调制表" class="headerlink" title="读操作调制表"></a>读操作调制表</h1><table><thead><tr><th>Transaction Trust State (0:Not trusted, 1:Trusted)</th><th>TMZ bit in GPU table</th><th>Modulation Result</th><th>Decryption State in TMZ</th></tr></thead><tbody><tr><td>0</td><td>0</td><td>Not Decrypted</td><td>OFF</td></tr><tr><td>1</td><td>1</td><td>Not Decrypted</td><td>OFF</td></tr><tr><td>1</td><td>0</td><td>Not Decrypted</td><td>OFF</td></tr><tr><td>1</td><td>1</td><td>Decrypted</td><td>ON</td></tr></tbody></table><h1 id="Per-IB-保护机制"><a href="#Per-IB-保护机制" class="headerlink" title="Per-IB 保护机制"></a>Per-IB 保护机制</h1><ul><li>Per-IB 保护提交<ul><li>IB（间接缓冲区）是存储 GFX 队列执行的数据包的命令缓冲区。</li><li>内核实现 Per-IB 保护以使用安全缓冲区执行命令提交。<ul><li>当发出具有不安全缓冲区的 IB 时，内核必须将 Transaction Trust State 设置为 Not Trusted。（遗留情况）</li><li>当发出具有安全缓冲区的 IB 时，内核必须将 Transaction Trust State 设置为 Trusted</li></ul></li></ul></li></ul><p><img src="/img/gpu/amd/tmz2.png" alt="Per-IB"></p><h1 id="使用安全缓冲区提交命令-GFX-SDMA-VCN"><a href="#使用安全缓冲区提交命令-GFX-SDMA-VCN" class="headerlink" title="使用安全缓冲区提交命令 - GFX&#x2F;SDMA&#x2F;VCN"></a>使用安全缓冲区提交命令 - GFX&#x2F;SDMA&#x2F;VCN</h1><ul><li>GFX 使用 FRAME_TMZ 位和 PACKET3_FRAME_CONTROL 数据包来控制 GFX 引擎进入可信状态。</li><li>SDMA 作为另一个可信硬件模块，它使用页表中的 TMZ 标志来决定执行常规读&#x2F;写还是可信读&#x2F;写。<ul><li>当内核使用 SDMA 进行安全缓冲区复制时，内核需要在 COPY_LINEAR 数据包的操作码处设置 TMZ 位。</li></ul></li><li>VCN 引擎不需要内核支持在上下文切换期间切换信任级别，它能够根据页表中的 TMZ 标志自行切换。</li></ul><h1 id="Display-Secure-Frame-Buffer"><a href="#Display-Secure-Frame-Buffer" class="headerlink" title="Display Secure Frame Buffer"></a>Display Secure Frame Buffer</h1><ul><li>根据寄存器设置显示引擎安全状态。（不同于 GFX&#x2F;SDMA&#x2F;VCN）<ul><li>显示驱动程序只对寄存器中的一位进行编程，以切换显示引擎的安全状态，而不是使用页表的 TMZ 位。（如果位编程错误，则无法获得有效数据）</li><li>这允许在不使用页表的情况下安全访问 VRAM 中的显示缓冲区。</li></ul></li></ul><h1 id="安全单元测试套件和相关参数"><a href="#安全单元测试套件和相关参数" class="headerlink" title="安全单元测试套件和相关参数"></a>安全单元测试套件和相关参数</h1><ul><li>在 libdrm amdgpu_test 中初始化安全测试套件：<ul><li>套件：11：ENABLED：安全测试<ul><li>测试：1：ENABLED：分配安全缓冲区测试</li><li>测试：2：ENABLED：图形安全命令提交</li><li>测试：3：ENABLED：sDMA 安全命令提交</li><li>测试：4：ENABLED：安全反弹</li></ul></li></ul></li><li>启用 TMZ 的内核参数：amdgpu.tmz&#x3D;1</li><li>启用 TMZ 的 Mesa 参数：AMD_DEBUG&#x3D;tmz</li></ul><h1 id="未加密与加密数据对比"><a href="#未加密与加密数据对比" class="headerlink" title="未加密与加密数据对比"></a>未加密与加密数据对比</h1><p><img src="/img/gpu/amd/tmz3.png" alt="data"><br>参考</p><ul><li><a href="https://lists.freedesktop.org/archives/amd-gfx/2019-September/039928.html">linux</a></li><li><a href="https://gitlab.freedesktop.org/mesa/drm/-/merge_requests/70">drm</a></li><li><a href="https://gitlab.freedesktop.org/mesa/mesa/-/merge_requests/4401">mesa</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>GPU</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TEE</tag>
      
      <tag>Confidential Compute</tag>
      
      <tag>GPU</tag>
      
      <tag>Security</tag>
      
      <tag>KMD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Rust 学习笔记</title>
    <link href="/2024/09/30/rust/"/>
    <url>/2024/09/30/rust/</url>
    
    <content type="html"><![CDATA[<p>Rust 一门赋予每个人构建可靠且高效软件能力的语言。</p><span id="more"></span><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><p>课程</p><ul><li><a href="https://opencamp.cn/os2edu/camp/2024fall">2024 秋冬季开源操作系统训练营</a></li><li><a href="https://course.rs/about-book.html">Rust语言圣经(Rust Course)</a></li><li><a href="https://github.com/sunface/rust-course">Rust语言圣经(Rust Course) 代码</a></li></ul></li><li><p>操作系统</p><ul><li><a href="https://rcore-os.cn/arceos-tutorial-book/ch01-02.html">AeceOS Tutorial Book</a></li><li><a href="https://github.com/arceos-org/arceos">ArceOS</a></li></ul></li><li><p>其他资料</p><ul><li><a href="https://github.com/LearningOS/rust-rustlings-2024-autumn-Jianliang-Shen">2024秋季课程测验仓库</a></li><li><a href="http://llever.com/exercism-rust-zh/index.html">Rust exercisms.io 快速练习</a></li></ul></li><li><p>官方资料</p><ul><li><a href="https://www.rust-lang.org/zh-CN/">Rust 中文官网</a></li><li><a href="https://doc.rust-lang.org/stable/reference/">The Rust Reference</a><ul><li><a href="https://rustwiki.org/zh-CN/reference/introduction.html">Rust 中文参考手册</a></li></ul></li><li><a href="https://doc.rust-lang.org/rust-by-example/">Rust By Example</a><ul><li><a href="https://rustwiki.org/zh-CN/rust-by-example/">非官方中文翻译</a></li></ul></li><li><a href="https://doc.rust-lang.org/stable/book/">Rust 英文官方手册</a><ul><li><a href="https://kaisery.github.io/trpl-zh-cn/">非官方中文翻译</a></li></ul></li><li><a href="https://doc.rust-lang.org/stable/embedded-book/">The Embedded Rust Book</a></li></ul></li></ul><h2 id="MacOS-环境配置"><a href="#MacOS-环境配置" class="headerlink" title="MacOS 环境配置"></a>MacOS 环境配置</h2><ul><li><p>安装rust</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> RUSTUP_UPDATE_ROOT=https://mirrors.tuna.tsinghua.edu.cn/rustup/rustup<br><span class="hljs-built_in">export</span> RUSTUP_DIST_SERVER=https://mirrors.tuna.tsinghua.edu.cn/rustup<br>curl https://sh.rustup.rs -sSf | sh<br><br>rustc --version<br><br><span class="hljs-comment"># version change</span><br>rustup install nightly<br>rustup default &lt;stable/nightly&gt;<br><br><span class="hljs-comment"># Uninstall</span><br>rustup self uninstall<br><br><span class="hljs-comment"># Open Book</span><br>rustup doc --book<br><br><span class="hljs-comment"># Vscode support for rust-analyzer extension</span><br>rustlings lsp<br></code></pre></td></tr></table></figure></li><li><p>安装 qemu</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">brew install qemu<br></code></pre></td></tr></table></figure></li><li><p>编译</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:arceos-org/arceos.git<br><span class="hljs-built_in">cd</span> arceos<br><br><span class="hljs-comment"># For clash, download packages.</span><br><span class="hljs-comment"># Note tsinghua mirror doesn&#x27;t work here</span><br><span class="hljs-comment"># Note nightly version may not work here</span><br><span class="hljs-built_in">export</span> https_proxy=http://127.0.0.1:7890 http_proxy=http://127.0.0.1:7890 all_proxy=socks5://127.0.0.1:7891<br><br><span class="hljs-comment"># install necessary packages: https://github.com/rust-embedded/rust-raspberrypi-OS-tutorials/issues/57</span><br>cargo install cargo-binutils<br><br><span class="hljs-comment"># Build Helloworld</span><br>make ARCH=riscv64 A=examples/helloworld run<br></code></pre></td></tr></table></figure></li></ul><p><img src="/img/rust/arceos_helloworld.png" alt="Hello World"></p><ul><li><p>简单编译文件</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">rustc source.rc<br></code></pre></td></tr></table></figure></li><li><p>cargo 管理项目</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">cargo run --release/debug<br></code></pre></td></tr></table></figure></li></ul>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Rust</tag>
      
      <tag>OS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ESP32 运行 LLM</title>
    <link href="/2024/09/24/esp-llm/"/>
    <url>/2024/09/24/esp-llm/</url>
    
    <content type="html"><![CDATA[<p>榨干ESP32，运行LLM。</p><span id="more"></span><ul><li><a href="https://www.amazon.com/-/zh_TW/T-Display-S3-AMOLED-ESP32-S3-RM67162-%E9%96%8B%E7%99%BC%E6%9D%BF%E7%84%A1%E7%B7%9A%E6%A8%A1%E7%B5%84/dp/B0C2T6T8YC?th=1">Lilygo</a></li><li><a href="https://github.com/DaveBben/esp32-llm/">ESP32 LLM</a></li><li><a href="https://www.youtube.com/watch?v=E6E_KrfyWFQ">演示视频</a></li></ul><p>启动报错：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs txt">quad_psram: PSRAM ID read error: 0x00ffffff, PSRAM chip not found or not supported, or wrong PSRAM line mode<br></code></pre></td></tr></table></figure><p>参考：</p><ul><li><a href="https://github.com/espressif/esp-dl/issues/140">https://github.com/espressif/esp-dl/issues/140</a></li><li><a href="https://github.com/espressif/esp-idf/issues/6288">https://github.com/espressif/esp-idf/issues/6288</a></li></ul><p>注意：</p><ul><li>Lilygo 是 OPI 的 PSRAM</li><li>退回到作者最早的第一次提交，以不使能 i2c-oled</li><li>目前只能续写</li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
      <tag>ESP</tag>
      
      <tag>AIoT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ESP32 语音助手</title>
    <link href="/2024/09/18/AI/esp32-assistant/"/>
    <url>/2024/09/18/AI/esp32-assistant/</url>
    
    <content type="html"><![CDATA[<p>ESP32S3 Box 提供了 chatgpt 的 demo。因为访问不了的原因，打算改来做一个本地化部署的专用语音助手。</p><span id="more"></span><div id="dplayer2" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer2"),"theme":"#FADFA3","loop":true,"lang":"zh-cn","screenshot":true,"hotkey":true,"preload":"auto","volume":0.9,"mutex":true,"video":{"url":"/img/esp32/esp.mp4","pic":"/img/esp32/esp.jpg"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><p>前置条件：</p><ul><li>&gt;&#x3D;12GB显存的显卡</li><li>ESP32S3-Box</li></ul><h1 id="语音助手"><a href="#语音助手" class="headerlink" title="语音助手"></a>语音助手</h1><p><img src="/img/esp32/design.png" alt="组成"></p><p>Roadmap:</p><ul><li><input checked="" disabled="" type="checkbox"> 更改demo中的默认界面语言，并且删除与OpenAI相关的代码实现</li><li><input checked="" disabled="" type="checkbox"> 更新demo的默认语音</li><li><input disabled="" type="checkbox"> 更新语音唤醒的提示词</li><li><input checked="" disabled="" type="checkbox"> 写一个python上位机服务器，接受ESP32的请求，处理完数据后<ul><li><input checked="" disabled="" type="checkbox"> 接收ESP的音频</li><li><input checked="" disabled="" type="checkbox"> 下发语音识别结果，即第一串字符</li><li><input checked="" disabled="" type="checkbox"> 下发ollama生成的结果，即第二串字符</li><li><input checked="" disabled="" type="checkbox"> 下发语音生成的结果，即第三段数据</li><li><input checked="" disabled="" type="checkbox"> ESP继续超时等待结果，收到后，播放声音</li></ul></li><li><input disabled="" type="checkbox"> 模型微调</li><li><input disabled="" type="checkbox"> <a href="https://chatgptcn.readthedocs.io/zh-cn/latest/prompt/system_prompt_cn/">提示词</a></li><li><input disabled="" type="checkbox"> 语音clone</li><li><input disabled="" type="checkbox"> 查看B站的开源示例，寻找降低延迟的手段</li></ul><h2 id="调试步骤"><a href="#调试步骤" class="headerlink" title="调试步骤"></a>调试步骤</h2><ul><li><p>Windows 运行 Docker Desktop</p></li><li><p>WSL 中打开 FunASR docker，参考：<a href="https://www.tech-odyssey.cn/2024/09/17/AI/voice-assistant/#FunASR">准备FunASR</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> bash work/funasr/funasr-runtime-deploy-online-cpu-zh.sh restart<br></code></pre></td></tr></table></figure></li><li><p>Powershell 打开Ollama server，设置支持局域网模式</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[Environment]::SetEnvironmentVariable(<span class="hljs-string">&#x27;OLLAMA_HOST&#x27;</span>, <span class="hljs-string">&#x27;0.0.0.0:11434&#x27;</span>, <span class="hljs-string">&#x27;Process&#x27;</span>)<br>[Environment]::SetEnvironmentVariable(<span class="hljs-string">&#x27;OLLAMA_ORIGINS&#x27;</span>, <span class="hljs-string">&#x27;*&#x27;</span>, <span class="hljs-string">&#x27;Process&#x27;</span>)<br>ollama serve<br></code></pre></td></tr></table></figure></li><li><p>Windows 运行cosyvoice docker，在 Docker Desktop 中直接运行。参考：<a href="https://www.tech-odyssey.cn/2024/09/17/AI/voice-assistant/#Cosyvoice-Docker">Cosyvoice docker</a></p></li><li><p>如果是 wsl 开发的 esp，则需要管理员模式打开powershell，绑定 ESP-IDF 串口，再进行下载</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">usbipd attach --wsl --busid=1-1<br></code></pre></td></tr></table></figure></li><li><p>运行 server.py 脚本</p><ul><li>windows 需要下载 ffmpeg，并在环境变量中添加 bin 的路径</li><li>安装一些脚本需要的依赖</li></ul> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install numpy websockets requests torchaudio ollama simpleaudio python-ffmpeg soundfile ffmpeg ffmpeg-python<br>python server.py<br></code></pre></td></tr></table></figure></li><li><p>下载烧录，编译参考 <a href="#%E7%BC%96%E8%AF%91-esp-assistant">编译 esp assistant</a></p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># WSL下需要使能idf环境</span><br><span class="hljs-comment"># get_idf</span><br>idf.py -p /dev/ttyACM0 flash monitor<br></code></pre></td></tr></table></figure></li></ul><h2 id="遇到的问题"><a href="#遇到的问题" class="headerlink" title="遇到的问题"></a>遇到的问题</h2><div class="note note-danger">            <ul><li><p><strong>chatgpt demo 连接不上wifi</strong>：点击进入返回出厂设置，这时候电脑显示连上了U盘，更改文件中的 wifi 设置即可</p></li><li><p><strong>进入工厂模式后无法烧写</strong>：按住boot键，松了按reset键，可以恢复烧写</p></li><li><p><strong>在WSL2中，server.py 脚本无法被ESP访问端口</strong>：通过转发端口方式，实际操作总是有问题。解决方法是把 server agent 放 windows 端，带来了下面的问题。</p></li><li><p><strong>server.py 脚本无法访问 Ollama server</strong>：把 VPN 关了。</p></li><li><p><strong>WSL2部署的 cosyvoice server 无法访问</strong>：创建 cosyvoice fastapi docker 容器，先提前下载一个镜像</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull pytorch/pytorch:2.0.1-cuda11.7-cudnn8-runtime<br></code></pre></td></tr></table></figure><p> 按照官方教程编译fasapi container。</p></li><li><p><strong>cosyvoice fasapi container 无法外部访问</strong>：需要将cosyvoice fastapi docker的ip设为0.0.0.0，以让host能够访问，需要下载一个vim，然后更改 fastapi 路径下的 server.py 里的 ip</p></li><li><p><strong>cosyvoice fastapi container 运行报错</strong>，显示为：CUFFT_INTERNAL_ERROR</p><ul><li><a href="https://forums.developer.nvidia.com/t/bug-ubuntu-on-wsl2-rtx4090-related-cufft-runtime-error/230883/5">Bug: Ubuntu on WSL2 - RTX4090 related cuFFT runtime error</a></li><li><a href="https://github.com/pytorch/pytorch/issues/88038">CUFFT_INTERNAL_ERROR on RTX 4090</a></li></ul><p>解决：到 cosyvoice 给的 docker container里，卸载掉 11.7 的 pytorch cuda：</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip uninstall torch torchaudio<br>pip install torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118<br></code></pre></td></tr></table></figure></li><li><p><strong>Windows Server 保存音频，save 时无法保存音频</strong>。在wsl2的客户端保存音频没问题</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">raise RuntimeError(f<span class="hljs-string">&quot;Couldn&#x27;t find appropriate backend to handle uri &#123;uri&#125; and format &#123;format&#125;.&quot;</span>)<br>RuntimeError: Couldn<span class="hljs-string">&#x27;t find appropriate backend to handle uri tmp.wav and format None.</span><br></code></pre></td></tr></table></figure><p> 在 save 时无法保存音频。解决，安装后端，并且不要使用windows conda，导致 pip 包混乱。</p> <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install ffmpeg soundfile<br></code></pre></td></tr></table></figure></li><li><p><strong>生成的音频转码至 mp3 下载到内存中无法播放</strong>：改用 wav 写入spiffs文件系统中，再调用播放的接口。</p></li><li><p><strong>wav 播放诡异</strong>：采样率不对，按照代码中设置的，在host端调用ffmpeg先调整一下采样率和比特率。</p></li><li><p><strong>ESP32 只能录音一部分，后面会丢失</strong>：TODO</p></li><li><p><strong>wav 文件下载太慢，文件IO操作次数太多，文件碎片严重</strong>：将文件压缩为 mp3，统一下载到内存后，写入文件系统，再进行播放。</p></li></ul>          </div><h1 id="详细记录"><a href="#详细记录" class="headerlink" title="详细记录"></a>详细记录</h1><p>推荐使用 Windows 版本的 ESP-IDF。</p><h2 id="Windows-安装-ESP-IDF"><a href="#Windows-安装-ESP-IDF" class="headerlink" title="Windows 安装 ESP-IDF"></a>Windows 安装 ESP-IDF</h2><p><a href="https://docs.espressif.com/projects/esp-idf/zh_CN/release-v5.1/esp32s3/get-started/windows-setup.html">Windows 安装教程</a>下载<a href="https://dl.espressif.cn/dl/idf-installer/esp-idf-tools-setup-offline-5.3.1.exe">release版本</a>的离线安装包就好了，然后进入powershell。Windows Terminal 也会创建 ESP-IDF 的页面。</p><h3 id="编译-esp-assistant"><a href="#编译-esp-assistant" class="headerlink" title="编译 esp assistant"></a>编译 esp assistant</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:Jianliang-Shen/ESP_Assistant.git<br><br><span class="hljs-comment"># 一些通用的例程要设置目标开发板</span><br><span class="hljs-comment"># idf.py set-target esp32s3</span><br><br><span class="hljs-built_in">cd</span> ESP_Assistant/factory_nvs<br>idf.py menuconfig<br>idf.py build<br><br><span class="hljs-built_in">cd</span> ..<br>idf.py build<br><br>idf.py -p COM3 flash monitor<br></code></pre></td></tr></table></figure><h2 id="WSL-安装-ESP-IDF"><a href="#WSL-安装-ESP-IDF" class="headerlink" title="WSL 安装 ESP-IDF"></a>WSL 安装 ESP-IDF</h2><p>不推荐使用WSL，各种大麻烦小麻烦。</p><h3 id="配置-IDF"><a href="#配置-IDF" class="headerlink" title="配置 IDF"></a>配置 IDF</h3><p>在linux环境中手动安装最新版本的 ESP-IDF：</p><ul><li><a href="https://docs.espressif.com/projects/esp-idf/zh_CN/v5.3.1/esp32s3/get-started/linux-macos-setup.html">Linux 和 macOS 平台工具链的标准设置</a></li><li><a href="https://github.com/espressif/esp-box/tree/master/examples/chatgpt_demo">ChatGPT Example</a></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install git wget flex bison gperf python3 python3-pip python3-venv cmake ninja-build ccache libffi-dev libssl-dev dfu-util libusb-1.0-0<br><br>git <span class="hljs-built_in">clone</span> git@github.com:espressif/esp-idf.git<br><span class="hljs-built_in">cd</span> esp-idf/<br><br><span class="hljs-built_in">export</span> IDF_GITHUB_ASSETS=<span class="hljs-string">&quot;dl.espressif.cn/github_assets&quot;</span><br>./install.sh esp32s3<br><br><span class="hljs-comment"># 完成后配置shell环境</span><br>. ./export.sh<br></code></pre></td></tr></table></figure><div class="note note-primary">            <p>卡住哪个压缩包下载不下来，就到网页中手动下载，然后它会创建python虚拟环境，到idf-tool.py中找到pip下载的部分，在后面加上<code>-i https://mirrors.aliyun.com/pypi/simple/</code>以加快速度</p>          </div><p>设置环境变量：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">vim ~/.bashrc<br><span class="hljs-built_in">alias</span> get_idf=<span class="hljs-string">&#x27;. $HOME/esp/esp-idf/export.sh&#x27;</span><br></code></pre></td></tr></table></figure><p>使用<code>get_idf</code>进入python虚拟环境</p><h3 id="编译-chatgpt-demo"><a href="#编译-chatgpt-demo" class="headerlink" title="编译 chatgpt demo"></a>编译 chatgpt demo</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:espressif/esp-box.git<br><span class="hljs-built_in">cd</span> examples/chatgpt_demo/factory_nvs<br>idf.py menuconfig<br></code></pre></td></tr></table></figure><p>这里设置一下wifi和openAI密钥等信息：</p><p><img src="/img/esp32/wifi.png" alt="WIFI"></p><p>OpenAI Key：<a href="https://platform.openai.com/api-keys">https://platform.openai.com/api-keys</a></p><p><img src="/img/esp32/openai.png" alt="OpenAI key"></p><div class="note note-primary">            <p>这里它会手动为IDF-ESP下载submodule，时间比较长，尤其会卡在esp_wifi包，如果卡住了，ctrl-C后继续，它会跳过这个包的更新去继续下载，然后进入menuconfig，但是最后编译的时候会报错，因为找不到库</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs txt">ninja: error: &#x27;/esp-idf/components/esp_wifi/lib/esp32s3/libcore.a&#x27;, needed by &#x27;factory_nvs.elf&#x27;, missing and no known rule to make it<br>ninja failed with exit code 1, output of the command is in the work/esp-box/examples/chatgpt_demo/factory_nvs/build/log/idf_py_stderr_output_18950 and /work/esp-box/examples/chatgpt_demo/factory_nvs/build/log/idf_py_stdout_output_18950<br></code></pre></td></tr></table></figure><p>到esp-idf&#x2F;components&#x2F;esp_wifi目录下，删除里面所有文件后通过git checkout 将文件还原，可以解决上述这个问题。</p><p>也有可能是网好了给我下载下来了，总之，祈祷网是好的。</p>          </div><p>完成后，开始build</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">idf.py build<br></code></pre></td></tr></table></figure><p>编译chatgpt-demo：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">cd</span> examples/chatgpt_demo/<br>idf.py menuconfig<br>idf.py build<br></code></pre></td></tr></table></figure><h3 id="串口映射"><a href="#串口映射" class="headerlink" title="串口映射"></a>串口映射</h3><p>参考：<a href="https://blog.csdn.net/weixin_42670590/article/details/137893045">wsl2中访问windows上的串口</a>。windows下载安装：<a href="https://github.com/dorssel/usbipd-win/releases/tag/v4.3.0">usbipd-win</a></p><p>在WSL中</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt install linux-tools-5.4.0-77-generic hwdata<br><span class="hljs-built_in">sudo</span> update-alternatives --install /usr/local/bin/usbip usbip /usr/lib/linux-tools/5.4.0-77-generic/usbip 20<br></code></pre></td></tr></table></figure><p>管理员模式下打开Powershell：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ usbipd list<br>Connected:<br>BUSID  VID:PID    DEVICE                                                        STATE<br>1-1    303a:1001  USB 串行设备 (COM7), USB JTAG/serial debug unit                Not shared<br><br>Persisted:<br>GUID                                  DEVICE<br>$ usbipd <span class="hljs-built_in">bind</span> --busid 1-1<br>$ usbipd attach --wsl --busid=1-1<br>$ usbipd: info: Using WSL distribution <span class="hljs-string">&#x27;Ubuntu-20.04&#x27;</span> to attach; the device will be available <span class="hljs-keyword">in</span> all WSL 2 distributions.<br>usbipd: info: Using IP address 172.18.128.1 to reach the host.<br></code></pre></td></tr></table></figure><p>WSL中，找到TTY：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ <span class="hljs-built_in">ls</span> /dev/tty*<br>/dev/ttyACM0<br></code></pre></td></tr></table></figure><h3 id="下载"><a href="#下载" class="headerlink" title="下载"></a>下载</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">idf.py -p /dev/ttyACM0 flash<br></code></pre></td></tr></table></figure><p>烧写不进去，按住BOOT，再按reset，等待串口烧录。找不到串口时，在powershell重复上述的操作。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>AIoT</tag>
      
      <tag>TTS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>异构 CPU-GPU 系统上的机密计算：调研和未来方向</title>
    <link href="/2024/09/18/AI-TEE/"/>
    <url>/2024/09/18/AI-TEE/</url>
    
    <content type="html"><![CDATA[<p>近年来，信息化的广泛普及和数据的快速爆炸式增长，对集成多个计算核心（如CPU、图形处理单元（GPU）、专用集成电路（ASIC）和现场可编程门阵列（FPGA））的高性能异构系统的需求日益增加。</p><span id="more"></span><p>CPU和GPU的组合由于其多功能性而尤为流行。然而，这些异构系​​统面临着巨大的安全和隐私风险。隐私保护技术的进步，特别是基于硬件的可信执行环境（TEE），为GPU应用提供了有效的保护。尽管如此，在异构系统中将TEE扩展到GPU所涉及的潜在安全风险仍不确定，需要进一步研究。</p><p>为了深入研究这些风险，我们研究了现有流行的GPU TEE设计，并总结和比较了它们的主要影响。此外，我们回顾了针对GPU和部署在CPU上的传统TEE的现有强大攻击，以及减轻这些威胁的努力。我们识别了GPU TEE引入的潜在攻击面，并深入了解了设计安全GPU TEE的关键考虑因素。由于针对异构系统（尤其是 GPU）的新 TEE 正在开发中，因此这项调查非常及时，凸显了了解潜在安全威胁以及构建高效和安全系统的必要性。</p><p>CCS 概念：</p><ul><li>一般和参考 → 调查和概述</li><li>计算机系统组织 → 异构（混合）系统；</li><li>安全和隐私 → 硬件攻击和对策；可信计算。</li></ul><p>附加的关键词和短语：机密计算、GPU 上的可信执行环境、硬件安全、GPU 攻击</p><h1 id="1-引言"><a href="#1-引言" class="headerlink" title="1. 引言"></a>1. 引言</h1><p>异构计算系统已成为现代技术的基石，其驱动力在于各种应用对提高能源效率和性能的需求。从超级计算机和高性能集群的巨大计算能力到智能手机和笔记本电脑的日常使用，如今各种计算架构都已集成在一起，以实现性能和功耗之间的最佳平衡 <sup id="fnref:79" class="footnote-ref"><a href="#fn:79" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ashfaq A. Khokhar, Viktor K. Prasanna, Muhammad E. Shaaban, and C-L Wang. 1993. Heterogeneous computing: Challenges and opportunities. Computer 26, 6 (1993), 18–27.">[79]</span></a></sup> <sup id="fnref:111" class="footnote-ref"><a href="#fn:111" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sparsh Mittal and Jeffrey S Vetter. 2015. A survey of CPU-GPU heterogeneous computing techniques. ACM Computing Surveys (CSUR) 47, 4 (2015), 1–35.">[111]</span></a></sup>。</p><p>异构计算是指利用多种计算核心的系统，包括 CPU、GPU、ASIC、FPGA 和神经处理单元 (NPU)。尽管异构计算的概念已经被探索了二十多年，但 GPU 等加速器的最新进展，加上机器学习 (ML) 的爆炸式增长，极大地改变了这些系统。特别是，自 2000 年代中期以来，研究表明，与传统 CPU 相比，GPU 可以将卷积神经网络 (CNN) 和其他流行 ML 模型的训练速度提高 10-30 倍 <sup id="fnref:145" class="footnote-ref"><a href="#fn:145" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shaohuai Shi, Qiang Wang, Pengfei Xu, and Xiaowen Chu. 2016. Benchmarking state-of-the-art deep learning software tools. In 2016 7th International Conference on Cloud Computing and Big Data (CCBD). IEEE, 99–104.">[145]</span></a></sup> <sup id="fnref:152" class="footnote-ref"><a href="#fn:152" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sijun Tan, Brian Knott, Yuan Tian, and David J Wu. 2021. CryptGPU: Fast privacy-preserving machine learning on the GPU. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 1021–1038.">[152]</span></a></sup>。这种加速使得使用 GPU 的异构计算系统成为当今 ML 基础设施中不可或缺的一部分，为人工智能 (AI) 技术的快速开发和部署提供关键支持。虽然异构计算系统提供了卓越的性能和能效，但它们也带来了新的挑战。这些系统的复杂架构可能会带来潜在的漏洞和安全风险，尤其是对于它们执行的任务，例如 ML 应用程序。</p><p>随着这些系统不断发展并扩大其在计算领域的作用，确保它们的安全性和可靠性至关重要。</p><p>为了确保异构计算系统的安全性和保密性，研究人员致力于将传统上用于 CPU 的隐私保护技术应用于 GPU 等加速器。这些技术包括加密方法，如同态加密 (HE) <sup id="fnref:40" class="footnote-ref"><a href="#fn:40" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shengyu Fan, Zhiwei Wang, Weizhi Xu, Rui Hou, Dan Meng, and Mingzhe Zhang. 2023. Tensorfhe: Achieving practical computation on encrypted data using gpgpu. In 2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 922–934.">[40]</span></a></sup> <sup id="fnref:110" class="footnote-ref"><a href="#fn:110" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pratyush Mishra, Ryan Lehmkuhl, Akshayaram Srinivasan, Wenting Zheng, and Raluca Ada Popa. 2020. Delphi: A cryptographic inference system for neural networks. In Proceedings of the 2020 Workshop on Privacy-Preserving Machine Learning in Practice. 27–30.">[110]</span></a></sup> <sup id="fnref:122" class="footnote-ref"><a href="#fn:122" rel="footnote"><span class="hint--top hint--rounded" aria-label="Lucien KL Ng and Sherman SM Chow. 2021. GForce:GPU-Friendly oblivious and rapid neural network inference. In 30th USENIX Security Symposium (USENIX Security 21). 2147–2164.">[122]</span></a></sup> 和安全多方计算 (MPC) <sup id="fnref:70" class="footnote-ref"><a href="#fn:70" rel="footnote"><span class="hint--top hint--rounded" aria-label="Neha Jawalkar, Kanav Gupta, Arkaprava Basu, Nishanth Chandran, Divya Gupta, and Rahul Sharma. 2023. Orca: FSS-based secure training with GPUs. Cryptology ePrint Archive (2023).">[70]</span></a></sup> <sup id="fnref:110" class="footnote-ref"><a href="#fn:110" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pratyush Mishra, Ryan Lehmkuhl, Akshayaram Srinivasan, Wenting Zheng, and Raluca Ada Popa. 2020. Delphi: A cryptographic inference system for neural networks. In Proceedings of the 2020 Workshop on Privacy-Preserving Machine Learning in Practice. 27–30.">[110]</span></a></sup> <sup id="fnref:122" class="footnote-ref"><a href="#fn:122" rel="footnote"><span class="hint--top hint--rounded" aria-label="Lucien KL Ng and Sherman SM Chow. 2021. GForce:GPU-Friendly oblivious and rapid neural network inference. In 30th USENIX Security Symposium (USENIX Security 21). 2147–2164.">[122]</span></a></sup> <sup id="fnref:152" class="footnote-ref"><a href="#fn:152" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sijun Tan, Brian Knott, Yuan Tian, and David J Wu. 2021. CryptGPU: Fast privacy-preserving machine learning on the GPU. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 1021–1038.">[152]</span></a></sup> <sup id="fnref:172" class="footnote-ref"><a href="#fn:172" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jean-Luc Watson, Sameer Wagh, and Raluca Ada Popa. 2022. Piranha: A GPU platform for secure computation. In 31st USENIX Security Symposium (USENIX Security 22). 827–844.">[172]</span></a></sup>，以及为 GPU 等加速器量身定制的 TEE <sup id="fnref:31" class="footnote-ref"><a href="#fn:31" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.">[31]</span></a></sup> <sup id="fnref:65" class="footnote-ref"><a href="#fn:65" rel="footnote"><span class="hint--top hint--rounded" aria-label="Andrei Ivanov, Benjamin Rothenberger, Arnaud Dethise, Marco Canini, Torsten Hoefler, and Adrian Perrig. 2023. SAGE: Software-based Attestation for GPU Execution. In 2023 USENIX Annual Technical Conference (USENIX ATC 23). 485–499.">[65]</span></a></sup> <sup id="fnref:66" class="footnote-ref"><a href="#fn:66" rel="footnote"><span class="hint--top hint--rounded" aria-label="Insu Jang, Adrian Tang, Taehoon Kim, Simha Sethumadhavan, and Jaehyuk Huh. 2019. Heterogeneous isolated execution for commodity gpus. In Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 455–468.">[66]</span></a></sup> <sup id="fnref:71" class="footnote-ref"><a href="#fn:71" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jianyu Jiang, Ji Qi, Tianxiang Shen, Xusheng Chen, Shixiong Zhao, Sen Wang, Li Chen, Gong Zhang, Xiapu Luo, and Heming Cui. 2022. CRONUS: Fault-isolated, secure and high-performance heterogeneous computing for trusted execution environment. In 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO). IEEE, 124–143.">[71]</span></a></sup> <sup id="fnref:86" class="footnote-ref"><a href="#fn:86" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sunho Lee, Jungwoo Kim, Seonjin Na, Jongse Park, and Jaehyuk Huh. 2022. Tnpu: Supporting trusted execution with tree-less integrity protection for neural processing unit. In 2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 229–243.">[86]</span></a></sup> <sup id="fnref:106" class="footnote-ref"><a href="#fn:106" rel="footnote"><span class="hint--top hint--rounded" aria-label="Haohui Mai, Jiacheng Zhao, Hongren Zheng, Yiyang Zhao, Zibin Liu, Mingyu Gao, Cong Wang, Huimin Cui, Xiaobing Feng, and Christos Kozyrakis. 2023. Honeycomb: Secure and Efficient GPU Executions via Static Validation. In 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23). 155–172.">[106]</span></a></sup> <sup id="fnref:124" class="footnote-ref"><a href="#fn:124" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA confidential computing. https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/.">[124]</span></a></sup> <sup id="fnref:162" class="footnote-ref"><a href="#fn:162" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 681–696.">[162]</span></a></sup> <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> <sup id="fnref:180" class="footnote-ref"><a href="#fn:180" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ardhi Wiratama Baskara Yudha, Jake Meyer, Shougang Yuan, Huiyang Zhou, and Yan Solihin. 2022. LITE: a low-cost practical inter-operable GPU TEE. In Proceedings of the 36th ACM International Conference on Supercomputing. 1–13.">[180]</span></a></sup> <sup id="fnref:190" class="footnote-ref"><a href="#fn:190" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jianping Zhu, Rui Hou, XiaoFeng Wang, Wenhao Wang, Jiangfeng Cao, Boyan Zhao, Zhongpu Wang, Yuhui Zhang, Jiameng Ying, Lixin Zhang, et al. 2020. Enabling rack-scale confidential computing using heterogeneous trusted execution environment. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1450–1465.">[190]</span></a></sup>。与加密方法相比，TEE 具有某些优势，特别是在性能和​​易于部署方面，它提供了一种基于硬件的强大安全机制，并且相对易于实现和管理。然而，与加密技术相比，TEE 的安全性依赖于对制造商的信任，并且很难进行严格分析和证明。</p><p>最近的研究探索了将 TEE 扩展到 GPU 等加速器，包括 x86 <sup id="fnref:65" class="footnote-ref"><a href="#fn:65" rel="footnote"><span class="hint--top hint--rounded" aria-label="Andrei Ivanov, Benjamin Rothenberger, Arnaud Dethise, Marco Canini, Torsten Hoefler, and Adrian Perrig. 2023. SAGE: Software-based Attestation for GPU Execution. In 2023 USENIX Annual Technical Conference (USENIX ATC 23). 485–499.">[65]</span></a></sup> <sup id="fnref:66" class="footnote-ref"><a href="#fn:66" rel="footnote"><span class="hint--top hint--rounded" aria-label="Insu Jang, Adrian Tang, Taehoon Kim, Simha Sethumadhavan, and Jaehyuk Huh. 2019. Heterogeneous isolated execution for commodity gpus. In Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 455–468.">[66]</span></a></sup> <sup id="fnref:86" class="footnote-ref"><a href="#fn:86" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sunho Lee, Jungwoo Kim, Seonjin Na, Jongse Park, and Jaehyuk Huh. 2022. Tnpu: Supporting trusted execution with tree-less integrity protection for neural processing unit. In 2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 229–243.">[86]</span></a></sup> <sup id="fnref:106" class="footnote-ref"><a href="#fn:106" rel="footnote"><span class="hint--top hint--rounded" aria-label="Haohui Mai, Jiacheng Zhao, Hongren Zheng, Yiyang Zhao, Zibin Liu, Mingyu Gao, Cong Wang, Huimin Cui, Xiaobing Feng, and Christos Kozyrakis. 2023. Honeycomb: Secure and Efficient GPU Executions via Static Validation. In 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23). 155–172.">[106]</span></a></sup> <sup id="fnref:124" class="footnote-ref"><a href="#fn:124" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA confidential computing. https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/.">[124]</span></a></sup> <sup id="fnref:162" class="footnote-ref"><a href="#fn:162" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 681–696.">[162]</span></a></sup> <sup id="fnref:180" class="footnote-ref"><a href="#fn:180" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ardhi Wiratama Baskara Yudha, Jake Meyer, Shougang Yuan, Huiyang Zhou, and Yan Solihin. 2022. LITE: a low-cost practical inter-operable GPU TEE. In Proceedings of the 36th ACM International Conference on Supercomputing. 1–13.">[180]</span></a></sup> <sup id="fnref:190" class="footnote-ref"><a href="#fn:190" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jianping Zhu, Rui Hou, XiaoFeng Wang, Wenhao Wang, Jiangfeng Cao, Boyan Zhao, Zhongpu Wang, Yuhui Zhang, Jiameng Ying, Lixin Zhang, et al. 2020. Enabling rack-scale confidential computing using heterogeneous trusted execution environment. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1450–1465.">[190]</span></a></sup> 和 Arm <sup id="fnref:31" class="footnote-ref"><a href="#fn:31" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.">[31]</span></a></sup> <sup id="fnref:71" class="footnote-ref"><a href="#fn:71" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jianyu Jiang, Ji Qi, Tianxiang Shen, Xusheng Chen, Shixiong Zhao, Sen Wang, Li Chen, Gong Zhang, Xiapu Luo, and Heming Cui. 2022. CRONUS: Fault-isolated, secure and high-performance heterogeneous computing for trusted execution environment. In 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO). IEEE, 124–143.">[71]</span></a></sup> <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> 架构。这些方法中的大多数涉及修改现有的 CPU TEE（尤其是基于进程的 TEE，如英特尔软件保护扩展 (SGX) 和 Arm TrustZone (TrustZone)）以保护 GPU 软件堆栈（如 GPU 驱动程序），并提出确保 GPU 内核执行隔离性和机密性的策略。除此之外，NVIDIA 在其 Hopper 架构 <sup id="fnref:124" class="footnote-ref"><a href="#fn:124" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA confidential computing. https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/.">[124]</span></a></sup> 中引入了一个开创性的商业平台，该平台通过内存加密和隔离执行上下文等功能支持机密计算。然而，在异构计算系统中跨 CPU 和加速器扩展 TEE 所带来的安全威胁仍不确定，需要进一步研究。</p><p>在本调查中，我们深入研究了当前加速器 TEE 设计中的潜在漏洞，特别强调了 GPU（称为 GPU TEE）。为此，我们首先回顾和分类致力于创建 GPU TEE 原型的研究工作。这些解决方案针对各个方面：<strong>一些旨在保护 GPU 软件堆栈，另一些则侧重于保护在 GPU 上处理的数据的机密性，还有一些提供强大的隔离机制。</strong>因此，每种设计都呈现出不同的攻击面。为了识别这些潜在的攻击面，我们对 GPU 上的现有攻击进行了分类和分析，包括<strong>架构&#x2F;逻辑攻击、微架构侧通道和隐蔽通道攻击、物理侧通道攻击和故障注入</strong>。异构计算系统中 GPU 的独特架构和可访问性与传统 CPU 相比具有显著差异，而传统 CPU 历来是此类攻击的主要目标。此外，我们还回顾了<strong>针对 Intel SGX、Arm TrustZone 和 AMD 安全加密虚拟化 (SEV) 等 CPU TEE 的现有攻击</strong>，并研究了它们对在 GPU TEE 上运行的代码和数据的影响。最后，通过综合这些见解，我们讨论了这些强大的攻击媒介在 GPU TEE 中暴露的潜在攻击面。</p><p>如图 1 和图 2 所示，GPU 的发展导致了越来越高性能架构的发展。因此，研究越来越关注通过探索新的架构漏洞来调查 GPU 中的潜在攻击面。同样，我们预计最近出现的 GPU TEE 的潜在安全威胁将受到越来越多的关注。我们相信，这项调查为设计 GPU TEE 的关键考虑因素、针对异构计算系统的现有攻击的主要工作流程以及为 CPU TEE 和 GPU 引入的潜在攻击面提供了关键见解。这种理解可以指导未来的研究，以开发异构系统上安全高性能计算的防御措施，并通过改进可信计算基 (TCB) 来增强 GPU TEE 上的机密计算。此外，我们相信我们的工作可以激发创建更多适合各种架构和实际应用的 GPU TEE 原型。</p><p><img src="/img/cc/gpu/1.png" alt="图1. 带有 GPU 的异构计算系统的安全研究现状。GPU Crypto 是指使用 HE 和 MPC 等加密技术保护基于 GPU 的应用程序隐私的论文。AA、MSCA、MCCA、PSCA、SFIA 是指架构、微架构侧通道/隐蔽通道、物理侧通道和基于软件的故障注入攻击。"></p><p><img src="/img/cc/gpu/2.png" alt="图2. 安全异构计算系统中重大事件的时间表。"></p><h1 id="2-背景"><a href="#2-背景" class="headerlink" title="2. 背景"></a>2. 背景</h1><p>在本节中，我们介绍 GPU 的基础知识、常见的攻击类型以及现有最流行的 TEE 设计。</p><h2 id="2-1-通用图形处理单元"><a href="#2-1-通用图形处理单元" class="headerlink" title="2.1 通用图形处理单元"></a>2.1 通用图形处理单元</h2><p>通用 GPU (GPGPU) 是专门设计的加速器，旨在处理传统图形渲染以外的各种计算密集型工作负载。凭借其强大的并行计算能力，这些 GPU 非常适合数据分析、机器学习、加密等应用。通常，GPGPU 由多个处理单元组成（即 NVIDIA GPU 中的 CUDA 核心和 Arm GPU 中的着色器核心和执行单元），能够同时执行数千个线程。除了 GPU 之外，还有几种著名的加速器旨在提高特定计算任务的性能。这些包括 FPGA、ASIC 和 NPU。在本次调查中，我们主要关注利用 GPU 的异构系统。</p><p>随着 GPU 的发展，英特尔、NVIDIA、AMD、Arm、高通等供应商推出了具有独特架构特性和功能的 GPU。不同的架构特性（例如内存层次结构）可能会在 GPU 上引入不同的攻击面。表 1 中详细介绍了目前广泛使用的 GPU，它们的架构设计各不相同，尤其是内存层次结构，这会影响它们对某些类型攻击的脆弱性（例如，第 5 节中对集成和独立 GPU 的微架构攻击）。为了全面概述这些 GPU，我们将在以下章节中考虑这些方面。</p><p><img src="/img/cc/gpu/3.png" alt="表1. 在虚拟化中，vGPU、GVT、MPS 和 MIG 分别表示虚拟图形处理单元、图形虚拟化技术、多进程服务和多实例 GPU。内存共享表示内存层次的某一层是否在 CPU 和加速器之间共享。"></p><ul><li><strong>集成&#x2F;独立 GPU。</strong>集成 GPU，例如表 1 中列出的 Intel HD&#x2F;Iris&#x2F;UHD&#x2F;Xe Graphics、Arm 和 Qualcomm GPU，与 CPU 集成在同一芯片或封装上。这些 GPU 与 CPU 共享系统内存。独立 GPU 是独立的专用图形处理单元，与 CPU 分开。它们有自己的专用内存，与系统内存不同（例如，表 1 中列出的 NVIDIA 和 AMD GPU）。</li><li><strong>GPU 虚拟化</strong>。图形虚拟化技术 (GVT)，又名 Intel GVT，允许单个物理 GPU 在具有专用 GPU 资源的多个虚拟机 (VM) 之间共享。 NVIDIA 的多进程服务 (MPS) 可在单个 GPU 上同时管理多个 CUDA 应用程序，但缺乏真正的 GPU 虚拟化的地址空间隔离，因此不适合多租户系统 <sup id="fnref:187" class="footnote-ref"><a href="#fn:187" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhenkai Zhang, Tyler Allen, Fan Yao, Xing Gao, and Rong Ge. 2023. TunneLs for Bootlegging: Fully Reverse-Engineering GPU TLBs for Challenging Isolation Guarantees of NVIDIA MIG. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security. 960–974.">[187]</span></a></sup>。与 MPS 不同，NVIDIA 的虚拟图形处理单元 (vGPU) 可确保单独的 GPU 地址空间和执行上下文。NVIDIA 的 A100 GPU 架构中引入的多实例 GPU (MIG) 将单个物理 GPU 划分为多个实例。每个 MIG 实例都作为单独的 GPU 运行，具有专用资源，包括计算核心、内存和缓存。</li><li><strong>GPU 源代码的开源状态</strong>。GPU 源代码（包括驱动程序和低级架构细节）的可用性因供应商的政策和特定的 GPU 架构而异。例如，AMD（例如 AMD 的 ROCm <sup id="fnref:60" class="footnote-ref"><a href="#fn:60" rel="footnote"><span class="hint--top hint--rounded" aria-label="Tyler Hunt, Zhipeng Jia, Vance Miller, Ariel Szekely, Yige Hu, Christopher J Rossbach, and Emmett Witchel. 2020. Telekine: Secure computing with cloud GPUs. In 17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20). 817–833.">[60]</span></a></sup>）和英特尔（Mesa 3D Graphics <sup id="fnref:64" class="footnote-ref"><a href="#fn:64" rel="footnote"><span class="hint--top hint--rounded" aria-label="Intel. 2024. Intel Mesa 3D Graphics Library. https://docs.mesa3d.org/systems.html.">[64]</span></a></sup>）等供应商为特定平台提供开源 GPU 驱动程序。但是，NVIDIA、ARM 和 Qualcomm 通常提供专有驱动程序，限制开发人员对设计细节的访问。因此，许多针对 GPU 攻击的研究工作通常依赖逆向工程来获取诸如转换后备缓冲区 (TLB) 级别、warp 调度程序等详细信息（参见第 5 节）。</li></ul><h2 id="2-2-GPU-攻击的类型"><a href="#2-2-GPU-攻击的类型" class="headerlink" title="2.2 GPU 攻击的类型"></a>2.2 GPU 攻击的类型</h2><p>近几十年来，一系列攻击已成为现代基于 CPU 的计算系统的重大威胁。随着 GPU 的使用越来越普遍，人们越来越有兴趣探索从 CPU 到 GPU 的潜在安全漏洞。在本次调查中，我们详细介绍了各种攻击媒介，包括架构&#x2F;逻辑攻击、微架构侧信道和隐蔽通道攻击、物理侧信道攻击和故障注入。</p><h3 id="2-2-1-架构-逻辑攻击"><a href="#2-2-1-架构-逻辑攻击" class="headerlink" title="2.2.1 架构&#x2F;逻辑攻击"></a>2.2.1 架构&#x2F;逻辑攻击</h3><p>这些攻击包括一类利用底层硬件架构中的漏洞或弱点的攻击。这些攻击旨在通过针对关键硬件元素的物理或逻辑设计来破坏系统，包括处理单元（例如处理器、硬件加速器和协处理器）、内存子系统以及负责与其他系统元素交互的通信组件 <sup id="fnref:45" class="footnote-ref"><a href="#fn:45" rel="footnote"><span class="hint--top hint--rounded" aria-label="Tara Ghasempouri, Jaan Raik, Cezar Reinbrecht, Said Hamdioui, and Mottaqiallah Taouil. 2023. Survey on architectural attacks: A unified classification and attack model. Comput. Surveys 56, 2 (2023), 1–32.">[45]</span></a></sup>。</p><h3 id="2-2-2-微架构侧信道和隐蔽通道攻击"><a href="#2-2-2-微架构侧信道和隐蔽通道攻击" class="headerlink" title="2.2.2 微架构侧信道和隐蔽通道攻击"></a>2.2.2 微架构侧信道和隐蔽通道攻击</h3><p>微架构侧信道攻击利用处理器微架构的意外行为来提取敏感信息。它们以缓存行为、分支预测或推测执行等组件为目标。这些攻击最初在 CPU 上进行演示，利用各种优化结构，例如缓存 <sup id="fnref:49" class="footnote-ref"><a href="#fn:49" rel="footnote"><span class="hint--top hint--rounded" aria-label="Daniel Gruss, Clémentine Maurice, Klaus Wagner, and Stefan Mangard. 2016. Flush+ Flush: a fast and stealthy cache attack. In Detection of Intrusions and Malware, and Vulnerability Assessment: 13th International Conference, DIMVA 2016, Spain, July 7-8, 2016. Springer, 279–299.">[49]</span></a></sup> <sup id="fnref:50" class="footnote-ref"><a href="#fn:50" rel="footnote"><span class="hint--top hint--rounded" aria-label="Daniel Gruss, Raphael Spreitzer, and Stefan Mangard. 2015. Cache template attacks: Automating attacks on inclusive Last-Level caches. In 24th USENIX Security Symposium (USENIX Security 15). 897–912.">[50]</span></a></sup> <sup id="fnref:102" class="footnote-ref"><a href="#fn:102" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B Lee. 2015. Last-level cache side-channel attacks are practical. In 2015 IEEE symposium on security and privacy. IEEE, 605–622.">[102]</span></a></sup> <sup id="fnref:127" class="footnote-ref"><a href="#fn:127" rel="footnote"><span class="hint--top hint--rounded" aria-label="Dag Arne Osvik, Adi Shamir, and Eran Tromer. 2006. Cache attacks and countermeasures: the case of AES. In Topics in Cryptology–CT-RSA 2006: The Cryptographers’ Track at the RSA Conference 2006, San Jose, CA, USA, February 13-17, 2005. Proceedings. Springer, 1–20.">[127]</span></a></sup> 和分支预测器 <sup id="fnref:37" class="footnote-ref"><a href="#fn:37" rel="footnote"><span class="hint--top hint--rounded" aria-label="Dmitry Evtyushkin, Dmitry Ponomarev, and Nael Abu-Ghazaleh. 2016. Jump over ASLR: Attacking branch predictors to bypass ASLR. In 2016 49th Annual IEEE/ACM International Symposium on Microarchitecture (MICRO). IEEE, 1–13.">[37]</span></a></sup> <sup id="fnref:38" class="footnote-ref"><a href="#fn:38" rel="footnote"><span class="hint--top hint--rounded" aria-label="Dmitry Evtyushkin, Dmitry Ponomarev, and Nael Abu-Ghazaleh. 2016. Understanding and mitigating covert channels through branch predictors. ACM Transactions on Architecture and Code Optimization (TACO) 13, 1 (2016), 1–23.">[38]</span></a></sup>。最近，CPU 上出现了一种新的微架构攻击，称为瞬时执行攻击 <sup id="fnref:176" class="footnote-ref"><a href="#fn:176" rel="footnote"><span class="hint--top hint--rounded" aria-label="Wenjie Xiong and Jakub Szefer. 2021. Survey of transient execution attacks and their mitigations. ACM Computing Surveys (CSUR) 54, 3 (2021), 1–36.">[176]</span></a></sup>。示例包括 Meltdown <sup id="fnref:99" class="footnote-ref"><a href="#fn:99" rel="footnote"><span class="hint--top hint--rounded" aria-label="Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas, Jann Horn, Stefan Mangard, Paul Kocher, Daniel Genkin, Yuval Yarom, et al. 2020. Meltdown: Reading kernel memory from user space. Commun. ACM 63, 6 (2020), 46–56.">[99]</span></a></sup>、Spectre <sup id="fnref:81" class="footnote-ref"><a href="#fn:81" rel="footnote"><span class="hint--top hint--rounded" aria-label="Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, et al. 2020. Spectre attacks: Exploiting speculative execution. Commun. ACM 63, 7 (2020), 93–101.">[81]</span></a></sup> 和微架构数据采样 (MDS) <sup id="fnref:132" class="footnote-ref"><a href="#fn:132" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hany Ragab, Alyssa Milburn, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. 2021. Crosstalk: Speculative data leaks across cores are real. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 1852–1867.">[132]</span></a></sup> <sup id="fnref:161" class="footnote-ref"><a href="#fn:161" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stephan Van Schaik, Alyssa Milburn, Sebastian Österlund, Pietro Frigo, Giorgi Maisuradze, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. 2019. RIDL: Rogue in-flight data load. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 88–105.">[161]</span></a></sup>，它们依赖于现代 CPU 中的无序和瞬时（推测）执行。与物理侧信道攻击不同，微架构攻击需要了解特定的微架构及其固有漏洞。</p><p>微架构隐蔽通道攻击是侧信道攻击的一种子类型。隐蔽通道涉及两个进程通过非预期通道建立未经授权的通信路径以泄露信息，这使得它们与云计算环境相关 <sup id="fnref:116" class="footnote-ref"><a href="#fn:116" rel="footnote"><span class="hint--top hint--rounded" aria-label="David N Muchene, Klevis Luli, and Craig A Shue. 2013. Reporting insider threats via covert channels. In 2013 IEEE Security and Privacy Workshops. IEEE, 68–71.">[116]</span></a></sup> <sup id="fnref:188" class="footnote-ref"><a href="#fn:188" rel="footnote"><span class="hint--top hint--rounded" aria-label="Wu Zhenyu, Xu Zhang, and H Wang. 2012. Whispers in the hyper-space: high-speed covert channel attacks in the cloud. In USENIX Security symposium. 159–173.">[188]</span></a></sup>。由于隔离和共享资源使用不完善，恶意进程可以利用此类资源与受害进程建立通信通道。隐蔽通道通常涉及发送者（称为“木马”）和接收者（通常称为“间谍”）。通过隐蔽通道，木马可以传输敏感信息或向间谍泄露数据 <sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jaeguk Ahn, Jiho Kim, Hans Kasan, Leila Delshadtehrani, Wonjun Song, Ajay Joshi, and John Kim. 2021. Network-on-chip microarchitecture-based covert channel in gpus. In MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture. 565–577.">[3]</span></a></sup>。</p><h3 id="2-2-3-物理侧信道攻击"><a href="#2-2-3-物理侧信道攻击" class="headerlink" title="2.2.3 物理侧信道攻击"></a>2.2.3 物理侧信道攻击</h3><p>这些被动攻击利用计算设备的物理特性，例如功耗、电磁 (EM) 或时间信息，来深入了解设备的运行情况。</p><p>示例包括差分功率分析 (DPA) 等攻击，它利用功耗波动来提取加密密钥或其他敏感数据。与微架构攻击不同，物理侧信道攻击并不总是需要了解设备的内部架构或漏洞。相反，他们利用物理信号和行为无意中泄露信息。</p><h3 id="2-2-4-故障注入攻击"><a href="#2-2-4-故障注入攻击" class="headerlink" title="2.2.4 故障注入攻击"></a>2.2.4 故障注入攻击</h3><p>故障注入攻击涉及主动将故障或错误引入系统以改变其行为或提取敏感信息。这些攻击通常可分为非侵入式、半侵入式和侵入式 <sup id="fnref:148" class="footnote-ref"><a href="#fn:148" rel="footnote"><span class="hint--top hint--rounded" aria-label="Amit Mazumder Shuvo, Tao Zhang, Farimah Farahmandi, and Mark Tehranipoor. 2023. A Comprehensive Survey on Non-Invasive Fault Injection Attacks. Cryptology ePrint Archive (2023).">[148]</span></a></sup>。非侵入式攻击允许攻击者使用时钟和电压故障、过热、电磁故障、软件故障和远程硬件故障等方法，进行物理或非物理访问。</p><p>半侵入式攻击需要对目标芯片进行（部分）解封装，以使用激光和光学故障注入等技术，而侵入式攻击则涉及更直接的方法，例如微探测和 IC 修改，这两种方法都需要深度物理访问。在这项工作中，我们主要关注非侵入式故障注入攻击。</p><h2 id="2-3-TEE"><a href="#2-3-TEE" class="headerlink" title="2.3 TEE"></a>2.3 TEE</h2><p>大多数现有的 GPU TEE 都依赖于 CPU TEE 来保护 CPU 主机上的 GPU 驱动程序，因为这些驱动程序可能会被攻击者破坏。本节介绍 CPU TEE，包括基于进程的 TEE，例如 Intel SGX 和 Arm TrustZone，它们在进程级别提供隔离，以及基于虚拟化的 TEE，例如 AMD SEV、Arm 机密计算架构 (CCA) 和 Intel 信任域扩展 (TDX)，它们在 VM 级别提供隔离。</p><h3 id="2-3-1-Intel-SGX-概述"><a href="#2-3-1-Intel-SGX-概述" class="headerlink" title="2.3.1 Intel SGX 概述"></a>2.3.1 Intel SGX 概述</h3><p>SGX 为敏感工作负载提供了一个安全且隔离的环境（称为 enclave），而无需依赖不受信任的主机操作系统 (OS) 的安全性。SGX 确保执行代码的真实性，维护运行时状态（例如 CPU 寄存器、内存和敏感 I&#x2F;O）的完整性，并通过密封过程保护存储在持久内存中的 enclave 代码、数据和运行时状态的机密性 <sup id="fnref:28" class="footnote-ref"><a href="#fn:28" rel="footnote"><span class="hint--top hint--rounded" aria-label="Victor Costan and Srinivas Devadas. 2016. Intel SGX explained. Cryptology ePrint Archive (2016).">[28]</span></a></sup>。</p><p><strong>Intel SGX 的威胁模型。</strong>攻击者可以控制底层计算平台的整个软件堆栈，包括虚拟机管理程序、BIOS 和操作系统。具体而言，在这种情况下，攻击者可以 (1) 在特权级别执行任意指令；(2) 根据需要启动、暂停和销毁 enclave 实例；(3) 控制非 enclave 环境中的软件堆栈，包括内存映射、I&#x2F;O 设备和 CPU 调度等任务 <sup id="fnref:91" class="footnote-ref"><a href="#fn:91" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li, Yuheng Yang, Guoxing Chen, Mengjia Yan, and Yinqian Zhang. 2024. SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments. (2024).">[91]</span></a></sup>。</p><p><strong>Intel SGX 的 TCB。</strong>SGX 的 TCB 是指系统中所有被视为可信并参与提供安全环境的硬件、固件和软件组件。任何 TCB 组件中的漏洞都会危及 SGX 的安全性。TCB 大小是评估 TEE 设计安全性的常用指标，较小的 TCB 大小通常表示代码行或硬件元素较少，这意味着漏洞风险降低。但是，仅基于 TCB 大小来比较两个 TEE 设计的安全性是困难且不合理的 <sup id="fnref:91" class="footnote-ref"><a href="#fn:91" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li, Yuheng Yang, Guoxing Chen, Mengjia Yan, and Yinqian Zhang. 2024. SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments. (2024).">[91]</span></a></sup>。正在进行的研究工作重点是使用内存安全的编程语言（例如 Rust-SGX <sup id="fnref:164" class="footnote-ref"><a href="#fn:164" rel="footnote"><span class="hint--top hint--rounded" aria-label="Huibo Wang, Pei Wang, Yu Ding, Mingshen Sun, Yiming Jing, Ran Duan, Long Li, Yulong Zhang, Tao Wei, and Zhiqiang Lin. 2019. Towards memory safe enclave programming with rust-sgx. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 2333–2350.">[164]</span></a></sup>）构建较小的 TEE OS。</p><h3 id="2-3-2-Arm-TrustZone-概述"><a href="#2-3-2-Arm-TrustZone-概述" class="headerlink" title="2.3.2 Arm TrustZone 概述"></a>2.3.2 Arm TrustZone 概述</h3><p>自 2004 年以来，TrustZone 已集成到 Arm 处理器（Cortex-A）中 <sup id="fnref:7" class="footnote-ref"><a href="#fn:7" rel="footnote"><span class="hint--top hint--rounded" aria-label="Arm. 2004. ARM Security Technology: Building a Secure System using TrustZone Technology. https://www.arm.com/products/security-onarm/trustzone.">[7]</span></a></sup>，主要用于移动设备。与 Intel SGX 不同，TrustZone 并非天生就适合云平台，并且缺乏对远程认证的支持，这将使远程方能够验证 TEE 实例的初始状态 <sup id="fnref:91" class="footnote-ref"><a href="#fn:91" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li, Yuheng Yang, Guoxing Chen, Mengjia Yan, and Yinqian Zhang. 2024. SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments. (2024).">[91]</span></a></sup>。TrustZone 围绕称为安全世界 (SW) 和正常世界 (NW) 的保护域概念运行。</p><p>它还通过在 ARMv8 指令集架构 (ISA) 中引入异常级别 (EL) 来扩展“特权环”的概念。“安全监视器”在最高特权级别 EL3 下运行，同时监督 SW 和 NW。</p><p>不受信任的操作系统在网络 (NW) 中运行，称为富执行环境 (REE)。在软件 (SW) 中，受信任的操作系统内核在 EL1 中运行，而安全用户空间在 EL0 中运行。软件 (SW) 和网络 (NW) 之间的分离确保特定的 RAM 区域和总线外设被指定为安全的，从而将访问限制在软件 (SW) 中。</p><p><strong>Arm TrustZone 的威胁模型。</strong>目前，缺乏 TrustZone 的正式威胁模型。通常假设的攻击者能力如下：攻击者 (1) 可以完全访问设备的 REE，包括操作系统。这可能是经过身份验证的 (root) 用户、安装在设备上的恶意第三方软件或受感染的操作系统；(2) 利用对软件 (SW) 内资源的未经授权的访问并提取敏感信息 <sup id="fnref:129" class="footnote-ref"><a href="#fn:129" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sandro Pinto and Nuno Santos. 2019. Demystifying arm trustzone: A comprehensive survey. ACM computing surveys (CSUR) 51, 6 (2019), 1–36.">[129]</span></a></sup>。</p><p><strong>Arm TrustZone 的 TCB。</strong>在软件 (SW) 中，受信任的操作系统在 EL1 中运行并提供运行时支持以维持受信任应用程序 (TA) 的生命周期，确保它们在用户模式 ​​(EL0) 下安全执行。可信操作系统的核心是可信内核，它为 TA 的调度和管理提供关键的操作系统原语。安全监视器实现了在世界之间进行安全上下文切换的机制，并以 EL3 中的最高权限运行。同时，TEE 引导加载程序将 TEE 系统启动到安全状态 <sup id="fnref:19" class="footnote-ref"><a href="#fn:19" rel="footnote"><span class="hint--top hint--rounded" aria-label="David Cerdeira, Nuno Santos, Pedro Fonseca, and Sandro Pinto. 2020. Sok: Understanding the prevailing security vulnerabilities in trustzone-assisted tee systems. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1416–1432.">[19]</span></a></sup>。简而言之，可信操作系统、安全监视器和 TEE 引导加载程序构成了 TrustZone 辅助 TEE 的 TCB。</p><h3 id="2-3-3-基于虚拟化的-TEE"><a href="#2-3-3-基于虚拟化的-TEE" class="headerlink" title="2.3.3 基于虚拟化的 TEE"></a>2.3.3 基于虚拟化的 TEE</h3><p>基于进程的 TEE（例如 Intel SGX）需要将应用程序划分为可信部分、安全区和不可信部分，这可能会使开发工作复杂化，因为开发人员必须遵守此安全模型并相应地细分其应用程序。作为回应，供应商现在迭代了他们以前的可信计算 CPU 扩展，以促进跨各种服务器平台的基于虚拟化的机密计算，从而无需对应用程序代码进行大量修改。这里我们概述了三种基于虚拟化的机密计算解决方案：Intel TDX <sup id="fnref:63" class="footnote-ref"><a href="#fn:63" rel="footnote"><span class="hint--top hint--rounded" aria-label="Intel. 2023. Intel Trust Domain Extensions (Intel TDX). https://www.intel.com/content/www/us/en/developer/tools/trust-domain-extensions/overview.html.">[63]</span></a></sup>、AMD SEV <sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="AMD. 2023. AMD Secure Encrypted Virtualization (SEV). https://www.amd.com/en/developer/sev.html.">[6]</span></a></sup> 和 Arm CCA <sup id="fnref:8" class="footnote-ref"><a href="#fn:8" rel="footnote"><span class="hint--top hint--rounded" aria-label="Arm. 2023. Arm Confidential Compute Architecture. https://www.arm.com/architecture/security-features/arm-confidential-compute-architecture.">[8]</span></a></sup>。</p><p><strong>AMD SEV。</strong>AMD 推出了具有 Zen 架构的 SEV，以实现云环境中的机密计算。最近的 AMD SEV-Secure Nested Paging (SNP) <sup id="fnref:142" class="footnote-ref"><a href="#fn:142" rel="footnote"><span class="hint--top hint--rounded" aria-label="AMD Sev-Snp. 2020. Strengthening VM isolation with integrity protection and more. White Paper, January 53 (2020), 1450–1465.">[142]</span></a></sup> 通过引入安全嵌套分页等功能来增强加密内存的完整性，从而扩展了 AMD SEV 的功能。</p><p><strong>Arm CCA。</strong>Arm CCA 是 Armv9 中引入的一项高级隔离技术。它保留了 TrustZone 的 NW 和 SW，同时引入了一个专为运行多个机密“领域”而设计的新领域。这些领域虽然与其他领域隔离，但由不受信任的软件组件（例如虚拟机管理程序）管理。轻量级领域管理监视器 (RMM) <sup id="fnref:9" class="footnote-ref"><a href="#fn:9" rel="footnote"><span class="hint--top hint--rounded" aria-label="Arm. 2023. Arm Realm Management Extension (RME) System Architecture. https://developer.arm.com/documentation/den0129/latest/.">[9]</span></a></sup> 在领域世界的虚拟机管理程序层内运行，可确保领域之间的内存隔离。CCA 包含一个根世界，以容纳存储在固件中的最高权限监视器代码 <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup>。</p><p><strong>Intel TDX。</strong> Intel TDX 利用 Intel 的多密钥全内存加密 (MKTME) <sup id="fnref:62" class="footnote-ref"><a href="#fn:62" rel="footnote"><span class="hint--top hint--rounded" aria-label="Intel. 2023. Intel Multi-Key Total Memory Encryption. https://www.intel.com/content/dam/www/central-libraries/us/en/documents/2022-10/inteltotal-memory-encryption-multi-key-whitepaper.pdf.">[62]</span></a></sup> 和经过 CPU 认证的软件模块来促进安全虚拟机的隔离执行。TDX 模块经过数字签名，并在一种名为 SEAM 的新型处理器模式下执行，可充当分离内核。它为虚拟机管理程序提供了一个接口，用于调度、创建和管理安全虚拟机（称为可信域）。有关 AMD SEV、Arm CCA 和 Intel TDX 的深入比较，我们参考了 <sup id="fnref:52" class="footnote-ref"><a href="#fn:52" rel="footnote"><span class="hint--top hint--rounded" aria-label="Roberto Guanciale, Nicolae Paladi, and Arash Vahidi. 2022. SoK: Confidential quartet-Comparison of platforms for virtualization-based confidential computing. In 2022 IEEE International Symposium on Secure and Private Execution Environment Design (SEED). IEEE, 109–120.">[52]</span></a></sup> 中的调查。</p><h1 id="3-概述和分类"><a href="#3-概述和分类" class="headerlink" title="3. 概述和分类"></a>3. 概述和分类</h1><p>GPU 上的机密计算是一个新兴领域，它确保在 GPU 上处理的敏感数据免受未经授权的访问和篡改，即使是具有特权访问权限的攻击者也是如此。其他隐私保护技术，如安全多方计算、同态加密和 TEE，提供了不同的安全保障。然而，在这项工作中，我们的主要重点是将 TEE 扩展到 GPU（即 GPU TEE）。从同构系统转向这种异构系统不可避免地会带来新的威胁和安全漏洞。了解这些新的攻击媒介对于设计能够有效缓解这些攻击的系统至关重要。与现有的 CPU TEE 相比，GPU TEE 从几个方面为攻击者提供了独特的机会：</p><p><img src="/img/cc/gpu/4.png" alt="图3. 异构 CPU-GPU 系统上的机密计算分类"></p><p><strong>CPU 上的 GPU 软件堆栈：</strong>GPU 驱动程序处理资源分配、任务调度和动态电源管理等关键方面。具体而言，在资源分配方面，GPU 驱动程序管理和分配资源，包括内存、处理单元和其他硬件组件。对于任务调度，它们有效地调度和管理任务以确保最佳性能，在 GPU 核心之间平衡工作负载。在动态电源管理中，驱动程序根据工作负载调整电压等参数，优化性能和效率以延长移动设备的电池寿命并降低数据中心的能源成本。在当前的 GPU TEE 中，GPU 驱动程序的保护，特别是它们在 CPU 主机中的位置，可能会引入新的攻击面。此外，一些针对 CPU TEE 的先进攻击也可能影响 GPU 驱动程序。</p><p><strong>GPU 上的硬件组件：</strong>GPU TEE 仍处于开发的早期阶段。大多数设计都是实验性研究，通常缺乏广泛的硬件修改，导致对 GPU 内存、外围组件互连 Express (PCIe) 总线和电源管理组件等组件的硬件保护不足。</p><p>即使是 GPU 制造商设计的产品（例如 NVIDIA H100 GPU）也可能缺乏对某些硬件组件（例如电源管理组件）的保护。因此，针对这些组件的现有攻击也可能转化为 GPU TEE 中的弱点。</p><p><strong>架构复杂性：</strong>尽管 GPU 的安全性才刚刚开始被探索，但已经记录了一些漏洞和攻击。由于 GPU 的架构复杂性，例如不同并发内核之间的内存共享以及 GPU 类型的多样性（例如集成和离散），一些现有的 GPU TEE 可能无法提供足够的保护。此外，许多设计忽略了缓存级访问保护，使其容易受到基于缓存的 GPU 攻击。</p><p>在图 3 中，我们根据相关工作总结了本次调查的基础分类法。在本文的其余部分，我们首先在第 4 节中回顾和讨论现有的 GPU TEE，涵盖它们的威胁模型、硬件修改、TCB 大小和性能开销。在第 5 节中，我们根据第 2 节中列出的攻击类型概述了针对 GPU 的现有攻击。我们还在第 6 节中回顾了针对现有 CPU TEE（例如 Intel SGX、Arm TrustZone 和 AMD SEV）的最新攻击。最后，基于这些 GPU TEE 设计和总结的攻击，我们在第 7 节中讨论了针对现有（和未来）GPU TEE 的潜在攻击。</p><h1 id="4-GPU-上的机密计算"><a href="#4-GPU-上的机密计算" class="headerlink" title="4. GPU 上的机密计算"></a>4. GPU 上的机密计算</h1><p>我们在表 2 中总结了基于 Intel、AMD 和 ARM 的最先进的 GPU TEE 设计。接下来，我们首先回顾所有现有方案，然后从威胁模型、硬件修改、TCB 大小和在加速器上实现可信执行所产生的性能开销等方面对它们进行讨论。</p><p><img src="/img/cc/gpu/5.png" alt="表2. 内存表示加速器是否与 CPU 共享内存。硬件修改说明是否需要对硬件进行修改（● = 是，o = 否）。Secure RM 和 GPU ME 是安全资源管理和 GPU 内存加密。† 表示该方案需要额外的支持（例如，NVIDIA H100 GPU 或下一代 Arm 设备中提供的硬件安全功能），因为他们目前没有考虑这些功能。"></p><h2 id="4-1-GPU-上的可信执行环境"><a href="#4-1-GPU-上的可信执行环境" class="headerlink" title="4.1 GPU 上的可信执行环境"></a>4.1 GPU 上的可信执行环境</h2><p>传统 CPU 和云系统已逐渐采用基于硬件的 TEE，以安全地将计算与恶意操作系统或某些硬件攻击（例如对内存总线的监听）隔离开来。然而，GPU 及其云部署在很大程度上尚未纳入对基于硬件的可信计算的支持。随着大量敏感数据被卸载到 GPU 以在云环境中加速，尤其是对于敏感的 ML 工作负载，迫切需要解决无处不在的 GPU 的可信计算要求。研究人员和商业供应商最近提出了各种设计来支持 GPU 上的机密计算。</p><p><strong>基于 x86 的 GPU TEE。</strong> Graviton <sup id="fnref:162" class="footnote-ref"><a href="#fn:162" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 681–696.">[162]</span></a></sup> 发起了在 GPU 等硬件加速器上进行可信执行的工作。</p><p>Graviton 直接在 GPU 内建立 TEE，这需要硬件修改，但避免了对 SGX 等 CPU 端 TEE 的需求。 Graviton 在不受信任的主机和 GPU 之间建立安全通道，通过将所有资源分配请求引导到 GPU 的命令处理器而不是 GPU 驱动程序来监控命令提交和数据传输。 尽管如此，为了保护数据，Graviton 假设 GPU 的封装内存是可以信任的。 假设是，即使有物理访问，攻击者也很难破坏 GPU 封装的完整性并窥探 GPU 和堆叠内存之间的硅互连。</p><p>HIX <sup id="fnref:66" class="footnote-ref"><a href="#fn:66" rel="footnote"><span class="hint--top hint--rounded" aria-label="Insu Jang, Adrian Tang, Taehoon Kim, Simha Sethumadhavan, and Jaehyuk Huh. 2019. Heterogeneous isolated execution for commodity gpus. In Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 455–468.">[66]</span></a></sup> 从操作系统驻留驱动程序中删除了控制 GPU 的关键功能，并将其放置在受信任的 GPU 飞地中，扩展了 SGX 飞地并合并了新的 SGX 样式指令，如 ECREATE 和 EADD。</p><p>此外，HIX 建立了安全的硬件 I&#x2F;O 路径，防止操作系统更改 GPU 内存映射 I&#x2F;O (MMIO) 区域的虚拟到物理地址映射，并防止操作系统推断通过 MMIO 和直接内存访问 (DMA) 传输的命令和数据。与 Graviton 一样，HIX 缺乏可信的 GPU 内存区域，导致 GPU 内存中的数据以明文形式访问。</p><p>为了消除对 CPU 或 GPU 芯片进行修改的需要，HETEE <sup id="fnref:190" class="footnote-ref"><a href="#fn:190" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jianping Zhu, Rui Hou, XiaoFeng Wang, Wenhao Wang, Jiangfeng Cao, Boyan Zhao, Zhongpu Wang, Yuhui Zhang, Jiameng Ying, Lixin Zhang, et al. 2020. Enabling rack-scale confidential computing using heterogeneous trusted execution environment. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1450–1465.">[190]</span></a></sup> 引入了数据中心级 GPU TEE，旨在支持广泛的机密计算，而无需进行任何芯片级更改。它有助于在机架内的所有服务器上动态分配安全和非​​敏感计算任务的计算资源。它们包含一个小型 TCB，例如具有支持任务隔离的定制代码的单个安全控制器，从而降低了设计复杂性并最大限度地减少了与不受信任的操作系统共享资源相关的攻击面。</p><p>与 HIX 类似，Honeycomb <sup id="fnref:106" class="footnote-ref"><a href="#fn:106" rel="footnote"><span class="hint--top hint--rounded" aria-label="Haohui Mai, Jiacheng Zhao, Hongren Zheng, Yiyang Zhao, Zibin Liu, Mingyu Gao, Cong Wang, Huimin Cui, Xiaobing Feng, and Christos Kozyrakis. 2023. Honeycomb: Secure and Efficient GPU Executions via Static Validation. In 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23). 155–172.">[106]</span></a></sup> 通过使用 CPU 端 TEE（例如 AMD SEV-SNP）将敏感数据传输到 GPU 并管理对 GPU MMIO 的访问，确保用户和 GPU 之间的安全通信。与以前的设计不同，Honeycomb 采用静态分析来确认相互不信任的 GPU 应用程序包含在其飞地中。这种方法通过将运行时检查移至加载时间来实现更高效的实现。此外，Honeycomb 通过排除用户空间和内核空间 GPU 驱动程序来减少 TCB，而是使用两个安全监视器来拦截和控制应用程序与 GPU 之间的所有流量。Honeycomb 在信任 GPU 的设备内存方面做出了与 Graviton 相同的假设，因为现代 GPU 通常使用同一封装内的 2.5D&#x2F;3D 硅中介层集成设备内存。</p><p>SAGE <sup id="fnref:65" class="footnote-ref"><a href="#fn:65" rel="footnote"><span class="hint--top hint--rounded" aria-label="Andrei Ivanov, Benjamin Rothenberger, Arnaud Dethise, Marco Canini, Torsten Hoefler, and Adrian Perrig. 2023. SAGE: Software-based Attestation for GPU Execution. In 2023 USENIX Annual Technical Conference (USENIX ATC 23). 485–499.">[65]</span></a></sup> 为可信 GPU 执行提供了一种基于软件的替代方案。它使用在主机上运行的 SGX 飞地作为本地验证器，并使用此飞地引导在 GPU 上建立动态信任根的软件原语。它确保不受信任设备上的用户内核保持不被修改，在不受信任的 GPU 上被调用执行，并且运行时不会被篡改。它补充了现有的基于硬件的 GPU TEE。</p><p>鉴于以前的设计忽略了内存安全性（即不加密 GPU 内存），LITE <sup id="fnref:180" class="footnote-ref"><a href="#fn:180" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ardhi Wiratama Baskara Yudha, Jake Meyer, Shougang Yuan, Huiyang Zhou, and Yan Solihin. 2022. LITE: a low-cost practical inter-operable GPU TEE. In Proceedings of the 36th ACM International Conference on Supercomputing. 1–13.">[180]</span></a></sup> 引入了与 CPU 共同设计的 GPU TEE 来建立统一的加密域，其中数据以密文形式存储在 GPU 缓存和内存中。具体而言，LITE 确保数据以加密形式进入 GPU 芯片。然后，软件使用算术逻辑单元 (ALU) 对数据进行解密，对寄存器中的数据进行操作。此外，数据可以暂时以明文形式存储在片上共享内存中。</p><p>TNPU <sup id="fnref:86" class="footnote-ref"><a href="#fn:86" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sunho Lee, Jungwoo Kim, Seonjin Na, Jongse Park, and Jaehyuk Huh. 2022. Tnpu: Supporting trusted execution with tree-less integrity protection for neural processing unit. In 2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 229–243.">[86]</span></a></sup> 为深度神经网络 (DNN) 加速器提出了无树的片外内存保护。核心思想是将连续的内存块分组为图块，并在图块级别提供新鲜度保证。TNPU 使用在主机 CPU 上运行的专用软件模块来管理版本号，这些版本号存储在主机 CPU 安全内存中的“张量表”中。张量表受完整性树保护。</p><p>NVIDIA 的 H100 Tensor Core GPU <sup id="fnref:124" class="footnote-ref"><a href="#fn:124" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA confidential computing. https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/.">[124]</span></a></sup> 基于 Hopper 架构，引入了用于机密计算的高级功能。要使用 H100 实现机密计算，需要特定的 CPU TEE，例如 Intel TDX、AMD SEV-SNP 和 Arm CCA。除了确保数据和代码的机密性和完整性之外，H100 还可以防御针对 PCIe 总线和双倍数据速率 RAM (DDR) 的基本物理攻击。H100 支持三种不同的操作模式，即 CC-Off、CC-On 和 CC-DevTools。在 CC-On 模式下，H100 以及 CPU 上的驱动程序完全激活所有可用的机密计算功能。在 CC-On 模式下，某些硬件资源（例如性能计数器）被禁用，以防止潜在的侧信道攻击，因为性能计数器可用于推断设备使用行为 <sup id="fnref:120" class="footnote-ref"><a href="#fn:120" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hoda Naghibijouybari, Ajaya Neupane, Zhiyun Qian, and Nael Abu-Ghazaleh. 2018. Rendered insecure: Gpu side channel attacks are practical. In Proceedings of the 2018 ACM SIGSAC conference on computer and communications security. 2139–2153.">[120]</span></a></sup>。但是，目前尚不清楚有关具体硬件更改（例如 H100 中的内存加密）的细节。</p><p><strong>基于 Arm 的 GPU TEE。</strong>由于存在许多架构差异，以前基于 Intel&#x2F;AMD 平台的设计无法轻易扩展到 Arm GPU。因此，StrongBox <sup id="fnref:31" class="footnote-ref"><a href="#fn:31" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.">[31]</span></a></sup> 引入了第一个 GPU TEE，用于在 Arm 端点上进行安全的通用计算，而无需进行硬件修改或架构更改。它在安全监视器内部署 StrongBox 运行时，以确保 GPU 独立执行。通过结合第 2 阶段转换和 TrustZone 地址空间控制器 (TZASC)，StrongBox 指定了六种不同的访问权限类型，以有效管理来自 DMA、GPU 和其他外围设备的安全访问。</p><p>CRONUS <sup id="fnref:71" class="footnote-ref"><a href="#fn:71" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jianyu Jiang, Ji Qi, Tianxiang Shen, Xusheng Chen, Shixiong Zhao, Sen Wang, Li Chen, Gong Zhang, Xiapu Luo, and Heming Cui. 2022. CRONUS: Fault-isolated, secure and high-performance heterogeneous computing for trusted execution environment. In 2022 55th IEEE/ACM International Symposium on Microarchitecture (MICRO). IEEE, 124–143.">[71]</span></a></sup> 引入了一种支持各种异构加速器的设计，可在单个加速器内实现空间共享，并确保跨多个加速器的强大隔离。利用 Arm 安全虚拟化技术，CRONUS 将异构计算划分为独立的 TEE 区域。每个区域都封装了一种特定类型的计算，例如 GPU 计算，并允许多个区域在空间上共享单个加速器。</p><p>为了支持下一代 Arm 设备上的机密 GPU 计算，CAGE <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> 提出了一种 Arm CCA 领域式架构的新方案。它将资源密集型但与数据无关的任务卸载到 NW，同时通过影子任务机制保护领域内的敏感数据。通过配置粒度保护检查 (GPC)，CAGE 限制了不受信任组件的访问。此外，它通过在 GPU GPC 中为每个领域提供不同的 GPU 内存视图来隔离 GPU 计算中的领域。CAGE 保持了高硬件兼容性，因为它不需要额外的硬件或对现有 CPU 和 GPU 配置进行修改。</p><h2 id="4-2-讨论"><a href="#4-2-讨论" class="headerlink" title="4.2 讨论"></a>4.2 讨论</h2><p>在本节中，我们讨论了设计有效且安全的 GPU TEE 的几个关键指标。</p><p><strong>威胁模型。</strong>基本上所有 GPU TEE 设计都采用与 CPU TEE 类似的威胁模型，旨在为 GPU 创建安全的执行环境。具体来说，他们考虑一个能够控制整个软件堆栈的对手，包括设备驱动程序、客户操作系统和虚拟机管理程序。此外，假设对手对硬件的物理访问有限，从而允许被动物理攻击，例如窥探 PCIe 流量。 </p><p>这意味着这样的对手可能会泄露或篡改 GPU 应用程序的敏感数据和执行结果。他们还可以访问或篡改 DMA 缓冲区中的用户数据或受害应用程序提交给 GPU 的命令。</p><p>关于 GPU 内存保护，许多设计都假设攻击者无法访问 GPU 内存中的机密，或者明确指出针对内存的物理攻击超出了他们的范围。例如，Graviton <sup id="fnref:162" class="footnote-ref"><a href="#fn:162" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 681–696.">[162]</span></a></sup> 和 Honeycomb <sup id="fnref:106" class="footnote-ref"><a href="#fn:106" rel="footnote"><span class="hint--top hint--rounded" aria-label="Haohui Mai, Jiacheng Zhao, Hongren Zheng, Yiyang Zhao, Zibin Liu, Mingyu Gao, Cong Wang, Huimin Cui, Xiaobing Feng, and Christos Kozyrakis. 2023. Honeycomb: Secure and Efficient GPU Executions via Static Validation. In 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23). 155–172.">[106]</span></a></sup> 信任 GPU 的设备内存，因为现代 GPU 通常在同一封装内使用 2.5D&#x2F;3D 硅中介层集成设备内存。这些设计主要侧重于通过更细粒度的访问控制防止攻击者访问存储在 GPU 内存中的敏感数据。为了填补这一空白，LITE <sup id="fnref:180" class="footnote-ref"><a href="#fn:180" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ardhi Wiratama Baskara Yudha, Jake Meyer, Shougang Yuan, Huiyang Zhou, and Yan Solihin. 2022. LITE: a low-cost practical inter-operable GPU TEE. In Proceedings of the 36th ACM International Conference on Supercomputing. 1–13.">[180]</span></a></sup> 设计了一个基于软件的统一加密域来保护存储在 GPU 内存中的敏感数据，包括 L1&#x2F;L2 缓存和设备内存。此外，NVIDIA H100 <sup id="fnref:124" class="footnote-ref"><a href="#fn:124" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA confidential computing. https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/.">[124]</span></a></sup> 和 TNPU <sup id="fnref:86" class="footnote-ref"><a href="#fn:86" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sunho Lee, Jungwoo Kim, Seonjin Na, Jongse Park, and Jaehyuk Huh. 2022. Tnpu: Supporting trusted execution with tree-less integrity protection for neural processing unit. In 2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 229–243.">[86]</span></a></sup> 支持基于硬件的内存加密，而 CAGE <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> 要求未来的 CCA 设备内置硬件辅助内存加密支持。</p><ul><li><p><strong>硬件变化。</strong>早期的 Graviton <sup id="fnref:162" class="footnote-ref"><a href="#fn:162" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 681–696.">[162]</span></a></sup> 和 HIX <sup id="fnref:66" class="footnote-ref"><a href="#fn:66" rel="footnote"><span class="hint--top hint--rounded" aria-label="Insu Jang, Adrian Tang, Taehoon Kim, Simha Sethumadhavan, and Jaehyuk Huh. 2019. Heterogeneous isolated execution for commodity gpus. In Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 455–468.">[66]</span></a></sup> 等工作需要对外围组件进行重大修改，例如 GPU 的命令处理器、引入新的 SGX 指令、特定的内存管理单元 (MMU) 页表遍历器和其他硬件更改。GPU TEE 设计修改硬件组件的程度决定了其实际兼容性，即其对各种 GPU 的适用性。许多设计需要进行硬件更改，而这些更改需要很长时间才能部署到生产环境中。因此，LITE <sup id="fnref:180" class="footnote-ref"><a href="#fn:180" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ardhi Wiratama Baskara Yudha, Jake Meyer, Shougang Yuan, Huiyang Zhou, and Yan Solihin. 2022. LITE: a low-cost practical inter-operable GPU TEE. In Proceedings of the 36th ACM International Conference on Supercomputing. 1–13.">[180]</span></a></sup>、SAGE <sup id="fnref:65" class="footnote-ref"><a href="#fn:65" rel="footnote"><span class="hint--top hint--rounded" aria-label="Andrei Ivanov, Benjamin Rothenberger, Arnaud Dethise, Marco Canini, Torsten Hoefler, and Adrian Perrig. 2023. SAGE: Software-based Attestation for GPU Execution. In 2023 USENIX Annual Technical Conference (USENIX ATC 23). 485–499.">[65]</span></a></sup> 和 Honeycomb <sup id="fnref:106" class="footnote-ref"><a href="#fn:106" rel="footnote"><span class="hint--top hint--rounded" aria-label="Haohui Mai, Jiacheng Zhao, Hongren Zheng, Yiyang Zhao, Zibin Liu, Mingyu Gao, Cong Wang, Huimin Cui, Xiaobing Feng, and Christos Kozyrakis. 2023. Honeycomb: Secure and Efficient GPU Executions via Static Validation. In 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23). 155–172.">[106]</span></a></sup> 等工作寻求纯软件方法来实现可信的 GPU 执行。CAGE <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> 主要利用 Arm CCA 和 GPU 中的通用硬件功能，而无需额外的硬件更改或对现有 CPU 和 GPU 进行定制。</p></li><li><p><strong>TCB 大小。</strong>GPU TEE 设计中的一个关键挑战是尽可能减小 TCB 大小。大型软件堆栈会增加 TCB，这可能会引入更多漏洞，从而威胁安全性。一种有效且高效的减少 TCB 的方法是将大部分 GPU 软件堆栈放在不受信任的操作系统中，同时仅将控制 GPU 的关键功能保留在 CPU 的受信任区域（例如 SGX 飞地）中。例如，CAGE <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> 通过使用其影子任务机制而不是将重量级的 GPU 软件加载到 TEE 中，为领域实现了“精简”的 TCB。它为 CPU 端隔离引入了 2-26K 行代码，为监视器引入了 1,301 行代码，从而实现了当前基于 Arm 的 GPU TEE 中最小的 TCB 大小。</p></li><li><p><strong>性能开销。</strong>设计 GPU TEE 的最终目标是确保 GPU 执行的强隔离，同时最大限度地降低与提供安全保障相关的性能开销。比较不同方案的性能开销具有挑战性，因为需要昂贵的重新实施工作，因为每个方案都针对不同的平台并在不同的条件下实施。例如，在 HIX 中，软件组件是在支持硬件修改的模拟系统（如 KVM 和 QEMU）之上实现的。与 GPU 上的不安全基线相比，加密操作的数量、在安全和正常世界之间切换的频率以及完整性检查等几个因素在优化性能方面发挥着重要作用。例如，CAGE <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> 在六个 Rodinia 基准测试中的表现比 StrongBox <sup id="fnref:31" class="footnote-ref"><a href="#fn:31" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.">[31]</span></a></sup> 高出 1.96%–13.16%。这种性能提升归因于 CAGE 能够安全地将纯文本数据传输到缓冲区并存储结果，而无需引入额外的加密操作。可以合理地推测，由于 NVIDIA H100 GPU 支持基于硬件的加密，因此其性能负担较小。一旦 NVIDIA H100 GPU 上的机密计算整个工作流程在未来完全可用，跨不同平台进行全面的性能比较将大有裨益。</p></li></ul><h1 id="5-GPU-的安全性"><a href="#5-GPU-的安全性" class="headerlink" title="5. GPU 的安全性"></a>5. GPU 的安全性</h1><p>由于 GPU 被广泛用作加速器，近年来，它受到了来自进攻和防御两方面的审查。研究人员探索了硬件架构和软件层面的 GPU 漏洞，展示了实际攻击并提出了缓解措施。我们认为，总结和分析对 GPU 的攻击将有助于探索对 GPU TEE 的潜在攻击。虽然 Naghibijouybari 等人 <sup id="fnref:119" class="footnote-ref"><a href="#fn:119" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hoda Naghibijouybari, Esmaeil Mohammadian Koruyeh, and Nael Abu-Ghazaleh. 2022. Microarchitectural attacks in heterogeneous systems: A survey. Comput. Surveys 55, 7 (2022), 1–40.">[119]</span></a></sup> 提供了一项全面的调查，对 GPU 安全漏洞和潜在对策进行了分类，但他们的分析并未涵盖自 2022 年下半年以来出现的重大进展。此外，他们主要强调跨不同加速器的微架构攻击，而不考虑利用物理访问或测量的攻击。尽管如此，考虑物理通道对于对 GPU TEE 的潜在攻击至关重要。</p><p>在本节中，我们回顾了现有的 GPU 攻击，包括微架构侧通道&#x2F;隐蔽通道攻击、物理侧通道攻击和故障注入攻击。表 3 提供了攻击、目标 GPU、威胁模型、攻击目标和方法的摘要。</p><h2 id="5-1-架构-逻辑攻击"><a href="#5-1-架构-逻辑攻击" class="headerlink" title="5.1 架构&#x2F;逻辑攻击"></a>5.1 架构&#x2F;逻辑攻击</h2><p>越来越多的研究针对 GPU 或其在 CPU 上的软件堆栈进行攻击。方案 <sup id="fnref:87" class="footnote-ref"><a href="#fn:87" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sangho Lee, Youngsok Kim, Jangwoo Kim, and Jong Kim. 2014. Stealing webpages rendered on your browser by exploiting GPU vulnerabilities. In 2014 IEEE Symposium on Security and Privacy. IEEE, 19–33.">[87]</span></a></sup> <sup id="fnref:109" class="footnote-ref"><a href="#fn:109" rel="footnote"><span class="hint--top hint--rounded" aria-label="Clémentine Maurice, Christoph Neumann, Olivier Heen, and Aurélien Francillon. 2014. Confidentiality issues on a GPU in a virtualized environment. In Financial Cryptography and Data Security: 18th International Conference, FC 2014, Christ Church, Barbados, March 3-7, 2014, Revised Selected Papers 18. Springer, 119–135.">[109]</span></a></sup> <sup id="fnref:128" class="footnote-ref"><a href="#fn:128" rel="footnote"><span class="hint--top hint--rounded" aria-label="Roberto Di Pietro, Flavio Lombardi, and Antonio Villani. 2016. CUDA leaks: a detailed hack for CUDA and a (partial) fix. ACM Transactions on Embedded Computing Systems (TECS) 15, 1 (2016), 1–25.">[128]</span></a></sup> <sup id="fnref:189" class="footnote-ref"><a href="#fn:189" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhe Zhou, Wenrui Diao, Xiangyu Liu, Zhou Li, Kehuan Zhang, and Rui Liu. 2016. Vulnerable gpu memory management: towards recovering raw data from gpu. arXiv preprint arXiv:1605.06610 (2016).">[189]</span></a></sup> 侧重于由于最近终止的进程剩余内存而导致的信息泄露。Lee 等人 <sup id="fnref:87" class="footnote-ref"><a href="#fn:87" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sangho Lee, Youngsok Kim, Jangwoo Kim, and Jong Kim. 2014. Stealing webpages rendered on your browser by exploiting GPU vulnerabilities. In 2014 IEEE Symposium on Security and Privacy. IEEE, 19–33.">[87]</span></a></sup> 利用 GPU 未初始化新分配的内存页面而产生的漏洞，从而在执行期间和终止后立即泄露受害者存储在 GPU 内存中的数据。在实践中，他们在分析 Chromium 和 Firefox 的剩余纹理时推断出受害者用户访问的网页。Maurice 等人 <sup id="fnref:109" class="footnote-ref"><a href="#fn:109" rel="footnote"><span class="hint--top hint--rounded" aria-label="Clémentine Maurice, Christoph Neumann, Olivier Heen, and Aurélien Francillon. 2014. Confidentiality issues on a GPU in a virtualized environment. In Financial Cryptography and Data Security: 18th International Conference, FC 2014, Christ Church, Barbados, March 3-7, 2014, Revised Selected Papers 18. Springer, 119–135.">[109]</span></a></sup> 通过观察 GPU 全局内存并不总是归零来恢复先前执行的 GPU 应用程序中的数据。Pietro 等人 <sup id="fnref:128" class="footnote-ref"><a href="#fn:128" rel="footnote"><span class="hint--top hint--rounded" aria-label="Roberto Di Pietro, Flavio Lombardi, and Antonio Villani. 2016. CUDA leaks: a detailed hack for CUDA and a (partial) fix. ACM Transactions on Embedded Computing Systems (TECS) 15, 1 (2016), 1–25.">[128]</span></a></sup> 利用交叉访问和不充分的数据处理来读取另一个进程存储在共享或全局内存中的信息。Zhou 等人 <sup id="fnref:189" class="footnote-ref"><a href="#fn:189" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhe Zhou, Wenrui Diao, Xiangyu Liu, Zhou Li, Kehuan Zhang, and Rui Liu. 2016. Vulnerable gpu memory management: towards recovering raw data from gpu. arXiv preprint arXiv:1605.06610 (2016).">[189]</span></a></sup> 演示了恶意程序如何利用 GPU 内存管理策略来突破内存隔离边界并从其他进程恢复图像。 HE 等人 <sup id="fnref:55" class="footnote-ref"><a href="#fn:55" rel="footnote"><span class="hint--top hint--rounded" aria-label="Wenjian HE, Wei Zhang, Sharad Sinha, and Sanjeev Das. 2020. Igpu leak: An information leakage vulnerability on intel integrated gpu. In 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). IEEE, 56–61.">[55]</span></a></sup> 发现，英特尔集成 GPU 中存在一个漏洞，该漏洞是由上下文管理缺陷引起的，上下文切换期间不会清除残留寄存器值和共享内存。此类漏洞通常可以通过在将内存重新分配给另一个应用程序之前清除内存（即内存清零）来修复。</p><h2 id="5-2-微架构侧通道-隐蔽通道攻击"><a href="#5-2-微架构侧通道-隐蔽通道攻击" class="headerlink" title="5.2 微架构侧通道&#x2F;隐蔽通道攻击"></a>5.2 微架构侧通道&#x2F;隐蔽通道攻击</h2><p>在本小节中，我们回顾了现有的针对 GPU 的攻击，包括微架构侧通道和隐蔽通道攻击。</p><h3 id="5-2-1-针对集成-GPU-的攻击"><a href="#5-2-1-针对集成-GPU-的攻击" class="headerlink" title="5.2.1 针对集成 GPU 的攻击"></a>5.2.1 针对集成 GPU 的攻击</h3><p>针对集成 GPU 的攻击因其安全风险而受到关注。集成通过利用共享资源开辟了新的攻击机会，从而导致跨组件微架构攻击。这些攻击的一个关键要求是共置，攻击者运行的代码足够接近受害者以进行交互 <sup id="fnref:119" class="footnote-ref"><a href="#fn:119" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hoda Naghibijouybari, Esmaeil Mohammadian Koruyeh, and Nael Abu-Ghazaleh. 2022. Microarchitectural attacks in heterogeneous systems: A survey. Comput. Surveys 55, 7 (2022), 1–40.">[119]</span></a></sup>。这种交互可能涉及诱导故障或争用以测量侧通道泄漏。因此，与 CPU 共享同一芯片的集成 GPU 提供了更多的攻击机会。</p><p>Dutta 等人 <sup id="fnref:34" class="footnote-ref"><a href="#fn:34" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sankha Baran Dutta, Hoda Naghibijouybari, Nael Abu-Ghazaleh, Andres Marquez, and Kevin Barker. 2021. Leaky buddies: Cross-component covert channels on integrated cpu-gpu systems. In ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA). IEEE, 972–984.">[34]</span></a></sup> 开发了两个隐蔽通道，使位于不同组件（CPU 和 iGPU）上的两个恶意应用程序能够通过共享硬件资源交换机密数据。一个通道利用英特尔集成 GPU 内共享的最后一级缓存 (LLC)，而另一个通道则依赖于环形总线的争用。Wang 等人 <sup id="fnref:168" class="footnote-ref"><a href="#fn:168" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yingchen Wang, Riccardo Paccagnella, Zhao Gang, Willy R Vasquez, David Kohlbrenner, Hovav Shacham, and Christopher W Fletcher. 2024. GPU. zip: On the Side-Channel Implications of Hardware-Based Graphical Data Compression. In 2024 IEEE Symposium on Security and Privacy (SP). 84–84.">[168]</span></a></sup> 通过利用 iGPU 压缩通道来诱导数据相关的 DRAM 流量和缓存利用率，在 Web 浏览器中开发跨源像素窃取攻击。鉴于 LLC 在 CPU 和 GPU 之间共享，他们演示了如何使用 LLC 行走时间来推断 GPU 引起的 CPU 缓存状态变化。Wang 等人 <sup id="fnref:171" class="footnote-ref"><a href="#fn:171" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhendong Wang, Rujia Wang, Zihang Jiang, Xulong Tang, Shouyi Yin, and Yang Hu. 2021. Towards a secure integrated heterogeneous platform via cooperative CPU/GPU encryption. In 2021 IEEE 30th Asian Test Symposium (ATS). IEEE, 115–120.">[171]</span></a></sup> 将之前对 AES 实现的定时侧信道攻击 <sup id="fnref:72" class="footnote-ref"><a href="#fn:72" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhen Hang Jiang, Yunsi Fei, and David Kaeli. 2016. A complete key recovery timing attack on a GPU. In 2016 IEEE International symposium on high performance computer architecture (HPCA). IEEE, 394–405.">[72]</span></a></sup> 扩展到 iGPU。</p><p>最近的一些研究也深入研究了 GPU，例如 Qualcomm Adreno GPU 和 Apple GPU。在 Arm 的系统级缓存的基础上，Cronin 等人 <sup id="fnref:29" class="footnote-ref"><a href="#fn:29" rel="footnote"><span class="hint--top hint--rounded" aria-label="Patrick Cronin, Xing Gao, Haining Wang, and Chase Cotton. 2021. An exploration of ARM system-level cache and GPU side channels. In Proceedings of the 37th Annual Computer Security Applications Conference. 784–795.">[29]</span></a></sup> 利用 Arm DynamIQ 的 GPU 和共享缓存架构创建了一个网站指纹识别侧信道。 Yang 等人 <sup id="fnref:178" class="footnote-ref"><a href="#fn:178" rel="footnote"><span class="hint--top hint--rounded" aria-label="Boyuan Yang, Ruirong Chen, Kai Huang, Jun Yang, and Wei Gao. 2022. Eavesdropping user credentials via GPU side channels on smartphones. In Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. 285–299.">[178]</span></a></sup> 以 Qualcomm Adreno GPU 为目标，研究了渲染用户按键弹出窗口导致的 GPU 过度绘制。每次按键都会导致所选 GPU 性能计数器发生独特的变化，从而可以准确推断这些按键。为了访问 Android 上的 GPU 性能计数器，他们从 GPU 设备文件（例如，Qualcomm Adreno GPU 驱动程序的开源头文件 msm_kgsl.h）读取 GPU PC 的原始值。</p><h3 id="5-2-2-对离散-GPU-的攻击"><a href="#5-2-2-对离散-GPU-的攻击" class="headerlink" title="5.2.2 对离散 GPU 的攻击"></a>5.2.2 对离散 GPU 的攻击</h3><p>对离散 GPU 的攻击通常可分为两类：(i) 间谍和受害者（或木马）应用程序共位于单个 GPU 上，表示为 sGPU；(ii) 间谍和受害者（或木马）应用程序共位于不同的 GPU 上，表示为 mGPU。例如，这种情况可能涉及配备多个 GPU 的系统，例如 NVIDIA 基于 Pascal 的 DGX-1 系统，包含八个 Tesla P100 GPU。</p><p>或者，它可能涉及配备 MIG 启用 GPU 的系统，其中单个物理 GPU 被划分为多个实例，每个实例都充当具有专用资源的独立 GPU，例如 NVIDIA A100 和 H100。</p><p><strong>针对单个 GPU 的攻击。</strong>此类攻击通常假设仅具有用户级权限的攻击者要么在单个 GPU 上启动 GPU 内核，以从执行时间、性能计数器和其他泄漏向量等测量中获取见解；要么与单个 GPU 上的受害者进程共置以建立隐蔽通道。</p><p>下面，我们回顾现有研究并将它们分为以下几个方面：</p><p><strong>在基于 GPU 的加密实现中恢复私钥：</strong>最近的研究展示了从在 GPU 上运行的加密应用程序中恢复加密密钥（例如 AES 和 RSA 私钥）的能力。 Jiang 等人 <sup id="fnref:72" class="footnote-ref"><a href="#fn:72" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhen Hang Jiang, Yunsi Fei, and David Kaeli. 2016. A complete key recovery timing attack on a GPU. In 2016 IEEE International symposium on high performance computer architecture (HPCA). IEEE, 394–405.">[72]</span></a></sup> 利用不同线程访问内存时生成的地址之间的时序差异，其中执行时间受合并后唯一内存请求数量的影响。因此，密钥会影响线程访问的地址模式，从而影响观察到的 AES 加密运行时间。在他们的另一项研究 <sup id="fnref:73" class="footnote-ref"><a href="#fn:73" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhen Hang Jiang, Yunsi Fei, and David Kaeli. 2017. A novel side-channel timing attack on GPUs. In Proceedings of the on Great Lakes Symposium on VLSI 2017. 167–172.">[73]</span></a></sup> 中，他们建立了 warp 表查找的执行时间与 warp 内线程生成的共享内存库冲突数量之间的相关性。然后使用这些与密钥相关的时序差异将测量的执行时间与 AES 加密在 GPU 上执行的最后一轮的密钥相关联。Ahn 等人 <sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jaeguk Ahn, Cheolgyu Jin, Jiho Kim, Minsoo Rhu, Yunsi Fei, David Kaeli, and John Kim. 2021. Trident: A hybrid correlation-collision GPU cache timing attack for AES key recovery. In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 332–344.">[2]</span></a></sup> 利用负时序相关性恢复 AES 的早期密钥字节，同时对后期的 AES 密钥字节使用缓存冲突攻击。最近，Giner 等人 <sup id="fnref:46" class="footnote-ref"><a href="#fn:46" rel="footnote"><span class="hint--top hint--rounded" aria-label="Lukas Giner, Roland Czerny, Christoph Gruber, Fabian Rauscher, Andreas Kogler, Daniel De Almeida Braga, and Daniel Gruss. 2024. Generic and Automated Drive-by GPU Cache Attacks from the Browser. (2024).">[46]</span></a></sup> 从 AES T 表 GPU 实现中恢复密钥。他们分配一个相当大的缓冲区来占用缓存的很大一部分，执行 AES 加密，然后使用 Prime+Probe 来识别与加密的输入和输出相关的被驱逐的缓冲区偏移量。他们在 6 分钟内恢复了整个 AES 密钥，表现出了卓越的性能，而之前的研究则需要 15 到 30 分钟。此外，除了基于 GPU 的 AES 实现之外，Luo 等人 <sup id="fnref:103" class="footnote-ref"><a href="#fn:103" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chao Luo, Yunsi Fei, and David Kaeli. 2019. Side-channel timing attack of RSA on a GPU. ACM Transactions on Architecture and Code Optimization (TACO) 16, 3 (2019), 1–18.">[103]</span></a></sup> 还介绍了一种针对 RSA 实现的定时侧信道攻击。他们利用解密时间与每个解密窗口的减少次数之间的相关性来提取 RSA 私钥。</p><p><img src="/img/cc/gpu/6.png" alt="图4. 用于在单个 GPU 上推断 NN 模型的攻击者模型。（a）攻击者可以使用总线监视设备监视 PCIe 流量或 GDDR5 （b）间谍和受害者位于两个不同的应用程序（或进程和虚拟机）上，共享同一个 GPU"></p><p><strong>从基于 GPU 的神经网络 (NN) 推断敏感信息：</strong>其他攻击利用侧信道泄漏从 NN 等 ML 模型推断信息。Zhu 等人 <sup id="fnref:191" class="footnote-ref"><a href="#fn:191" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yuankun Zhu, Yueqiang Cheng, Husheng Zhou, and Yantao Lu. 2021. Hermes attack: Steal DNN models with lossless inference accuracy. In 30th USENIX Security Symposium (USENIX Security 21).">[191]</span></a></sup> 和 Hu 等人 <sup id="fnref:59" class="footnote-ref"><a href="#fn:59" rel="footnote"><span class="hint--top hint--rounded" aria-label="Xing Hu, Ling Liang, Shuangchen Li, Lei Deng, Pengfei Zuo, Yu Ji, Xinfeng Xie, Yufei Ding, Chang Liu, Timothy Sherwood, et al. 2020. Deepsniffer: A dnn model extraction framework based on learning architectural hints. In Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems. 385–399.">[59]</span></a></sup> 专注于总线的攻击面，特别是 PCIe（如图 4a 所示）。Zhu 等人 <sup id="fnref:191" class="footnote-ref"><a href="#fn:191" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yuankun Zhu, Yueqiang Cheng, Husheng Zhou, and Yantao Lu. 2021. Hermes attack: Steal DNN models with lossless inference accuracy. In 30th USENIX Security Symposium (USENIX Security 21).">[191]</span></a></sup> 离线对关键数据结构（例如 GPU 命令头）进行逆向工程，并通过监听设备收集受害 PCIe 数据包以在在线阶段重建模型。被盗的 DNN 模型具有与原始模型相同的参数和语义相同的架构。这种攻击的一个潜在缓解措施是加密 PCIe 流量。相比之下，Hu 等人 <sup id="fnref:59" class="footnote-ref"><a href="#fn:59" rel="footnote"><span class="hint--top hint--rounded" aria-label="Xing Hu, Ling Liang, Shuangchen Li, Lei Deng, Pengfei Zuo, Yu Ji, Xinfeng Xie, Yufei Ding, Chang Liu, Timothy Sherwood, et al. 2020. Deepsniffer: A dnn model extraction framework based on learning architectural hints. In Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems. 385–399.">[59]</span></a></sup> 假设对手无法访问通过总线的数据，只能访问地址，即使使用加密数据也可以进行攻击。</p><p>他们对离散 GPU 的内存和 PCIe 总线进行总线监听攻击，获取内核读&#x2F;写访问量和内存地址跟踪。将提取的架构事件与模型内部架构相关联。另一类攻击发生在两个并发的 GPU 应用程序之间，如图 4b 所示。在 <sup id="fnref:118" class="footnote-ref"><a href="#fn:118" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hoda Naghibijouybari, Khaled N Khasawneh, and Nael Abu-Ghazaleh. 2017. Constructing and characterizing covert channels on gpgpus. In Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture. 354–366.">[118]</span></a></sup> 中，它们 (i) 通过 GPU 内存利用率应用程序编程接口 (API) 或 GPU 性能计数器实施网站指纹攻击；(ii) 通过按键时序分析在交互期间或在键盘上键入字符时监视用户的网络活动；(iii) 利用 GPU 计算堆栈中的 CUDA 间谍利用共享资源推断 NN 结构。与 <sup id="fnref:118" class="footnote-ref"><a href="#fn:118" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hoda Naghibijouybari, Khaled N Khasawneh, and Nael Abu-Ghazaleh. 2017. Constructing and characterizing covert channels on gpgpus. In Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture. 354–366.">[118]</span></a></sup> 相比，Wei 等人 <sup id="fnref:173" class="footnote-ref"><a href="#fn:173" rel="footnote"><span class="hint--top hint--rounded" aria-label="Junyi Wei, Yicheng Zhang, Zhe Zhou, Zhou Li, and Mohammad Abdullah Al Faruque. 2020. Leaky dnn: Stealing deep-learning model secret with gpu context-switching side-channel. In 2020 50th Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 125–137.">[173]</span></a></sup> 考虑在不同 VM 上进行应用程序的细粒度时间分片共享，并利用性能计数器上的上下文切换惩罚作为泄漏向量来恢复 DNN 的层组成和超参数。</p><p>大多数这些攻击需要对 NVIDIA GPU 细节进行广泛的逆向工程。这是因为 GPU 驱动程序和内部 GPU 工作原理是闭源的，并且关键数据结构未记录（参见第 2.1 节）。换句话说，这些因素在一定程度上增加了攻击的难度，但并不能从根本上阻止攻击。</p><p><strong>间谍和受害者同时在单个 GPU 上运行的隐蔽通道攻击：</strong>成功的隐蔽通道攻击的关键是识别木马和间谍所使用的共享资源，这通常需要对 GPU 架构进行大量的逆向工程。这一过程对于揭示有关 GPU 组件的详细信息（如 TLB 和其他共享资源）是必不可少的，这些详细信息可用于隐蔽通信。Naghibijouybari 等人 <sup id="fnref:118" class="footnote-ref"><a href="#fn:118" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hoda Naghibijouybari, Khaled N Khasawneh, and Nael Abu-Ghazaleh. 2017. Constructing and characterizing covert channels on gpgpus. In Proceedings of the 50th Annual IEEE/ACM International Symposium on Microarchitecture. 354–366.">[118]</span></a></sup> 首先对硬件块和 warp-to-warp 调度程序进行逆向工程以建立共置，然后了解缓存、功能单元和内存上的争用情况，最后基于这些资源构建隐蔽通道，无错误带宽超过 4 Mbps。由此，他们恢复了 NN 中的神经元数量。Ahn 等人 <sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jaeguk Ahn, Jiho Kim, Hans Kasan, Leila Delshadtehrani, Wonjun Song, Ajay Joshi, and John Kim. 2021. Network-on-chip microarchitecture-based covert channel in gpus. In MICRO-54: 54th Annual IEEE/ACM International Symposium on Microarchitecture. 565–577.">[3]</span></a></sup> 首先对现代 GPU 内的片上网络结构进行逆向工程，并注意到 GPU 的分层组织导致相邻核心之间共享互连带宽。然后，他们利用互连通道的争用，利用时钟寄存器进行发送方-接收方同步，最终建立具有惊人高带宽 24 Mbps 的微架构隐蔽通道。Nayak 等人 <sup id="fnref:121" class="footnote-ref"><a href="#fn:121" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ajay Nayak, Vinod Ganapathy, and Arkaprava Basu. 2021. (Mis) managed: A novel TLB-based covert channel on GPUs. In Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security. 872–885.">[121]</span></a></sup> 对 NVIDIA 1080Ti 的 TLB 层次结构细节以及所有 TLB 级别的细节（例如条目数和结合性）进行了逆向工程。他们使用 Prime+Probe 通过共享 L3 TLB 创建隐蔽时序通道。借助 MPS，他们将 GPU 基于 L3 TLB 的隐蔽通道的带宽增加到 81 Kbps。与以前的工作依赖通过 CUDA 或 OpenGL 访问本机 GPU API 进行高精度性能计数器监控不同，Giner 等人 <sup id="fnref:46" class="footnote-ref"><a href="#fn:46" rel="footnote"><span class="hint--top hint--rounded" aria-label="Lukas Giner, Roland Czerny, Christoph Gruber, Fabian Rauscher, Andreas Kogler, Daniel De Almeida Braga, and Daniel Gruss. 2024. Generic and Automated Drive-by GPU Cache Attacks from the Browser. (2024).">[46]</span></a></sup> 不依赖 WebGPU 提供的硬件计时器。相反，他们使用共享内存缓冲区和专用线程来不断增加共享变量，充当计时器。利用此计时器及其 GPU 加速缓存驱逐集构造，他们为 L2 缓存建立了一个 Prime+Probe 缓存隐蔽通道，带宽为 10.9 KB&#x2F;s。</p><p><strong>攻击多个 GPU。</strong>在 NVIDIA 的 DGX 机器中，离散 GPU 通过 NVLink 和 PCIe 连接，Dutta 等人 <sup id="fnref:35" class="footnote-ref"><a href="#fn:35" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sankha Baran Dutta, Hoda Naghibijouybari, Arjun Gupta, Nael Abu-Ghazaleh, Andres Marquez, and Kevin Barker. 2023. Spy in the GPU-box: Covert and side channel attacks on multi-GPU systems. In Proceedings of the 50th Annual International Symposium on Computer Architecture. 1–13.">[35]</span></a></sup> 对缓存层次结构进行逆向工程，并表明一个 GPU 上的攻击者可以通过 NVLink 在另一个 GPU 的 L2 缓存中创建争用。他们在两个 GPU 之间建立了一个 Prime+Probe 隐蔽通道，带宽达到 4 MB&#x2F;s。此外，他们的侧信道攻击允许攻击者监视在不同 GPU 上运行的另一个应用程序，从而能够恢复 NN 的神经元数量。<strong>通过对最近的 NVIDIA GPU（例如 A100 和 H100）中的 TLB 结构进行逆向工程，Zhang 等人 <sup id="fnref:187" class="footnote-ref"><a href="#fn:187" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhenkai Zhang, Tyler Allen, Fan Yao, Xing Gao, and Rong Ge. 2023. TunneLs for Bootlegging: Fully Reverse-Engineering GPU TLBs for Challenging Isolation Guarantees of NVIDIA MIG. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security. 960–974.">[187]</span></a></sup> 发现了<a href="https://dl.acm.org/doi/pdf/10.1145/3576915.3616672">NVIDIA MIG 功能中的一个设计缺陷</a>：MIG 不会对所有 GPU 实例共享的最后一级 TLB 进行分区。他们转储 GPU 内存以找到相应的表条目，并通过 1 MB GPU 内存窗口 (MMIO) 访问目标条目以进行运行时修改。他们最终基于共享 TLB 建立了一个跨 GPU 实例隐蔽通道。总之，这两项研究都首先识别多 GPU 系统中存在的共享资源，例如共享远程 L2 缓存 <sup id="fnref:35" class="footnote-ref"><a href="#fn:35" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sankha Baran Dutta, Hoda Naghibijouybari, Arjun Gupta, Nael Abu-Ghazaleh, Andres Marquez, and Kevin Barker. 2023. Spy in the GPU-box: Covert and side channel attacks on multi-GPU systems. In Proceedings of the 50th Annual International Symposium on Computer Architecture. 1–13.">[35]</span></a></sup> 和共享 L3 TLB <sup id="fnref:187" class="footnote-ref"><a href="#fn:187" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhenkai Zhang, Tyler Allen, Fan Yao, Xing Gao, and Rong Ge. 2023. TunneLs for Bootlegging: Fully Reverse-Engineering GPU TLBs for Challenging Isolation Guarantees of NVIDIA MIG. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security. 960–974.">[187]</span></a></sup>，然后在这些共享资源上创建可见的争用。</strong></p><h3 id="5-2-3-对策"><a href="#5-2-3-对策" class="headerlink" title="5.2.3 对策"></a>5.2.3 对策</h3><p>对策可总结如下：</p><ul><li><strong>资源分区：</strong>对于利用共享微架构资源的攻击，攻击者和受害者之间的共置至关重要。缓解这种威胁的一种解决方案是静态或动态地划分资源（例如 LLC）<sup id="fnref:83" class="footnote-ref"><a href="#fn:83" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jingfei Kong, Onur Aciiçmez, Jean-Pierre Seifert, and Huiyang Zhou. 2009. Hardware-software integrated approaches to defend against software cache-based side channel attacks. In 2009 IEEE 15th international symposium on high performance computer architecture. IEEE, 393–404.">[83]</span></a></sup> <sup id="fnref:101" class="footnote-ref"><a href="#fn:101" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fangfei Liu, Qian Ge, Yuval Yarom, Frank Mckeen, Carlos Rozas, Gernot Heiser, and Ruby B Lee. 2016. Catalyst: Defeating last-level cache side channel attacks in cloud computing. In 2016 IEEE international symposium on high performance computer architecture (HPCA). IEEE, 406–418.">[101]</span></a></sup> <sup id="fnref:170" class="footnote-ref"><a href="#fn:170" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhenghong Wang and Ruby B Lee. 2007. New cache designs for thwarting software cache-based side channel attacks. In Proceedings of the 34th annual international symposium on Computer architecture. 494–505.">[170]</span></a></sup>。通过将间谍和木马分配到不同的缓存分区，它们无法替换彼此的缓存行。第 2.1 节中介绍的 MIG 可能通过隔离独立 GPU 实例之间的资源来缓解这些攻击。然而，Zhang 等人 <sup id="fnref:187" class="footnote-ref"><a href="#fn:187" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhenkai Zhang, Tyler Allen, Fan Yao, Xing Gao, and Rong Ge. 2023. TunneLs for Bootlegging: Fully Reverse-Engineering GPU TLBs for Challenging Isolation Guarantees of NVIDIA MIG. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security. 960–974.">[187]</span></a></sup> 指出，启用 MIG 的 GPU 实例之间的最后一级 TLB 未正确分区，允许使用此漏洞创建隐蔽通道。</li><li><strong>消除争用：</strong>可以通过控制内存控制器中的流量来消除进程之间的争用。这涉及将来自每个处理器的内存请求分组到同一个队列中，可能访问相同的内存组&#x2F;端口 <sup id="fnref:143" class="footnote-ref"><a href="#fn:143" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ali Shafiee, Akhila Gundu, Manjunath Shevgoor, Rajeev Balasubramonian, and Mohit Tiwari. 2015. Avoiding information leakage in the memory controller with fixed service policies. In Proceedings of the 48th International Symposium on Microarchitecture. 89–101.">[143]</span></a></sup> <sup id="fnref:167" class="footnote-ref"><a href="#fn:167" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yao Wang, Andrew Ferraiuolo, and G Edward Suh. 2014. Timing channel protection for a shared memory controller. In 2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA). IEEE, 225–236.">[167]</span></a></sup>。例如，TL​​B-pilot <sup id="fnref:32" class="footnote-ref"><a href="#fn:32" rel="footnote"><span class="hint--top hint--rounded" aria-label="Bang Di, Daokun Hu, Zhen Xie, Jianhua Sun, Hao Chen, Jinkui Ren, and Dong Li. 2021. TLB-pilot: Mitigating TLB Contention Attack on GPUs with Microarchitecture-Aware Scheduling. ACM Transactions on Architecture and Code Optimization (TACO) 19, 1 (2021), 1–23.">[32]</span></a></sup> 通过考虑最后一级 TLB 的硬件隔离和应用程序的资源需求，将来自不同内核的线程块绑定到不同的流式多处理器组。它在内核启动之前收集内核信息，并通过协调软件和硬件调度以及采用内核拆分策略来减少负载不平衡。还有针对基于合并的相关性时序攻击的防御措施。例如，Kadam 等人 <sup id="fnref:74" class="footnote-ref"><a href="#fn:74" rel="footnote"><span class="hint--top hint--rounded" aria-label="Gurunath Kadam, Danfeng Zhang, and Adwait Jog. 2018. Rcoal: mitigating gpu timing attack via subwarp-based randomized coalescing techniques. In 2018 IEEE international symposium on high performance computer architecture (HPCA). IEEE, 156–167.">[74]</span></a></sup> <sup id="fnref:75" class="footnote-ref"><a href="#fn:75" rel="footnote"><span class="hint--top hint--rounded" aria-label="Gurunath Kadam, Danfeng Zhang, and Adwait Jog. 2020. Bcoal: Bucketing-based memory coalescing for efficient and secure gpus. In 2020 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEE, 570–581.">[75]</span></a></sup> 增加了额外的内存访问，使执行时间更难预测。为了防止基于 GPU 的 AES 中的时序和基于缓存的攻击，Lin 等人 <sup id="fnref:96" class="footnote-ref"><a href="#fn:96" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhen Lin, Utkarsh Mathur, and Huiyang Zhou. 2019. Scatter-and-gather revisited: High-performance side-channel-resistant AES on GPUs. In Proceedings of the 12th Workshop on General Purpose Processing Using GPUs. 2–11.">[96]</span></a></sup> 使用分散和聚集技术来重新组织 AES 表，避免因时序或地址泄漏而进行依赖于密钥的查找。</li></ul><h2 id="5-3-物理侧信道攻击"><a href="#5-3-物理侧信道攻击" class="headerlink" title="5.3 物理侧信道攻击"></a>5.3 物理侧信道攻击</h2><p>我们将允许攻击者直接接近或接触 GPU 或其周围硬件组件的攻击归类为基于物理访问的攻击。这样的攻击者在物理上靠近设备并可以直接与其交互。这可能涉及在设备上或附近直接放置传感器或监控设备以捕获物理信号或发射。请注意，我们将从远处监控或操纵目标设备的物理属性，而不直接物理访问设备本身的攻击称为基于远程访问的攻击（在 <sup id="fnref:153" class="footnote-ref"><a href="#fn:153" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hritvik Taneja, Jason Kim, Jie Jeff Xu, Stephan Van Schaik, Daniel Genkin, and Yuval Yarom. 2023. Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and Arm SoCs. In 32nd USENIX Security Symposium (USENIX Security 23). 6275–6292.">[153]</span></a></sup> 中称为混合攻击）。此类攻击使用例如无线传感器或网络连接设备从远处捕获目标设备发出的信号或发射。</p><h3 id="5-3-1-基于物理访问"><a href="#5-3-1-基于物理访问" class="headerlink" title="5.3.1 基于物理访问"></a>5.3.1 基于物理访问</h3><p>Luo 等人 <sup id="fnref:104" class="footnote-ref"><a href="#fn:104" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chao Luo, Yunsi Fei, Pei Luo, Saoni Mukherjee, and David Kaeli. 2015. Side-channel power analysis of a GPU AES implementation. In 2015 33rd IEEE International Conference on Computer Design (ICCD). IEEE, 281–288.">[104]</span></a></sup> 和 Gao 等人 <sup id="fnref:44" class="footnote-ref"><a href="#fn:44" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yiwen Gao, Hailong Zhang, Wei Cheng, Yongbin Zhou, and Yuchen Cao. 2018. Electro-magnetic analysis of GPU-based AES implementation. In Proceedings of the 55th Annual Design Automation Conference. 1–6.">[44]</span></a></sup> 专注于通过利用物理属性来恢复 AES 私钥。Luo 等人利用相关功率分析来分析 GPU 的功耗（即电源迹线），从而迫使攻击者对电源进行检测。Gao 等人采用精确触发机制对 EM 迹线进行采样，并建立启发式泄漏模型以利用并行场景中的并发 MMIO 泄漏。</p><p>此方法需要移除 GPU 的散热器并将探针放置在 GPU 芯片表面附近。</p><p>Hu 等人 <sup id="fnref:59" class="footnote-ref"><a href="#fn:59" rel="footnote"><span class="hint--top hint--rounded" aria-label="Xing Hu, Ling Liang, Shuangchen Li, Lei Deng, Pengfei Zuo, Yu Ji, Xinfeng Xie, Yufei Ding, Chang Liu, Timothy Sherwood, et al. 2020. Deepsniffer: A dnn model extraction framework based on learning architectural hints. In Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems. 385–399.">[59]</span></a></sup> 利用 MMIO 侧信道攻击来捕获内存访问量和内核执行时间，方法是针对 CPU-GPU 互连或共置 CUDA 间谍。这使他们能够在没有任何 NN 模型先验知识的情况下推断出模型架构。同样，Chmielewski 和 Weissbart <sup id="fnref:24" class="footnote-ref"><a href="#fn:24" rel="footnote"><span class="hint--top hint--rounded" aria-label="Łukasz Chmielewski and Léo Weissbart. 2021. On reverse engineering neural network implementation on GPU. In Applied Cryptography and Network Security Workshops: ACNS 2021 Satellite Workshops, AIBlock, AIHWS, AIoTS, CIMSS, Cloud S&P, SCI, SecMT, and SiMLA, Kamakura, Japan, June 21–24, 2021, Proceedings. Springer, 96–113.">[24]</span></a></sup> 使用简单的 MMIO 分析来恢复 NN 模型的部分信息。 Maia 等人 <sup id="fnref:107" class="footnote-ref"><a href="#fn:107" rel="footnote"><span class="hint--top hint--rounded" aria-label="Henrique Teles Maia, Chang Xiao, Dingzeyu Li, Eitan Grinspun, and Changxi Zheng. 2022. Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel.. In USENIX Security Symposium. 4383–4400.">[107]</span></a></sup> 展示了如何通过物理传感器利用 GPU 电源线发出的磁通量来恢复 64 个 NN 的完整模型架构。Horvath 等人 <sup id="fnref:57" class="footnote-ref"><a href="#fn:57" rel="footnote"><span class="hint--top hint--rounded" aria-label="Peter Horvath, Lukasz Chmielewski, Leo Weissbart, Lejla Batina, and Yuval Yarom. 2023. BarraCUDA: Bringing Electromagnetic Side Channel Into Play to Steal the Weights of Neural Networks from NVIDIA GPUs. arXiv preprint arXiv:2312.07783 (2023).">[57]</span></a></sup> 使用相关 EM 分析来恢复 CNN 模型卷积层中的权重和偏差。</p><p>Taneja 等人 <sup id="fnref:153" class="footnote-ref"><a href="#fn:153" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hritvik Taneja, Jason Kim, Jie Jeff Xu, Stephan Van Schaik, Daniel Genkin, and Yuval Yarom. 2023. Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and Arm SoCs. In 32nd USENIX Security Symposium (USENIX Security 23). 6275–6292.">[153]</span></a></sup> 捕获频率、功率和温度（通过内部传感器监控）的侧信道泄漏，以响应集成和独立 GPU 中执行的工作负载。他们的攻击会观察指令和数据相关行为，根据供应商的不同需要不同的权限级别。例如，Apple 允许非特权访问两者，而 Google 限制温度读数但允许非特权访问电源。</p><h3 id="5-3-2-基于远程访问"><a href="#5-3-2-基于远程访问" class="headerlink" title="5.3.2 基于远程访问"></a>5.3.2 基于远程访问</h3><p>Zhan 等人 <sup id="fnref:182" class="footnote-ref"><a href="#fn:182" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zihao Zhan, Zhenkai Zhang, Sisheng Liang, Fan Yao, and Xenofon Koutsoukos. 2022. Graphics peeping unit: Exploiting em side-channel information of gpus to eavesdrop on your neighbors. In 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 1440–1457.">[182]</span></a></sup> 将 GPU 中使用的 DVFS 功能确定为 MMIO 侧信道漏洞的根本原因。在受害者使用 NVIDIA 或 AMD GPU 而不共享的情况下，攻击者可以监视受害者的活动并辨别访问过的网页（即网站指纹攻击）。关键思想是在网页渲染期间捕获 GPU 波动的工作负载，这会影响其发出的 MMIO 信号。这些工作负载变化，加上管理热量产生、风扇噪音和最小化功耗的需求，导致 GPU 性能水平发生变化（例如，NVIDIA GPU 中的 P 状态）。因此，当性能级别打开或关闭时，与 GPU 的内存时钟频率相对应的不同 MMIO 信号会出现或消失在频谱中。值得注意的是，这种攻击可以拦截距离最远 6 米的 MMIO 信号泄漏，甚至穿过一堵墙。Liang 等人 <sup id="fnref:95" class="footnote-ref"><a href="#fn:95" rel="footnote">&lt;span class&#x3D;”hint–top hint–rounded” aria-label&#x3D;”Sisheng Liang, Zihao Zhan, Fan Yao, Long Cheng, and Zhenkai Zhang. 2022. Clairvoyance: exploiting far-field em emanations of gpu to” see” your dnn models through obstacles at a distance. In 2022 IEEE Security and Privacy Workshops (SPW). IEEE, 312–322.”&gt;[95]</span></a></sup> 进行了类似的远场 MMIO 侧信道攻击，以推断 NN 模型中的层数及其类型、内核数量、层大小和步幅。</p><h3 id="5-3-3-对策"><a href="#5-3-3-对策" class="headerlink" title="5.3.3 对策"></a>5.3.3 对策</h3><p>当这些 EM 信号依赖于计算时，可以利用 GPU 的 MMIO 侧信道，从而揭示有关正在进行的活动的信息。当这些侧信道信号很强并且可以传播几米时，很容易测量。两种对策可以缓解此类漏洞。</p><p>(i) 隐藏和掩蔽 <sup id="fnref:108" class="footnote-ref"><a href="#fn:108" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stefan Mangard, Elisabeth Oswald, and Thomas Popp. 2008. Power analysis attacks: Revealing the secrets of smart cards. Vol. 31. Springer Science & Business Media.">[108]</span></a></sup>：隐藏旨在降低攻击者可用的信噪比 (SNR)。产生 MMIO 噪声是可能的，但屏蔽计算机以降低发射的 MMIO 信号的强度更有效。</p><p>硬件制造商还可以专注于在未来的产品设计中最大限度地减少 MMIO 排放。掩蔽涉及将数据与随机掩码值相结合，以确保可观察到的泄漏与秘密无关。例如，在敏感任务期间创建随机 GPU 工作负载可能会破坏使用模式并降低可预测性 <sup id="fnref:105" class="footnote-ref"><a href="#fn:105" rel="footnote"><span class="hint--top hint--rounded" aria-label="Dina G Mahmoud, Vincent Lenders, and Mirjana Stojilović. 2022. Electrical-level attacks on CPUs, FPGAs, and GPUs: Survey and implications in the heterogeneous era. ACM Computing Surveys (CSUR) 55, 3 (2022), 1–40.">[105]</span></a></sup> <sup id="fnref:182" class="footnote-ref"><a href="#fn:182" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zihao Zhan, Zhenkai Zhang, Sisheng Liang, Fan Yao, and Xenofon Koutsoukos. 2022. Graphics peeping unit: Exploiting em side-channel information of gpus to eavesdrop on your neighbors. In 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 1440–1457.">[182]</span></a></sup>。</p><p>但是，由于需要随机掩码和算法的额外复杂性，掩蔽可能很复杂。</p><p>（二）粗化粒度：另一种方法是降低 GPU DVFS 对工作负载变化的敏感度。这将使性能更加稳定，泄露的信息更少，敏感数据被推断的可能性也更低 <sup id="fnref:182" class="footnote-ref"><a href="#fn:182" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zihao Zhan, Zhenkai Zhang, Sisheng Liang, Fan Yao, and Xenofon Koutsoukos. 2022. Graphics peeping unit: Exploiting em side-channel information of gpus to eavesdrop on your neighbors. In 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 1440–1457.">[182]</span></a></sup>。然而，这样的变化可能会对 DVFS 的效率优势产生负面影响。</p><h2 id="5-4-故障注入攻击"><a href="#5-4-故障注入攻击" class="headerlink" title="5.4 故障注入攻击"></a>5.4 故障注入攻击</h2><h3 id="5-4-1-基于软件"><a href="#5-4-1-基于软件" class="headerlink" title="5.4.1 基于软件"></a>5.4.1 基于软件</h3><p>Frigo 等人 <sup id="fnref:43" class="footnote-ref"><a href="#fn:43" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pietro Frigo, Cristiano Giuffrida, Herbert Bos, and Kaveh Razavi. 2018. Grand pwning unit: Accelerating microarchitectural attacks with the GPU. In 2018 ieee symposium on security and privacy (sp). IEEE, 195–210.">[43]</span></a></sup> 使用基于 GPU 的计时器执行基于 JavaScript 的侧信道攻击，使攻击者能够识别物理内存的连续区域。此方法允许在已识别的内存区域中远程触发 Rowhammer 位翻转。因此，攻击者可以破坏地址空间布局随机化 (ASLR) 并逃避配备集成 Qualcomm Adreno GPU 的 Android 平台上的 Firefox 沙盒。Sabbagh 等人 <sup id="fnref:134" class="footnote-ref"><a href="#fn:134" rel="footnote"><span class="hint--top hint--rounded" aria-label="Majid Sabbagh, Yunsi Fei, and David Kaeli. 2020. A novel GPU overdrive fault attack. In 2020 57th ACM/IEEE Design Automation Conference (DAC). IEEE, 1–6.">[134]</span></a></sup> 引入了第一个名为“过载”的非侵入式 GPU 故障攻击。通过利用 DVFS 接口，攻击者可以在主机 CPU 上配置超出规格的电压和频率组合，并向 GPU 控制寄存器发送恶意过载命令，在 GPU 内核执行期间引发随机故障。他们还对受害者 CNN 推理执行错误分类攻击 <sup id="fnref:135" class="footnote-ref"><a href="#fn:135" rel="footnote"><span class="hint--top hint--rounded" aria-label="Majid Sabbagh, Yunsi Fei, and David Kaeli. 2021. Gpu overdrive fault attacks on neural networks. In 2021 IEEE/ACM International Conference On Computer Aided Design (ICCAD). IEEE, 1–8.">[135]</span></a></sup>，通过解决其在时间精度方面的局限性以及缺乏对故障注入如何影响静默数据损坏的分析来改进过载攻击。</p><p>然而，与硬件故障注入攻击非常有效的加密算法不同，ML 模型，尤其是训练有素的商业 DNN 模型，本质上具有更高的容错性。这是因为随机硬件故障产生的计算错误通常会被后面的层吸收，不会对准确性产生很大影响。因此，在特定时间点引发硬件故障、优化毛刺电压-频率对以及确定适当的故障持续时间对于在 ML 模型中生成可控且有影响力的故障至关重要。为此，Sun 等人 <sup id="fnref:151" class="footnote-ref"><a href="#fn:151" rel="footnote"><span class="hint--top hint--rounded" aria-label="Rihui Sun, Pengfei Qiu, Yongqiang Lyu, Jian Dong, Haixia Wang, Dongsheng Wang, and Gang Qu. 2023. Lightning: Leveraging DVFS-induced Transient Fault Injection to Attack Deep Learning Accelerator of GPUs. ACM Transactions on Design Automation of Electronic Systems 29, 1 (2023).">[151]</span></a></sup> 专注于搜索 CNN 模型的敏感目标，确定适当的时间和位置参数，优化故障注入参数，最终将推理准确率平均降低 69.1%。Santos 等人 <sup id="fnref:136" class="footnote-ref"><a href="#fn:136" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fernando F dos Santos, Josie E Rodriguez Condia, Luigi Carro, Matteo Sonza Reorda, and Paolo Rech. 2021. Revealing gpus vulnerabilities by combining register-transfer and software-level fault injection. In 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 292–304.">[136]</span></a></sup> 提出了一个两级故障注入框架，将寄存器传输级 (RTL) 故障注入的准确性与软件故障注入的效率相结合。</p><p>总体而言，研究人员主要利用软件接口来注入故障，通常利用 DVFS 或 Rowhammer 攻击。 Rowhammer 攻击利用了 DRAM 漏洞，即对内存行的重复访问（即锤击）可能导致相邻行的位翻转，从而导致危险的漏洞，例如从普通用户到系统管理员的权限升级。GPU 固有的高并行性和内存带宽可能使它们更容易受到 Rowhammer 攻击，因为它们可以比 CPU 更快地生成内存访问。</p><h3 id="5-4-2-对策"><a href="#5-4-2-对策" class="headerlink" title="5.4.2 对策"></a>5.4.2 对策</h3><p>在主内存或内存控制器中实施针对 Rowhammer 漏洞的保护最有效。Frigo 等人<sup id="fnref:43" class="footnote-ref"><a href="#fn:43" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pietro Frigo, Cristiano Giuffrida, Herbert Bos, and Kaveh Razavi. 2018. Grand pwning unit: Accelerating microarchitectural attacks with the GPU. In 2018 ieee symposium on security and privacy (sp). IEEE, 195–210.">[43]</span></a></sup> 研究通过实施更严格的内存重用策略来防止攻击者瞄准有价值的数据。一种解决方案是增强 CATT <sup id="fnref:12" class="footnote-ref"><a href="#fn:12" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ferdinand Brasser, Lucas Davi, David Gens, Christopher Liebchen, and Ahmad-Reza Sadeghi. 2017. CAn’t touch this: Software-only mitigation against rowhammer attacks targeting kernel memory. In 26th USENIX Security Symposium (USENIX Security 17). 117–130.">[12]</span></a></sup> 建议的对用户空间应用程序的物理分区。然而，这种方法在复杂性、性能和容量方面带来了权衡，因为动态分配（隔离）页面会增加复杂性并可能对性能产生影响。</p><p>关于基于 DVFS 的攻击，可以使对手更难以控制和利用接口。电压和时钟信号监视器可用于检测非常规变化1 。此外，一些供应商已禁用 DVFS 的所有软件可访问接口。例如，英特尔通过 BIOS 设置禁用超频邮箱接口，并通过微代码更新（在 SGX TCB 证明中包含此设置的当前状态）来防御基于 DVFS 的英特尔 SGX 攻击 <sup id="fnref:117" class="footnote-ref"><a href="#fn:117" rel="footnote"><span class="hint--top hint--rounded" aria-label="Kit Murdock, David Oswald, Flavio D Garcia, Jo Van Bulck, Daniel Gruss, and Frank Piessens. 2020. Plundervolt: Software-based fault injection attacks against Intel SGX. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1466–1482.">[117]</span></a></sup>。类似的策略也可以应用于 GPU。</p><h1 id="6-CPU-TEE-的安全性"><a href="#6-CPU-TEE-的安全性" class="headerlink" title="6. CPU TEE 的安全性"></a>6. CPU TEE 的安全性</h1><p>在本节中，我们介绍针对 CPU TEE 的典型攻击。由于已经存在专注于回顾现有针对 CPU TEE 的攻击的调查论文，并且本调查的目的是探索针对 GPU TEE 的潜在攻击，因此我们在此仅根据其技术细节和现有调查 <sup id="fnref:19" class="footnote-ref"><a href="#fn:19" rel="footnote"><span class="hint--top hint--rounded" aria-label="David Cerdeira, Nuno Santos, Pedro Fonseca, and Sandro Pinto. 2020. Sok: Understanding the prevailing security vulnerabilities in trustzone-assisted tee systems. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1416–1432.">[19]</span></a></sup> <sup id="fnref:41" class="footnote-ref"><a href="#fn:41" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shufan Fei, Zheng Yan, Wenxiu Ding, and Haomeng Xie. 2021. Security vulnerabilities of SGX and countermeasures: A survey. ACM Computing Surveys (CSUR) 54, 6 (2021), 1–36.">[41]</span></a></sup> <sup id="fnref:90" class="footnote-ref"><a href="#fn:90" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li. 2022. Understanding and Exploiting Design Flaws of AMD Secure Encrypted Virtualization. The Ohio State University.">[90]</span></a></sup> <sup id="fnref:123" class="footnote-ref"><a href="#fn:123" rel="footnote"><span class="hint--top hint--rounded" aria-label="Alexander Nilsson, Pegah Nikbakht Bideh, and Joakim Brorsson. 2020. A survey of published attacks on Intel SGX. arXiv preprint arXiv:2006.13598 (2020).">[123]</span></a></sup> 对最常见的攻击进行分类。</p><h2 id="6-1-Intel-SGX-的安全性"><a href="#6-1-Intel-SGX-的安全性" class="headerlink" title="6.1 Intel SGX 的安全性"></a>6.1 Intel SGX 的安全性</h2><h3 id="6-1-1-受控通道和基于地址转换的攻击"><a href="#6-1-1-受控通道和基于地址转换的攻击" class="headerlink" title="6.1.1 受控通道和基于地址转换的攻击"></a>6.1.1 受控通道和基于地址转换的攻击</h3><p>受控通道攻击是 Xu 等人 <sup id="fnref:177" class="footnote-ref"><a href="#fn:177" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yuanzhong Xu, Weidong Cui, and Marcus Peinado. 2015. Controlled-channel attacks: Deterministic side channels for untrusted operating systems. In 2015 IEEE Symposium on Security and Privacy. IEEE, 640–656.">[177]</span></a></sup> 于 2015 年提出的概念，它利用操作系统的权限来监视和操纵页表。这使攻击者能够发现 enclave 代码的内存访问模式，另请参见 <sup id="fnref:147" class="footnote-ref"><a href="#fn:147" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shweta Shinde, Zheng Leong Chua, Viswesh Narayanan, and Prateek Saxena. 2016. Preventing page faults from telling your secrets. In Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security. 317–328.">[147]</span></a></sup>。这种攻击特别有效，因为虽然 Intel SGX enclave 保护敏感计算免受受损操作系统的攻击，但操作系统仍管理内存并可以观察页面错误，从而推断出有关 enclave 操作的详细信息。 SGX-Step <sup id="fnref:158" class="footnote-ref"><a href="#fn:158" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2017. SGX-Step: A practical attack framework for precise enclave execution control. In Proceedings of the 2nd Workshop on System Software for Trusted Execution. 1–6.">[158]</span></a></sup> 是一种实用工具，可用于执行此类受控通道攻击，具体方式包括配置高级可编程中断控制器 (APIC) 计时器、发出中断和跟踪页表条目。SGX-Step 支持确定性单步执行 enclave 执行，从而可以精确监控一段时间内的内存访问模式。</p><p>在无故障页表攻击 <sup id="fnref:80" class="footnote-ref"><a href="#fn:80" rel="footnote"><span class="hint--top hint--rounded" aria-label="Deokjin Kim, Daehee Jang, Minjoon Park, Yunjong Jeong, Jonghwan Kim, Seokjin Choi, and Brent Byunghoon Kang. 2019. SGX-LEGO: Fine-grained SGX controlled-channel attack and its countermeasure. computers & security 82 (2019), 118–139.">[80]</span></a></sup> <sup id="fnref:159" class="footnote-ref"><a href="#fn:159" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jo Van Bulck, Nico Weichbrodt, Rüdiger Kapitza, Frank Piessens, and Raoul Strackx. 2017. Telling your secrets without page faults: Stealthy page Table-Based attacks on enclaved execution. In 26th USENIX Security Symposium (USENIX Security 17). 1041–1056.">[159]</span></a></sup> <sup id="fnref:166" class="footnote-ref"><a href="#fn:166" rel="footnote"><span class="hint--top hint--rounded" aria-label="Wenhao Wang, Guoxing Chen, Xiaorui Pan, Yinqian Zhang, XiaoFeng Wang, Vincent Bindschaedler, Haixu Tang, and Carl A Gunter. 2017. Leaky cauldron on the dark land: Understanding memory side-channel hazards in SGX. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 2421–2434.">[166]</span></a></sup> 中，攻击者利用页表本身，而不是依赖页面错误。</p><p>这样，他们就可以通过检查页表属性和&#x2F;或观察未受保护页表内存的缓存行为来推断目标的内存访问模式。但是，这些攻击仅限于页面级精度。</p><p>分段攻击 <sup id="fnref:53" class="footnote-ref"><a href="#fn:53" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jago Gyselinck, Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2018. Off-limits: Abusing legacy x86 memory segmentation to spy on enclaved execution. In Engineering Secure Software and Systems: 10th International Symposium, ESSoS 2018, France, June 26-27, 2018. Springer, 44–60.">[53]</span></a></sup> 允许攻击者通过操纵分段单元来推断出更精细的内存访问模式，但这仅适用于 32 位 enclave，因为 64 位 enclave 中已禁用分段 <sup id="fnref:41" class="footnote-ref"><a href="#fn:41" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shufan Fei, Zheng Yan, Wenxiu Ding, and Haomeng Xie. 2021. Security vulnerabilities of SGX and countermeasures: A survey. ACM Computing Surveys (CSUR) 54, 6 (2021), 1–36.">[41]</span></a></sup>。</p><h3 id="6-1-2-基于缓存的攻击"><a href="#6-1-2-基于缓存的攻击" class="headerlink" title="6.1.2 基于缓存的攻击"></a>6.1.2 基于缓存的攻击</h3><p>典型的缓存时序通道攻击（在非 SGX 场景中）包括四种主要变体，包括 Evict+Time <sup id="fnref:155" class="footnote-ref"><a href="#fn:155" rel="footnote"><span class="hint--top hint--rounded" aria-label="Eran Tromer, Dag Arne Osvik, and Adi Shamir. 2010. Efficient cache attacks on AES, and countermeasures. Journal of Cryptology 23 (2010), 37–71.">[155]</span></a></sup>、Evict+Reload <sup id="fnref:50" class="footnote-ref"><a href="#fn:50" rel="footnote"><span class="hint--top hint--rounded" aria-label="Daniel Gruss, Raphael Spreitzer, and Stefan Mangard. 2015. Cache template attacks: Automating attacks on inclusive Last-Level caches. In 24th USENIX Security Symposium (USENIX Security 15). 897–912.">[50]</span></a></sup>、Prime+Probe <sup id="fnref:127" class="footnote-ref"><a href="#fn:127" rel="footnote"><span class="hint--top hint--rounded" aria-label="Dag Arne Osvik, Adi Shamir, and Eran Tromer. 2006. Cache attacks and countermeasures: the case of AES. In Topics in Cryptology–CT-RSA 2006: The Cryptographers’ Track at the RSA Conference 2006, San Jose, CA, USA, February 13-17, 2005. Proceedings. Springer, 1–20.">[127]</span></a></sup> 和 Flush+Reload <sup id="fnref:179" class="footnote-ref"><a href="#fn:179" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yuval Yarom and Katrina Falkner. 2014. FLUSH+ RELOAD: A high resolution, low noise, l3 cache Side-Channel attack. In 23rd USENIX security symposium (USENIX security 14). 719–732.">[179]</span></a></sup>，所有这些攻击都依赖于缓存命中和未命中之间的时间差。最近的研究 <sup id="fnref:14" class="footnote-ref"><a href="#fn:14" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ferdinand Brasser, Urs Müller, Alexandra Dmitrienko, Kari Kostiainen, Srdjan Capkun, and Ahmad-Reza Sadeghi. 2017. Software grand exposure:SGX cache attacks are practical. In 11th USENIX workshop on offensive technologies (WOOT 17).">[14]</span></a></sup> <sup id="fnref:30" class="footnote-ref"><a href="#fn:30" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fergus Dall, Gabrielle De Micheli, Thomas Eisenbarth, Daniel Genkin, Nadia Heninger, Ahmad Moghimi, and Yuval Yarom. 2018. Cachequote: Efficiently recovering long-term secrets of SGX EPID via cache attacks. (2018).">[30]</span></a></sup> <sup id="fnref:47" class="footnote-ref"><a href="#fn:47" rel="footnote"><span class="hint--top hint--rounded" aria-label="Johannes Götzfried, Moritz Eckert, Sebastian Schinzel, and Tilo Müller. 2017. Cache attacks on Intel SGX. In Proceedings of the 10th European Workshop on Systems Security. 1–6.">[47]</span></a></sup> <sup id="fnref:112" class="footnote-ref"><a href="#fn:112" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ahmad Moghimi, Gorka Irazoqui, and Thomas Eisenbarth. 2017. Cachezoom: How SGX amplifies the power of cache attacks. In Cryptographic Hardware and Embedded Systems–CHES 2017: 19th International Conference, Taipei, Taiwan, September 25-28, 2017, Proceedings. Springer, 69–90.">[112]</span></a></sup> <sup id="fnref:113" class="footnote-ref"><a href="#fn:113" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ahmad Moghimi, Jan Wichelmann, Thomas Eisenbarth, and Berk Sunar. 2019. Memjam: A false dependency attack against constant-time crypto implementations. International Journal of Parallel Programming 47 (2019), 538–570.">[113]</span></a></sup> <sup id="fnref:140" class="footnote-ref"><a href="#fn:140" rel="footnote"><span class="hint--top hint--rounded" aria-label="Michael Schwarz, Samuel Weiser, Daniel Gruss, Clémentine Maurice, and Stefan Mangard. 2017. Malware guard extension: Using SGX to conceal cache attacks. In Detection of Intrusions and Malware, and Vulnerability Assessment: 14th International Conference, DIMVA 2017, Bonn, Germany, July 6-7, 2017, Proceedings 14. Springer, 3–24.">[140]</span></a></sup> 表明，SGX 飞地与任何其他软件应用程序一样容易受到相同的缓存攻击。事实上，由于 SGX 威胁模型中增强的攻击者，它们可能更容易受到攻击。几篇论文 <sup id="fnref:14" class="footnote-ref"><a href="#fn:14" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ferdinand Brasser, Urs Müller, Alexandra Dmitrienko, Kari Kostiainen, Srdjan Capkun, and Ahmad-Reza Sadeghi. 2017. Software grand exposure:SGX cache attacks are practical. In 11th USENIX workshop on offensive technologies (WOOT 17).">[14]</span></a></sup> <sup id="fnref:47" class="footnote-ref"><a href="#fn:47" rel="footnote"><span class="hint--top hint--rounded" aria-label="Johannes Götzfried, Moritz Eckert, Sebastian Schinzel, and Tilo Müller. 2017. Cache attacks on Intel SGX. In Proceedings of the 10th European Workshop on Systems Security. 1–6.">[47]</span></a></sup> <sup id="fnref:112" class="footnote-ref"><a href="#fn:112" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ahmad Moghimi, Gorka Irazoqui, and Thomas Eisenbarth. 2017. Cachezoom: How SGX amplifies the power of cache attacks. In Cryptographic Hardware and Embedded Systems–CHES 2017: 19th International Conference, Taipei, Taiwan, September 25-28, 2017, Proceedings. Springer, 69–90.">[112]</span></a></sup> <sup id="fnref:140" class="footnote-ref"><a href="#fn:140" rel="footnote"><span class="hint--top hint--rounded" aria-label="Michael Schwarz, Samuel Weiser, Daniel Gruss, Clémentine Maurice, and Stefan Mangard. 2017. Malware guard extension: Using SGX to conceal cache attacks. In Detection of Intrusions and Malware, and Vulnerability Assessment: 14th International Conference, DIMVA 2017, Bonn, Germany, July 6-7, 2017, Proceedings 14. Springer, 3–24.">[140]</span></a></sup> 利用 Prime+Probe 方法利用 L1 缓存和共享 LLC 作为攻击面。 Dall 等人 <sup id="fnref:30" class="footnote-ref"><a href="#fn:30" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fergus Dall, Gabrielle De Micheli, Thomas Eisenbarth, Daniel Genkin, Nadia Heninger, Ahmad Moghimi, and Yuval Yarom. 2018. Cachequote: Efficiently recovering long-term secrets of SGX EPID via cache attacks. (2018).">[30]</span></a></sup> 采取了略有不同的方法，他们在英特尔的配置区域上使用 Prime+Probe，从而使英特尔自己能够破坏增强隐私 ID (EPID) 不可链接性属性。Memjam <sup id="fnref:113" class="footnote-ref"><a href="#fn:113" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ahmad Moghimi, Jan Wichelmann, Thomas Eisenbarth, and Berk Sunar. 2019. Memjam: A false dependency attack against constant-time crypto implementations. International Journal of Parallel Programming 47 (2019), 538–570.">[113]</span></a></sup> 利用由 L1 缓存的 4K 别名引起的读写错误依赖关系来进行 Evict+Time 式攻击。</p><h3 id="6-1-3-分支预测攻击"><a href="#6-1-3-分支预测攻击" class="headerlink" title="6.1.3 分支预测攻击"></a>6.1.3 分支预测攻击</h3><p>与基于地址转换和基于缓存的攻击相比，分支预测攻击提供了更详细的利用率级别。它们以分支预测单元为目标，包括分支目标缓冲区 (BTB) <sup id="fnref:20" class="footnote-ref"><a href="#fn:20" rel="footnote"><span class="hint--top hint--rounded" aria-label="Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H Lai. 2019. Sgxpectre: Stealing intel secrets from sgx enclaves via speculative execution. In 2019 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 142–157.">[20]</span></a></sup> <sup id="fnref:88" class="footnote-ref"><a href="#fn:88" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sangho Lee, Ming-Wei Shih, Prasun Gera, Taesoo Kim, Hyesoon Kim, and Marcus Peinado. 2017. Inferring fine-grained control flow inside SGX enclaves with branch shadowing. In 26th USENIX Security Symposium (USENIX Security 17). 557–574.">[88]</span></a></sup>、页面历史表 (PHT) <sup id="fnref:39" class="footnote-ref"><a href="#fn:39" rel="footnote"><span class="hint--top hint--rounded" aria-label="Dmitry Evtyushkin, Ryan Riley, Nael CSE Abu-Ghazaleh, ECE, and Dmitry Ponomarev. 2018. Branchscope: A new side-channel attack on directional branch predictor. ACM SIGPLAN Notices 53, 2 (2018), 693–707.">[39]</span></a></sup> <sup id="fnref:61" class="footnote-ref"><a href="#fn:61" rel="footnote"><span class="hint--top hint--rounded" aria-label="Tianlin Huo, Xiaoni Meng, Wenhao Wang, Chunliang Hao, Pei Zhao, Jian Zhai, and Mingshu Li. 2020. Bluethunder: A 2-level directional predictor based side-channel attack against sgx. IACR Transactions on Cryptographic Hardware and Embedded Systems (2020), 321–347.">[61]</span></a></sup> 和返回堆栈缓冲区 (RSB) <sup id="fnref:84" class="footnote-ref"><a href="#fn:84" rel="footnote"><span class="hint--top hint--rounded" aria-label="Esmaeil Mohammadian Koruyeh, Khaled N Khasawneh, Chengyu Song, and Nael Abu-Ghazaleh. 2018. Spectre returns! speculation attacks using the return stack buffer. In 12th USENIX Workshop on Offensive Technologies (WOOT 18).">[84]</span></a></sup>。攻击者利用 BTB 来确定受害者是否采取了特定的分支指令。PHT 攻击试图引发受害者和攻击者进程之间的分支冲突，随后推断受害者进程分支的方向。 RSB 攻击依靠污染 RSB 来引发错误推测，从而导致泄漏。</p><h3 id="6-1-4-瞬态执行攻击"><a href="#6-1-4-瞬态执行攻击" class="headerlink" title="6.1.4 瞬态执行攻击"></a>6.1.4 瞬态执行攻击</h3><p>瞬态执行攻击利用指令的无序和推测执行（总结于第 2.2 节），也在 SGX 的背景下进行了研究。前面提到的 BTB 和 RSB 攻击 <sup id="fnref:20" class="footnote-ref"><a href="#fn:20" rel="footnote"><span class="hint--top hint--rounded" aria-label="Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H Lai. 2019. Sgxpectre: Stealing intel secrets from sgx enclaves via speculative execution. In 2019 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 142–157.">[20]</span></a></sup> <sup id="fnref:84" class="footnote-ref"><a href="#fn:84" rel="footnote"><span class="hint--top hint--rounded" aria-label="Esmaeil Mohammadian Koruyeh, Khaled N Khasawneh, Chengyu Song, and Nael Abu-Ghazaleh. 2018. Spectre returns! speculation attacks using the return stack buffer. In 12th USENIX Workshop on Offensive Technologies (WOOT 18).">[84]</span></a></sup> 也属于此类攻击，源自 Spectre <sup id="fnref:81" class="footnote-ref"><a href="#fn:81" rel="footnote"><span class="hint--top hint--rounded" aria-label="Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, et al. 2020. Spectre attacks: Exploiting speculative execution. Commun. ACM 63, 7 (2020), 93–101.">[81]</span></a></sup>。此外，Foreshadow 攻击 <sup id="fnref:156" class="footnote-ref"><a href="#fn:156" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F Wenisch, Yuval Yarom, and Raoul Strackx. 2018. Foreshadow: Extracting the keys to the intel SGX kingdom with transient Out-of-Order execution. In 27th USENIX Security Symposium (USENIX Security 18). 991–1008.">[156]</span></a></sup> 通过使用类似 Meltdown 的技术针对 SGX，破坏了飞地执行机密性。</p><p>虽然 MDS 攻击 <sup id="fnref:17" class="footnote-ref"><a href="#fn:17" rel="footnote"><span class="hint--top hint--rounded" aria-label="Claudio Canella, Daniel Genkin, Lukas Giner, Daniel Gruss, Moritz Lipp, Marina Minkin, Daniel Moghimi, Frank Piessens, Michael Schwarz, Berk Sunar, et al. 2019. Fallout: Leaking data on meltdown-resistant cpus. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 769–784.">[17]</span></a></sup> <sup id="fnref:139" class="footnote-ref"><a href="#fn:139" rel="footnote"><span class="hint--top hint--rounded" aria-label="Michael Schwarz, Moritz Lipp, Daniel Moghimi, Jo Van Bulck, Julian Stecklina, Thomas Prescher, and Daniel Gruss. 2019. ZombieLoad: Crossprivilege-boundary data sampling. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 753–768.">[139]</span></a></sup> <sup id="fnref:161" class="footnote-ref"><a href="#fn:161" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stephan Van Schaik, Alyssa Milburn, Sebastian Österlund, Pietro Frigo, Giorgi Maisuradze, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. 2019. RIDL: Rogue in-flight data load. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 88–105.">[161]</span></a></sup> 也利用推测和无序执行，但它们主要利用目标微架构的各种特定于实现且未记录的中间缓冲区的信息泄漏。</p><p>SGAxe <sup id="fnref:160" class="footnote-ref"><a href="#fn:160" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stephan Van Schaik, Andrew Kwong, Daniel Genkin, and Yuval Yarom. 2020. SGAxe: How SGX fails in practice.">[160]</span></a></sup> 和 Crosstalk <sup id="fnref:132" class="footnote-ref"><a href="#fn:132" rel="footnote"><span class="hint--top hint--rounded" aria-label="Hany Ragab, Alyssa Milburn, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. 2021. Crosstalk: Speculative data leaks across cores are real. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 1852–1867.">[132]</span></a></sup> 扩展了 MDS，以便从 SGX 飞地中提取私钥。</p><h3 id="6-1-5-基于软件的故障注入和侧信道攻击"><a href="#6-1-5-基于软件的故障注入和侧信道攻击" class="headerlink" title="6.1.5 基于软件的故障注入和侧信道攻击"></a>6.1.5 基于软件的故障注入和侧信道攻击</h3><p>在故障注入攻击中，攻击者通过引入恶意故障来破坏系统的正常运行，然后从故障执行中获取秘密信息。</p><p>基于软件的故障攻击将威胁模型从需要物理访问目标设备的本地攻击者扩展到仅具有本地代码执行能力的潜在远程攻击者。多项研究 <sup id="fnref:77" class="footnote-ref"><a href="#fn:77" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zijo Kenjar, Tommaso Frassetto, David Gens, Michael Franz, and Ahmad-Reza Sadeghi. 2020. V0LTpwn: Attacking x86 processor integrity from software. In 29th USENIX Security Symposium (USENIX Security 20). 1445–1461.">[77]</span></a></sup> <sup id="fnref:117" class="footnote-ref"><a href="#fn:117" rel="footnote"><span class="hint--top hint--rounded" aria-label="Kit Murdock, David Oswald, Flavio D Garcia, Jo Van Bulck, Daniel Gruss, and Frank Piessens. 2020. Plundervolt: Software-based fault injection attacks against Intel SGX. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1466–1482.">[117]</span></a></sup> <sup id="fnref:131" class="footnote-ref"><a href="#fn:131" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pengfei Qiu, Dongsheng Wang, Yongqiang Lyu, Ruidong Tian, Chunlu Wang, and Gang Qu. 2020. Voltjockey: A new dynamic voltage scaling-based fault injection attack on intel sgx. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 40, 6 (2020), 1130–1143.">[131]</span></a></sup> 利用 x86 CPU 上的特权 DVFS 可靠地破坏飞地计算，从而损害飞地的机密性和完整性。Chen 和 Oswald <sup id="fnref:22" class="footnote-ref"><a href="#fn:22" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zitai Chen and David Oswald. 2023. PMFault: Faulting and Bricking Server CPUs through Management Interfaces: Or: A Modern Example of Halt and Catch Fire. IACR Transactions on Cryptographic Hardware and Embedded Systems 2023, 2 (Mar. 2023), 1–23.">[22]</span></a></sup> 表明，对 SGX 的软件故障攻击也可以通过转向 Supermicro 服务器系统上的管理芯片来发起，甚至可以永久损坏主机 CPU。除了基于电压缩放的攻击外，SGX-Bomb <sup id="fnref:69" class="footnote-ref"><a href="#fn:69" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yeongjin Jang, Jaehyuk Lee, Sangho Lee, and Taesoo Kim. 2017. SGX-Bomb: Locking down the processor via Rowhammer attack. In Proceedings of the 2nd Workshop on System Software for Trusted Execution. 1–6.">[69]</span></a></sup> 还利用 Rowhammer 漏洞在飞地内存中引发位翻转，导致数据完整性检查失败并随后导致系统锁定。</p><p>除了这些故障注入攻击外，Lipp 等人 <sup id="fnref:98" class="footnote-ref"><a href="#fn:98" rel="footnote"><span class="hint--top hint--rounded" aria-label="Moritz Lipp, Andreas Kogler, David Oswald, Michael Schwarz, Catherine Easdon, Claudio Canella, and Daniel Gruss. 2021. PLATYPUS: Softwarebased power side-channel attacks on x86. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 355–371.">[98]</span></a></sup> 还利用对英特尔运行平均功率限制 (RAPL) 接口的非特权访问来利用侧信道攻击。该接口揭示了与功耗相关的值，从而创建了一个可在英特尔服务器、台式机和笔记本电脑 CPU 上利用的电源侧通道。Wang 等人 <sup id="fnref:169" class="footnote-ref"><a href="#fn:169" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yingchen Wang, Riccardo Paccagnella, Elizabeth Tang He, Hovav Shacham, Christopher W. Fletcher, and David Kohlbrenner. 2022. Hertzbleed: Turning Power Side-Channel Attacks Into Remote Timing Attacks on x86. In 31st USENIX Security Symposium (USENIX Security 22). Boston, MA, 679–697.">[169]</span></a></sup> 表明，可以通过频率缩放等间接渠道测量功率泄漏，而 Liu 等人 <sup id="fnref:100" class="footnote-ref"><a href="#fn:100" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chen Liu, Abhishek Chakraborty, Nikhil Chawla, and Neer Roggel. 2022. Frequency Throttling Side-Channel Attack. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 1977–1991.">[100]</span></a></sup> 使用节流等相关功能来泄露 SGX 飞地的机密。</p><h3 id="6-1-6-基于硬件的攻击"><a href="#6-1-6-基于硬件的攻击" class="headerlink" title="6.1.6 基于硬件的攻击"></a>6.1.6 基于硬件的攻击</h3><p>除了基于软件的故障注入攻击外，Chen 等人 <sup id="fnref:22" class="footnote-ref"><a href="#fn:22" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zitai Chen and David Oswald. 2023. PMFault: Faulting and Bricking Server CPUs through Management Interfaces: Or: A Modern Example of Halt and Catch Fire. IACR Transactions on Cryptographic Hardware and Embedded Systems 2023, 2 (Mar. 2023), 1–23.">[22]</span></a></sup> <sup id="fnref:23" class="footnote-ref"><a href="#fn:23" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zitai Chen, Georgios Vasilakis, Kit Murdock, Edward Dean, David Oswald, and Flavio D Garcia. 2021. VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface. In 30th USENIX Security Symposium (USENIX Security 21). 699–716.">[23]</span></a></sup> 还探索了针对 SGX 飞地的硬件级故障注入攻击。“VoltPillager”是一种低成本工具，可在 CPU 和电压调节器之间的串行电压识别 (SVID) 总线上注入消息，从而破坏英特尔 SGX 飞地的机密性和完整性 <sup id="fnref:23" class="footnote-ref"><a href="#fn:23" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zitai Chen, Georgios Vasilakis, Kit Murdock, Edward Dean, David Oswald, and Flavio D Garcia. 2021. VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface. In 30th USENIX Security Symposium (USENIX Security 21). 699–716.">[23]</span></a></sup>。 Chen 和 Oswald 后来证明，通过电源管理总线 (PMBus) 降压同样可以破坏 SGX 飞地的完整性，从而绕过英特尔针对先前软件降压攻击的对策 <sup id="fnref:77" class="footnote-ref"><a href="#fn:77" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zijo Kenjar, Tommaso Frassetto, David Gens, Michael Franz, and Ahmad-Reza Sadeghi. 2020. V0LTpwn: Attacking x86 processor integrity from software. In 29th USENIX Security Symposium (USENIX Security 20). 1445–1461.">[77]</span></a></sup> <sup id="fnref:117" class="footnote-ref"><a href="#fn:117" rel="footnote"><span class="hint--top hint--rounded" aria-label="Kit Murdock, David Oswald, Flavio D Garcia, Jo Van Bulck, Daniel Gruss, and Frank Piessens. 2020. Plundervolt: Software-based fault injection attacks against Intel SGX. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1466–1482.">[117]</span></a></sup> <sup id="fnref:131" class="footnote-ref"><a href="#fn:131" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pengfei Qiu, Dongsheng Wang, Yongqiang Lyu, Ruidong Tian, Chunlu Wang, and Gang Qu. 2020. Voltjockey: A new dynamic voltage scaling-based fault injection attack on intel sgx. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 40, 6 (2020), 1130–1143.">[131]</span></a></sup>。“MEMBUSTER” <sup id="fnref:85" class="footnote-ref"><a href="#fn:85" rel="footnote"><span class="hint--top hint--rounded" aria-label="Dayeol Lee, Dongha Jung, Ian T. Fang, Chia che Tsai, and Raluca Ada Popa. 2020. An Off-Chip Attack on Hardware Enclaves via the Memory Bus. In 29th USENIX Security Symposium (USENIX Security ’20). 487–504.">[85]</span></a></sup> 引入了一种片外攻击，通过监听内存总线（使用高规格、昂贵的实验室设备）、提取内存访问模式并使用关键页面白名单和缓存压缩等技术增加缓存未命中来破坏 SGX 飞地的机密性。</p><h3 id="6-1-7-基于接口的攻击"><a href="#6-1-7-基于接口的攻击" class="headerlink" title="6.1.7 基于接口的攻击"></a>6.1.7 基于接口的攻击</h3><p>如果 SGX 飞地未能严格遵守受信任和不受信任代码之间的安全接口，则可能会危及安全性。尽管有精心设计的开源软件开发工具包 (SDK)，但 Van Bulck 等人 <sup id="fnref:157" class="footnote-ref"><a href="#fn:157" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jo Van Bulck, David Oswald, Eduard Marin, Abdulla Aldoseri, Flavio D Garcia, and Frank Piessens. 2019. A tale of two worlds: Assessing the vulnerability of enclave shielding runtimes. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 1741–1758.">[157]</span></a></sup> 发现了应用程序二进制接口 (ABI) 和 API 中的几个清理漏洞，导致内存安全和侧信道漏洞。 Alder 等人 <sup id="fnref:5" class="footnote-ref"><a href="#fn:5" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fritz Alder, Jo Van Bulck, David Oswald, and Frank Piessens. 2020. Faulty point unit: ABI poisoning attacks on Intel SGX. In Proceedings of the 36th Annual Computer Security Applications Conference. 415–427.">[5]</span></a></sup> 通过 ABI 探索了影响 SGX 安全区中浮点计算的攻击面，表明控制和状态寄存器并不总是得到正确清理。</p><p>最近，人们开始关注 SGX 的符号执行工具 <sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fritz Alder, Lesly-Ann Daniel, David Oswald, Frank Piessens, and Jo Van Bulck. 2024. Pandora: Principled symbolic validation of Intel SGX enclave runtimes. In 45th IEEE Symposium on Security and Privacy (S&P).">[4]</span></a></sup> <sup id="fnref:26" class="footnote-ref"><a href="#fn:26" rel="footnote"><span class="hint--top hint--rounded" aria-label="Tobias Cloosters, Michael Rodler, and Lucas Davi. 2020. TeeRex: Discovery and exploitation of memory corruption vulnerabilities in SGX enclaves. In 29th USENIX Security Symposium (USENIX Security 20). 841–858.">[26]</span></a></sup> <sup id="fnref:78" class="footnote-ref"><a href="#fn:78" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mustakimur Rahman Khandaker, Yueqiang Cheng, Zhi Wang, and Tao Wei. 2020. COIN attacks: On insecurity of enclave untrusted interfaces in SGX. In Proceedings of the 25th International Conference on Architectural Support for Programming Languages and Operating Systems. 971–985.">[78]</span></a></sup>。Pandora <sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Fritz Alder, Lesly-Ann Daniel, David Oswald, Frank Piessens, and Jo Van Bulck. 2024. Pandora: Principled symbolic validation of Intel SGX enclave runtimes. In 45th IEEE Symposium on Security and Privacy (S&P).">[4]</span></a></sup> 支持与运行时无关的符号执行精确认证的安全区二进制文件，并验证安全区屏蔽运行时。Pandora 可以在 11 个不同的 SGX 屏蔽运行时中自主发现 200 个新的和 69 个已知的易受攻击的代码位置。</p><h3 id="6-1-8-对策"><a href="#6-1-8-对策" class="headerlink" title="6.1.8 对策"></a>6.1.8 对策</h3><p>在本节中，我们根据先前的调查 <sup id="fnref:41" class="footnote-ref"><a href="#fn:41" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shufan Fei, Zheng Yan, Wenxiu Ding, and Haomeng Xie. 2021. Security vulnerabilities of SGX and countermeasures: A survey. ACM Computing Surveys (CSUR) 54, 6 (2021), 1–36.">[41]</span></a></sup> <sup id="fnref:123" class="footnote-ref"><a href="#fn:123" rel="footnote"><span class="hint--top hint--rounded" aria-label="Alexander Nilsson, Pegah Nikbakht Bideh, and Joakim Brorsson. 2020. A survey of published attacks on Intel SGX. arXiv preprint arXiv:2006.13598 (2020).">[123]</span></a></sup> 和我们总结的攻击论文中提出的潜在解决方案，回顾和分类最相关的对策。</p><ol><li><strong>系统&#x2F;微代码级对策：</strong>CPU 的复杂指令通常由称为微代码的低级软件管理，而不是完全在硬件中实现。因此，英特尔可以发布微代码更新，这通常是最有效的方法。例如，为了应对基于 DVFS 的攻击（如 Plundervolt <sup id="fnref:117" class="footnote-ref"><a href="#fn:117" rel="footnote"><span class="hint--top hint--rounded" aria-label="Kit Murdock, David Oswald, Flavio D Garcia, Jo Van Bulck, Daniel Gruss, and Frank Piessens. 2020. Plundervolt: Software-based fault injection attacks against Intel SGX. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1466–1482.">[117]</span></a></sup>），英特尔发布了微代码更新，通过 MSR 0x150 完全禁用软件电压调节接口。</li><li><strong>基于编译器的对策：</strong>除了英特尔的解决方案外，基于编译器的方法也很有效。确定性多路复用 <sup id="fnref:147" class="footnote-ref"><a href="#fn:147" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shweta Shinde, Zheng Leong Chua, Viswesh Narayanan, and Prateek Saxena. 2016. Preventing page faults from telling your secrets. In Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security. 317–328.">[147]</span></a></sup> 通过主动访问预定顺序中的所有数据和代码，确保页面错误访问模式无论输入值如何都保持一致。 “T-SGX” <sup id="fnref:146" class="footnote-ref"><a href="#fn:146" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ming-Wei Shih, Sangho Lee, Taesoo Kim, and Marcus Peinado. 2017. T-SGX: Eradicating Controlled-Channel Attacks Against Enclave Programs.. In NDSS.">[146]</span></a></sup> 使用英特尔的事务同步扩展 (TSX) 将异常和中断重定向到特定页面，如果检测到页面错误，则终止程序。Chen 等人 <sup id="fnref:21" class="footnote-ref"><a href="#fn:21" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sanchuan Chen, Xiaokuan Zhang, Michael K Reiter, and Yinqian Zhang. 2017. Detecting privileged side-channel attacks in shielded execution with Déjá Vu. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. 7–18.">[21]</span></a></sup> 提出使用可靠的时间测量进行屏蔽执行，以检查目标程序的执行时间。“Cloak” <sup id="fnref:48" class="footnote-ref"><a href="#fn:48" rel="footnote"><span class="hint--top hint--rounded" aria-label="Daniel Gruss, Julian Lettner, Felix Schuster, Olya Ohrimenko, Istvan Haller, and Manuel Costa. 2017. Strong and efficient cache {Side-Channel} protection using hardware transactional memory. In 26th USENIX Security Symposium (USENIX Security 17). 217–233.">[48]</span></a></sup> 使用硬件事务内存 (HTM) 来防止恶意缓存观察。同样，故障检测 <sup id="fnref:149" class="footnote-ref"><a href="#fn:149" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chad Spensky, Aravind Machiry, Nathan Burow, Hamed Okhravi, Rick Housley, Zhongshu Gu, Hani Jamjoom, Christopher Kruegel, and Giovanni Vigna. 2021. Glitching demystified: analyzing control-flow-based glitching attacks and defenses. In 2021 51st Annual IEEE/IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 400–412.">[149]</span></a></sup> 可以帮助缓解基于 DVFS 的故障注入攻击。</li><li><strong>随机化：</strong>“SGX-Shield” <sup id="fnref:141" class="footnote-ref"><a href="#fn:141" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jaebaek Seo, Byoungyoung Lee, Seong Min Kim, Ming-Wei Shih, Insik Shin, Dongsu Han, and Taesoo Kim. 2017. SGX-shield: Enabling address space layout randomization for SGX programs.. In NDSS.">[141]</span></a></sup> 利用 ASLR 创建一个安全的 enclave 加载器，秘密随机化内存空间布局，向攻击者隐藏敏感操作。Hosseinzadeh 等人 <sup id="fnref:58" class="footnote-ref"><a href="#fn:58" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shohreh Hosseinzadeh, Hans Liljestrand, Ville Leppänen, and Andrew Paverd. 2018. Mitigating branch-shadowing attacks on intel sgx using control flow randomization. In Proceedings of the 3rd Workshop on System Software for Trusted Execution. 42–47.">[58]</span></a></sup> 提出运行时控制流随机化，作为 llvm 上的编译器扩展实现。“DR.SGX” <sup id="fnref:11" class="footnote-ref"><a href="#fn:11" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ferdinand Brasser, Srdjan Capkun, Alexandra Dmitrienko, Tommaso Frassetto, Kari Kostiainen, and Ahmad-Reza Sadeghi. 2019. DR. SGX: Automated and adjustable side-channel protection for SGX using data location randomization. In Proceedings of the 35th Annual Computer Security Applications Conference. 788–800.">[11]</span></a></sup> 通过排列数据位置来破坏内存观察。</li><li><strong>应用程序&#x2F;源代码设计：</strong>最后，开发人员可以以防侧信道的方式设计安全区应用程序。早期的作品如“OBFUSCURO”<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="Adil Ahmad, Byunggill Joe, Yuan Xiao, Yinqian Zhang, Insik Shin, and Byoungyoung Lee. 2019. OBFUSCURO: A commodity obfuscation engine on Intel SGX. In Network and Distributed System Security Symposium.">[1]</span></a></sup>，使用 Oblivious RAM (ORAM) 保护来强制操作，以防止攻击者推断访问模式。几种方案 <sup id="fnref:126" class="footnote-ref"><a href="#fn:126" rel="footnote"><span class="hint--top hint--rounded" aria-label="Olga Ohrimenko, Felix Schuster, Cédric Fournet, Aastha Mehta, Sebastian Nowozin, Kapil Vaswani, and Manuel Costa. 2016. Oblivious Multi-Party machine learning on trusted processors. In 25th USENIX Security Symposium (USENIX Security 16). 619–636.">[126]</span></a></sup> <sup id="fnref:130" class="footnote-ref"><a href="#fn:130" rel="footnote"><span class="hint--top hint--rounded" aria-label="Rishabh Poddar, Ganesh Ananthanarayanan, Srinath Setty, Stavros Volos, and Raluca Ada Popa. 2020. Visor:Privacy-Preserving video analytics as a cloud service. In 29th USENIX Security Symposium (USENIX Security 20). 1039–1056.">[130]</span></a></sup> <sup id="fnref:165" class="footnote-ref"><a href="#fn:165" rel="footnote"><span class="hint--top hint--rounded" aria-label="Qifan Wang, Shujie Cui, Lei Zhou, Ocean Wu, Yonghua Zhu, and Giovanni Russello. 2022. Enclavetree: Privacy-preserving data stream training and inference using tee. In Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security. 741–755.">[165]</span></a></sup> 利用 x86_64 汇编中实现的 Oblivious 原语来设计数据无关的应用程序。这些原语专门在处理器专用的寄存器上操作，确保对安全区外部代码隐藏的内容以及任何寄存器到寄存器的数据操作都是数据无关的。</li></ol><h2 id="6-2-Arm-TrustZone-的安全性"><a href="#6-2-Arm-TrustZone-的安全性" class="headerlink" title="6.2 Arm TrustZone 的安全性"></a>6.2 Arm TrustZone 的安全性</h2><h3 id="6-2-1-构建-BUG"><a href="#6-2-1-构建-BUG" class="headerlink" title="6.2.1 构建 BUG"></a>6.2.1 构建 BUG</h3><p>Cerdeira 等人 <sup id="fnref:19" class="footnote-ref"><a href="#fn:19" rel="footnote"><span class="hint--top hint--rounded" aria-label="David Cerdeira, Nuno Santos, Pedro Fonseca, and Sandro Pinto. 2020. Sok: Understanding the prevailing security vulnerabilities in trustzone-assisted tee systems. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1416–1432.">[19]</span></a></sup> 检查了从公共通用漏洞和暴露 (CVE) 数据库和供应商公告报告中获得的错误报告，将它们分为验证错误、功能错误和外部错误。这些错误无处不在，经常被利用来提升权限，使攻击者能够完全劫持 Qualcomm <sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><span class="hint--top hint--rounded" aria-label="Gal Beniamini. 2016. TrustZone Kernel Privilege Escalation (CVE-2016-2431).">[10]</span></a></sup> 和华为 <sup id="fnref:144" class="footnote-ref"><a href="#fn:144" rel="footnote"><span class="hint--top hint--rounded" aria-label="Di Shen. 2015. Exploiting trustzone on android. Black Hat USA 2 (2015), 267–280.">[144]</span></a></sup> 设备中的内核或破坏 Samsung Pay <sup id="fnref:82" class="footnote-ref"><a href="#fn:82" rel="footnote"><span class="hint--top hint--rounded" aria-label="Daniel Komaromy. 2018. Unbox Your Phone. https://medium.com/taszksec/unbox-your-phone-part-i-331bbf44c30c">[82]</span></a></sup> 等客户端应用程序。</p><h3 id="6-2-2-基于缓存的攻击"><a href="#6-2-2-基于缓存的攻击" class="headerlink" title="6.2.2 基于缓存的攻击"></a>6.2.2 基于缓存的攻击</h3><p>鉴于在启用 TrustZone 的处理器中缓存在 NW 和 SW 之间共享，一些研究利用由这种缓存一致性引起的争用来提取敏感信息 <sup id="fnref:25" class="footnote-ref"><a href="#fn:25" rel="footnote"><span class="hint--top hint--rounded" aria-label="Haehyun Cho, Penghui Zhang, Donguk Kim, Jinbum Park, Choong-Hoon Lee, Ziming Zhao, Adam Doupé, and Gail-Joon Ahn. 2018. Prime+count: Novel cross-world covert channels on arm trustzone. In Proceedings of the 34th Annual Computer Security Applications Conference. 441–452.">[25]</span></a></sup> <sup id="fnref:51" class="footnote-ref"><a href="#fn:51" rel="footnote"><span class="hint--top hint--rounded" aria-label="Roberto Guanciale, Hamed Nemati, Christoph Baumann, and Mads Dam. 2016. Cache storage channels: Alias-driven attacks and verified countermeasures. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 38–55.">[51]</span></a></sup> <sup id="fnref:97" class="footnote-ref"><a href="#fn:97" rel="footnote"><span class="hint--top hint--rounded" aria-label="Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and Stefan Mangard. 2016. ARMageddon: Cache attacks on mobile devices. In 25th USENIX Security Symposium (USENIX Security 16). 549–564.">[97]</span></a></sup> <sup id="fnref:183" class="footnote-ref"><a href="#fn:183" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ning Zhang, He Sun, Kun Sun, Wenjing Lou, and Y Thomas Hou. 2016. CacheKit: Evading memory introspection using cache incoherence. In 2016 IEEE European Symposium on Security and Privacy (EuroS&P). IEEE, 337–352.">[183]</span></a></sup> <sup id="fnref:185" class="footnote-ref"><a href="#fn:185" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ning Zhang, Kun Sun, Deborah Shands, Wenjing Lou, and Y Thomas Hou. 2016. Truspy: Cache side-channel information leakage from the secure world on arm devices. Cryptology ePrint Archive (2016).">[185]</span></a></sup>。几位作者 <sup id="fnref:25" class="footnote-ref"><a href="#fn:25" rel="footnote"><span class="hint--top hint--rounded" aria-label="Haehyun Cho, Penghui Zhang, Donguk Kim, Jinbum Park, Choong-Hoon Lee, Ziming Zhao, Adam Doupé, and Gail-Joon Ahn. 2018. Prime+count: Novel cross-world covert channels on arm trustzone. In Proceedings of the 34th Annual Computer Security Applications Conference. 441–452.">[25]</span></a></sup> <sup id="fnref:97" class="footnote-ref"><a href="#fn:97" rel="footnote"><span class="hint--top hint--rounded" aria-label="Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and Stefan Mangard. 2016. ARMageddon: Cache attacks on mobile devices. In 25th USENIX Security Symposium (USENIX Security 16). 549–564.">[97]</span></a></sup> <sup id="fnref:185" class="footnote-ref"><a href="#fn:185" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ning Zhang, Kun Sun, Deborah Shands, Wenjing Lou, and Y Thomas Hou. 2016. Truspy: Cache side-channel information leakage from the secure world on arm devices. Cryptology ePrint Archive (2016).">[185]</span></a></sup> 使用 Prime+Probe 方法来监视 TrustZone 内的缓存活动。</p><h3 id="6-2-3-分支预测攻击"><a href="#6-2-3-分支预测攻击" class="headerlink" title="6.2.3 分支预测攻击"></a>6.2.3 分支预测攻击</h3><p>与前面提到的对英特尔 SGX 的攻击类似，分支预测器也可用于攻击 TrustZone。由于 BTB 在 NW 和 SW 之间共享，因此可以使用 Prime+Probe 等技术向 NW 泄露安全信息。例如，Ryan <sup id="fnref:133" class="footnote-ref"><a href="#fn:133" rel="footnote"><span class="hint--top hint--rounded" aria-label="Keegan Ryan. 2019. Hardware-backed heist: Extracting ECDSA keys from qualcomm’s trustzone. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 181–194.">[133]</span></a></sup> 成功地从高通硬件支持的密钥库中恢复了一个 256 位私钥。</p><h3 id="6-2-4-基于软件的故障注入攻击"><a href="#6-2-4-基于软件的故障注入攻击" class="headerlink" title="6.2.4 基于软件的故障注入攻击"></a>6.2.4 基于软件的故障注入攻击</h3><p>一些研究还将基于软件的故障注入攻击扩展到 TrustZone 或基于 TrustZone 的系统。“CLKSCREW” <sup id="fnref:154" class="footnote-ref"><a href="#fn:154" rel="footnote"><span class="hint--top hint--rounded" aria-label="Adrian Tang, Simha Sethumadhavan, and Salvatore Stolfo. 2017. CLKSCREW: Exposing the perils of Security-Oblivious energy management. In 26th USENIX Security Symposium (USENIX Security 17). 1057–1074.">[154]</span></a></sup> 利用对 DVFS 的操纵来诱导错误计算，以突破 TrustZone 硬件强制边界、提取密钥并绕过代码签名操作。</p><p>基于 Rowhammer 的攻击也已被改编以破坏 TrustZone 安全性。鉴于超频通常涉及以高频率运行处理器，而这相对容易检测和预防（例如，通过硬件频率锁定），“VoltJockey” <sup id="fnref:131" class="footnote-ref"><a href="#fn:131" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pengfei Qiu, Dongsheng Wang, Yongqiang Lyu, Ruidong Tian, Chunlu Wang, and Gang Qu. 2020. Voltjockey: A new dynamic voltage scaling-based fault injection attack on intel sgx. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 40, 6 (2020), 1130–1143.">[131]</span></a></sup> 采用不同的策略，通过操纵电压而不是频率来在受害核心上产生硬件故障。 Carru <sup id="fnref:18" class="footnote-ref"><a href="#fn:18" rel="footnote"><span class="hint--top hint--rounded" aria-label="Pierre Carru. 2017. Attack TrustZone using Rowhammer. https://grehack.fr/data/2017/slides/GreHack17_Attack_TrustZone_with_Rowhammer.pdf">[18]</span></a></sup> 使用位翻转绕过安全措施并访问安全内存，从而能够提取 RSA 密钥并破坏 TrustZone 提供的安全存储。</p><h3 id="6-2-5-对策"><a href="#6-2-5-对策" class="headerlink" title="6.2.5 对策"></a>6.2.5 对策</h3><p>在本节中，我们根据之前的调查 <sup id="fnref:19" class="footnote-ref"><a href="#fn:19" rel="footnote"><span class="hint--top hint--rounded" aria-label="David Cerdeira, Nuno Santos, Pedro Fonseca, and Sandro Pinto. 2020. Sok: Understanding the prevailing security vulnerabilities in trustzone-assisted tee systems. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1416–1432.">[19]</span></a></sup> 和总结的攻击论文中的潜在解决方案对对策进行回顾和分类。</p><p>在解决 Arm TrustZone 的架构防御问题时，一些研究工作 <sup id="fnref:13" class="footnote-ref"><a href="#fn:13" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ferdinand Brasser, David Gens, Patrick Jauernig, Ahmad-Reza Sadeghi, and Emmanuel Stapf. 2019. SANCTUARY: ARMing TrustZone with User-space Enclaves.. In NDSS.">[13]</span></a></sup> <sup id="fnref:150" class="footnote-ref"><a href="#fn:150" rel="footnote"><span class="hint--top hint--rounded" aria-label="He Sun, Kun Sun, Yuewu Wang, Jiwu Jing, and Haining Wang. 2015. Trustice: Hardware-assisted isolated computing environments on mobile devices. In 2015 45th Annual IEEE/IFIP International Conference on Dependable Systems and Networks. IEEE, 367–378.">[150]</span></a></sup> 增强了 TEE 组件之间的隔离粒度并减少了在 SW 中运行的代码量，从而降低了在 SW 内发生严重特权升级攻击的风险。对策 <sup id="fnref:67" class="footnote-ref"><a href="#fn:67" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jinsoo Jang and Brent Byunghoon Kang. 2018. Retrofitting the partially privileged mode for TEE communication channel protection. IEEE Transactions on Dependable and Secure Computing 17, 5 (2018), 1000–1014.">[67]</span></a></sup> <sup id="fnref:68" class="footnote-ref"><a href="#fn:68" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jin Soo Jang, Sunjune Kong, Minsu Kim, Daegyeong Kim, and Brent Byunghoon Kang. 2015. Secret: Secure channel between rich execution environment and trusted execution environment.. In NDSS. 1–15.">[68]</span></a></sup> 解决了从 NW 访问 TEE 资源时身份验证不足&#x2F;薄弱的弱点，以及用于跨 NW-SW 边界数据交换的共享内存可能不安全的问题。与英特尔 SGX 不同，TrustZone 缺乏内置的片上内存加密，这促使一些研究 <sup id="fnref:181" class="footnote-ref"><a href="#fn:181" rel="footnote"><span class="hint--top hint--rounded" aria-label="Min Hong Yun and Lin Zhong. 2019. Ginseng: Keeping Secrets in Registers When You Distrust the Operating System.. In NDSS.">[181]</span></a></sup> <sup id="fnref:184" class="footnote-ref"><a href="#fn:184" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ning Zhang, Kun Sun, Wenjing Lou, and Y Thomas Hou. 2016. Case: Cache-assisted secure execution on arm processors. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 72–90.">[184]</span></a></sup> 设计加密策略来弥补这一缺陷。为了进一步加强对 TEE 和 TA 二进制文件的完整性和身份的验证，一些研究 <sup id="fnref:42" class="footnote-ref"><a href="#fn:42" rel="footnote"><span class="hint--top hint--rounded" aria-label="Andrew Ferraiuolo, Andrew Baumann, Chris Hawblitzel, and Bryan Parno. 2017. Komodo: Using verification to disentangle secure-enclave hardware from software. In Proceedings of the 26th Symposium on Operating Systems Principles. 287–305.">[42]</span></a></sup> <sup id="fnref:89" class="footnote-ref"><a href="#fn:89" rel="footnote"><span class="hint--top hint--rounded" aria-label="Matthew Lentz, Rijurekha Sen, Peter Druschel, and Bobby Bhattacharjee. 2018. Secloak: Arm trustzone-based mobile peripheral control. In Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services. 1–13.">[89]</span></a></sup> 引入了额外的可信计算原语，例如增强型远程证明和密封存储。为了解决实现错误，“RustZone” <sup id="fnref:36" class="footnote-ref"><a href="#fn:36" rel="footnote"><span class="hint--top hint--rounded" aria-label="Eric Evenchick. 2018. Rustzone: Writing trusted applications in rust. Black Hat Asia (2018).">[36]</span></a></sup> 通过使用 Rust 实现 TA 来扩展 TrustZone，Rust 本身就提供了内存安全和线程安全。</p><p>通过在软件 <sup id="fnref:51" class="footnote-ref"><a href="#fn:51" rel="footnote"><span class="hint--top hint--rounded" aria-label="Roberto Guanciale, Hamed Nemati, Christoph Baumann, and Mads Dam. 2016. Cache storage channels: Alias-driven attacks and verified countermeasures. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 38–55.">[51]</span></a></sup> 中仔细实现加密算法或使用专用硬件 <sup id="fnref:97" class="footnote-ref"><a href="#fn:97" rel="footnote"><span class="hint--top hint--rounded" aria-label="Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and Stefan Mangard. 2016. ARMageddon: Cache attacks on mobile devices. In 25th USENIX Security Symposium (USENIX Security 16). 549–564.">[97]</span></a></sup>，可以缓解缓存侧信道攻击。缓存维护技术也可以有效缓解泄漏。例如，就 BTB 攻击而言，在 NW 和 SW 之间传输时刷新共享的微架构结构可以防止攻击通过 BTB 瞄准密钥。但是，正如 <sup id="fnref:133" class="footnote-ref"><a href="#fn:133" rel="footnote"><span class="hint--top hint--rounded" aria-label="Keegan Ryan. 2019. Hardware-backed heist: Extracting ECDSA keys from qualcomm’s trustzone. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 181–194.">[133]</span></a></sup> 在 Nexus 5X 固件中观察到的那样，L1 缓存没有被刷新，这使得基于 Prime+Probe 的攻击仍然可行。</p><p>针对基于 DVFS 的故障注入攻击的对策与针对 SGX 的对策类似。与针对 TrustZone 的其他攻击相比，Rowhammer 攻击相对容易缓解。它们依赖于在相邻的内存行中诱导位翻转，只有当非安全内存位于 SW 内的内存行旁边时，它们才可行。如果安全内存位于单独的内存存储设备上，Rowhammer 攻击就变得不切实际。</p><h2 id="6-3-AMD-SEV-的安全性"><a href="#6-3-AMD-SEV-的安全性" class="headerlink" title="6.3 AMD SEV 的安全性"></a>6.3 AMD SEV 的安全性</h2><h3 id="6-3-1-内存加密问题"><a href="#6-3-1-内存加密问题" class="headerlink" title="6.3.1 内存加密问题"></a>6.3.1 内存加密问题</h3><p>自 AMD SEV <sup id="fnref:6" class="footnote-ref"><a href="#fn:6" rel="footnote"><span class="hint--top hint--rounded" aria-label="AMD. 2023. AMD Secure Encrypted Virtualization (SEV). https://www.amd.com/en/developer/sev.html.">[6]</span></a></sup> 发布以来，许多攻击都针对其早期的内存安全机制 <sup id="fnref:15" class="footnote-ref"><a href="#fn:15" rel="footnote"><span class="hint--top hint--rounded" aria-label="Robert Buhren, Shay Gueron, Jan Nordholz, Jean-Pierre Seifert, and Julian Vetter. 2017. Fault attacks on encrypted general purpose compute platforms. In Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy. 197–204.">[15]</span></a></sup> <sup id="fnref:33" class="footnote-ref"><a href="#fn:33" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhao-Hui Du, Zhiwei Ying, Zhenke Ma, Yufei Mai, Phoebe Wang, Jesse Liu, and Jesse Fang. 2017. Secure encrypted virtualization is unsecure. arXiv preprint arXiv:1712.05090 (2017).">[33]</span></a></sup> <sup id="fnref:56" class="footnote-ref"><a href="#fn:56" rel="footnote"><span class="hint--top hint--rounded" aria-label="Felicitas Hetzelt and Robert Buhren. 2017. Security analysis of encrypted virtual machines. ACM SIGPLAN Notices 52, 7 (2017), 129–142.">[56]</span></a></sup> <sup id="fnref:114" class="footnote-ref"><a href="#fn:114" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mathias Morbitzer, Manuel Huber, Julian Horsch, and Sascha Wessel. 2018. SEVered: Subverting AMD’s virtual machine encryption. In Proceedings of the 11th European Workshop on Systems Security. 1–6.">[114]</span></a></sup>。Hetzelt 和 Buhren <sup id="fnref:56" class="footnote-ref"><a href="#fn:56" rel="footnote"><span class="hint--top hint--rounded" aria-label="Felicitas Hetzelt and Robert Buhren. 2017. Security analysis of encrypted virtual machines. ACM SIGPLAN Notices 52, 7 (2017), 129–142.">[56]</span></a></sup> 利用类似返回导向编程的攻击来利用未加密的 VM 控制块，从而实现对客户 VM 中加密内存的任意读写。此类漏洞已在 SEV-ES <sup id="fnref:76" class="footnote-ref"><a href="#fn:76" rel="footnote"><span class="hint--top hint--rounded" aria-label="David Kaplan. 2017. Protecting VM register state with SEV-ES. White paper (2017), 13.">[76]</span></a></sup> 中得到解决。Du 等人 <sup id="fnref:33" class="footnote-ref"><a href="#fn:33" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhao-Hui Du, Zhiwei Ying, Zhenke Ma, Yufei Mai, Phoebe Wang, Jesse Liu, and Jesse Fang. 2017. Secure encrypted virtualization is unsecure. arXiv preprint arXiv:1712.05090 (2017).">[33]</span></a></sup> 利用内存加密中的电子代码本 (ECB) 模式通过安装在客户 VM 上的 HTTP 服务器进行选择明文攻击。</p><p>Sevurity <sup id="fnref:174" class="footnote-ref"><a href="#fn:174" rel="footnote"><span class="hint--top hint--rounded" aria-label="Luca Wilke, Jan Wichelmann, Mathias Morbitzer, and Thomas Eisenbarth. 2020. Sevurity: No security without integrity: Breaking integrity-free memory encryption with minimal assumptions. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1483–1496.">[174]</span></a></sup> 利用 Xor-Encrypt-Xor (XEX) 模式中的漏洞将任意 2 字节指令插入加密内存，而 Morbitzer 等人 <sup id="fnref:114" class="footnote-ref"><a href="#fn:114" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mathias Morbitzer, Manuel Huber, Julian Horsch, and Sascha Wessel. 2018. SEVered: Subverting AMD’s virtual machine encryption. In Proceedings of the 11th European Workshop on Systems Security. 1–6.">[114]</span></a></sup> 通过操纵嵌套页表来破坏机密性，从而更改客户 VM 的虚拟内存。大多数这些攻击源于缺乏完整性保护，但 SEV-SNP <sup id="fnref:142" class="footnote-ref"><a href="#fn:142" rel="footnote"><span class="hint--top hint--rounded" aria-label="AMD Sev-Snp. 2020. Strengthening VM isolation with integrity protection and more. White Paper, January 53 (2020), 1450–1465.">[142]</span></a></sup> 通过反向映射表解决了这些问题。相反，“CIPHERLEAKS” <sup id="fnref:93" class="footnote-ref"><a href="#fn:93" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li, Yinqian Zhang, Huibo Wang, Kang Li, and Yueqiang Cheng. 2021. CIPHERLEAKS: Breaking Constant-time Cryptography on AMDSEV via the Ciphertext Side Channel. In 30th USENIX Security Symposium (USENIX Security 21). 717–732.">[93]</span></a></sup> 允许特权攻击者通过监视受害虚拟机密文的变化来推断客户虚拟机的执行状态或恢复某些明文。</p><p>作者强调，AMD 已确认 SEV-SNP 也容易受到 CIPHERLEAKS 攻击 <sup id="fnref:90" class="footnote-ref"><a href="#fn:90" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li. 2022. Understanding and Exploiting Design Flaws of AMD Secure Encrypted Virtualization. The Ohio State University.">[90]</span></a></sup>。</p><p>此外，“CROSSLINE”及其由 Li 等人 <sup id="fnref:90" class="footnote-ref"><a href="#fn:90" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li. 2022. Understanding and Exploiting Design Flaws of AMD Secure Encrypted Virtualization. The Ohio State University.">[90]</span></a></sup> <sup id="fnref:92" class="footnote-ref"><a href="#fn:92" rel="footnote">&lt;span class&#x3D;”hint–top hint–rounded” aria-label&#x3D;”Mengyuan Li, Yinqian Zhang, and Zhiqiang Lin. 2021. Crossline: Breaking” security-by-crash” based memory isolation in amd sev. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. 2937–2950.”&gt;[92]</span></a></sup> 编写的变体通过利用地址空间标识符 (ASID) 的不当使用来控制虚拟机对加密内存页面、缓存行和 TLB 条目的访问，从而提取受害虚拟机的内存内容。它们还通过毒害 TLB 条目来损害 SEV 虚拟机的完整性和机密性 <sup id="fnref:94" class="footnote-ref"><a href="#fn:94" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mengyuan Li, Yinqian Zhang, Huibo Wang, Kang Li, and Yueqiang Cheng. 2021. TLB Poisoning Attacks on AMD Secure Encrypted Virtualization. In Proceedings of the 37th Annual Computer Security Applications Conference. 609–619.">[94]</span></a></sup>。值得注意的是，SEV-SNP 有望解决这些问题，包括 TLB 滥用。</p><h3 id="6-3-2-基于软件的故障注入攻击"><a href="#6-3-2-基于软件的故障注入攻击" class="headerlink" title="6.3.2 基于软件的故障注入攻击"></a>6.3.2 基于软件的故障注入攻击</h3><p>Morbitzer 等人 <sup id="fnref:115" class="footnote-ref"><a href="#fn:115" rel="footnote"><span class="hint--top hint--rounded" aria-label="Mathias Morbitzer, Sergej Proskurin, Martin Radev, Marko Dorfhuber, and Erick Quintanar Salas. 2021. Severity: Code injection attacks against encrypted virtual machines. In 2021 IEEE Security and Privacy Workshops (SPW). IEEE, 444–455.">[115]</span></a></sup> 利用系统缺乏内存完整性保护，通过 I&#x2F;O 通道在 SEV VM 中注入故障并执行任意代码，使用虚拟机管理程序定位并触发加密有效负载的执行。但是，SEV-SNP <sup id="fnref:142" class="footnote-ref"><a href="#fn:142" rel="footnote"><span class="hint--top hint--rounded" aria-label="AMD Sev-Snp. 2020. Strengthening VM isolation with integrity protection and more. White Paper, January 53 (2020), 1450–1465.">[142]</span></a></sup> 可以通过反向映射表 (RMP) 缓解此问题。Buhren 等人 <sup id="fnref:16" class="footnote-ref"><a href="#fn:16" rel="footnote"><span class="hint--top hint--rounded" aria-label="Robert Buhren, Hans-Niklas Jacob, Thilo Krachenfels, and Jean-Pierre Seifert. 2021. One glitch to rule them all: Fault injection attacks against amd’s secure encrypted virtualization. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. 2875–2889.">[16]</span></a></sup> 提出了一种电压故障注入攻击，可以在 AMD 安全处理器上执行自定义有效负载，随后通过部署自定义 SEV 固件解密 VM 的内存。</p><p>“CacheWarp” <sup id="fnref:186" class="footnote-ref"><a href="#fn:186" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ruiyi Zhang, CISPA Helmholtz Center, Lukas Gerlach, Daniel Weber, Lorenz Hetterich, Youheng Lü, Andreas Kogler, and Michael Schwarz. 2024. CacheWarp: Software-based Fault Injection using Selective State Reset. (2024).">[186]</span></a></sup> 提出了一种针对 AMD SEV-ES 和 SEV-SNP 的新型基于软件的故障攻击，利用在架构级别将修改后的客户 VM 缓存行恢复到其先前（陈旧）状态的可能性。此攻击只需要在攻击者选择的点中断 VM，即可使修改后的缓存行无效，而无需将其写回内存。最近，Schlüter 等人 <sup id="fnref:137" class="footnote-ref"><a href="#fn:137" rel="footnote"><span class="hint--top hint--rounded" aria-label="Benedict Schlüter, Supraja Sridhara, Andrin Bertschi, and Shweta Shinde. 2024. WeSee: Using Malicious# VC Interrupts to Break AMD SEV-SNP. arXiv preprint arXiv:2404.03526 (2024).">[137]</span></a></sup> 介绍了一种新型攻击，其中虚拟机管理程序将精心设计的恶意 #VC（AMD 的新异常，用于促进虚拟机与不受信任的虚拟机管理程序之间的通信）注入受害虚拟机的 CPU，使攻击者能够在虚拟机中诱发任意行为。在另一个相关攻击中，“HECKLER” <sup id="fnref:138" class="footnote-ref"><a href="#fn:138" rel="footnote"><span class="hint--top hint--rounded" aria-label="Benedict Schlüter, Supraja Sridhara, Mark Kuhne, Andrin Bertschi, and Shweta Shinde. 2024. Heckler: Breaking Confidential VMs with Malicious Interrupts. In USENIX Security.">[138]</span></a></sup> 表明虚拟机管理程序可以注入恶意的非计时器中断来破坏虚拟机。</p><p>它们利用具有全局效果的中断处理程序，允许操纵虚拟机的寄存器状态来改变数据和控制流。一般来说，SEV-SNP 仍然容易受到这种基于软件的故障注入攻击。</p><h3 id="6-3-3-中断驱动攻击"><a href="#6-3-3-中断驱动攻击" class="headerlink" title="6.3.3 中断驱动攻击"></a>6.3.3 中断驱动攻击</h3><p>与 SGX-Step 框架 <sup id="fnref:158" class="footnote-ref"><a href="#fn:158" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2017. SGX-Step: A practical attack framework for precise enclave execution control. In Proceedings of the 2nd Workshop on System Software for Trusted Execution. 1–6.">[158]</span></a></sup> 类似，SEV-Step <sup id="fnref:175" class="footnote-ref"><a href="#fn:175" rel="footnote"><span class="hint--top hint--rounded" aria-label="Luca Wilke, Jan Wichelmann, Anja Rabich, and Thomas Eisenbarth. 2024. SEV-Step A Single-Stepping Framework for AMD-SEV. IACR Transactions on Cryptographic Hardware and Embedded Systems 2024, 1 (2024), 180–206.">[175]</span></a></sup> 引入了针对 SEV VM 的可靠单步执行。除了此功能之外，SEV-Step 还方便访问常见的攻击技术，例如页面错误跟踪和针对 SEV 的缓存攻击。</p><h3 id="6-3-4-对策"><a href="#6-3-4-对策" class="headerlink" title="6.3.4 对策"></a>6.3.4 对策</h3><p>大多数与内存相关的攻击已在最近的 AMD 产品更新中得到解决。在这里，我们重点介绍针对故障注入攻击的对策。对于恶意电压下降或故障，类似于用于 SGX 和 TrustZone 的对策，可以实现硬件级电压监控电路和基于软件的检测机制。为了应对通过特定的虚拟机管理程序指令实现细粒度内存写抑制的故障攻击，在硬件级别限制这些指令的使用或实现编译器级别的解决方案可以确保正确的内存操作。对于注入恶意中断的攻击，可以通过监视外部中断或禁用中断处理程序来阻止或检测注入。</p><h1 id="7-关于-GPU-TEE-未来方向的结论"><a href="#7-关于-GPU-TEE-未来方向的结论" class="headerlink" title="7. 关于 GPU TEE 未来方向的结论"></a>7. 关于 GPU TEE 未来方向的结论</h1><p>在本节中，基于前面讨论的相关工作，我们概述了未来可能与 GPU TEE 相关的潜在攻击。我们注意到，由于 GPU TEE 尚未广泛商业化，因此目前还不可能实际评估这些攻击媒介，但相信未来可能会发现相应的漏洞。</p><h2 id="7-1-针对基于-x86-的-GPU-TEE-原型的潜在攻击"><a href="#7-1-针对基于-x86-的-GPU-TEE-原型的潜在攻击" class="headerlink" title="7.1 针对基于 x86 的 GPU TEE 原型的潜在攻击"></a>7.1 针对基于 x86 的 GPU TEE 原型的潜在攻击</h2><p>如第 4 节所述，针对 x86 架构的最新设计各自具有独特的特性，旨在减小 TCB 大小并最大限度地减少硬件修改。这些设计的主要目标是保护 GPU 资源免受受感染操作系统的侵害，包括 GPU 驱动程序。我们在图 5 中概述了关键设计思想并提供了总体概述。具体来说，在这种威胁模型中，攻击者控制整个软件堆栈，包括操作系统、虚拟机管理程序和设备驱动程序。攻击者还旨在破坏用户应用程序和 GPU 之间的硬件和软件 I&#x2F;O 数据路径。GPU 驱动程序的功能通常分为安全部分和非安全部分，而不是将整个驱动程序移植到 TEE 区域，这会增加 TCB 大小。鉴于攻击者可以破坏操作系统，位于操作系统中的 GPU 驱动程序也在此范围内。GPU 的设备内存是可信的，攻击者无法观察或破坏存储在其中的数据。此外，我们认识到，位于 CPU 和 GPU 两侧的电源和频率管理模块不在保护范围之内。接下来，基于此安全模型，我们将分析在实际应用中部署此类设计时可能构成威胁并泄露信息的潜在攻击。</p><p><img src="/img/cc/gpu/7.png" alt="图5. 针对基于 x86 的 GPU TEE 原型的潜在攻击。"></p><h3 id="7-1-1-针对英特尔-SGX-的现有攻击"><a href="#7-1-1-针对英特尔-SGX-的现有攻击" class="headerlink" title="7.1.1 针对英特尔 SGX 的现有攻击"></a>7.1.1 针对英特尔 SGX 的现有攻击</h3><p>鉴于 GPU 驱动程序中的基本 GPU 资源管理功能位于 TEE 区域内，第 6.1 节中概述的大多数攻击都可能以该区域为目标来窃取机密（参见图 5 中的攻击面 ➀）。值得注意的是，虽然一些研究可能断言大多数针对 SGX 的旁道攻击超出了范围，但在考虑在实际云平台中部署 GPU TEE 设计时，提供相应的保护至关重要（其中甚至某些形式的恶意内部人员的物理访问也可能相关）。这些潜在泄漏可归类如下：(i) 观察内存访问模式可让攻击者推断出 SGX 区域内程序的控制流，包括决策过程。有了这种洞察力，攻击者可以监视 GPU 命令和数据传输，从而推断出在 GPU 上执行的任务。例如，推断基于 CNN 的视频分析任务每帧中检测到的对象的数量（和大小）可能变得可行 <sup id="fnref:130" class="footnote-ref"><a href="#fn:130" rel="footnote"><span class="hint--top hint--rounded" aria-label="Rishabh Poddar, Ganesh Ananthanarayanan, Srinath Setty, Stavros Volos, and Raluca Ada Popa. 2020. Visor:Privacy-Preserving video analytics as a cloud service. In 29th USENIX Security Symposium (USENIX Security 20). 1039–1056.">[130]</span></a></sup>。(ii) 监视页面错误模式使攻击者能够从某些加密开源软件库（例如 OpenSSL 和 Libgcrypt）的实现中提取加密密钥 <sup id="fnref:147" class="footnote-ref"><a href="#fn:147" rel="footnote"><span class="hint--top hint--rounded" aria-label="Shweta Shinde, Zheng Leong Chua, Viswesh Narayanan, and Prateek Saxena. 2016. Preventing page faults from telling your secrets. In Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security. 317–328.">[147]</span></a></sup>。有了这些知识，攻击者随后可以访问传输到 GPU 的所有敏感信息。(iii) 利用时间通道可让攻击者推断出有关在 GPU 上运行的内核的敏感信息。例如，Telekine <sup id="fnref:60" class="footnote-ref"><a href="#fn:60" rel="footnote"><span class="hint--top hint--rounded" aria-label="Tyler Hunt, Zhipeng Jia, Vance Miller, Ariel Szekely, Yige Hu, Christopher J Rossbach, and Emmett Witchel. 2020. Telekine: Secure computing with cloud GPUs. In 17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20). 817–833.">[60]</span></a></sup> 展示了攻击者如何通过仅观察 GPU 内核执行的时间来准确地对 ImageNet 中的图像进行分类，而无需访问图像本身。</p><h3 id="7-1-2-基于-DVFS-的攻击"><a href="#7-1-2-基于-DVFS-的攻击" class="headerlink" title="7.1.2 基于 DVFS 的攻击"></a>7.1.2 基于 DVFS 的攻击</h3><p>为了提高能源效率，许多当前的 CPU 处理器都启用了 DVFS 扩展，该扩展可根据实时计算负载调整处理器核心的频率和电压。此功能现在扩展到 NVIDIA GPU 等加速器。如 Lightning <sup id="fnref:151" class="footnote-ref"><a href="#fn:151" rel="footnote"><span class="hint--top hint--rounded" aria-label="Rihui Sun, Pengfei Qiu, Yongqiang Lyu, Jian Dong, Haixia Wang, Dongsheng Wang, and Gang Qu. 2023. Lightning: Leveraging DVFS-induced Transient Fault Injection to Attack Deep Learning Accelerator of GPUs. ACM Transactions on Design Automation of Electronic Systems 29, 1 (2023).">[151]</span></a></sup> 所示，NVIDIA GPU 工作电压可以通过 NVIDIA 驱动程序在 CPU 上执行的软件指令进行更改，这可能使攻击者能够引发瞬态电压故障以进行故障注入攻击。此外，当前的 NVIDIA GPU 为锁相环 (PLL) 和时钟分频器提供不受限制的控制，允许通过使用 NVIDIA 调整频率偏移轻松超频，从而可能促进基于频率的故障注入攻击。因此，对于基于 x86 的 GPU TEE 原型，我们在图 5 中确定了关于基于 DVFS 的攻击的两个攻击面（参见➁ 和 ➅）。</p><ul><li><strong>在 CPU 方面。</strong>在许多现有的 GPU TEE 原型 <sup id="fnref:65" class="footnote-ref"><a href="#fn:65" rel="footnote"><span class="hint--top hint--rounded" aria-label="Andrei Ivanov, Benjamin Rothenberger, Arnaud Dethise, Marco Canini, Torsten Hoefler, and Adrian Perrig. 2023. SAGE: Software-based Attestation for GPU Execution. In 2023 USENIX Annual Technical Conference (USENIX ATC 23). 485–499.">[65]</span></a></sup> <sup id="fnref:66" class="footnote-ref"><a href="#fn:66" rel="footnote"><span class="hint--top hint--rounded" aria-label="Insu Jang, Adrian Tang, Taehoon Kim, Simha Sethumadhavan, and Jaehyuk Huh. 2019. Heterogeneous isolated execution for commodity gpus. In Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 455–468.">[66]</span></a></sup> <sup id="fnref:86" class="footnote-ref"><a href="#fn:86" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sunho Lee, Jungwoo Kim, Seonjin Na, Jongse Park, and Jaehyuk Huh. 2022. Tnpu: Supporting trusted execution with tree-less integrity protection for neural processing unit. In 2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 229–243.">[86]</span></a></sup> <sup id="fnref:162" class="footnote-ref"><a href="#fn:162" rel="footnote"><span class="hint--top hint--rounded" aria-label="Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 681–696.">[162]</span></a></sup> <sup id="fnref:180" class="footnote-ref"><a href="#fn:180" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ardhi Wiratama Baskara Yudha, Jake Meyer, Shougang Yuan, Huiyang Zhou, and Yan Solihin. 2022. LITE: a low-cost practical inter-operable GPU TEE. In Proceedings of the 36th ACM International Conference on Supercomputing. 1–13.">[180]</span></a></sup> <sup id="fnref:190" class="footnote-ref"><a href="#fn:190" rel="footnote"><span class="hint--top hint--rounded" aria-label="Jianping Zhu, Rui Hou, XiaoFeng Wang, Wenhao Wang, Jiangfeng Cao, Boyan Zhao, Zhongpu Wang, Yuhui Zhang, Jiameng Ying, Lixin Zhang, et al. 2020. Enabling rack-scale confidential computing using heterogeneous trusted execution environment. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1450–1465.">[190]</span></a></sup> 中，GPU 驱动程序负责 DVFS 参数控制的部分位于其 TCB 之外。因此，攻击者可以从 CPU 端灵活调整 GPU 电压和频率，从而在 GPU 端引发故障。此外，值得调查的是，之前针对 SGX 的攻击是否可以访问相关内存区域以更改 DVFS 参数，即使管理这些参数的 GPU 驱动程序在 SGX 飞地中运行受到保护。</li><li><strong>在 GPU 方面。</strong>由于 GPU 硬件缺乏保护，具有 GPU 硬件物理访问权限的攻击者可以直接操纵 GPU 电压，从而向正在运行的 GPU 内核注入故障。例如，“VoltPillager” <sup id="fnref:23" class="footnote-ref"><a href="#fn:23" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zitai Chen, Georgios Vasilakis, Kit Murdock, Edward Dean, David Oswald, and Flavio D Garcia. 2021. VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface. In 30th USENIX Security Symposium (USENIX Security 21). 699–716.">[23]</span></a></sup> 可以在 CPU 和主板上的电压调节器之间的 SVID 总线上注入消息，从而实现对 CPU 核心电压的精确控制。最终，这会危及英特尔 SGX 飞地的机密性和完整性。</li></ul><p>探索攻击者是否可以将恶意 SVID 数据包（或类似数据包）注入 GPU 卡上的相应总线，为进一步调查提供了一条有趣的途径。</p><h3 id="7-1-3-对-PCIe-总线和-GPU-内存的物理攻击"><a href="#7-1-3-对-PCIe-总线和-GPU-内存的物理攻击" class="headerlink" title="7.1.3 对 PCIe 总线和 GPU 内存的物理攻击"></a>7.1.3 对 PCIe 总线和 GPU 内存的物理攻击</h3><p>在许多现有的 GPU TEE 原型中，由于缺乏供应商硬件支持（参见图 5 中的攻击面 ➂ 和 ➄），GPU 缺乏可信内存区域，导致 GPU 内存中的数据以明文形式暴露。因此，直接物理访问 GPU 内存可能会危及敏感数据。此外，如果攻击者可以确保（例如通过冷却）受 TEE 保护的内存内容得以保留，并且可以在 GPU 重置后读取，则冷启动攻击 <sup id="fnref:54" class="footnote-ref"><a href="#fn:54" rel="footnote"><span class="hint--top hint--rounded" aria-label="J. Alex Halderman, Seth D. Schoen, Nadia Heninger, William Clarkson, William Paul, Joseph A. Calandrino, Ariel J. Feldman, Jacob Appelbaum, and Edward W. Felten. [n. d.]. Lest We Remember: Cold Boot Attacks on Encryption Keys. In 17th USENIX Security Symposium (USENIX Security 08).">[54]</span></a></sup> 可能具有相关性。</p><p>此外，由于 PCIe 互连暴露，因此可以通过专用硬件注入恶意 PCIe 数据包。</p><p>仅仅保护到 GPU 的路由路径不足以保护通过 MMIO 或 DMA 的 GPU 控制 <sup id="fnref:66" class="footnote-ref"><a href="#fn:66" rel="footnote"><span class="hint--top hint--rounded" aria-label="Insu Jang, Adrian Tang, Taehoon Kim, Simha Sethumadhavan, and Jaehyuk Huh. 2019. Heterogeneous isolated execution for commodity gpus. In Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 455–468.">[66]</span></a></sup>。虽然大多数设计都采用经过身份验证的加密来确保传输过程中的数据完整性，但仅凭这一点不足以保护数据的机密性和完整性。例如，某些设计缺乏安全身份验证和建立可信通信通道所必需的硬件信任根，包括加密密钥的安全存储和加密操作的安全执行环境。此外，确保安全启动和固件完整性对于保证安全通道建立过程的正确性至关重要。</p><h3 id="7-1-4-针对-GPU-的架构-逻辑攻击"><a href="#7-1-4-针对-GPU-的架构-逻辑攻击" class="headerlink" title="7.1.4 针对 GPU 的架构&#x2F;逻辑攻击"></a>7.1.4 针对 GPU 的架构&#x2F;逻辑攻击</h3><p>先前针对内存漏洞的攻击（参见第 5.1 节）也是可能的，因为当前的 GPU TEE 设计经常忽略不同 GPU 上下文之间的内存清除（这在上述冷启动攻击的情况下在重置之间也很重要）。因此，安全的内存管理策略（包括内存初始化和清除）对于 GPU TEE 工作流的完整性和安全性至关重要。</p><h2 id="7-2-针对基于-NVIDIA-Hopper-H100-的-GPU-TEE-的潜在攻击"><a href="#7-2-针对基于-NVIDIA-Hopper-H100-的-GPU-TEE-的潜在攻击" class="headerlink" title="7.2 针对基于 NVIDIA Hopper H100 的 GPU TEE 的潜在攻击"></a>7.2 针对基于 NVIDIA Hopper H100 的 GPU TEE 的潜在攻击</h2><p>除了最先进的基于 x86 的 GPU TEE 原型外，基于 Hopper 架构的 NVIDIA Hopper H100 Tensor Core GPU 最近推出了用于机密计算的高级功能（目前仅对部分用户可用）。根据 NVIDIA 的白皮书 <sup id="fnref:124" class="footnote-ref"><a href="#fn:124" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA confidential computing. https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/.">[124]</span></a></sup>，H100 依赖特定的 CPU TEE（例如 Intel TDX、AMD SEV-SNP 或 Arm CCA）来实现机密计算。在这里，我们根据图 6 中的白皮书提供了基于 NVIDIA Hopper H100 的 GPU TEE 的通用系统模型。具体来说，在 CPU 方面，此 GPU TEE 在基于 VM 的 TEE 的标准威胁模型内运行 <sup id="fnref:137" class="footnote-ref"><a href="#fn:137" rel="footnote"><span class="hint--top hint--rounded" aria-label="Benedict Schlüter, Supraja Sridhara, Andrin Bertschi, and Shweta Shinde. 2024. WeSee: Using Malicious# VC Interrupts to Break AMD SEV-SNP. arXiv preprint arXiv:2404.03526 (2024).">[137]</span></a></sup> <sup id="fnref:138" class="footnote-ref"><a href="#fn:138" rel="footnote"><span class="hint--top hint--rounded" aria-label="Benedict Schlüter, Supraja Sridhara, Mark Kuhne, Andrin Bertschi, and Shweta Shinde. 2024. Heckler: Breaking Confidential VMs with Malicious Interrupts. In USENIX Security.">[138]</span></a></sup> <sup id="fnref:186" class="footnote-ref"><a href="#fn:186" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ruiyi Zhang, CISPA Helmholtz Center, Lukas Gerlach, Daniel Weber, Lorenz Hetterich, Youheng Lü, Andreas Kogler, and Michael Schwarz. 2024. CacheWarp: Software-based Fault Injection using Selective State Reset. (2024).">[186]</span></a></sup>。不受信任的虚拟机管理程序将 VM 映像加载到内存中并管理初始配置。远程证明在启动启动过程之前测量 VM 的初始内存状态。在 VM 中执行的软件（包括客户操作系统、用户应用程序和 TEE 的可信模块）是 TCB 的一部分。规范要求虚拟机管理程序设置某些初始状态（例如，vCPU 的数量、支持的硬件功能和内存大小）。硬件会验证这些配置，并且只有在设置正确的情况下才会进入 VM。此外，硬件在退出 VM 之前将某些值（例如，特定的通用寄存器）清零，并管理 VM 上下文切换期间的上下文保存和恢复。</p><p><strong>在 GPU 方面，</strong>H100 GPU 预计将配备内存加密引擎（很可能是类似于 SGX 的内存加密引擎 (MEE) <sup id="fnref:27" class="footnote-ref"><a href="#fn:27" rel="footnote"><span class="hint--top hint--rounded" aria-label="Intel Corporation. 2015. Intel R © Software Guard Extensions. https://community.intel.com/legacyfs/online/drupal_files/332680-002.pdf.">[27]</span></a></sup>）和其他功能，以确保数据和代码的机密性和完整性，甚至可以防御针对 PCIe 总线和 GPU 内存的基本物理攻击。但是，白皮书没有提供有关这些功能的详细技术信息。</p><h3 id="7-2-1-针对基于-VM-的-TEE-的现有攻击"><a href="#7-2-1-针对基于-VM-的-TEE-的现有攻击" class="headerlink" title="7.2.1 针对基于 VM 的 TEE 的现有攻击"></a>7.2.1 针对基于 VM 的 TEE 的现有攻击</h3><p><img src="/img/cc/gpu/8.png" alt="图6. 针对基于 NVIDIA Hopper H100 的 GPU TEE 的潜在攻击"></p><p>可能是因为基于 VM 的 TEE 是近年来才提出的，目前对针对它们的攻击的研究有限。然而，最近的发展表明，基于软件的故障注入攻击对 AMD SEV-SNP 非常有效。这些攻击将允许对手破坏 VM 中的 GPU 驱动程序，从而实现对 GPU 上运行的敏感任务的精确控制（参见图 6 中的攻击面 ➀）。例如，“WeSee”攻击 <sup id="fnref:137" class="footnote-ref"><a href="#fn:137" rel="footnote"><span class="hint--top hint--rounded" aria-label="Benedict Schlüter, Supraja Sridhara, Andrin Bertschi, and Shweta Shinde. 2024. WeSee: Using Malicious# VC Interrupts to Break AMD SEV-SNP. arXiv preprint arXiv:2404.03526 (2024).">[137]</span></a></sup> 针对基于 NVIDIA H100 的 GPU TEE 中使用的 AMD SEV-SNP，允许攻击者通过伪造 #VC 进行 MMIO 读取来执行任意内存写入。</p><p>此功能将使攻击者能够修改发送到 GPU 的命令和数据。更重要的是，像 CacheWarp <sup id="fnref:186" class="footnote-ref"><a href="#fn:186" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ruiyi Zhang, CISPA Helmholtz Center, Lukas Gerlach, Daniel Weber, Lorenz Hetterich, Youheng Lü, Andreas Kogler, and Michael Schwarz. 2024. CacheWarp: Software-based Fault Injection using Selective State Reset. (2024).">[186]</span></a></sup> 这样的攻击在最新的 SEV-SNP 实现中仍然没有得到缓解，它们不依赖于客户虚拟机的具体情况。因此，为基于 NVIDIA H100 的 GPU TEE 配备针对这些攻击的保护措施以保护 GPU 数据的机密性和完整性至关重要。探索针对其他基于 VM 的 TEE（如 Intel TDX）的潜在攻击也很重要，因为它们是基于 NVIDIA H100 的 GPU TEE 不可或缺的一部分。</p><h3 id="7-2-2-基于-DVFS-的攻击"><a href="#7-2-2-基于-DVFS-的攻击" class="headerlink" title="7.2.2 基于 DVFS 的攻击"></a>7.2.2 基于 DVFS 的攻击</h3><p>与 GPU TEE 原型类似，我们在图 6 中确定了基于 DVFS 的攻击的两个攻击面（参见➀ 和 ➃）。</p><p>在 CPU 方面。回想一下，针对基于 VM 的 TEE（例如 AMD SEV-SNP）的现有攻击允许攻击者将权限提升到 root 并将他们选择的任何值写入受害 VM 中的任何位置。因此，具有这些能力的攻击者可能能够使用通过 NVIDIA 驱动程序在 CPU 上执行的软件指令来操纵 GPU 的电压和频率。</p><p>在 GPU 方面。H100 白皮书 <sup id="fnref:125" class="footnote-ref"><a href="#fn:125" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA H100 Tensor Core GPU Architecture. https://resources.nvidia.com/en-us-data-center-overview-mc/en-us-data-centeroverview/gtc22-whitepaper-hopper?pflpid=17841&lb-mode=preview.">[125]</span></a></sup> 缺乏有关电压和频率管理的详细信息。假设攻击者具有物理访问权限，他们可能会执行类似“VoltPillager” <sup id="fnref:23" class="footnote-ref"><a href="#fn:23" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zitai Chen, Georgios Vasilakis, Kit Murdock, Edward Dean, David Oswald, and Flavio D Garcia. 2021. VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface. In 30th USENIX Security Symposium (USENIX Security 21). 699–716.">[23]</span></a></sup> 的攻击，将恶意 SVID 数据包或等效数据包注入相关 GPU 卡的总线，从而改变 GPU 电压。</p><p>总之，具有所述能力的攻击者可以从 CPU 和 GPU 两方面修改电压和频率。然而，这些变化是否以及如何影响在 NVIDIA H100 GPU 上运行的任务仍不确定。具体而言，目前尚不清楚诱发的故障是否会显著影响任务，例如降低 ML 模型准确性或完全提取私有加密密钥。在撰写本调查时，基于 NVIDIA H100 的 GPU TEE 的完整机密工作流程尚不可用，因为相应的 NVIDIA 库仍在开发中。</p><h3 id="7-2-3-GPU-上的微架构侧通道和隐蔽通道攻击"><a href="#7-2-3-GPU-上的微架构侧通道和隐蔽通道攻击" class="headerlink" title="7.2.3 GPU 上的微架构侧通道和隐蔽通道攻击"></a>7.2.3 GPU 上的微架构侧通道和隐蔽通道攻击</h3><p>H100 白皮书 <sup id="fnref:125" class="footnote-ref"><a href="#fn:125" rel="footnote"><span class="hint--top hint--rounded" aria-label="NVIDIA. 2022. NVIDIA H100 Tensor Core GPU Architecture. https://resources.nvidia.com/en-us-data-center-overview-mc/en-us-data-centeroverview/gtc22-whitepaper-hopper?pflpid=17841&lb-mode=preview.">[125]</span></a></sup> 强调了 Hopper 架构针对机密计算的增强安全功能，特别是在协作多方计算场景中，即具有多个 GPU 的单个租户和具有单个 GPU 的多个租户。</p><p>但是，第 5.2 节中讨论的漏洞可能会导致 NVIDIA H100 GPU 上的安全漏洞。</p><p><strong>具有多个 GPU 的单个租户。</strong>在具有多个 GPU 的单个租户场景中，单个 VM 同时分配多个物理上独立的 GPU，每个 GPU 通过 NVLink 连接。回想一下，Dutta 等人 <sup id="fnref:35" class="footnote-ref"><a href="#fn:35" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sankha Baran Dutta, Hoda Naghibijouybari, Arjun Gupta, Nael Abu-Ghazaleh, Andres Marquez, and Kevin Barker. 2023. Spy in the GPU-box: Covert and side channel attacks on multi-GPU systems. In Proceedings of the 50th Annual International Symposium on Computer Architecture. 1–13.">[35]</span></a></sup> 证明，一个 GPU 上的攻击者可以通过 NVLink 在另一个 GPU 的 L2 缓存上引发争用，从而实现跨 GPU 的隐蔽通道和 Prime+Probe 攻击。然而，由于两个关键因素（参见图 6 中的攻击面 ➁），此类攻击在 NVIDIA H100 GPU 模型中可能会面临挑战。首先，攻击者的进程需要通过 NVLink 访问远程 GPU 的内存，这在 NVIDIA H100 GPU TEE 的威胁模型中可能会受到限制。因此，挑战在于如何使间谍进程能够在其中一个指定的 GPU 中运行并访问另一个 GPU 的内存。其次，H100 GPU 具有 50 MB 的 L2 缓存，比 A100 GPU 大 1.25 倍。然而，更大的 L2 缓存具有更多的集合和路径，可以使 Prime+Probe 攻击更加困难，因为攻击者需要填充和监视更多的缓存行。</p><p><strong>单个 GPU 上的多个租户。</strong>在单个 GPU 上有多个租户的情况下（参见图 6 中的攻击面 ➂），借助 MIG 功能，NVIDIA H100 GPU 可以划分为多个 GPU 实例，每个实例在内存系统路径方面都是独立的，包括片上交叉开关端口、L2 缓存组、内存控制器和 DRAM 地址总线。然而，如第 5.2 节所述，Zhang 等人 <sup id="fnref:187" class="footnote-ref"><a href="#fn:187" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zhenkai Zhang, Tyler Allen, Fan Yao, Xing Gao, and Rong Ge. 2023. TunneLs for Bootlegging: Fully Reverse-Engineering GPU TLBs for Challenging Isolation Guarantees of NVIDIA MIG. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security. 960–974.">[187]</span></a></sup> 展示了 MIG 功能的一个设计缺陷，即最后一级 TLB 并未被所有 GPU 实例安全地划分。因此，此缺陷可导致不同 GPU 实例之间发生隐蔽通道攻击。鉴于此模式支持多租户，有必要调查使用 MIG 创建的每个 GPU 实例是否确实具有通过其他微架构组件（例如 L1 缓存、warp 调度程序和命令处理器）的单独且隔离的路径。</p><h2 id="7-3-针对基于-Arm-的-GPU-TEE-原型的潜在攻击"><a href="#7-3-针对基于-Arm-的-GPU-TEE-原型的潜在攻击" class="headerlink" title="7.3 针对基于 Arm 的 GPU TEE 原型的潜在攻击"></a>7.3 针对基于 Arm 的 GPU TEE 原型的潜在攻击</h2><p>由于 Arm GPU 的 TEE 存在各种架构差异，已有多项研究对基于 Arm 的 GPU TEE 进行了探索。在图 7 中，我们以 StrongBox <sup id="fnref:31" class="footnote-ref"><a href="#fn:31" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.">[31]</span></a></sup> 提出的设计为基础。StrongBox 是一个合适的基础，因为它是最近推出的，不依赖于特定的 Arm 端点功能，也不需要对 GPU 或 CPU 芯片进行硬件修改。值得注意的是，虽然 Arm 或 Intel 平台上的安全 GPU 计算可能与 Arm 的 CCA 领域风格架构 <sup id="fnref:163" class="footnote-ref"><a href="#fn:163" rel="footnote"><span class="hint--top hint--rounded" aria-label="Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.">[163]</span></a></sup> 不一致，但我们省略了有关这方面的见解，因为它与基于 NVIDIA Hopper H100 的 GPU TEE 非常相似。在图 7 中，攻击者获得了对内核和整个 GPU 软件堆栈的控制权，包括 GPU 驱动程序和运行时。这种控制使他们能够操纵 GPU 应用程序中的敏感数据和代码。他们可以直接访问用于 GPU 任务的统一内存或操纵外围设备以逃避检测。此外，通过破坏 GPU 驱动程序，攻击者可以破坏 GPU 应用程序的内存管理，从而可能将敏感数据映射到不受保护的区域。与现有的基于 x86 的 GPU TEE 类似，信任被置于 GPU 和安全世界中。基于此威胁模型，我们将在下面讨论潜在的攻击。</p><h3 id="7-3-1-针对-Arm-TrustZone-的现有攻击"><a href="#7-3-1-针对-Arm-TrustZone-的现有攻击" class="headerlink" title="7.3.1 针对 Arm TrustZone 的现有攻击"></a>7.3.1 针对 Arm TrustZone 的现有攻击</h3><p>第 6.2 节中总结的针对 TrustZone 的攻击也适用于此基于 Arm 的 GPU TEE 原型。这些侧信道攻击对 TrustZone 的影响间接影响基于 Arm 的 GPU TEE（参见图 7 中的攻击面 ➀ 和 ➁）。潜在后果可总结如下：(i) 攻击者可以将权限提升到 root 以提交大量恶意任务 <sup id="fnref:10" class="footnote-ref"><a href="#fn:10" rel="footnote"><span class="hint--top hint--rounded" aria-label="Gal Beniamini. 2016. TrustZone Kernel Privilege Escalation (CVE-2016-2431).">[10]</span></a></sup> <sup id="fnref:144" class="footnote-ref"><a href="#fn:144" rel="footnote"><span class="hint--top hint--rounded" aria-label="Di Shen. 2015. Exploiting trustzone on android. Black Hat USA 2 (2015), 267–280.">[144]</span></a></sup>。但是，在恶意任务和受害者任务之间建立隐蔽通道的可能性不大，因为 GPU 任务在 Arm 端点 GPU 上是按顺序执行的 <sup id="fnref:31" class="footnote-ref"><a href="#fn:31" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.">[31]</span></a></sup>。(ii) 攻击者可能会监视缓存活动以从 TrustZone 中提取 AES 密钥 <sup id="fnref:51" class="footnote-ref"><a href="#fn:51" rel="footnote"><span class="hint--top hint--rounded" aria-label="Roberto Guanciale, Hamed Nemati, Christoph Baumann, and Mads Dam. 2016. Cache storage channels: Alias-driven attacks and verified countermeasures. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 38–55.">[51]</span></a></sup> <sup id="fnref:97" class="footnote-ref"><a href="#fn:97" rel="footnote"><span class="hint--top hint--rounded" aria-label="Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and Stefan Mangard. 2016. ARMageddon: Cache attacks on mobile devices. In 25th USENIX Security Symposium (USENIX Security 16). 549–564.">[97]</span></a></sup> <sup id="fnref:185" class="footnote-ref"><a href="#fn:185" rel="footnote"><span class="hint--top hint--rounded" aria-label="Ning Zhang, Kun Sun, Deborah Shands, Wenjing Lou, and Y Thomas Hou. 2016. Truspy: Cache side-channel information leakage from the secure world on arm devices. Cryptology ePrint Archive (2016).">[185]</span></a></sup>，从而损害 CPU 和 GPU 之间传输的数据的机密性。</p><p><img src="/img/cc/gpu/9.png" alt="图7. 针对基于 Arm 的 GPU TEE 的潜在攻击"></p><h3 id="7-3-2-集成-GPU-上的微架构侧信道和隐蔽通道攻击"><a href="#7-3-2-集成-GPU-上的微架构侧信道和隐蔽通道攻击" class="headerlink" title="7.3.2 集成 GPU 上的微架构侧信道和隐蔽通道攻击"></a>7.3.2 集成 GPU 上的微架构侧信道和隐蔽通道攻击</h3><p>如表 3 所述，有几项研究调查了集成 GPU 上的侧信道和隐蔽信道攻击，其中一些可能适用于基于 Arm 的 GPU TEE 原型（参见图 7 中的攻击面 ➂）。</p><ul><li>CPU 和 iGPU 之间的隐蔽通道：Dutta 等人 <sup id="fnref:34" class="footnote-ref"><a href="#fn:34" rel="footnote"><span class="hint--top hint--rounded" aria-label="Sankha Baran Dutta, Hoda Naghibijouybari, Nael Abu-Ghazaleh, Andres Marquez, and Kevin Barker. 2021. Leaky buddies: Cross-component covert channels on integrated cpu-gpu systems. In ACM/IEEE 48th Annual International Symposium on Computer Architecture (ISCA). IEEE, 972–984.">[34]</span></a></sup> 通过 LLC 在 CPU 上的木马进程和英特尔集成 GPU 上的间谍进程（反之亦然）之间建立了双向隐蔽通道。考虑到基于 Arm 的 GPU TEE 中的这种攻击，一种可能的情况是使用在 CPU 的正常世界中启动的木马进程，将位传送给 GPU。然而，由于未记录的 LLC&#x2F;系统级缓存行为以及 Arm 架构中 CPU 和 GPU 之间缓存利用率的不对称视图，出现了挑战。</li><li>基于 Arm 的 GPU TEE 的现有威胁模型可能无法有效缓解利用数据依赖型 DRAM 流量和压缩引起的缓存利用率来揭示正常世界中的用户像素的攻击 <sup id="fnref:168" class="footnote-ref"><a href="#fn:168" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yingchen Wang, Riccardo Paccagnella, Zhao Gang, Willy R Vasquez, David Kohlbrenner, Hovav Shacham, and Christopher W Fletcher. 2024. GPU. zip: On the Side-Channel Implications of Hardware-Based Graphical Data Compression. In 2024 IEEE Symposium on Security and Privacy (SP). 84–84.">[168]</span></a></sup>。需要进一步测试以评估此类攻击对基于 Arm 的 GPU TEE 的成功率。</li></ul><h3 id="7-3-3-对-GPU-内存的物理攻击"><a href="#7-3-3-对-GPU-内存的物理攻击" class="headerlink" title="7.3.3 对 GPU 内存的物理攻击"></a>7.3.3 对 GPU 内存的物理攻击</h3><p>大多数现有的基于 Arm 的 GPU TEE 原型主要侧重于提供硬件强制隔离以保护敏感代码和数据，而不是采用像 Intel SGX 的 MEE 这样的内存加密机制。因此，直接物理访问 GPU 内存（也可能通过冷启动攻击 <sup id="fnref:54" class="footnote-ref"><a href="#fn:54" rel="footnote"><span class="hint--top hint--rounded" aria-label="J. Alex Halderman, Seth D. Schoen, Nadia Heninger, William Clarkson, William Paul, Joseph A. Calandrino, Ariel J. Feldman, Jacob Appelbaum, and Edward W. Felten. [n. d.]. Lest We Remember: Cold Boot Attacks on Encryption Keys. In 17th USENIX Security Symposium (USENIX Security 08).">[54]</span></a></sup>）可能会危及敏感数据（参见图 7 中的攻击面 ➃）。例如，在 StrongBox <sup id="fnref:31" class="footnote-ref"><a href="#fn:31" rel="footnote"><span class="hint--top hint--rounded" aria-label="Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.">[31]</span></a></sup> 中，统一内存中定义为安全任务 RAM 的区域用作为机密 GPU 应用程序保留的固定和非安全内存区域。其主要目的是动态分配内存并建立 GPU 页表映射，从而防止对该区域的未经授权的访问控制。</p><h3 id="7-3-4-基于-DVFS-的攻击"><a href="#7-3-4-基于-DVFS-的攻击" class="headerlink" title="7.3.4 基于 DVFS 的攻击"></a>7.3.4 基于 DVFS 的攻击</h3><p>与 NVIDIA GPU 中的 DVFS 相比，Arm GPU（例如 Mali 系列）的电压和频率通常由电源管理集成电路 (PMIC) 控制。此组件负责管理各种系统元件（包括 CPU 和 GPU）的电源分配。因此，如图 7 所示（参见攻击面 ➄），具有权限的攻击者可以通过 PMIC 操纵处理器电压和频率设置，从而诱发硬件故障。此外，假设攻击者获得对片上系统 (SoC) 内电压调节器或时钟控制模块的物理访问权限，这促使进一步调查针对这些组件的硬件攻击 <sup id="fnref:23" class="footnote-ref"><a href="#fn:23" rel="footnote"><span class="hint--top hint--rounded" aria-label="Zitai Chen, Georgios Vasilakis, Kit Murdock, Edward Dean, David Oswald, and Flavio D Garcia. 2021. VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface. In 30th USENIX Security Symposium (USENIX Security 21). 699–716.">[23]</span></a></sup> 是否也适用于 Arm GPU。</p><h1 id="8-结论"><a href="#8-结论" class="headerlink" title="8. 结论"></a>8. 结论</h1><p>随着集成 GPU 的异构系统的激增，GPU TEE 正在成为确保机密性和完整性的有效解决方案。在本次调查中，我们首先研究了现有的 GPU TEE 原型和 NVIDIA 的第一个商用 GPU TEE，提供了有关其设计含义和特性的关键见解。我们回顾了最近针对各种类型 GPU 的攻击，包括集成 GPU、单个 GPU 和多个 GPU，以及减轻这些威胁的努力。此外，我们总结了针对常见 CPU TEE（如 Intel SGX、Arm TrustZone 和 AMD SEV）的流行攻击。基于这些见解，我们探索了基于 x86 和基于 Arm 的 GPU TEE 原型以及 NVIDIA H100 GPU 的物理和软件级别的潜在攻击，强调需要仔细分析已经很复杂的攻击面。随着 GPU 架构和 GPU TEE 隔离机制的创新，这个攻击面将进一步扩大，随着这些系统广泛部署在计算领域，安全设计和防御策略需要不断发展。</p><ul><li><a href="https://arxiv.org/pdf/2408.11601">Confidential Computing on Heterogeneous CPU-GPU Systems: Survey and Future Directions</a></li></ul><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>Adil Ahmad, Byunggill Joe, Yuan Xiao, Yinqian Zhang, Insik Shin, and Byoungyoung Lee. 2019. OBFUSCURO: A commodity obfuscation engine on Intel SGX. In Network and Distributed System Security Symposium.<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>Jaeguk Ahn, Cheolgyu Jin, Jiho Kim, Minsoo Rhu, Yunsi Fei, David Kaeli, and John Kim. 2021. Trident: A hybrid correlation-collision GPU cache timing attack for AES key recovery. In 2021 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 332–344.<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>Jaeguk Ahn, Jiho Kim, Hans Kasan, Leila Delshadtehrani, Wonjun Song, Ajay Joshi, and John Kim. 2021. Network-on-chip microarchitecture-based covert channel in gpus. In MICRO-54: 54th Annual IEEE&#x2F;ACM International Symposium on Microarchitecture. 565–577.<a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>Fritz Alder, Lesly-Ann Daniel, David Oswald, Frank Piessens, and Jo Van Bulck. 2024. Pandora: Principled symbolic validation of Intel SGX enclave runtimes. In 45th IEEE Symposium on Security and Privacy (S&amp;P).<a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:5" class="footnote-text"><span>Fritz Alder, Jo Van Bulck, David Oswald, and Frank Piessens. 2020. Faulty point unit: ABI poisoning attacks on Intel SGX. In Proceedings of the 36th Annual Computer Security Applications Conference. 415–427.<a href="#fnref:5" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:6" class="footnote-text"><span>AMD. 2023. AMD Secure Encrypted Virtualization (SEV). <a href="https://www.amd.com/en/developer/sev.html">https://www.amd.com/en/developer/sev.html</a>.<a href="#fnref:6" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:7" class="footnote-text"><span>Arm. 2004. ARM Security Technology: Building a Secure System using TrustZone Technology. <a href="https://www.arm.com/products/security-onarm/trustzone">https://www.arm.com/products/security-onarm/trustzone</a>.<a href="#fnref:7" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:8" class="footnote-text"><span>Arm. 2023. Arm Confidential Compute Architecture. <a href="https://www.arm.com/architecture/security-features/arm-confidential-compute-architecture">https://www.arm.com/architecture/security-features/arm-confidential-compute-architecture</a>.<a href="#fnref:8" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:9" class="footnote-text"><span>Arm. 2023. Arm Realm Management Extension (RME) System Architecture. <a href="https://developer.arm.com/documentation/den0129/latest/">https://developer.arm.com/documentation/den0129/latest/</a>.<a href="#fnref:9" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:10" class="footnote-text"><span>Gal Beniamini. 2016. TrustZone Kernel Privilege Escalation (CVE-2016-2431).<a href="#fnref:10" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:11" class="footnote-text"><span>Ferdinand Brasser, Srdjan Capkun, Alexandra Dmitrienko, Tommaso Frassetto, Kari Kostiainen, and Ahmad-Reza Sadeghi. 2019. DR. SGX: Automated and adjustable side-channel protection for SGX using data location randomization. In Proceedings of the 35th Annual Computer Security Applications Conference. 788–800.<a href="#fnref:11" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:12" class="footnote-text"><span>Ferdinand Brasser, Lucas Davi, David Gens, Christopher Liebchen, and Ahmad-Reza Sadeghi. 2017. CAn’t touch this: Software-only mitigation against rowhammer attacks targeting kernel memory. In 26th USENIX Security Symposium (USENIX Security 17). 117–130.<a href="#fnref:12" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:13" class="footnote-text"><span>Ferdinand Brasser, David Gens, Patrick Jauernig, Ahmad-Reza Sadeghi, and Emmanuel Stapf. 2019. SANCTUARY: ARMing TrustZone with User-space Enclaves.. In NDSS.<a href="#fnref:13" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:14" class="footnote-text"><span>Ferdinand Brasser, Urs Müller, Alexandra Dmitrienko, Kari Kostiainen, Srdjan Capkun, and Ahmad-Reza Sadeghi. 2017. Software grand exposure:SGX cache attacks are practical. In 11th USENIX workshop on offensive technologies (WOOT 17).<a href="#fnref:14" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:15" class="footnote-text"><span>Robert Buhren, Shay Gueron, Jan Nordholz, Jean-Pierre Seifert, and Julian Vetter. 2017. Fault attacks on encrypted general purpose compute platforms. In Proceedings of the Seventh ACM on Conference on Data and Application Security and Privacy. 197–204.<a href="#fnref:15" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:16" class="footnote-text"><span>Robert Buhren, Hans-Niklas Jacob, Thilo Krachenfels, and Jean-Pierre Seifert. 2021. One glitch to rule them all: Fault injection attacks against amd’s secure encrypted virtualization. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. 2875–2889.<a href="#fnref:16" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:17" class="footnote-text"><span>Claudio Canella, Daniel Genkin, Lukas Giner, Daniel Gruss, Moritz Lipp, Marina Minkin, Daniel Moghimi, Frank Piessens, Michael Schwarz, Berk Sunar, et al. 2019. Fallout: Leaking data on meltdown-resistant cpus. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 769–784.<a href="#fnref:17" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:18" class="footnote-text"><span>Pierre Carru. 2017. Attack TrustZone using Rowhammer. <a href="https://grehack.fr/data/2017/slides/GreHack17_Attack_TrustZone_with_Rowhammer.pdf">https://grehack.fr/data/2017/slides/GreHack17_Attack_TrustZone_with_Rowhammer.pdf</a><a href="#fnref:18" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:19" class="footnote-text"><span>David Cerdeira, Nuno Santos, Pedro Fonseca, and Sandro Pinto. 2020. Sok: Understanding the prevailing security vulnerabilities in trustzone-assisted tee systems. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1416–1432.<a href="#fnref:19" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:20" class="footnote-text"><span>Guoxing Chen, Sanchuan Chen, Yuan Xiao, Yinqian Zhang, Zhiqiang Lin, and Ten H Lai. 2019. Sgxpectre: Stealing intel secrets from sgx enclaves via speculative execution. In 2019 IEEE European Symposium on Security and Privacy (EuroS&amp;P). IEEE, 142–157.<a href="#fnref:20" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:21" class="footnote-text"><span>Sanchuan Chen, Xiaokuan Zhang, Michael K Reiter, and Yinqian Zhang. 2017. Detecting privileged side-channel attacks in shielded execution with Déjá Vu. In Proceedings of the 2017 ACM on Asia Conference on Computer and Communications Security. 7–18.<a href="#fnref:21" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:22" class="footnote-text"><span>Zitai Chen and David Oswald. 2023. PMFault: Faulting and Bricking Server CPUs through Management Interfaces: Or: A Modern Example of Halt and Catch Fire. IACR Transactions on Cryptographic Hardware and Embedded Systems 2023, 2 (Mar. 2023), 1–23.<a href="#fnref:22" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:23" class="footnote-text"><span>Zitai Chen, Georgios Vasilakis, Kit Murdock, Edward Dean, David Oswald, and Flavio D Garcia. 2021. VoltPillager: Hardware-based fault injection attacks against Intel SGX Enclaves using the SVID voltage scaling interface. In 30th USENIX Security Symposium (USENIX Security 21). 699–716.<a href="#fnref:23" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:24" class="footnote-text"><span>Łukasz Chmielewski and Léo Weissbart. 2021. On reverse engineering neural network implementation on GPU. In Applied Cryptography and Network Security Workshops: ACNS 2021 Satellite Workshops, AIBlock, AIHWS, AIoTS, CIMSS, Cloud S&amp;P, SCI, SecMT, and SiMLA, Kamakura, Japan, June 21–24, 2021, Proceedings. Springer, 96–113.<a href="#fnref:24" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:25" class="footnote-text"><span>Haehyun Cho, Penghui Zhang, Donguk Kim, Jinbum Park, Choong-Hoon Lee, Ziming Zhao, Adam Doupé, and Gail-Joon Ahn. 2018. Prime+count: Novel cross-world covert channels on arm trustzone. In Proceedings of the 34th Annual Computer Security Applications Conference. 441–452.<a href="#fnref:25" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:26" class="footnote-text"><span>Tobias Cloosters, Michael Rodler, and Lucas Davi. 2020. TeeRex: Discovery and exploitation of memory corruption vulnerabilities in SGX enclaves. In 29th USENIX Security Symposium (USENIX Security 20). 841–858.<a href="#fnref:26" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:27" class="footnote-text"><span>Intel Corporation. 2015. Intel R © Software Guard Extensions. <a href="https://community.intel.com/legacyfs/online/drupal_files/332680-002.pdf">https://community.intel.com/legacyfs/online/drupal_files/332680-002.pdf</a>.<a href="#fnref:27" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:28" class="footnote-text"><span>Victor Costan and Srinivas Devadas. 2016. Intel SGX explained. Cryptology ePrint Archive (2016).<a href="#fnref:28" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:29" class="footnote-text"><span>Patrick Cronin, Xing Gao, Haining Wang, and Chase Cotton. 2021. An exploration of ARM system-level cache and GPU side channels. In Proceedings of the 37th Annual Computer Security Applications Conference. 784–795.<a href="#fnref:29" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:30" class="footnote-text"><span>Fergus Dall, Gabrielle De Micheli, Thomas Eisenbarth, Daniel Genkin, Nadia Heninger, Ahmad Moghimi, and Yuval Yarom. 2018. Cachequote: Efficiently recovering long-term secrets of SGX EPID via cache attacks. (2018).<a href="#fnref:30" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:31" class="footnote-text"><span>Yunjie Deng, Chenxu Wang, Shunchang Yu, Shiqing Liu, Zhenyu Ning, Kevin Leach, Jin Li, Shoumeng Yan, Zhengyu He, Jiannong Cao, et al. 2022. Strongbox: A gpu tee on arm endpoints. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 769–783.<a href="#fnref:31" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:32" class="footnote-text"><span>Bang Di, Daokun Hu, Zhen Xie, Jianhua Sun, Hao Chen, Jinkui Ren, and Dong Li. 2021. TLB-pilot: Mitigating TLB Contention Attack on GPUs with Microarchitecture-Aware Scheduling. ACM Transactions on Architecture and Code Optimization (TACO) 19, 1 (2021), 1–23.<a href="#fnref:32" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:33" class="footnote-text"><span>Zhao-Hui Du, Zhiwei Ying, Zhenke Ma, Yufei Mai, Phoebe Wang, Jesse Liu, and Jesse Fang. 2017. Secure encrypted virtualization is unsecure. arXiv preprint arXiv:1712.05090 (2017).<a href="#fnref:33" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:34" class="footnote-text"><span>Sankha Baran Dutta, Hoda Naghibijouybari, Nael Abu-Ghazaleh, Andres Marquez, and Kevin Barker. 2021. Leaky buddies: Cross-component covert channels on integrated cpu-gpu systems. In ACM&#x2F;IEEE 48th Annual International Symposium on Computer Architecture (ISCA). IEEE, 972–984.<a href="#fnref:34" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:35" class="footnote-text"><span>Sankha Baran Dutta, Hoda Naghibijouybari, Arjun Gupta, Nael Abu-Ghazaleh, Andres Marquez, and Kevin Barker. 2023. Spy in the GPU-box: Covert and side channel attacks on multi-GPU systems. In Proceedings of the 50th Annual International Symposium on Computer Architecture. 1–13.<a href="#fnref:35" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:36" class="footnote-text"><span>Eric Evenchick. 2018. Rustzone: Writing trusted applications in rust. Black Hat Asia (2018).<a href="#fnref:36" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:37" class="footnote-text"><span>Dmitry Evtyushkin, Dmitry Ponomarev, and Nael Abu-Ghazaleh. 2016. Jump over ASLR: Attacking branch predictors to bypass ASLR. In 2016 49th Annual IEEE&#x2F;ACM International Symposium on Microarchitecture (MICRO). IEEE, 1–13.<a href="#fnref:37" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:38" class="footnote-text"><span>Dmitry Evtyushkin, Dmitry Ponomarev, and Nael Abu-Ghazaleh. 2016. Understanding and mitigating covert channels through branch predictors. ACM Transactions on Architecture and Code Optimization (TACO) 13, 1 (2016), 1–23.<a href="#fnref:38" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:39" class="footnote-text"><span>Dmitry Evtyushkin, Ryan Riley, Nael CSE Abu-Ghazaleh, ECE, and Dmitry Ponomarev. 2018. Branchscope: A new side-channel attack on directional branch predictor. ACM SIGPLAN Notices 53, 2 (2018), 693–707.<a href="#fnref:39" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:40" class="footnote-text"><span>Shengyu Fan, Zhiwei Wang, Weizhi Xu, Rui Hou, Dan Meng, and Mingzhe Zhang. 2023. Tensorfhe: Achieving practical computation on encrypted data using gpgpu. In 2023 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 922–934.<a href="#fnref:40" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:41" class="footnote-text"><span>Shufan Fei, Zheng Yan, Wenxiu Ding, and Haomeng Xie. 2021. Security vulnerabilities of SGX and countermeasures: A survey. ACM Computing Surveys (CSUR) 54, 6 (2021), 1–36.<a href="#fnref:41" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:42" class="footnote-text"><span>Andrew Ferraiuolo, Andrew Baumann, Chris Hawblitzel, and Bryan Parno. 2017. Komodo: Using verification to disentangle secure-enclave hardware from software. In Proceedings of the 26th Symposium on Operating Systems Principles. 287–305.<a href="#fnref:42" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:43" class="footnote-text"><span>Pietro Frigo, Cristiano Giuffrida, Herbert Bos, and Kaveh Razavi. 2018. Grand pwning unit: Accelerating microarchitectural attacks with the GPU. In 2018 ieee symposium on security and privacy (sp). IEEE, 195–210.<a href="#fnref:43" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:44" class="footnote-text"><span>Yiwen Gao, Hailong Zhang, Wei Cheng, Yongbin Zhou, and Yuchen Cao. 2018. Electro-magnetic analysis of GPU-based AES implementation. In Proceedings of the 55th Annual Design Automation Conference. 1–6.<a href="#fnref:44" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:45" class="footnote-text"><span>Tara Ghasempouri, Jaan Raik, Cezar Reinbrecht, Said Hamdioui, and Mottaqiallah Taouil. 2023. Survey on architectural attacks: A unified classification and attack model. Comput. Surveys 56, 2 (2023), 1–32.<a href="#fnref:45" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:46" class="footnote-text"><span>Lukas Giner, Roland Czerny, Christoph Gruber, Fabian Rauscher, Andreas Kogler, Daniel De Almeida Braga, and Daniel Gruss. 2024. Generic and Automated Drive-by GPU Cache Attacks from the Browser. (2024).<a href="#fnref:46" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:47" class="footnote-text"><span>Johannes Götzfried, Moritz Eckert, Sebastian Schinzel, and Tilo Müller. 2017. Cache attacks on Intel SGX. In Proceedings of the 10th European Workshop on Systems Security. 1–6.<a href="#fnref:47" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:48" class="footnote-text"><span>Daniel Gruss, Julian Lettner, Felix Schuster, Olya Ohrimenko, Istvan Haller, and Manuel Costa. 2017. Strong and efficient cache {Side-Channel} protection using hardware transactional memory. In 26th USENIX Security Symposium (USENIX Security 17). 217–233.<a href="#fnref:48" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:49" class="footnote-text"><span>Daniel Gruss, Clémentine Maurice, Klaus Wagner, and Stefan Mangard. 2016. Flush+ Flush: a fast and stealthy cache attack. In Detection of Intrusions and Malware, and Vulnerability Assessment: 13th International Conference, DIMVA 2016, Spain, July 7-8, 2016. Springer, 279–299.<a href="#fnref:49" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:50" class="footnote-text"><span>Daniel Gruss, Raphael Spreitzer, and Stefan Mangard. 2015. Cache template attacks: Automating attacks on inclusive Last-Level caches. In 24th USENIX Security Symposium (USENIX Security 15). 897–912.<a href="#fnref:50" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:51" class="footnote-text"><span>Roberto Guanciale, Hamed Nemati, Christoph Baumann, and Mads Dam. 2016. Cache storage channels: Alias-driven attacks and verified countermeasures. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 38–55.<a href="#fnref:51" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:52" class="footnote-text"><span>Roberto Guanciale, Nicolae Paladi, and Arash Vahidi. 2022. SoK: Confidential quartet-Comparison of platforms for virtualization-based confidential computing. In 2022 IEEE International Symposium on Secure and Private Execution Environment Design (SEED). IEEE, 109–120.<a href="#fnref:52" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:53" class="footnote-text"><span>Jago Gyselinck, Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2018. Off-limits: Abusing legacy x86 memory segmentation to spy on enclaved execution. In Engineering Secure Software and Systems: 10th International Symposium, ESSoS 2018, France, June 26-27, 2018. Springer, 44–60.<a href="#fnref:53" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:54" class="footnote-text"><span>J. Alex Halderman, Seth D. Schoen, Nadia Heninger, William Clarkson, William Paul, Joseph A. Calandrino, Ariel J. Feldman, Jacob Appelbaum, and Edward W. Felten. [n. d.]. Lest We Remember: Cold Boot Attacks on Encryption Keys. In 17th USENIX Security Symposium (USENIX Security 08).<a href="#fnref:54" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:55" class="footnote-text"><span>Wenjian HE, Wei Zhang, Sharad Sinha, and Sanjeev Das. 2020. Igpu leak: An information leakage vulnerability on intel integrated gpu. In 2020 25th Asia and South Pacific Design Automation Conference (ASP-DAC). IEEE, 56–61.<a href="#fnref:55" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:56" class="footnote-text"><span>Felicitas Hetzelt and Robert Buhren. 2017. Security analysis of encrypted virtual machines. ACM SIGPLAN Notices 52, 7 (2017), 129–142.<a href="#fnref:56" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:57" class="footnote-text"><span>Peter Horvath, Lukasz Chmielewski, Leo Weissbart, Lejla Batina, and Yuval Yarom. 2023. BarraCUDA: Bringing Electromagnetic Side Channel Into Play to Steal the Weights of Neural Networks from NVIDIA GPUs. arXiv preprint arXiv:2312.07783 (2023).<a href="#fnref:57" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:58" class="footnote-text"><span>Shohreh Hosseinzadeh, Hans Liljestrand, Ville Leppänen, and Andrew Paverd. 2018. Mitigating branch-shadowing attacks on intel sgx using control flow randomization. In Proceedings of the 3rd Workshop on System Software for Trusted Execution. 42–47.<a href="#fnref:58" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:59" class="footnote-text"><span>Xing Hu, Ling Liang, Shuangchen Li, Lei Deng, Pengfei Zuo, Yu Ji, Xinfeng Xie, Yufei Ding, Chang Liu, Timothy Sherwood, et al. 2020. Deepsniffer: A dnn model extraction framework based on learning architectural hints. In Proceedings of the Twenty-Fifth International Conference on Architectural Support for Programming Languages and Operating Systems. 385–399.<a href="#fnref:59" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:60" class="footnote-text"><span>Tyler Hunt, Zhipeng Jia, Vance Miller, Ariel Szekely, Yige Hu, Christopher J Rossbach, and Emmett Witchel. 2020. Telekine: Secure computing with cloud GPUs. In 17th USENIX Symposium on Networked Systems Design and Implementation (NSDI 20). 817–833.<a href="#fnref:60" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:61" class="footnote-text"><span>Tianlin Huo, Xiaoni Meng, Wenhao Wang, Chunliang Hao, Pei Zhao, Jian Zhai, and Mingshu Li. 2020. Bluethunder: A 2-level directional predictor based side-channel attack against sgx. IACR Transactions on Cryptographic Hardware and Embedded Systems (2020), 321–347.<a href="#fnref:61" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:62" class="footnote-text"><span>Intel. 2023. Intel Multi-Key Total Memory Encryption. <a href="https://www.intel.com/content/dam/www/central-libraries/us/en/documents/2022-10/inteltotal-memory-encryption-multi-key-whitepaper.pdf">https://www.intel.com/content/dam/www/central-libraries/us/en/documents/2022-10/inteltotal-memory-encryption-multi-key-whitepaper.pdf</a>.<a href="#fnref:62" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:63" class="footnote-text"><span>Intel. 2023. Intel Trust Domain Extensions (Intel TDX). <a href="https://www.intel.com/content/www/us/en/developer/tools/trust-domain-extensions/overview.html">https://www.intel.com/content/www/us/en/developer/tools/trust-domain-extensions/overview.html</a>.<a href="#fnref:63" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:64" class="footnote-text"><span>Intel. 2024. Intel Mesa 3D Graphics Library. <a href="https://docs.mesa3d.org/systems.html">https://docs.mesa3d.org/systems.html</a>.<a href="#fnref:64" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:65" class="footnote-text"><span>Andrei Ivanov, Benjamin Rothenberger, Arnaud Dethise, Marco Canini, Torsten Hoefler, and Adrian Perrig. 2023. SAGE: Software-based Attestation for GPU Execution. In 2023 USENIX Annual Technical Conference (USENIX ATC 23). 485–499.<a href="#fnref:65" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:66" class="footnote-text"><span>Insu Jang, Adrian Tang, Taehoon Kim, Simha Sethumadhavan, and Jaehyuk Huh. 2019. Heterogeneous isolated execution for commodity gpus. In Proceedings of the Twenty-Fourth International Conference on Architectural Support for Programming Languages and Operating Systems. 455–468.<a href="#fnref:66" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:67" class="footnote-text"><span>Jinsoo Jang and Brent Byunghoon Kang. 2018. Retrofitting the partially privileged mode for TEE communication channel protection. IEEE Transactions on Dependable and Secure Computing 17, 5 (2018), 1000–1014.<a href="#fnref:67" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:68" class="footnote-text"><span>Jin Soo Jang, Sunjune Kong, Minsu Kim, Daegyeong Kim, and Brent Byunghoon Kang. 2015. Secret: Secure channel between rich execution environment and trusted execution environment.. In NDSS. 1–15.<a href="#fnref:68" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:69" class="footnote-text"><span>Yeongjin Jang, Jaehyuk Lee, Sangho Lee, and Taesoo Kim. 2017. SGX-Bomb: Locking down the processor via Rowhammer attack. In Proceedings of the 2nd Workshop on System Software for Trusted Execution. 1–6.<a href="#fnref:69" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:70" class="footnote-text"><span>Neha Jawalkar, Kanav Gupta, Arkaprava Basu, Nishanth Chandran, Divya Gupta, and Rahul Sharma. 2023. Orca: FSS-based secure training with GPUs. Cryptology ePrint Archive (2023).<a href="#fnref:70" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:71" class="footnote-text"><span>Jianyu Jiang, Ji Qi, Tianxiang Shen, Xusheng Chen, Shixiong Zhao, Sen Wang, Li Chen, Gong Zhang, Xiapu Luo, and Heming Cui. 2022. CRONUS: Fault-isolated, secure and high-performance heterogeneous computing for trusted execution environment. In 2022 55th IEEE&#x2F;ACM International Symposium on Microarchitecture (MICRO). IEEE, 124–143.<a href="#fnref:71" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:72" class="footnote-text"><span>Zhen Hang Jiang, Yunsi Fei, and David Kaeli. 2016. A complete key recovery timing attack on a GPU. In 2016 IEEE International symposium on high performance computer architecture (HPCA). IEEE, 394–405.<a href="#fnref:72" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:73" class="footnote-text"><span>Zhen Hang Jiang, Yunsi Fei, and David Kaeli. 2017. A novel side-channel timing attack on GPUs. In Proceedings of the on Great Lakes Symposium on VLSI 2017. 167–172.<a href="#fnref:73" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:74" class="footnote-text"><span>Gurunath Kadam, Danfeng Zhang, and Adwait Jog. 2018. Rcoal: mitigating gpu timing attack via subwarp-based randomized coalescing techniques. In 2018 IEEE international symposium on high performance computer architecture (HPCA). IEEE, 156–167.<a href="#fnref:74" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:75" class="footnote-text"><span>Gurunath Kadam, Danfeng Zhang, and Adwait Jog. 2020. Bcoal: Bucketing-based memory coalescing for efficient and secure gpus. In 2020 IEEE International Symposium on High Performance Computer Architecture (HPCA). IEEE, 570–581.<a href="#fnref:75" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:76" class="footnote-text"><span>David Kaplan. 2017. Protecting VM register state with SEV-ES. White paper (2017), 13.<a href="#fnref:76" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:77" class="footnote-text"><span>Zijo Kenjar, Tommaso Frassetto, David Gens, Michael Franz, and Ahmad-Reza Sadeghi. 2020. V0LTpwn: Attacking x86 processor integrity from software. In 29th USENIX Security Symposium (USENIX Security 20). 1445–1461.<a href="#fnref:77" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:78" class="footnote-text"><span>Mustakimur Rahman Khandaker, Yueqiang Cheng, Zhi Wang, and Tao Wei. 2020. COIN attacks: On insecurity of enclave untrusted interfaces in SGX. In Proceedings of the 25th International Conference on Architectural Support for Programming Languages and Operating Systems. 971–985.<a href="#fnref:78" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:79" class="footnote-text"><span>Ashfaq A. Khokhar, Viktor K. Prasanna, Muhammad E. Shaaban, and C-L Wang. 1993. Heterogeneous computing: Challenges and opportunities. Computer 26, 6 (1993), 18–27.<a href="#fnref:79" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:80" class="footnote-text"><span>Deokjin Kim, Daehee Jang, Minjoon Park, Yunjong Jeong, Jonghwan Kim, Seokjin Choi, and Brent Byunghoon Kang. 2019. SGX-LEGO: Fine-grained SGX controlled-channel attack and its countermeasure. computers &amp; security 82 (2019), 118–139.<a href="#fnref:80" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:81" class="footnote-text"><span>Paul Kocher, Jann Horn, Anders Fogh, Daniel Genkin, Daniel Gruss, Werner Haas, Mike Hamburg, Moritz Lipp, Stefan Mangard, Thomas Prescher, et al. 2020. Spectre attacks: Exploiting speculative execution. Commun. ACM 63, 7 (2020), 93–101.<a href="#fnref:81" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:82" class="footnote-text"><span>Daniel Komaromy. 2018. Unbox Your Phone. <a href="https://medium.com/taszksec/unbox-your-phone-part-i-331bbf44c30c">https://medium.com/taszksec/unbox-your-phone-part-i-331bbf44c30c</a><a href="#fnref:82" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:83" class="footnote-text"><span>Jingfei Kong, Onur Aciiçmez, Jean-Pierre Seifert, and Huiyang Zhou. 2009. Hardware-software integrated approaches to defend against software cache-based side channel attacks. In 2009 IEEE 15th international symposium on high performance computer architecture. IEEE, 393–404.<a href="#fnref:83" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:84" class="footnote-text"><span>Esmaeil Mohammadian Koruyeh, Khaled N Khasawneh, Chengyu Song, and Nael Abu-Ghazaleh. 2018. Spectre returns! speculation attacks using the return stack buffer. In 12th USENIX Workshop on Offensive Technologies (WOOT 18).<a href="#fnref:84" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:85" class="footnote-text"><span>Dayeol Lee, Dongha Jung, Ian T. Fang, Chia che Tsai, and Raluca Ada Popa. 2020. An Off-Chip Attack on Hardware Enclaves via the Memory Bus. In 29th USENIX Security Symposium (USENIX Security ’20). 487–504.<a href="#fnref:85" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:86" class="footnote-text"><span>Sunho Lee, Jungwoo Kim, Seonjin Na, Jongse Park, and Jaehyuk Huh. 2022. Tnpu: Supporting trusted execution with tree-less integrity protection for neural processing unit. In 2022 IEEE International Symposium on High-Performance Computer Architecture (HPCA). IEEE, 229–243.<a href="#fnref:86" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:87" class="footnote-text"><span>Sangho Lee, Youngsok Kim, Jangwoo Kim, and Jong Kim. 2014. Stealing webpages rendered on your browser by exploiting GPU vulnerabilities. In 2014 IEEE Symposium on Security and Privacy. IEEE, 19–33.<a href="#fnref:87" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:88" class="footnote-text"><span>Sangho Lee, Ming-Wei Shih, Prasun Gera, Taesoo Kim, Hyesoon Kim, and Marcus Peinado. 2017. Inferring fine-grained control flow inside SGX enclaves with branch shadowing. In 26th USENIX Security Symposium (USENIX Security 17). 557–574.<a href="#fnref:88" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:89" class="footnote-text"><span>Matthew Lentz, Rijurekha Sen, Peter Druschel, and Bobby Bhattacharjee. 2018. Secloak: Arm trustzone-based mobile peripheral control. In Proceedings of the 16th Annual International Conference on Mobile Systems, Applications, and Services. 1–13.<a href="#fnref:89" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:90" class="footnote-text"><span>Mengyuan Li. 2022. Understanding and Exploiting Design Flaws of AMD Secure Encrypted Virtualization. The Ohio State University.<a href="#fnref:90" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:91" class="footnote-text"><span>Mengyuan Li, Yuheng Yang, Guoxing Chen, Mengjia Yan, and Yinqian Zhang. 2024. SoK: Understanding Designs Choices and Pitfalls of Trusted Execution Environments. (2024).<a href="#fnref:91" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:92" class="footnote-text"><span>Mengyuan Li, Yinqian Zhang, and Zhiqiang Lin. 2021. Crossline: Breaking” security-by-crash” based memory isolation in amd sev. In Proceedings of the 2021 ACM SIGSAC Conference on Computer and Communications Security. 2937–2950.<a href="#fnref:92" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:93" class="footnote-text"><span>Mengyuan Li, Yinqian Zhang, Huibo Wang, Kang Li, and Yueqiang Cheng. 2021. CIPHERLEAKS: Breaking Constant-time Cryptography on AMDSEV via the Ciphertext Side Channel. In 30th USENIX Security Symposium (USENIX Security 21). 717–732.<a href="#fnref:93" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:94" class="footnote-text"><span>Mengyuan Li, Yinqian Zhang, Huibo Wang, Kang Li, and Yueqiang Cheng. 2021. TLB Poisoning Attacks on AMD Secure Encrypted Virtualization. In Proceedings of the 37th Annual Computer Security Applications Conference. 609–619.<a href="#fnref:94" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:95" class="footnote-text"><span>Sisheng Liang, Zihao Zhan, Fan Yao, Long Cheng, and Zhenkai Zhang. 2022. Clairvoyance: exploiting far-field em emanations of gpu to” see” your dnn models through obstacles at a distance. In 2022 IEEE Security and Privacy Workshops (SPW). IEEE, 312–322.<a href="#fnref:95" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:96" class="footnote-text"><span>Zhen Lin, Utkarsh Mathur, and Huiyang Zhou. 2019. Scatter-and-gather revisited: High-performance side-channel-resistant AES on GPUs. In Proceedings of the 12th Workshop on General Purpose Processing Using GPUs. 2–11.<a href="#fnref:96" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:97" class="footnote-text"><span>Moritz Lipp, Daniel Gruss, Raphael Spreitzer, Clémentine Maurice, and Stefan Mangard. 2016. ARMageddon: Cache attacks on mobile devices. In 25th USENIX Security Symposium (USENIX Security 16). 549–564.<a href="#fnref:97" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:98" class="footnote-text"><span>Moritz Lipp, Andreas Kogler, David Oswald, Michael Schwarz, Catherine Easdon, Claudio Canella, and Daniel Gruss. 2021. PLATYPUS: Softwarebased power side-channel attacks on x86. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 355–371.<a href="#fnref:98" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:99" class="footnote-text"><span>Moritz Lipp, Michael Schwarz, Daniel Gruss, Thomas Prescher, Werner Haas, Jann Horn, Stefan Mangard, Paul Kocher, Daniel Genkin, Yuval Yarom, et al. 2020. Meltdown: Reading kernel memory from user space. Commun. ACM 63, 6 (2020), 46–56.<a href="#fnref:99" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:100" class="footnote-text"><span>Chen Liu, Abhishek Chakraborty, Nikhil Chawla, and Neer Roggel. 2022. Frequency Throttling Side-Channel Attack. In Proceedings of the 2022 ACM SIGSAC Conference on Computer and Communications Security. 1977–1991.<a href="#fnref:100" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:101" class="footnote-text"><span>Fangfei Liu, Qian Ge, Yuval Yarom, Frank Mckeen, Carlos Rozas, Gernot Heiser, and Ruby B Lee. 2016. Catalyst: Defeating last-level cache side channel attacks in cloud computing. In 2016 IEEE international symposium on high performance computer architecture (HPCA). IEEE, 406–418.<a href="#fnref:101" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:102" class="footnote-text"><span>Fangfei Liu, Yuval Yarom, Qian Ge, Gernot Heiser, and Ruby B Lee. 2015. Last-level cache side-channel attacks are practical. In 2015 IEEE symposium on security and privacy. IEEE, 605–622.<a href="#fnref:102" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:103" class="footnote-text"><span>Chao Luo, Yunsi Fei, and David Kaeli. 2019. Side-channel timing attack of RSA on a GPU. ACM Transactions on Architecture and Code Optimization (TACO) 16, 3 (2019), 1–18.<a href="#fnref:103" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:104" class="footnote-text"><span>Chao Luo, Yunsi Fei, Pei Luo, Saoni Mukherjee, and David Kaeli. 2015. Side-channel power analysis of a GPU AES implementation. In 2015 33rd IEEE International Conference on Computer Design (ICCD). IEEE, 281–288.<a href="#fnref:104" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:105" class="footnote-text"><span>Dina G Mahmoud, Vincent Lenders, and Mirjana Stojilović. 2022. Electrical-level attacks on CPUs, FPGAs, and GPUs: Survey and implications in the heterogeneous era. ACM Computing Surveys (CSUR) 55, 3 (2022), 1–40.<a href="#fnref:105" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:106" class="footnote-text"><span>Haohui Mai, Jiacheng Zhao, Hongren Zheng, Yiyang Zhao, Zibin Liu, Mingyu Gao, Cong Wang, Huimin Cui, Xiaobing Feng, and Christos Kozyrakis. 2023. Honeycomb: Secure and Efficient GPU Executions via Static Validation. In 17th USENIX Symposium on Operating Systems Design and Implementation (OSDI 23). 155–172.<a href="#fnref:106" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:107" class="footnote-text"><span>Henrique Teles Maia, Chang Xiao, Dingzeyu Li, Eitan Grinspun, and Changxi Zheng. 2022. Can one hear the shape of a neural network?: Snooping the GPU via Magnetic Side Channel.. In USENIX Security Symposium. 4383–4400.<a href="#fnref:107" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:108" class="footnote-text"><span>Stefan Mangard, Elisabeth Oswald, and Thomas Popp. 2008. Power analysis attacks: Revealing the secrets of smart cards. Vol. 31. Springer Science &amp; Business Media.<a href="#fnref:108" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:109" class="footnote-text"><span>Clémentine Maurice, Christoph Neumann, Olivier Heen, and Aurélien Francillon. 2014. Confidentiality issues on a GPU in a virtualized environment. In Financial Cryptography and Data Security: 18th International Conference, FC 2014, Christ Church, Barbados, March 3-7, 2014, Revised Selected Papers 18. Springer, 119–135.<a href="#fnref:109" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:110" class="footnote-text"><span>Pratyush Mishra, Ryan Lehmkuhl, Akshayaram Srinivasan, Wenting Zheng, and Raluca Ada Popa. 2020. Delphi: A cryptographic inference system for neural networks. In Proceedings of the 2020 Workshop on Privacy-Preserving Machine Learning in Practice. 27–30.<a href="#fnref:110" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:111" class="footnote-text"><span>Sparsh Mittal and Jeffrey S Vetter. 2015. A survey of CPU-GPU heterogeneous computing techniques. ACM Computing Surveys (CSUR) 47, 4 (2015), 1–35.<a href="#fnref:111" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:112" class="footnote-text"><span>Ahmad Moghimi, Gorka Irazoqui, and Thomas Eisenbarth. 2017. Cachezoom: How SGX amplifies the power of cache attacks. In Cryptographic Hardware and Embedded Systems–CHES 2017: 19th International Conference, Taipei, Taiwan, September 25-28, 2017, Proceedings. Springer, 69–90.<a href="#fnref:112" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:113" class="footnote-text"><span>Ahmad Moghimi, Jan Wichelmann, Thomas Eisenbarth, and Berk Sunar. 2019. Memjam: A false dependency attack against constant-time crypto implementations. International Journal of Parallel Programming 47 (2019), 538–570.<a href="#fnref:113" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:114" class="footnote-text"><span>Mathias Morbitzer, Manuel Huber, Julian Horsch, and Sascha Wessel. 2018. SEVered: Subverting AMD’s virtual machine encryption. In Proceedings of the 11th European Workshop on Systems Security. 1–6.<a href="#fnref:114" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:115" class="footnote-text"><span>Mathias Morbitzer, Sergej Proskurin, Martin Radev, Marko Dorfhuber, and Erick Quintanar Salas. 2021. Severity: Code injection attacks against encrypted virtual machines. In 2021 IEEE Security and Privacy Workshops (SPW). IEEE, 444–455.<a href="#fnref:115" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:116" class="footnote-text"><span>David N Muchene, Klevis Luli, and Craig A Shue. 2013. Reporting insider threats via covert channels. In 2013 IEEE Security and Privacy Workshops. IEEE, 68–71.<a href="#fnref:116" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:117" class="footnote-text"><span>Kit Murdock, David Oswald, Flavio D Garcia, Jo Van Bulck, Daniel Gruss, and Frank Piessens. 2020. Plundervolt: Software-based fault injection attacks against Intel SGX. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1466–1482.<a href="#fnref:117" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:118" class="footnote-text"><span>Hoda Naghibijouybari, Khaled N Khasawneh, and Nael Abu-Ghazaleh. 2017. Constructing and characterizing covert channels on gpgpus. In Proceedings of the 50th Annual IEEE&#x2F;ACM International Symposium on Microarchitecture. 354–366.<a href="#fnref:118" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:119" class="footnote-text"><span>Hoda Naghibijouybari, Esmaeil Mohammadian Koruyeh, and Nael Abu-Ghazaleh. 2022. Microarchitectural attacks in heterogeneous systems: A survey. Comput. Surveys 55, 7 (2022), 1–40.<a href="#fnref:119" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:120" class="footnote-text"><span>Hoda Naghibijouybari, Ajaya Neupane, Zhiyun Qian, and Nael Abu-Ghazaleh. 2018. Rendered insecure: Gpu side channel attacks are practical. In Proceedings of the 2018 ACM SIGSAC conference on computer and communications security. 2139–2153.<a href="#fnref:120" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:121" class="footnote-text"><span>Ajay Nayak, Vinod Ganapathy, and Arkaprava Basu. 2021. (Mis) managed: A novel TLB-based covert channel on GPUs. In Proceedings of the 2021 ACM Asia Conference on Computer and Communications Security. 872–885.<a href="#fnref:121" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:122" class="footnote-text"><span>Lucien KL Ng and Sherman SM Chow. 2021. GForce:GPU-Friendly oblivious and rapid neural network inference. In 30th USENIX Security Symposium (USENIX Security 21). 2147–2164.<a href="#fnref:122" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:123" class="footnote-text"><span>Alexander Nilsson, Pegah Nikbakht Bideh, and Joakim Brorsson. 2020. A survey of published attacks on Intel SGX. arXiv preprint arXiv:2006.13598 (2020).<a href="#fnref:123" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:124" class="footnote-text"><span>NVIDIA. 2022. NVIDIA confidential computing. <a href="https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/">https://www.nvidia.com/en-us/data-center/solutions/confidentialcomputing/</a>.<a href="#fnref:124" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:125" class="footnote-text"><span>NVIDIA. 2022. NVIDIA H100 Tensor Core GPU Architecture. <a href="https://resources.nvidia.com/en-us-data-center-overview-mc/en-us-data-centeroverview/gtc22-whitepaper-hopper?pflpid=17841&lb-mode=preview">https://resources.nvidia.com/en-us-data-center-overview-mc/en-us-data-centeroverview/gtc22-whitepaper-hopper?pflpid=17841&amp;lb-mode=preview</a>.<a href="#fnref:125" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:126" class="footnote-text"><span>Olga Ohrimenko, Felix Schuster, Cédric Fournet, Aastha Mehta, Sebastian Nowozin, Kapil Vaswani, and Manuel Costa. 2016. Oblivious Multi-Party machine learning on trusted processors. In 25th USENIX Security Symposium (USENIX Security 16). 619–636.<a href="#fnref:126" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:127" class="footnote-text"><span>Dag Arne Osvik, Adi Shamir, and Eran Tromer. 2006. Cache attacks and countermeasures: the case of AES. In Topics in Cryptology–CT-RSA 2006: The Cryptographers’ Track at the RSA Conference 2006, San Jose, CA, USA, February 13-17, 2005. Proceedings. Springer, 1–20.<a href="#fnref:127" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:128" class="footnote-text"><span>Roberto Di Pietro, Flavio Lombardi, and Antonio Villani. 2016. CUDA leaks: a detailed hack for CUDA and a (partial) fix. ACM Transactions on Embedded Computing Systems (TECS) 15, 1 (2016), 1–25.<a href="#fnref:128" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:129" class="footnote-text"><span>Sandro Pinto and Nuno Santos. 2019. Demystifying arm trustzone: A comprehensive survey. ACM computing surveys (CSUR) 51, 6 (2019), 1–36.<a href="#fnref:129" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:130" class="footnote-text"><span>Rishabh Poddar, Ganesh Ananthanarayanan, Srinath Setty, Stavros Volos, and Raluca Ada Popa. 2020. Visor:Privacy-Preserving video analytics as a cloud service. In 29th USENIX Security Symposium (USENIX Security 20). 1039–1056.<a href="#fnref:130" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:131" class="footnote-text"><span>Pengfei Qiu, Dongsheng Wang, Yongqiang Lyu, Ruidong Tian, Chunlu Wang, and Gang Qu. 2020. Voltjockey: A new dynamic voltage scaling-based fault injection attack on intel sgx. IEEE Transactions on Computer-Aided Design of Integrated Circuits and Systems 40, 6 (2020), 1130–1143.<a href="#fnref:131" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:132" class="footnote-text"><span>Hany Ragab, Alyssa Milburn, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. 2021. Crosstalk: Speculative data leaks across cores are real. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 1852–1867.<a href="#fnref:132" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:133" class="footnote-text"><span>Keegan Ryan. 2019. Hardware-backed heist: Extracting ECDSA keys from qualcomm’s trustzone. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 181–194.<a href="#fnref:133" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:134" class="footnote-text"><span>Majid Sabbagh, Yunsi Fei, and David Kaeli. 2020. A novel GPU overdrive fault attack. In 2020 57th ACM&#x2F;IEEE Design Automation Conference (DAC). IEEE, 1–6.<a href="#fnref:134" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:135" class="footnote-text"><span>Majid Sabbagh, Yunsi Fei, and David Kaeli. 2021. Gpu overdrive fault attacks on neural networks. In 2021 IEEE&#x2F;ACM International Conference On Computer Aided Design (ICCAD). IEEE, 1–8.<a href="#fnref:135" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:136" class="footnote-text"><span>Fernando F dos Santos, Josie E Rodriguez Condia, Luigi Carro, Matteo Sonza Reorda, and Paolo Rech. 2021. Revealing gpus vulnerabilities by combining register-transfer and software-level fault injection. In 2021 51st Annual IEEE&#x2F;IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 292–304.<a href="#fnref:136" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:137" class="footnote-text"><span>Benedict Schlüter, Supraja Sridhara, Andrin Bertschi, and Shweta Shinde. 2024. WeSee: Using Malicious# VC Interrupts to Break AMD SEV-SNP. arXiv preprint arXiv:2404.03526 (2024).<a href="#fnref:137" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:138" class="footnote-text"><span>Benedict Schlüter, Supraja Sridhara, Mark Kuhne, Andrin Bertschi, and Shweta Shinde. 2024. Heckler: Breaking Confidential VMs with Malicious Interrupts. In USENIX Security.<a href="#fnref:138" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:139" class="footnote-text"><span>Michael Schwarz, Moritz Lipp, Daniel Moghimi, Jo Van Bulck, Julian Stecklina, Thomas Prescher, and Daniel Gruss. 2019. ZombieLoad: Crossprivilege-boundary data sampling. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 753–768.<a href="#fnref:139" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:140" class="footnote-text"><span>Michael Schwarz, Samuel Weiser, Daniel Gruss, Clémentine Maurice, and Stefan Mangard. 2017. Malware guard extension: Using SGX to conceal cache attacks. In Detection of Intrusions and Malware, and Vulnerability Assessment: 14th International Conference, DIMVA 2017, Bonn, Germany, July 6-7, 2017, Proceedings 14. Springer, 3–24.<a href="#fnref:140" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:141" class="footnote-text"><span>Jaebaek Seo, Byoungyoung Lee, Seong Min Kim, Ming-Wei Shih, Insik Shin, Dongsu Han, and Taesoo Kim. 2017. SGX-shield: Enabling address space layout randomization for SGX programs.. In NDSS.<a href="#fnref:141" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:142" class="footnote-text"><span>AMD Sev-Snp. 2020. Strengthening VM isolation with integrity protection and more. White Paper, January 53 (2020), 1450–1465.<a href="#fnref:142" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:143" class="footnote-text"><span>Ali Shafiee, Akhila Gundu, Manjunath Shevgoor, Rajeev Balasubramonian, and Mohit Tiwari. 2015. Avoiding information leakage in the memory controller with fixed service policies. In Proceedings of the 48th International Symposium on Microarchitecture. 89–101.<a href="#fnref:143" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:144" class="footnote-text"><span>Di Shen. 2015. Exploiting trustzone on android. Black Hat USA 2 (2015), 267–280.<a href="#fnref:144" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:145" class="footnote-text"><span>Shaohuai Shi, Qiang Wang, Pengfei Xu, and Xiaowen Chu. 2016. Benchmarking state-of-the-art deep learning software tools. In 2016 7th International Conference on Cloud Computing and Big Data (CCBD). IEEE, 99–104.<a href="#fnref:145" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:146" class="footnote-text"><span>Ming-Wei Shih, Sangho Lee, Taesoo Kim, and Marcus Peinado. 2017. T-SGX: Eradicating Controlled-Channel Attacks Against Enclave Programs.. In NDSS.<a href="#fnref:146" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:147" class="footnote-text"><span>Shweta Shinde, Zheng Leong Chua, Viswesh Narayanan, and Prateek Saxena. 2016. Preventing page faults from telling your secrets. In Proceedings of the 11th ACM on Asia Conference on Computer and Communications Security. 317–328.<a href="#fnref:147" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:148" class="footnote-text"><span>Amit Mazumder Shuvo, Tao Zhang, Farimah Farahmandi, and Mark Tehranipoor. 2023. A Comprehensive Survey on Non-Invasive Fault Injection Attacks. Cryptology ePrint Archive (2023).<a href="#fnref:148" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:149" class="footnote-text"><span>Chad Spensky, Aravind Machiry, Nathan Burow, Hamed Okhravi, Rick Housley, Zhongshu Gu, Hani Jamjoom, Christopher Kruegel, and Giovanni Vigna. 2021. Glitching demystified: analyzing control-flow-based glitching attacks and defenses. In 2021 51st Annual IEEE&#x2F;IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 400–412.<a href="#fnref:149" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:150" class="footnote-text"><span>He Sun, Kun Sun, Yuewu Wang, Jiwu Jing, and Haining Wang. 2015. Trustice: Hardware-assisted isolated computing environments on mobile devices. In 2015 45th Annual IEEE&#x2F;IFIP International Conference on Dependable Systems and Networks. IEEE, 367–378.<a href="#fnref:150" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:151" class="footnote-text"><span>Rihui Sun, Pengfei Qiu, Yongqiang Lyu, Jian Dong, Haixia Wang, Dongsheng Wang, and Gang Qu. 2023. Lightning: Leveraging DVFS-induced Transient Fault Injection to Attack Deep Learning Accelerator of GPUs. ACM Transactions on Design Automation of Electronic Systems 29, 1 (2023).<a href="#fnref:151" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:152" class="footnote-text"><span>Sijun Tan, Brian Knott, Yuan Tian, and David J Wu. 2021. CryptGPU: Fast privacy-preserving machine learning on the GPU. In 2021 IEEE Symposium on Security and Privacy (SP). IEEE, 1021–1038.<a href="#fnref:152" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:153" class="footnote-text"><span>Hritvik Taneja, Jason Kim, Jie Jeff Xu, Stephan Van Schaik, Daniel Genkin, and Yuval Yarom. 2023. Hot Pixels: Frequency, Power, and Temperature Attacks on GPUs and Arm SoCs. In 32nd USENIX Security Symposium (USENIX Security 23). 6275–6292.<a href="#fnref:153" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:154" class="footnote-text"><span>Adrian Tang, Simha Sethumadhavan, and Salvatore Stolfo. 2017. CLKSCREW: Exposing the perils of Security-Oblivious energy management. In 26th USENIX Security Symposium (USENIX Security 17). 1057–1074.<a href="#fnref:154" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:155" class="footnote-text"><span>Eran Tromer, Dag Arne Osvik, and Adi Shamir. 2010. Efficient cache attacks on AES, and countermeasures. Journal of Cryptology 23 (2010), 37–71.<a href="#fnref:155" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:156" class="footnote-text"><span>Jo Van Bulck, Marina Minkin, Ofir Weisse, Daniel Genkin, Baris Kasikci, Frank Piessens, Mark Silberstein, Thomas F Wenisch, Yuval Yarom, and Raoul Strackx. 2018. Foreshadow: Extracting the keys to the intel SGX kingdom with transient Out-of-Order execution. In 27th USENIX Security Symposium (USENIX Security 18). 991–1008.<a href="#fnref:156" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:157" class="footnote-text"><span>Jo Van Bulck, David Oswald, Eduard Marin, Abdulla Aldoseri, Flavio D Garcia, and Frank Piessens. 2019. A tale of two worlds: Assessing the vulnerability of enclave shielding runtimes. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 1741–1758.<a href="#fnref:157" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:158" class="footnote-text"><span>Jo Van Bulck, Frank Piessens, and Raoul Strackx. 2017. SGX-Step: A practical attack framework for precise enclave execution control. In Proceedings of the 2nd Workshop on System Software for Trusted Execution. 1–6.<a href="#fnref:158" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:159" class="footnote-text"><span>Jo Van Bulck, Nico Weichbrodt, Rüdiger Kapitza, Frank Piessens, and Raoul Strackx. 2017. Telling your secrets without page faults: Stealthy page Table-Based attacks on enclaved execution. In 26th USENIX Security Symposium (USENIX Security 17). 1041–1056.<a href="#fnref:159" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:160" class="footnote-text"><span>Stephan Van Schaik, Andrew Kwong, Daniel Genkin, and Yuval Yarom. 2020. SGAxe: How SGX fails in practice.<a href="#fnref:160" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:161" class="footnote-text"><span>Stephan Van Schaik, Alyssa Milburn, Sebastian Österlund, Pietro Frigo, Giorgi Maisuradze, Kaveh Razavi, Herbert Bos, and Cristiano Giuffrida. 2019. RIDL: Rogue in-flight data load. In 2019 IEEE Symposium on Security and Privacy (SP). IEEE, 88–105.<a href="#fnref:161" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:162" class="footnote-text"><span>Stavros Volos, Kapil Vaswani, and Rodrigo Bruno. 2018. Graviton: Trusted execution environments on GPUs. In 13th USENIX Symposium on Operating Systems Design and Implementation (OSDI 18). 681–696.<a href="#fnref:162" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:163" class="footnote-text"><span>Chenxu Wang, Fengwei Zhang, Yunjie Deng, Kevin Leach, Jiannong Cao, Zhenyu Ning, Shoumeng Yan, and Zhengyu He. 2024. CAGE: Complementing Arm CCA with GPU Extensions. In Proceedings of the 31st Annual Network and Distributed System Security Symposium.<a href="#fnref:163" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:164" class="footnote-text"><span>Huibo Wang, Pei Wang, Yu Ding, Mingshen Sun, Yiming Jing, Ran Duan, Long Li, Yulong Zhang, Tao Wei, and Zhiqiang Lin. 2019. Towards memory safe enclave programming with rust-sgx. In Proceedings of the 2019 ACM SIGSAC Conference on Computer and Communications Security. 2333–2350.<a href="#fnref:164" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:165" class="footnote-text"><span>Qifan Wang, Shujie Cui, Lei Zhou, Ocean Wu, Yonghua Zhu, and Giovanni Russello. 2022. Enclavetree: Privacy-preserving data stream training and inference using tee. In Proceedings of the 2022 ACM on Asia Conference on Computer and Communications Security. 741–755.<a href="#fnref:165" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:166" class="footnote-text"><span>Wenhao Wang, Guoxing Chen, Xiaorui Pan, Yinqian Zhang, XiaoFeng Wang, Vincent Bindschaedler, Haixu Tang, and Carl A Gunter. 2017. Leaky cauldron on the dark land: Understanding memory side-channel hazards in SGX. In Proceedings of the 2017 ACM SIGSAC Conference on Computer and Communications Security. 2421–2434.<a href="#fnref:166" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:167" class="footnote-text"><span>Yao Wang, Andrew Ferraiuolo, and G Edward Suh. 2014. Timing channel protection for a shared memory controller. In 2014 IEEE 20th International Symposium on High Performance Computer Architecture (HPCA). IEEE, 225–236.<a href="#fnref:167" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:168" class="footnote-text"><span>Yingchen Wang, Riccardo Paccagnella, Zhao Gang, Willy R Vasquez, David Kohlbrenner, Hovav Shacham, and Christopher W Fletcher. 2024. GPU. zip: On the Side-Channel Implications of Hardware-Based Graphical Data Compression. In 2024 IEEE Symposium on Security and Privacy (SP). 84–84.<a href="#fnref:168" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:169" class="footnote-text"><span>Yingchen Wang, Riccardo Paccagnella, Elizabeth Tang He, Hovav Shacham, Christopher W. Fletcher, and David Kohlbrenner. 2022. Hertzbleed: Turning Power Side-Channel Attacks Into Remote Timing Attacks on x86. In 31st USENIX Security Symposium (USENIX Security 22). Boston, MA, 679–697.<a href="#fnref:169" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:170" class="footnote-text"><span>Zhenghong Wang and Ruby B Lee. 2007. New cache designs for thwarting software cache-based side channel attacks. In Proceedings of the 34th annual international symposium on Computer architecture. 494–505.<a href="#fnref:170" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:171" class="footnote-text"><span>Zhendong Wang, Rujia Wang, Zihang Jiang, Xulong Tang, Shouyi Yin, and Yang Hu. 2021. Towards a secure integrated heterogeneous platform via cooperative CPU&#x2F;GPU encryption. In 2021 IEEE 30th Asian Test Symposium (ATS). IEEE, 115–120.<a href="#fnref:171" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:172" class="footnote-text"><span>Jean-Luc Watson, Sameer Wagh, and Raluca Ada Popa. 2022. Piranha: A GPU platform for secure computation. In 31st USENIX Security Symposium (USENIX Security 22). 827–844.<a href="#fnref:172" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:173" class="footnote-text"><span>Junyi Wei, Yicheng Zhang, Zhe Zhou, Zhou Li, and Mohammad Abdullah Al Faruque. 2020. Leaky dnn: Stealing deep-learning model secret with gpu context-switching side-channel. In 2020 50th Annual IEEE&#x2F;IFIP International Conference on Dependable Systems and Networks (DSN). IEEE, 125–137.<a href="#fnref:173" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:174" class="footnote-text"><span>Luca Wilke, Jan Wichelmann, Mathias Morbitzer, and Thomas Eisenbarth. 2020. Sevurity: No security without integrity: Breaking integrity-free memory encryption with minimal assumptions. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1483–1496.<a href="#fnref:174" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:175" class="footnote-text"><span>Luca Wilke, Jan Wichelmann, Anja Rabich, and Thomas Eisenbarth. 2024. SEV-Step A Single-Stepping Framework for AMD-SEV. IACR Transactions on Cryptographic Hardware and Embedded Systems 2024, 1 (2024), 180–206.<a href="#fnref:175" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:176" class="footnote-text"><span>Wenjie Xiong and Jakub Szefer. 2021. Survey of transient execution attacks and their mitigations. ACM Computing Surveys (CSUR) 54, 3 (2021), 1–36.<a href="#fnref:176" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:177" class="footnote-text"><span>Yuanzhong Xu, Weidong Cui, and Marcus Peinado. 2015. Controlled-channel attacks: Deterministic side channels for untrusted operating systems. In 2015 IEEE Symposium on Security and Privacy. IEEE, 640–656.<a href="#fnref:177" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:178" class="footnote-text"><span>Boyuan Yang, Ruirong Chen, Kai Huang, Jun Yang, and Wei Gao. 2022. Eavesdropping user credentials via GPU side channels on smartphones. In Proceedings of the 27th ACM International Conference on Architectural Support for Programming Languages and Operating Systems. 285–299.<a href="#fnref:178" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:179" class="footnote-text"><span>Yuval Yarom and Katrina Falkner. 2014. FLUSH+ RELOAD: A high resolution, low noise, l3 cache Side-Channel attack. In 23rd USENIX security symposium (USENIX security 14). 719–732.<a href="#fnref:179" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:180" class="footnote-text"><span>Ardhi Wiratama Baskara Yudha, Jake Meyer, Shougang Yuan, Huiyang Zhou, and Yan Solihin. 2022. LITE: a low-cost practical inter-operable GPU TEE. In Proceedings of the 36th ACM International Conference on Supercomputing. 1–13.<a href="#fnref:180" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:181" class="footnote-text"><span>Min Hong Yun and Lin Zhong. 2019. Ginseng: Keeping Secrets in Registers When You Distrust the Operating System.. In NDSS.<a href="#fnref:181" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:182" class="footnote-text"><span>Zihao Zhan, Zhenkai Zhang, Sisheng Liang, Fan Yao, and Xenofon Koutsoukos. 2022. Graphics peeping unit: Exploiting em side-channel information of gpus to eavesdrop on your neighbors. In 2022 IEEE Symposium on Security and Privacy (SP). IEEE, 1440–1457.<a href="#fnref:182" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:183" class="footnote-text"><span>Ning Zhang, He Sun, Kun Sun, Wenjing Lou, and Y Thomas Hou. 2016. CacheKit: Evading memory introspection using cache incoherence. In 2016 IEEE European Symposium on Security and Privacy (EuroS&amp;P). IEEE, 337–352.<a href="#fnref:183" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:184" class="footnote-text"><span>Ning Zhang, Kun Sun, Wenjing Lou, and Y Thomas Hou. 2016. Case: Cache-assisted secure execution on arm processors. In 2016 IEEE Symposium on Security and Privacy (SP). IEEE, 72–90.<a href="#fnref:184" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:185" class="footnote-text"><span>Ning Zhang, Kun Sun, Deborah Shands, Wenjing Lou, and Y Thomas Hou. 2016. Truspy: Cache side-channel information leakage from the secure world on arm devices. Cryptology ePrint Archive (2016).<a href="#fnref:185" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:186" class="footnote-text"><span>Ruiyi Zhang, CISPA Helmholtz Center, Lukas Gerlach, Daniel Weber, Lorenz Hetterich, Youheng Lü, Andreas Kogler, and Michael Schwarz. 2024. CacheWarp: Software-based Fault Injection using Selective State Reset. (2024).<a href="#fnref:186" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:187" class="footnote-text"><span>Zhenkai Zhang, Tyler Allen, Fan Yao, Xing Gao, and Rong Ge. 2023. TunneLs for Bootlegging: Fully Reverse-Engineering GPU TLBs for Challenging Isolation Guarantees of NVIDIA MIG. In Proceedings of the 2023 ACM SIGSAC Conference on Computer and Communications Security. 960–974.<a href="#fnref:187" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:188" class="footnote-text"><span>Wu Zhenyu, Xu Zhang, and H Wang. 2012. Whispers in the hyper-space: high-speed covert channel attacks in the cloud. In USENIX Security symposium. 159–173.<a href="#fnref:188" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:189" class="footnote-text"><span>Zhe Zhou, Wenrui Diao, Xiangyu Liu, Zhou Li, Kehuan Zhang, and Rui Liu. 2016. Vulnerable gpu memory management: towards recovering raw data from gpu. arXiv preprint arXiv:1605.06610 (2016).<a href="#fnref:189" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:190" class="footnote-text"><span>Jianping Zhu, Rui Hou, XiaoFeng Wang, Wenhao Wang, Jiangfeng Cao, Boyan Zhao, Zhongpu Wang, Yuhui Zhang, Jiameng Ying, Lixin Zhang, et al. 2020. Enabling rack-scale confidential computing using heterogeneous trusted execution environment. In 2020 IEEE Symposium on Security and Privacy (SP). IEEE, 1450–1465.<a href="#fnref:190" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:191" class="footnote-text"><span>Yuankun Zhu, Yueqiang Cheng, Husheng Zhou, and Yantao Lu. 2021. Hermes attack: Steal DNN models with lossless inference accuracy. In 30th USENIX Security Symposium (USENIX Security 21).<a href="#fnref:191" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>Security</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TEE</tag>
      
      <tag>Confidential Compute</tag>
      
      <tag>GPU</tag>
      
      <tag>Security</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>A Local AI Assistant like Siri</title>
    <link href="/2024/09/17/AI/voice-assistant/"/>
    <url>/2024/09/17/AI/voice-assistant/</url>
    
    <content type="html"><![CDATA[<p>This is a <a href="https://github.com/Jianliang-Shen/ASR-Ollama-Chattts">project</a> to deploy a local AI assistant. This combines <a href="https://github.com/modelscope/FunASR">FunASR</a>,<a href="https://github.com/ollama/ollama">Ollama</a> and <a href="https://github.com/FunAudioLLM/CosyVoice">CosyVoice</a>.</p><span id="more"></span><ul><li>FunASR version: 1af68ba6ffc21d4dc3bd5f01cda656def97e361c</li><li>CosyVoice version: 9e0b99e48e67c3a874b7d0bbdc1a6a15c35f422e</li></ul><p><img src="/img/ai/assistant/assistant.png" alt="Architecture"></p><div class="note note-danger">            <p>Current version cannot use the cosyvoice.</p>          </div><h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul><li><input disabled="" type="checkbox"> Cosyvoice Streaming…</li><li><input disabled="" type="checkbox"> Solve the defect that when playing the result audio, the microphone records the input and enter the death loop.</li></ul><h1 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h1><h2 id="FunASR"><a href="#FunASR" class="headerlink" title="FunASR"></a>FunASR</h2><p>You need to guarantee the WSL and Windows host can share the docker, this can be opened WSL in the docker desktop.</p><p><img src="/img/ai/assistant/docker.png" alt="Docker Setup"></p><p>Follow this tutorial to deploy FunASR: <a href="https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_tutorial_online.md">FunASR Realtime Transcribe Service</a>.</p><ul><li><p>Download workspace and run the local Asr server:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -O https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/shell/funasr-runtime-deploy-online-cpu-zh.sh<br><span class="hljs-built_in">sudo</span> bash funasr-runtime-deploy-online-cpu-zh.sh install --workspace ./funasr-runtime-resources<br><br><span class="hljs-comment"># Restart the container</span><br><span class="hljs-built_in">sudo</span> bash funasr-runtime-deploy-online-cpu-zh.sh restart<br></code></pre></td></tr></table></figure></li><li><p>In the container, it will download models from the modelscope. After that you should see:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker ps -a<br>docker <span class="hljs-built_in">exec</span> -it &lt;contianer ID&gt; bash<br><br><span class="hljs-comment"># In container:</span><br>watch -n 0.1 <span class="hljs-string">&quot;cat FunASR/runtime/log.txt | tail -n 10&quot;</span><br></code></pre></td></tr></table></figure></li></ul><p>We need to stop recording when the mic is not active. Here the technology is called <strong>VAD</strong>.</p><p>We also need to judge when the users input stop, not by the mic, but the results count from FunASR server. The count of sentences(messages) sent from the ASR server increases when user is saying. When user stopped, the count will stop increasing. I set the latency to 2s, when there is no more sentences coming from the server, the thread of <code>wait_end_and_send_to_ollama</code> will block and wait the results from the Ollama server.</p><div class="note note-danger">            <p>FIX: Note that when assistant is saying, the users input at the same time will be set as next input. An important feature is that user can interrupt the assistant.</p>          </div><h2 id="Ollama"><a href="#Ollama" class="headerlink" title="Ollama"></a>Ollama</h2><p>Download and install ollama in windows. After that, run <code>ollama run llama3.1</code> or <code>ollama run qwen:7b</code> in the Powershell to download the model. Then start the ollama server:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ollama serve<br></code></pre></td></tr></table></figure><p>You can easily follow the Ollama PyPi tutorial to use ollama APIs.</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> ollama<br><br><span class="hljs-comment"># Response streaming can be enabled by setting stream=True, modifying function</span><br><span class="hljs-comment"># calls to return a Python generator where each part is an object in the stream.</span><br>stream = ollama.chat(<br>    model=<span class="hljs-string">&#x27;llama3.1&#x27;</span>,<br>    messages=[&#123;<span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;Why is the sky blue?&#x27;</span>&#125;],<br>    stream=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> stream:<br>    <span class="hljs-built_in">print</span>(chunk[<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>], end=<span class="hljs-string">&#x27;&#x27;</span>, flush=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure><h2 id="CosyVoice"><a href="#CosyVoice" class="headerlink" title="CosyVoice"></a>CosyVoice</h2><p>Follow the tutorial: <a href="https://github.com/FunAudioLLM/CosyVoice">CosyVoice</a></p><ul><li><p>Cuda 11.8 torch and torchaudio:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118<br></code></pre></td></tr></table></figure></li><li><p>If you want to <strong>clone audio</strong>, transform audio file recorded from windows recorder:</p>  <div class="note note-danger">            <p>This is a very funny feature provided by CosyVoice, for example, you can clone Trump’s voice. This is already realized several years ago, but here it supports Chinese and uses LLM. <strong>Note that you should follow the law and privacy policy, it is very significant.</strong></p>          </div>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ffmpeg -i input.m4a output.wav<br></code></pre></td></tr></table></figure></li><li><p>ONNX Runtime Issue: <code>onnxruntime::Provider&amp; onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcufft.so.10: cannot open shared object file: No such file or directory</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install onnxruntime-gpu==1.18.1 -i https://mirrors.aliyun.com/pypi/simple/<br>pip3 install onnxruntime==1.18.1 -i https://mirrors.aliyun.com/pypi/simple/<br></code></pre></td></tr></table></figure></li><li><p>Glibc issue: <code>version GLIBCXX_3.4.29 not found</code></p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">find ~ -name <span class="hljs-string">&quot;libstdc++.so.6*&quot;</span><br>strings .conda/envs/cosyvoice/lib/libstdc++.so.6 | grep -i <span class="hljs-string">&quot;glibcxx&quot;</span><br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">cp</span> .conda/envs/cosyvoice/lib/libstdc++.so.6.0.33 /lib/x86_64-linux-gnu<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> /usr/lib/x86_64-linux-gnu/libstdc++.so.6<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">ln</span> -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.33 /usr/lib/x86_64-linux-gnu/libstdc++.so.6<br></code></pre></td></tr></table></figure></li></ul><h3 id="Server-and-client"><a href="#Server-and-client" class="headerlink" title="Server and client"></a>Server and client</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装依赖</span><br><span class="hljs-built_in">cd</span> runtime/python/grpc &amp;&amp; python3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. cosyvoice.proto<br><br><span class="hljs-comment"># 将文字请求发送至server，并返回语音文件 demo.wav</span><br>python3 runtime/python/grpc/server.py --port 50000 --max_conc 4 --model_dir pretrained_models/CosyVoice-300M &amp;&amp; <span class="hljs-built_in">sleep</span> infinit<br>python3 runtime/python/grpc/client.py --port 50000 --mode sft<br><br><span class="hljs-comment"># Fast API</span><br>python3 runtime/python/fastapi/server.py --port 50000 --model_dir pretrained_models/CosyVoice-300M &amp;&amp; <span class="hljs-built_in">sleep</span> infinity<br>python3 runtime/python/fastapi/client.py --port 50000 --mode sft<br></code></pre></td></tr></table></figure><h3 id="Cosyvoice-Docker"><a href="#Cosyvoice-Docker" class="headerlink" title="Cosyvoice Docker"></a>Cosyvoice Docker</h3><p>You can also follow the tutorial to build the container. Thus in windows, the server can be accessed from the host or any other devices in the LAN.</p><p>Note that there may be a <code>CUFFT_INTERNAL_ERROR</code> bug in <code>cu117</code> docker. You can update to <code>cu118</code> manually in the docker.</p><ul><li><a href="https://forums.developer.nvidia.com/t/bug-ubuntu-on-wsl2-rtx4090-related-cufft-runtime-error/230883/5">Bug: Ubuntu on WSL2 - RTX4090 related cuFFT runtime error</a></li><li><a href="https://github.com/pytorch/pytorch/issues/88038">CUFFT_INTERNAL_ERROR on RTX 4090</a></li></ul><p>Uninstall 11.7 pytorch cuda in the container.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip uninstall torch torchaudio<br>pip install torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118<br></code></pre></td></tr></table></figure><h3 id="Play-the-audio-in-python"><a href="#Play-the-audio-in-python" class="headerlink" title="Play the audio in python"></a>Play the audio in python</h3><p>After get the <code>.wav</code> files from the server, you can use <code>simpleaudio</code> python library to play the audio.</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> simpleaudio <span class="hljs-keyword">as</span> sa<br> <br><span class="hljs-comment"># Load audio file</span><br>filename = <span class="hljs-string">&#x27;demo.wav&#x27;</span><br>wave_obj = sa.WaveObject.from_wave_file(filename)<br> <br><span class="hljs-comment"># Play the audio</span><br>play_obj = wave_obj.play()<br>play_obj.wait_done()<br></code></pre></td></tr></table></figure><h1 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h1><h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><p>Run the script:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install websockets pyaudio ollama<br>python3 funasr_client.py --host <span class="hljs-string">&quot;127.0.0.1&quot;</span> --port 10095 --hotword hotword.txt --powershell 1 --llm_mode llama3.1 --llamahost <span class="hljs-string">&quot;localhost:11434&quot;</span><br></code></pre></td></tr></table></figure><p><img src="/img/ai/assistant/demo.png" alt="Voice ollama"></p><h2 id="WSL"><a href="#WSL" class="headerlink" title="WSL"></a>WSL</h2><ul><li><p>If ollama runs in the Windows host, you should enable wsl to access it in LAN (For other devices, this should also be enabled). In Powershell:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[Environment]::SetEnvironmentVariable(<span class="hljs-string">&#x27;OLLAMA_HOST&#x27;</span>, <span class="hljs-string">&#x27;0.0.0.0:11434&#x27;</span>, <span class="hljs-string">&#x27;Process&#x27;</span>)<br>[Environment]::SetEnvironmentVariable(<span class="hljs-string">&#x27;OLLAMA_ORIGINS&#x27;</span>, <span class="hljs-string">&#x27;*&#x27;</span>, <span class="hljs-string">&#x27;Process&#x27;</span>)<br>ollama serve<br></code></pre></td></tr></table></figure></li><li><p>Run <code>ipconfig</code> in Poweshell to get the IPv4 of Host, for example: <code>172.20.10.2</code>.</p></li><li><p>The audio may not work due to the audio card. A way to solve the problem:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install python3-pyaudio pulseaudio portaudio19-dev<br></code></pre></td></tr></table></figure></li><li><p>Run the scripts:</p>  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install websockets pyaudio ollama<br>python3 funasr_client.py --host <span class="hljs-string">&quot;127.0.0.1&quot;</span> --port 10095 --hotword hotword.txt --llamahost <span class="hljs-string">&quot;172.20.10.2:11434&quot;</span> --llm_model <span class="hljs-string">&quot;qwen:7b&quot;</span><br></code></pre></td></tr></table></figure></li></ul><h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul><li><a href="https://pypi.org/project/ollama/">Ollama PyPI</a></li><li><a href="https://github.com/ollama/ollama/blob/main/docs/api.md">Ollama API</a></li><li><a href="https://blog.csdn.net/tianya_lu/article/details/140048604">version GLIBCXX_3.4.29 not found</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>TTS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Jetson Whisper 语音识别测试</title>
    <link href="/2024/09/13/AI/Jetson-ASR/"/>
    <url>/2024/09/13/AI/Jetson-ASR/</url>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/openai/whisper">Whisper</a> 是一种通用语音识别模型。它是在大量不同音频数据集上进行训练的，也是一个多任务模型，可以执行多语言语音识别、语音翻译和语言识别。</p><span id="more"></span><p>由于官方NV的测试套件中，orin nano 8GB不支持TTS，本文使用 faster whisper 尝试运行 TTS。</p><h1 id="Whisper"><a href="#Whisper" class="headerlink" title="Whisper"></a>Whisper</h1><p><img src="/img/ai/whisper/whisper.png" alt="OpenAI Whisper"></p><p>测试，用Chattts生成一段语音：<code>四川美食确实以辣闻名，但也有不辣的选择。比如甜水面、赖汤圆、蛋烘糕、叶儿粑等，这些小吃口味温和，甜而不腻，也很受欢迎。</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ pip install -U openai-whisper<br>$ <span class="hljs-built_in">sudo</span> apt update &amp;&amp; <span class="hljs-built_in">sudo</span> apt install ffmpeg<br>$ pip install setuptools-rust<br><br>$ whisper ../audio.wav --model tiny<br>100%|█████████████████████████████████████| 72.1M/72.1M [00:36&lt;00:00, 2.08MiB/s]<br>/home/jetson/.local/lib/python3.8/site-packages/whisper/__init__.py:146: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), <span class="hljs-built_in">which</span> uses the default pickle module implicitly. It is possible to construct malicious pickle data <span class="hljs-built_in">which</span> will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models <span class="hljs-keyword">for</span> more details). In a future release, the default value <span class="hljs-keyword">for</span> `weights_only` will be flipped to `True`. This limits the <span class="hljs-built_in">functions</span> that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` <span class="hljs-keyword">for</span> any use <span class="hljs-keyword">case</span> <span class="hljs-built_in">where</span> you don<span class="hljs-string">&#x27;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.</span><br><span class="hljs-string">  checkpoint = torch.load(fp, map_location=device)</span><br><span class="hljs-string">/home/jetson/.local/lib/python3.8/site-packages/whisper/transcribe.py:115: UserWarning: FP16 is not supported on CPU; using FP32 instead</span><br><span class="hljs-string">  warnings.warn(&quot;FP16 is not supported on CPU; using FP32 instead&quot;)</span><br><span class="hljs-string">Detecting language using up to the first 30 seconds. Use `--language` to specify the language</span><br><span class="hljs-string">Detected language: Chinese</span><br><span class="hljs-string">[00:00.000 --&gt; 00:03.680] 四川美時確實以辣文明 但以有不辣的選擇</span><br><span class="hljs-string">[00:03.680 --&gt; 00:07.200] 比如潛水面 賴湯圓 再轟高夜熱八等</span><br><span class="hljs-string">[00:07.200 --&gt; 00:11.560] 這些小市口維溫和 然後甜而不膩也很受歡迎</span><br></code></pre></td></tr></table></figure><p>这个是CPU运行的😂，GPU都没带喘的。</p><h1 id="Faster-Whisper"><a href="#Faster-Whisper" class="headerlink" title="Faster Whisper"></a>Faster Whisper</h1><p><a href="https://github.com/SYSTRAN/faster-whisper">fast-whisper</a> 是使用 <a href="https://github.com/OpenNMT/CTranslate2/">CTranslate2</a> 重新实现 OpenAI 的 Whisper 模型，CTranslate2 是 Transformer 模型的快速推理引擎。</p><p><del>Funasr有个大问题，它的实时转录是CPU的，很慢。</del>GPU的支持离线语音转文字，但又不能实时。找到了一个faster-whisper可以支持实时GPU转录，也支持中文。</p><div class="note note-primary">            <p>我收回这句话，实测FunAsr不仅比推理快，延时低，准确率还很高，至于faster-whisper在Jetson的实测效果，惨不忍睹</p>          </div><ul><li><a href="https://blog.csdn.net/a71468293a/article/details/135995878">Faster-Whisper 实时识别电脑语音转文本</a></li><li><a href="https://huggingface.co/Systran/faster-whisper-large-v3">模型：faster-whisper-large-v3</a></li></ul><h2 id="安装使用"><a href="#安装使用" class="headerlink" title="安装使用"></a>安装使用</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install faster-whisper<br></code></pre></td></tr></table></figure><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">from</span> faster_whisper <span class="hljs-keyword">import</span> WhisperModel<br><br>model_size = <span class="hljs-string">&quot;large-v3&quot;</span><br><br><span class="hljs-comment"># Run on GPU with FP16</span><br><span class="hljs-comment"># model = WhisperModel(model_size, device=&quot;cuda&quot;, compute_type=&quot;float16&quot;)</span><br><br><span class="hljs-comment"># or run on GPU with INT8</span><br>model = WhisperModel(model_size, device=<span class="hljs-string">&quot;cuda&quot;</span>, compute_type=<span class="hljs-string">&quot;int8_float16&quot;</span>)<br><span class="hljs-comment"># or run on CPU with INT8</span><br><span class="hljs-comment"># model = WhisperModel(model_size, device=&quot;cpu&quot;, compute_type=&quot;int8&quot;)</span><br><br>segments, info = model.transcribe(<span class="hljs-string">&quot;audio.mp3&quot;</span>, beam_size=<span class="hljs-number">5</span>)<br><br><span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;Detected language &#x27;%s&#x27; with probability %f&quot;</span> % (info.language, info.language_probability))<br><br><span class="hljs-keyword">for</span> segment <span class="hljs-keyword">in</span> segments:<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;[%.2fs -&gt; %.2fs] %s&quot;</span> % (segment.start, segment.end, segment.text))<br></code></pre></td></tr></table></figure><h2 id="尝试WSL部署"><a href="#尝试WSL部署" class="headerlink" title="尝试WSL部署"></a>尝试WSL部署</h2><ul><li>Cuda：12.6</li><li>Cudnn：9.2</li></ul><p>直接运行，报错<a href="https://github.com/SYSTRAN/faster-whisper/issues/951">Could not load library libcudnn_ops_infer.so.8. Error: libcudnn_ops_infer.so.8: cannot open shared object file: No such file or directory</a>，这是需要cublas，cudnn的python库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install nvidia-cublas-cu12 nvidia-cudnn-cu12<br><br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=`python3 -c <span class="hljs-string">&#x27;import os; import nvidia.cublas.lib; import nvidia.cudnn.lib; print(os.path.dirname(nvidia.cublas.lib.__file__) + &quot;:&quot; + os.path.dirname(nvidia.cudnn.lib.__file__))&#x27;</span>`<br></code></pre></td></tr></table></figure><p>但是仍然跑不起来，因为：</p><blockquote><p>Version 9+ of nvidia-cudnn-cu12 appears to cause issues due its reliance on cuDNN 9 (Faster-Whisper does not currently support cuDNN 9). Ensure your version of the Python package is for cuDNN 8.</p></blockquote><p>那我安装 Cudnn 8 不就行了？果断下载cudnn8 for cuda 12.x，但是每次都安装cudnn9.4，除了降cuda版本，否则没办法恢复到cudnn8。</p><h2 id="尝试-Jetson-部署"><a href="#尝试-Jetson-部署" class="headerlink" title="尝试 Jetson 部署"></a>尝试 Jetson 部署</h2><ul><li>Cuda：11.4</li><li>Cudnn：8.6.0</li></ul><p>简直量身定制啊！首先尝试安装cudnn python库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ pip3 install faster-whisper -i https://mirrors.aliyun.com/pypi/simple/<br><br><span class="hljs-comment"># 贴心的提示我们：For all these methods below, keep in mind the above note</span><br><span class="hljs-comment"># regarding CUDA versions. Depending on your setup, you may need to install the</span><br><span class="hljs-comment"># CUDA 11 versions of libraries that correspond to the CUDA 12 libraries listed</span><br><span class="hljs-comment"># in the instructions below.</span><br><br>$ pip install --extra-index-url https://pypi.nvidia.com nvidia-cudnn-cu11<br>...<br>The installation of nvidia-cudnn-cu11 <span class="hljs-keyword">for</span> version 9.0.0.312 failed.<br><br>      This is a special placeholder package <span class="hljs-built_in">which</span> downloads a real wheel package<br>      from https://pypi.nvidia.com. If https://pypi.nvidia.com is not reachable, we<br>      cannot download the real wheel file to install.<br><br>      You might try installing this package via<br>      $ pip install --extra-index-url https://pypi.nvidia.com nvidia-cudnn-cu11<br><br>      Here is some debug information about your platform to include <span class="hljs-keyword">in</span> any bug<br>      report:<br><br>      Python Version: CPython 3.8.10<br>      Operating System: Linux 5.10.104-tegra<br>      CPU Architecture: aarch64<br>      nvidia-smi <span class="hljs-built_in">command</span> not found. Ensure NVIDIA drivers are installed.<br></code></pre></td></tr></table></figure><p>原来是 <a href="https://pypi.nvidia.cn/nvidia-cudnn-cu11/">nvidia-cudnnn-cu11</a>没有<code>aarch64 Arm</code>版本！但是<a href="https://pypi.nvidia.cn/nvidia-cudnn-cu12/">nvidia-cudnn-cu12</a>有。</p><p>怎么办，安装cuda 12.2？Jetson的系统是<a href="https://www.yahboom.com/build.html?id=6443&cid=590">离线刷机</a>，<a href="https://developer.nvidia.com/embedded/jetpack-sdk-60">jetpack 6</a>确实支持12.2和cudnn8：</p><p><img src="/img/ai/whisper/1.png" alt="Jetpack Cuda"></p><p>已经准备买新的固态刷机了，但是太麻烦了，得装虚拟机装刷机SDK，得拆机箱改跳帽，得重新配置ssh网络连接，关键是，得花钱！</p><p><img src="/img/ai/whisper/2.jpg" alt="JD"></p><p>不试试怎么行呢，我不信邪，就安装cudnn12 python库：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ pip install --extra-index-url https://pypi.nvidia.com nvidia-cudnn-cu12<br>Defaulting to user installation because normal site-packages is not writeable<br>Looking <span class="hljs-keyword">in</span> indexes: https://pypi.org/simple, https://pypi.nvidia.com<br>Collecting nvidia-cudnn-cu12<br>  Downloading nvidia_cudnn_cu12-9.4.0.58-py3-none-manylinux2014_aarch64.whl.metadata (1.6 kB)<br>Collecting nvidia-cublas-cu12 (from nvidia-cudnn-cu12)<br>  Downloading https://pypi.nvidia.com/nvidia-cublas-cu12/nvidia_cublas_cu12-12.6.1.4-py3-none-manylinux2014_aarch64.whl (376.7 MB)<br>     ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 376.7/376.7 MB 12.9 MB/s eta 0:00:00<br>Downloading nvidia_cudnn_cu12-9.4.0.58-py3-none-manylinux2014_aarch64.whl (572.7 MB)<br>   ━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━ 572.7/572.7 MB 1.1 MB/s eta 0:00:00<br>Installing collected packages: nvidia-cublas-cu12, nvidia-cudnn-cu12<br>Successfully installed nvidia-cublas-cu12-12.6.1.4 nvidia-cudnn-cu12-9.4.0.58<br></code></pre></td></tr></table></figure><p>跑一下demo：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash">test.py<br>preprocessor_config.json: 100%|████████████████████████████████| 340/340 [00:00&lt;00:00, 118kB/s]<br>config.json: 100%|█████████████████████████████████████████████| 2.39k/2.39k [00:00&lt;00:00, 1.03MB/s]<br>vocabulary.json: 100%|█████████████████████████████████████████| 1.07M/1.07M [00:00&lt;00:00, 1.13MB/s]<br>tokenizer.json: 100%|██████████████████████████████████████████| 2.48M/2.48M [00:01&lt;00:00, 2.14MB/s]<br>model.bin: 100%|███████████████████████████████████████████████| 3.09G/3.09G [03:18&lt;00:00, 9.89MB/s]<br>Traceback (most recent call last):<br>  File <span class="hljs-string">&quot;test.py&quot;</span>, line 9, <span class="hljs-keyword">in</span> &lt;module&gt;<br>    model = WhisperModel(model_size, device=<span class="hljs-string">&quot;cuda&quot;</span>, compute_type=<span class="hljs-string">&quot;int8_float16&quot;</span>)<br>  File <span class="hljs-string">&quot;/home/jetson/.local/lib/python3.8/site-packages/faster_whisper/transcribe.py&quot;</span>, line 145, <span class="hljs-keyword">in</span> __init__<br>    self.model = ctranslate2.models.Whisper(<br>ValueError: This CTranslate2 package was not compiled with CUDA support<br></code></pre></td></tr></table></figure><p>Holy🤬，这又是咋回事，找一下：<a href="https://github.com/OpenNMT/CTranslate2/issues/1306">This CTranslate2 package was not compiled with CUDA support #1306</a>，跳过他们的讨论，结合faster-whisper库里的描述：</p><blockquote><p>Note: Latest versions of ctranslate2 support CUDA 12 only. For CUDA 11, the current workaround is downgrading to the 3.24.0 version of ctranslate2 (This can be done with pip install –force-reinstall ctranslate2&#x3D;&#x3D;3.24.0 or specifying the version in a requirements.txt).</p></blockquote><p>又是cuda11的幺蛾子，它说要使用降级的方法：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ pip install --force-reinstall ctranslate2==3.24.0<br>ERROR: pip<span class="hljs-string">&#x27;s dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.</span><br><span class="hljs-string">mediapipe 0.8.4 requires opencv-contrib-python, which is not installed.</span><br><span class="hljs-string">onnx-graphsurgeon 0.3.12 requires onnx, which is not installed.</span><br><span class="hljs-string">d2l 0.17.6 requires numpy==1.21.5, but you have numpy 1.24.4 which is incompatible.</span><br><span class="hljs-string">d2l 0.17.6 requires requests==2.25.1, but you have requests 2.32.3 which is incompatible.</span><br><span class="hljs-string">faster-whisper 1.0.3 requires ctranslate2&lt;5,&gt;=4.0, but you have ctranslate2 3.24.0 which is incompatible.</span><br></code></pre></td></tr></table></figure><p><strong>呸！😶</strong></p><p>我试试自己编一个cuda版本的：<a href="https://opennmt.net/CTranslate2/installation.html#compile-the-c-library">https://opennmt.net/CTranslate2/installation.html#compile-the-c-library</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ pip3 uninstall ctranslate2 whisper-ctranslate2<br>$ git <span class="hljs-built_in">clone</span> --recursive https://github.com/OpenNMT/CTranslate2.git<br>$ <span class="hljs-built_in">mkdir</span> build &amp;&amp; <span class="hljs-built_in">cd</span> build<br>$ cmake ..<br>...<br>CMake Error at CMakeLists.txt:294 (message):<br>  Intel OpenMP runtime libiomp5 not found<br><br>-- Configuring incomplete, errors occurred!<br></code></pre></td></tr></table></figure><p>哪来的intel？找找，原来是，By default, the library is compiled with the Intel MKL backend which should be installed separately. See the Build options to select or add another backend. 改一下，不用老in家的：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 老张我给你表演什么叫一镜到底，注意看，我只表演一次：</span><br>$ cmake .. -DOPENMP_RUNTIME=COMP -DWITH_MKL=OFF -DWITH_CUDA=ON -DWITH_CUDNN=ON<br>$ make -j32<br>$ <span class="hljs-built_in">sudo</span> make install<br>$ <span class="hljs-built_in">sudo</span> ldconfig<br>$ <span class="hljs-built_in">cd</span> ../python<br>$ pip install -r install_requirements.txt<br>$ python setup.py bdist_wheel<br>$ pip install dist/*.whl<br></code></pre></td></tr></table></figure><p><img src="/img/ai/whisper/res.png" alt="Result"></p><p>喜大普奔！</p><h2 id="时间戳"><a href="#时间戳" class="headerlink" title="时间戳"></a>时间戳</h2><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">from</span> faster_whisper <span class="hljs-keyword">import</span> WhisperModel<br><br>model_size = <span class="hljs-string">&quot;large-v3&quot;</span><br><br><span class="hljs-comment"># Run on GPU with FP16</span><br><span class="hljs-comment"># model = WhisperModel(model_size, device=&quot;cuda&quot;, compute_type=&quot;float16&quot;)</span><br><br><span class="hljs-comment"># or run on GPU with INT8</span><br>model = WhisperModel(model_size, device=<span class="hljs-string">&quot;cuda&quot;</span>, compute_type=<span class="hljs-string">&quot;int8_float16&quot;</span>)<br><span class="hljs-comment"># or run on CPU with INT8</span><br><span class="hljs-comment"># model = WhisperModel(model_size, device=&quot;cpu&quot;, compute_type=&quot;int8&quot;)</span><br><br><br><br>segments, _ = model.transcribe(<span class="hljs-string">&quot;audio.wav&quot;</span>, word_timestamps=<span class="hljs-literal">True</span>)<br><br><span class="hljs-keyword">for</span> segment <span class="hljs-keyword">in</span> segments:<br>    <span class="hljs-keyword">for</span> word <span class="hljs-keyword">in</span> segment.words:<br>        <span class="hljs-built_in">print</span>(<span class="hljs-string">&quot;[%.2fs -&gt; %.2fs] %s&quot;</span> % (word.start, word.end, word.word))<br></code></pre></td></tr></table></figure><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs txt">[0.00s -&gt; 0.24s] 四<br>[0.24s -&gt; 0.44s] 川<br>[0.44s -&gt; 0.58s] 美<br>[0.58s -&gt; 0.78s] 食<br>[0.78s -&gt; 1.10s] 确<br>..<br>[9.72s -&gt; 9.96s] 腻<br>[9.96s -&gt; 10.42s] 也<br>[10.42s -&gt; 10.68s] 很<br>[10.68s -&gt; 10.82s] 受<br>[10.82s -&gt; 11.04s] 欢<br>[11.04s -&gt; 11.22s] 迎<br></code></pre></td></tr></table></figure><h1 id="实时转录"><a href="#实时转录" class="headerlink" title="实时转录"></a>实时转录</h1><p><a href="https://github.com/ufal/whisper_streaming">Whisper 实时流式传输</a>，用于长时间语音到文本的转录和翻译。Whisper 是最近最先进的多语言语音识别和翻译模型之一，然而，它并不是为实时转录而设计的。在本文中，我们在 Whisper 之上构建并创建了 Whisper-Streaming，这是一种实时语音转录和类似 Whisper 模型翻译的实现。 Whisper-Streaming 使用本地协议策略和自适应延迟来实现流式转录。我们证明 Whisper-Streaming 在未分段的长格式语音转录测试集上实现了高质量和 3.3 秒的延迟，并且我们在多语言会议上展示了其作为实时转录服务组件的鲁棒性和实际可用性。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ git <span class="hljs-built_in">clone</span> git@github.com:ufal/whisper_streaming.git<br>$ <span class="hljs-built_in">cd</span> whisper_streaming<br>$ python3 whisper_online.py ../audio.wav --language zh --min-chunk-size 1<br>INFO    Audio duration is: 11.68 seconds<br>INFO    Loading Whisper large-v2 model <span class="hljs-keyword">for</span> zh...<br>INFO    <span class="hljs-keyword">done</span>. It took 14.19 seconds.<br>DEBUG   PROMPT:<br>DEBUG   CONTEXT:<br>DEBUG   transcribing 1.00 seconds from 0.00<br>DEBUG   &gt;&gt;&gt;&gt;COMPLETE NOW: (None, None, <span class="hljs-string">&#x27;&#x27;</span>)<br>DEBUG   INCOMPLETE: (0.0, 0.98, <span class="hljs-string">&#x27;四川美食群&#x27;</span>)<br>DEBUG   len of buffer now: 1.00<br>DEBUG   <span class="hljs-comment">## last processed 1.00 s, now is 5.30, the latency is 4.29</span><br>DEBUG   PROMPT:<br>DEBUG   CONTEXT:<br>DEBUG   transcribing 5.30 seconds from 0.00<br>DEBUG   &gt;&gt;&gt;&gt;COMPLETE NOW: (0.0, 0.88, <span class="hljs-string">&#x27;四川美食&#x27;</span>)<br>DEBUG   INCOMPLETE: (0.88, 5.26, <span class="hljs-string">&#x27;确实以辣为名,但也有不辣的选择,比如甜水面赖淘宝。&#x27;</span>)<br>DEBUG   len of buffer now: 5.30<br>11643.5227 0 880 四川美食<br>11643.5227 0 880 四川美食<br>DEBUG   <span class="hljs-comment">## last processed 5.30 s, now is 11.64, the latency is 6.35</span><br>DEBUG   PROMPT:<br>DEBUG   CONTEXT: 四川美食<br>DEBUG   transcribing 11.64 seconds from 0.00<br>DEBUG   &gt;&gt;&gt;&gt;COMPLETE NOW: (None, None, <span class="hljs-string">&#x27;&#x27;</span>)<br>DEBUG   INCOMPLETE: (0.88, 11.24, <span class="hljs-string">&#x27;確實以辣聞名,但也有不辣的選擇,比如甜水麵、瀨湯圓、炸烘糕 、葉子粑等,這些小吃口味溫和,然後甜而不膩,也很受歡迎。&#x27;</span>)<br>DEBUG   len of buffer now: 11.64<br>DEBUG   <span class="hljs-comment">## last processed 11.64 s, now is 21.61, the latency is 9.96</span><br>DEBUG   PROMPT:<br>DEBUG   CONTEXT: 四川美食<br>DEBUG   transcribing 11.68 seconds from 0.00<br>DEBUG   &gt;&gt;&gt;&gt;COMPLETE NOW: (None, None, <span class="hljs-string">&#x27;&#x27;</span>)<br>DEBUG   INCOMPLETE: (0.88, 11.32, <span class="hljs-string">&#x27;确实以辣闻名,但也有不辣的选择,比如甜水面、赖汤圆、炸烘糕 叶、热巴等,这些小吃口味温和,然后甜而不腻,也很受欢迎。&#x27;</span>)<br>DEBUG   len of buffer now: 11.68<br>DEBUG   <span class="hljs-comment">## last processed 21.61 s, now is 31.53, the latency is 9.92</span><br>DEBUG   last, noncommited: (0.88, 11.32, <span class="hljs-string">&#x27;确实以辣闻名,但也有不辣的选择,比如甜水面、赖汤圆、炸烘糕叶、热巴等,这些小吃口味温和,然后甜而不腻,也很受欢迎。&#x27;</span>)<br>31528.1091 880 11320 确实以辣闻名,但也有不辣的选择,比如甜水面、赖汤圆、炸烘糕叶、热巴等,这些小吃口味温和,然后甜而不腻,也很受欢迎。<br>31528.1091 880 11320 确实以辣闻名,但也有不辣的选择,比如甜水面、赖汤圆、炸烘糕叶、热巴等,这些小吃口味温和,然后甜而不腻,也很受欢迎。<br></code></pre></td></tr></table></figure><p>注：更改模型量化：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># this worked fast and reliably on NVIDIA L40</span><br><span class="hljs-comment"># model = WhisperModel(model_size_or_path, device=&quot;cuda&quot;, compute_type=&quot;float16&quot;, download_root=cache_dir)</span><br><br><span class="hljs-comment"># or run on GPU with INT8</span><br><span class="hljs-comment"># tested: the transcripts were different, probably worse than with FP16, and it was slightly (appx 20%) slower</span><br>model = WhisperModel(model_size_or_path, device=<span class="hljs-string">&quot;cuda&quot;</span>, compute_type=<span class="hljs-string">&quot;int8_float16&quot;</span>)<br></code></pre></td></tr></table></figure><p>实测在Jetson上，使用tiny和small模型，准确率不高，使用large-v2模型，速度很慢，延迟非常高。</p><h1 id="结论"><a href="#结论" class="headerlink" title="结论"></a>结论</h1><p>选择使用FunAsr CPU实时推理实现语音的输入。</p><div class="note note-primary">            <p>注：Jetson语音识别的硬件：耳麦+USB转音频口</p><p><img src="/img/ai/whisper/jetson.png" alt="Jetson音频输入"></p>          </div><p>FunAsr 见 <a href="https://www.tech-odyssey.cn/2024/09/10/AI/ASR/">https://www.tech-odyssey.cn/2024/09/10/AI/ASR/</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ curl -O https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/shell/funasr-runtime-deploy-online-cpu-zh.sh<br>$ <span class="hljs-built_in">sudo</span> bash funasr-runtime-deploy-online-cpu-zh.sh install --workspace ./funasr-runtime-resources<br>$ <span class="hljs-built_in">cd</span> samples/python<br>$ python3 funasr_wss_client.py --host <span class="hljs-string">&quot;127.0.0.1&quot;</span> --port 10096 --mode 2pass<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>ASR</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>莫塔社区有趣的 AI 应用</title>
    <link href="/2024/09/10/AI/AI-Applications/"/>
    <url>/2024/09/10/AI/AI-Applications/</url>
    
    <content type="html"><![CDATA[<p>魔塔社区</p><span id="more"></span><h1 id="魔塔社区速递"><a href="#魔塔社区速递" class="headerlink" title="魔塔社区速递"></a>魔塔社区速递</h1><ul><li><a href="https://www.modelscope.cn/headlines/article/660">魔搭社区每周速递（9.1-9.7）</a></li><li><a href="https://www.modelscope.cn/headlines/article/648">魔搭社区每周速递（8.25-8.31）</a></li><li><a href="https://www.modelscope.cn/headlines/article/635">魔搭社区每周速递（8.18-8.24）</a></li></ul><h1 id="好玩工具"><a href="#好玩工具" class="headerlink" title="好玩工具"></a>好玩工具</h1><h2 id="MinerU"><a href="#MinerU" class="headerlink" title="MinerU"></a><a href="https://modelscope.cn/studios/OpenDataLab/MinerU">MinerU</a></h2><p>一款全能、开源的文档与网页数据提取工具，致力于简化AI数据处理流程。不仅能将混合了图片、表格、公式等在内的多模态PDF文档精准转化为清晰、易于分析的Markdown格式；还能从包含广告等各种干扰信息的网页中快速解析、抽取正式内容；同时支持epub、mobi、docx等多种格式批量转化为Markdown。</p><h2 id="麦橘写实"><a href="#麦橘写实" class="headerlink" title="麦橘写实"></a><a href="https://www.liblib.art/modelinfo/bced6d7ec1460ac7b923fc5bc95c4540?from=feed">麦橘写实</a></h2><p>网站可以自定下载 Stable Diffusion 模型</p><h2 id="字节：Hyper-SD"><a href="#字节：Hyper-SD" class="headerlink" title="字节：Hyper-SD"></a>字节：<a href="https://modelscope.cn/models/bytedance/hyper-sd">Hyper-SD</a></h2><h1 id="模型导航"><a href="#模型导航" class="headerlink" title="模型导航"></a>模型导航</h1><p>字节：<a href="https://huggingface.co/ByteDance">hugging face</a></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>FunASR 部署</title>
    <link href="/2024/09/10/AI/ASR/"/>
    <url>/2024/09/10/AI/ASR/</url>
    
    <content type="html"><![CDATA[<p>FunASR希望在语音识别的学术研究和工业应用之间架起一座桥梁。</p><span id="more"></span><p>通过发布工业级语音识别模型的训练和微调，研究人员和开发人员可以更方便地进行语音识别模型的研究和生产，并推动语音识别生态的发展。让语音识别更有趣！</p><p>参考：<a href="https://github.com/modelscope/FunASR/blob/main/README_zh.md">FunASR</a></p><p><img src="/img/ai/funasr/top.svg"></p><h1 id="安装"><a href="#安装" class="headerlink" title="安装"></a>安装</h1><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install -U funasr  -i https://pypi.tuna.tsinghua.edu.cn/simple<br></code></pre></td></tr></table></figure><h1 id="测试"><a href="#测试" class="headerlink" title="测试"></a>测试</h1>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-28ab9646" role="button" aria-expanded="false" aria-controls="collapse-28ab9646">        <div class="fold-arrow">▶</div>测试demo      </div>      <div class="fold-collapse collapse" id="collapse-28ab9646">        <div class="fold-content">          <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br></pre></td><td class="code"><pre><code class="hljs bash">funasr ++model=paraformer-zh ++vad_model=<span class="hljs-string">&quot;fsmn-vad&quot;</span> ++punc_model=<span class="hljs-string">&quot;ct-punc&quot;</span> ++input=/home/sjl/.cache/modelscope/hub/iic/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online/example/asr_example.wav<br>funasr version: 1.1.6.<br>Check update of funasr, and it would cost few <span class="hljs-built_in">times</span>. You may <span class="hljs-built_in">disable</span> it by <span class="hljs-built_in">set</span> `disable_update=True` <span class="hljs-keyword">in</span> AutoModel<br>You are using the latest version of funasr-1.1.6<br>[2024-09-10 22:30:03,671][root][INFO] - download models from model hub: ms<br>2024-09-10 22:30:04,808 - modelscope - WARNING - Using branch: master as version is unstable, use with caution<br>[2024-09-10 22:30:06,197][root][INFO] - Loading pretrained params from /home/sjl/.cache/modelscope/hub/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt<br>[2024-09-10 22:30:06,200][root][INFO] - ckpt: /home/sjl/.cache/modelscope/hub/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt<br>/home/sjl/.conda/envs/torch-gpu/lib/python3.9/site-packages/funasr/train_utils/load_pretrained_model.py:38: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), <span class="hljs-built_in">which</span> uses the default pickle module implicitly. It is possible to construct malicious pickle data <span class="hljs-built_in">which</span> will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models <span class="hljs-keyword">for</span> more details). In a future release, the default value <span class="hljs-keyword">for</span> `weights_only` will be flipped to `True`. This limits the <span class="hljs-built_in">functions</span> that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` <span class="hljs-keyword">for</span> any use <span class="hljs-keyword">case</span> <span class="hljs-built_in">where</span> you don<span class="hljs-string">&#x27;t have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.</span><br><span class="hljs-string">  src_state = torch.load(path, map_location=map_location)</span><br><span class="hljs-string">[2024-09-10 22:30:06,476][root][INFO] - scope_map: [&#x27;</span>module.<span class="hljs-string">&#x27;, &#x27;</span>None<span class="hljs-string">&#x27;]</span><br><span class="hljs-string">[2024-09-10 22:30:06,477][root][INFO] - excludes: None</span><br><span class="hljs-string">[2024-09-10 22:30:06,548][root][INFO] - Loading ckpt: /home/sjl/.cache/modelscope/hub/iic/speech_seaco_paraformer_large_asr_nat-zh-cn-16k-common-vocab8404-pytorch/model.pt, status: &lt;All keys matched successfully&gt;</span><br><span class="hljs-string">[2024-09-10 22:30:06,859][root][INFO] - Building VAD model.</span><br><span class="hljs-string">[2024-09-10 22:30:06,859][root][INFO] - download models from model hub: ms</span><br><span class="hljs-string">2024-09-10 22:30:07,208 - modelscope - WARNING - Using branch: master as version is unstable, use with caution</span><br><span class="hljs-string">[2024-09-10 22:30:07,480][root][INFO] - Loading pretrained params from /home/sjl/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt</span><br><span class="hljs-string">[2024-09-10 22:30:07,480][root][INFO] - ckpt: /home/sjl/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt</span><br><span class="hljs-string">[2024-09-10 22:30:07,482][root][INFO] - scope_map: [&#x27;</span>module.<span class="hljs-string">&#x27;, &#x27;</span>None<span class="hljs-string">&#x27;]</span><br><span class="hljs-string">[2024-09-10 22:30:07,482][root][INFO] - excludes: None</span><br><span class="hljs-string">[2024-09-10 22:30:07,483][root][INFO] - Loading ckpt: /home/sjl/.cache/modelscope/hub/iic/speech_fsmn_vad_zh-cn-16k-common-pytorch/model.pt, status: &lt;All keys matched successfully&gt;</span><br><span class="hljs-string">[2024-09-10 22:30:07,486][root][INFO] - Building punc model.</span><br><span class="hljs-string">[2024-09-10 22:30:07,487][root][INFO] - download models from model hub: ms</span><br><span class="hljs-string">2024-09-10 22:30:07,794 - modelscope - WARNING - Using branch: master as version is unstable, use with caution</span><br><span class="hljs-string">Building prefix dict from the default dictionary ...</span><br><span class="hljs-string">[2024-09-10 22:30:08,976][jieba][DEBUG] - Building prefix dict from the default dictionary ...</span><br><span class="hljs-string">Loading model from cache /tmp/jieba.cache</span><br><span class="hljs-string">[2024-09-10 22:30:08,976][jieba][DEBUG] - Loading model from cache /tmp/jieba.cache</span><br><span class="hljs-string">Loading model cost 0.281 seconds.</span><br><span class="hljs-string">[2024-09-10 22:30:09,257][jieba][DEBUG] - Loading model cost 0.281 seconds.</span><br><span class="hljs-string">Prefix dict has been built successfully.</span><br><span class="hljs-string">[2024-09-10 22:30:09,257][jieba][DEBUG] - Prefix dict has been built successfully.</span><br><span class="hljs-string">[2024-09-10 22:30:19,126][root][INFO] - Loading pretrained params from /home/sjl/.cache/modelscope/hub/iic/punc_ct-transformer_cn-en-common-vocab471067-large/model.pt</span><br><span class="hljs-string">[2024-09-10 22:30:19,127][root][INFO] - ckpt: /home/sjl/.cache/modelscope/hub/iic/punc_ct-transformer_cn-en-common-vocab471067-large/model.pt</span><br><span class="hljs-string">[2024-09-10 22:30:19,357][root][INFO] - scope_map: [&#x27;</span>module.<span class="hljs-string">&#x27;, &#x27;</span>None<span class="hljs-string">&#x27;]</span><br><span class="hljs-string">[2024-09-10 22:30:19,357][root][INFO] - excludes: None</span><br><span class="hljs-string">[2024-09-10 22:30:19,419][root][INFO] - Loading ckpt: /home/sjl/.cache/modelscope/hub/iic/punc_ct-transformer_cn-en-common-vocab471067-large/model.pt, status: &lt;All keys matched successfully&gt;</span><br><span class="hljs-string">rtf_avg: 0.026: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  6.90it/s]</span><br><span class="hljs-string">  0%|                                                                                                                                            | 0/1 [00:00&lt;?, ?it/s/home/sjl/.conda/envs/torch-gpu/lib/python3.9/site-packages/funasr/models/paraformer/model.py:251: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast(&#x27;</span>cuda<span class="hljs-string">&#x27;, args...)` instead.</span><br><span class="hljs-string">  with autocast(False):</span><br><span class="hljs-string">rtf_avg: 0.129: 100%|████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.57it/s]</span><br><span class="hljs-string">rtf_avg: -0.015: 100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00, 64.17it/s]</span><br><span class="hljs-string">rtf_avg: 0.118, time_speech:  5.547, time_escape: 0.655: 100%|███████████████████████████████████████████████████████████████████████████| 1/1 [00:00&lt;00:00,  1.52it/s]</span><br><span class="hljs-string">[&#123;&#x27;</span>key<span class="hljs-string">&#x27;: &#x27;</span>asr_example<span class="hljs-string">&#x27;, &#x27;</span>text<span class="hljs-string">&#x27;: &#x27;</span>欢迎大家来体验达摩院推出的语音识别模型。<span class="hljs-string">&#x27;, &#x27;</span>timestamp<span class="hljs-string">&#x27;: [[880, 1120], [1120, 1360], [1380, 1540], [1540, 1780], [1780, 2020], [2020, 2180], [2180, 2420], [2480, 2600], [2600, 2780], [2780, 3020], [3040, 3240], [3240, 3480], [3480, 3700], [3700, 3900], [3900, 4140], [4180, 4420], [4420, 4620], [4620, 4780], [4780, 5195]]&#125;]</span><br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h1 id="实时语音-CPU"><a href="#实时语音-CPU" class="headerlink" title="实时语音 CPU"></a>实时语音 CPU</h1><p>参考：<a href="https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_advanced_guide_online_zh.md">FunASR实时语音听写服务开发指南</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker pull registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.10<br><span class="hljs-built_in">mkdir</span> -p ./funasr-runtime-resources/models<br>docker run -p 10096:10095 -it --privileged=<span class="hljs-literal">true</span> -v <span class="hljs-variable">$PWD</span>/funasr-runtime-resources/models:/workspace/models registry.cn-hangzhou.aliyuncs.com/funasr_repo/funasr:funasr-runtime-sdk-online-cpu-0.1.10<br><br><span class="hljs-built_in">cd</span> FunASR/runtime<br><span class="hljs-built_in">cat</span> test.sh<br><span class="hljs-built_in">nohup</span> bash run_server_2pass.sh \<br>  --download-model-dir /workspace/models \<br>  --vad-dir damo/speech_fsmn_vad_zh-cn-16k-common-onnx \<br>  --model-dir damo/speech_paraformer-large-vad-punc_asr_nat-zh-cn-16k-common-vocab8404-onnx  \<br>  --online-model-dir damo/speech_paraformer-large_asr_nat-zh-cn-16k-common-vocab8404-online-onnx  \<br>  --punc-dir damo/punc_ct-transformer_zh-cn-common-vad_realtime-vocab272727-onnx \<br>  --lm-dir damo/speech_ngram_lm_zh-cn-ai-wesp-fst \<br>  --itn-dir thuduj12/fst_itn_zh \<br>  --hotword /workspace/models/hotwords.txt &gt; log.txt 2&gt;&amp;1 &amp;<br>root@2bf110b5e876:/workspace/FunASR/runtime# <span class="hljs-built_in">cat</span> log.txt<br><br><span class="hljs-built_in">chmod</span> +x test.sh &amp;&amp; ./test.sh<br></code></pre></td></tr></table></figure><h1 id="客户端"><a href="#客户端" class="headerlink" title="客户端"></a>客户端</h1><p>参考：<a href="https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_tutorial_online_zh.md#python-client">FunASR实时语音听写便捷部署教程</a></p><p>可以使用脚本一键部署服务端的容器，实测CPU识别速度挺快，延迟不到一秒。比faster whisper在Jetson的效果好很多。Jetson 部署见 <a href="https://www.tech-odyssey.cn/2024/09/13/AI/Jetson-ASR/#%E7%BB%93%E8%AE%BA">Jetson 语音识别</a></p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>ASR</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Transformer Explainer 中文</title>
    <link href="/2024/09/06/AI/Transformer-Explainer/"/>
    <url>/2024/09/06/AI/Transformer-Explainer/</url>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/poloclub/transformer-explainer">Transformer 的可视化解释：了解 LLM Transformer 模型如何与交互式可视化配合使用</a></p><span id="more"></span><h1 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h1><p>Nodejs version &gt; 20.0</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/poloclub/transformer-explainer.git<br><span class="hljs-built_in">cd</span> transformer-explainer<br>npm install<br>npm run dev<br><br><span class="hljs-comment"># fix: cnpm install --platform=win32 --arch=x64 sharp</span><br></code></pre></td></tr></table></figure><h1 id="中文演示"><a href="#中文演示" class="headerlink" title="中文演示"></a>中文演示</h1><div id="dplayer1" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer1"),"theme":"#FADFA3","loop":true,"lang":"zh-cn","screenshot":true,"hotkey":true,"preload":"auto","volume":0.9,"mutex":true,"video":{"url":"/img/ai/TransformerExplainer/transformer.mp4","pic":"/img/ai/TransformerExplainer/index.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><h1 id="互动功能"><a href="#互动功能" class="headerlink" title="互动功能"></a>互动功能</h1><p>Transformer Explainer 是交互式的，可让您探索 Transformer 的内部工作原理。以下是您可以使用的一些交互式功能：</p><ul><li>输入您自己的文本序列，看看模型如何处理它并预测下一个单词。探索注意力权重、中间计算， 并看看最终输出概率是如何计算的。</li><li>使用温度滑块控制模型预测的随机性。探索如何通过更改温度值使模型输出更具确定性或更具创造性。</li><li>与注意力图交互，查看模型如何关注输入序列中的不同标记。将鼠标悬停在标记上 以突出显示其注意力权重，并探索模型如何捕获上下文和单词之间的关系。</li></ul><h1 id="什么是-Transformer？"><a href="#什么是-Transformer？" class="headerlink" title="什么是 Transformer？"></a>什么是 Transformer？</h1><p>Transformer 首次出现在 2017 年的开创性论文 《Attention is All You Need》 中，此后已成为深度学习模型的首选架构，为 OpenAI 的 GPT、Meta 的 Llama 和 Google 的 Gemini 等文本生成模型提供支持。 除了文本之外，Transformer 还应用于 音频生成、 图像识别、 蛋白质结构预测，甚至 游戏中，展示了其在众多领域的多功能性。</p><p>从根本上讲，文本生成 Transformer 模型的运行原理是下一个单词预测：给定用户的文本提示， 紧随此输入之后的最有可能的下一个单词是什么？Transformer 的核心创新和强大之处在于它们使用了 自注意力机制，这使得它们能够比以前的架构更有效地处理整个序列并捕获长距离依赖关系。</p><p>GPT-2 系列模型是文本生成 Transformers 的杰出代表。Transformer Explainer 基于 GPT-2 (small)，该模型有 1.24 亿个参数。虽然它不是最新或最强大的 Transformer 模型， 但它具有许多与当前最先进模型相同的架构组件和原理，使其成为理解基础知识的理想起点。</p><h1 id="Transformer-架构"><a href="#Transformer-架构" class="headerlink" title="Transformer 架构"></a>Transformer 架构</h1><p>每个文本生成 Transformer 都由以下三个关键组件组成：</p><ul><li>嵌入（Embedding）：文本输入被划分为更小的单位， 称为标记（token），可以是单词或子单词。这些标记被转换成数值向量，称为嵌入（Embedding），用于捕获单词的语义。</li><li>Transformer Block 是模型的基本构建块，用于处理和转换输入数据。 每个块包括：<ul><li>注意力机制（Attention Mechanism），Transformer 模块的核心组件。它允许 token 与其他 token 进行通信，从而捕获上下文信息和单词之间的关系。</li><li>MLP 层（多层感知器 Multilayer Perceptron）, 一个独立对每个标记进行操作的前馈网络。注意层的目标是在标记之间路由 信息，而 MLP 的目标是优化每个标记的表示。</li></ul></li><li>输出概率（Output Probabilities）： 最后的线性层和 softmax 层将处理后的嵌入转换为概率，使模型能够对序列中的下一个标记做出预测。</li></ul><h2 id="嵌入"><a href="#嵌入" class="headerlink" title="嵌入"></a>嵌入</h2><p>假设您想使用 Transformer 模型生成文本。您添加如下提示词（prompt）：“Data visualization empowers users to”。 此输入需要转换为模型可以理解和处理的格式。这就是嵌入的作用所在：它将文本转换为模型可以使用的数字表示。要将提示转换为嵌入， 我们需要 1) 对输入进行标记，2) 获取标记嵌入，3) 添加位置信息，最后 4) 将标记和位置编码相加以获得最终嵌入。 让我们看看每个步骤是如何完成的。</p><p><img src="/img/ai/TransformerExplainer/embedding.png" alt="图1，展开嵌入层视图，显示如何将输入提示转换为矢量表示。 该过程涉及 (1)标记化(2)标记嵌入(3)位置编码和(4)最终嵌入"></p><h3 id="步骤1：标记化"><a href="#步骤1：标记化" class="headerlink" title="步骤1：标记化"></a>步骤1：标记化</h3><p>标记化（Tokenization）是将输入文本分解为更小、更易于管理的部分（称为标记）的过程。这些标记可以是单词或子单词。 单词 “Data” 和 “visualization” 对应于唯一标记，而单词 “empowers” 则 被拆分为两个标记。完整的标记词汇表是在训练模型之前确定的：GPT-2 的词汇表有 50,257 个唯一标记。 现在我们将输入文本拆分为具有不同 ID 的标记，我们可以从嵌入中获取它们的向量表示。</p><h3 id="步骤2：Token-嵌入"><a href="#步骤2：Token-嵌入" class="headerlink" title="步骤2：Token 嵌入"></a>步骤2：Token 嵌入</h3><p>GPT-2 Small 将词汇表中的每个标记表示为一个 768 维向量；向量的维度取决于模型。这些嵌入向量存储在形状为 (50,257, 768) 的矩阵中，包含大约 3900 万个参数！这个广泛的矩阵允许模型为每个标记分配语义含义。</p><h3 id="步骤3：位置编码"><a href="#步骤3：位置编码" class="headerlink" title="步骤3：位置编码"></a>步骤3：位置编码</h3><p>Embedding 层还对每个 token 在输入提示中的位置信息进行编码。不同的模型使用不同的方法进行位置编码。 GPT-2 从头开始​​训练自己的位置编码矩阵，将其直接集成到训练过程中。</p><h3 id="步骤4：最终嵌入"><a href="#步骤4：最终嵌入" class="headerlink" title="步骤4：最终嵌入"></a>步骤4：最终嵌入</h3><p>最后，我们将标记和位置编码相加以获得最终的嵌入表示。这种组合表示既捕获了标记的语义含义，也捕获了它们在输入序列中的位置。</p><h2 id="Transformer-块"><a href="#Transformer-块" class="headerlink" title="Transformer 块"></a>Transformer 块</h2><p>Transformer 处理的核心在于 Transformer 块，它由多头自注意力和多层感知器层组成。大多数模型由多个这样的块组成， 这些块按顺序一个接一个地堆叠在一起。Token 表示通过层级演变，从第一个块到第 12 个块，使模型能够对每个 Token 建立复杂的理解。 这种分层方法可以实现输入的高阶表示。</p><h3 id="多头自注意力"><a href="#多头自注意力" class="headerlink" title="多头自注意力"></a>多头自注意力</h3><p>自注意力机制使模型能够专注于输入序列的相关部分，从而能够捕获数据中的复杂关系和依赖关系。 让我们一步步看看这种自注意力是如何计算的。</p><h4 id="第一步：查询、键和值矩阵（Query-Key-and-Value-Matrices）"><a href="#第一步：查询、键和值矩阵（Query-Key-and-Value-Matrices）" class="headerlink" title="第一步：查询、键和值矩阵（Query, Key, and Value Matrices）"></a>第一步：查询、键和值矩阵（Query, Key, and Value Matrices）</h4><p><img src="/img/ai/TransformerExplainer/QKV.png" alt="图2，根据原始嵌入计算查询、键和值矩阵"><br>每个 token 的嵌入向量被转换成三个向量： Query (Q)、 Key (K)和 Value (V)。这些向量是通过将输入嵌入矩阵与学习到的权重矩阵相乘而得出的 Q、 K和 V。这里有一个网络搜索类比，可以帮助我们建立这些矩阵背后的一些直觉：</p><ul><li>Query (Q) 是您在搜索引擎栏中输入的搜索文本。 这是您想要“查找更多信息”的标记。</li><li>Key (K) 是搜索结果窗口中每个网页的标题。 它表示查询可以关注的可能的标记。</li><li>Value (V)是网页显示的实际内容。 当我们将适当的搜索词（Query）与相关结果（Key）匹配后，我们希望获得最相关页面的内容（Value）。<br>通过使用这些 QKV 值，模型可以计算注意力分数，这决定了每个标记在生成预测时应该获得多少关注。</li></ul><h4 id="第二步：掩码自注意力机制"><a href="#第二步：掩码自注意力机制" class="headerlink" title="第二步：掩码自注意力机制"></a>第二步：掩码自注意力机制</h4><p>掩码自注意力机制（Masked Self-Attention）允许模型通过关注输入的相关部分来生成序列，同时阻止访问未来的标记。</p><p><img src="/img/ai/TransformerExplainer/attention.png" alt="图3，使用查询、键和值矩阵来计算掩蔽自注意力"></p><ul><li>注意力分数：Query和Key 矩阵的点积确定每个查询与每个键的对齐方式，从而产生一个反映所有输入标记之间关系的方阵。</li><li>掩码：对注意力矩阵的上三角应用掩码，以防止模型访问未来的标记，并将这些值设置为负无穷大。 模型需要学习如何在不“窥视”未来的情况下预测下一个标记。</li><li>Softmax：经过掩码处理后，注意力得分通过 softmax 运算转换为概率，该运算取每个注意 力得分的指数。矩阵的每一行总和为 1，并表示其左侧每个其他标记的相关性。</li></ul><h4 id="第三步：输出"><a href="#第三步：输出" class="headerlink" title="第三步：输出"></a>第三步：输出</h4><p>该模型使用掩码后的自注意力得分，并将其与 Value 矩阵相乘， 以获得自注意力机制的 最终输出。GPT-2 有 12 个 自注意力 heads，每个 head 捕获 token 之间的不同关系。这些 head 的输出被连接起来并通过线性投影（linear projection）。</p><h3 id="多层感知器"><a href="#多层感知器" class="headerlink" title="多层感知器"></a>多层感知器</h3><p><img src="/img/ai/TransformerExplainer/mlp.png" alt="图4，使用 MLP 层将自注意力表征投影到更高维度，以增强模型的表征能力"></p><p>在多个自注意力机制捕获输入 token 之间的不同关系后，连接的输出将通过多层感知器（MLP，Multi-Layer Perceptron）层， 以增强模型的表示能力。MLP 块由两个线性变换组成，中间有一个 GELU 激活函数。 第一个线性变换将输入的维数从 768 增加了四倍至 3072。 第二个线性变换将维数降低回原始大小 768，确保后续层接收一致维度的输入。 与自注意力机制不同，MLP 独立处理 token 并简单地将它们从一种表示映射到另一种表示。</p><h2 id="输出概率"><a href="#输出概率" class="headerlink" title="输出概率"></a>输出概率</h2><p>在输入经过所有 Transformer 块处理后，输出将通过最后的线性层，为标记预测做好准备。 此层将最终表示投影到 50,257 维空间中，词汇表中的每个标记都有一个对应的值， 称为 logit。任何标记都可以是下一个单词，因此此过程允许我们根据它们成为 下一个单词的可能性对这些标记进行简单排序。然后，我们应用 softmax 函数将 logit 转换为 总和为 1 的概率分布。这将使我们能够根据其可能性对下一个标记进行采样。</p><p><img src="/img/ai/TransformerExplainer/softmax.png" alt="图5，词汇表中的每个标记都根据模型的输出逻辑 分配一个概率，这些概率决定了每个标记成为序列中下一个单词的可能性"></p><p>最后一步是从该分布中采样来生成下一个标记。temperature 超参数在 此过程中起着关键作用。从数学上讲，这是一个非常简单的操作：模型输出 logits 只 需除以 temperature：</p><ul><li>temperature &#x3D; 1：将 logits 除以 1 对 softmax 输出没有影响。</li><li>temperature &lt; 1：较低的温度通过锐化概率分布使模型更加自信和确定，从而产生更可预测的输出。</li><li>temperature &gt; 1：较高的温度会产生更柔和的概率分布，从而允许生成的文本具有更多的随机性 - 有些人称之为模型“创造力”。<br>调节温度，看看如何在确定性和多样化输出之间取得平衡！</li></ul><h1 id="高级架构功能"><a href="#高级架构功能" class="headerlink" title="高级架构功能"></a>高级架构功能</h1><p>有几种高级架构功能可增强 Transformer 模型的性能。虽然它们对于模型的整体性能很重要， 但对于理解架构的核心概念却不那么重要。层规范化、Dropout 和残差连接是 Transformer 模型中的关键组件，尤其是在训练阶段。层规范化可以稳定训练并帮助模型更快地收敛。 Dropout 通过随机停用神经元来防止过度拟合。残差连接允许梯度直接流过网络并有助于防止梯度消失问题。</p><h2 id="层归一化"><a href="#层归一化" class="headerlink" title="层归一化"></a>层归一化</h2><p>层归一化（Layer Normalization）有助于稳定训练过程并提高收敛性。它通过对特征之间的输入进行归一化来工作， 确保激活的均值和方差一致。这种归一化有助于缓解与内部协变量偏移相关的问题， 使模型能够更有效地学习并降低对初始权重的敏感度。每个 Transformer 块中都会 应用两次层归一化，一次在自注意力机制之前，一次在 MLP 层之前。</p><h2 id="暂退法"><a href="#暂退法" class="headerlink" title="暂退法"></a>暂退法</h2><p>暂退法（Dropout）是一种正则化技术，通过在训练期间随机将模型权重的一部分设置为零来防止神经网络过度拟合。 这鼓励模型学习更稳健的特征并减少对特定神经元的依赖，帮助网络更好地推广到新的、未见过的数据。 在模型推理期间，Dropout 被停用。这本质上意味着我们正在使用经过训练的子网络的集合，从而提高模型性能。</p><h2 id="残差连接"><a href="#残差连接" class="headerlink" title="残差连接"></a>残差连接</h2><p>残差连接（Residual Connections）于 2015 年首次在 ResNet 模型中引入。这种架构创新通过实现非常深的神经网络的训练， 彻底改变了深度学习。本质上，残差连接是绕过一个或多个层的捷径，将层的输入添加到其输出中。 这有助于缓解梯度消失问题，从而更容易训练堆叠在一起的多个 Transformer 块的深度网络。 在 GPT-2 中，每个 Transformer 块内使用两次残差连接：一次在 MLP 之前，一次在 MLP 之后， 以确保梯度更容易流动，并且较早的层在反向传播期间获得足够的更新。</p><h1 id="Transformer-Explainer-是如何构建的？"><a href="#Transformer-Explainer-是如何构建的？" class="headerlink" title="Transformer Explainer 是如何构建的？"></a>Transformer Explainer 是如何构建的？</h1><p>Transformer Explainer 具有一个可直接在浏览器中运行的实时 GPT-2（小型）模型。 该模型源自 Andrej Karpathy 的 nanoGPT 项目 PyTorch GPT 实现，并已转换为 ONNX Runtime 实现浏览器内无缝执行。该界面使用 JavaScript 构建，借助 Svelte 作为前端框架以及使用 D3.js 创建动态可视化。数值根据用户输入实时更新。</p><h1 id="谁开发了-Transformer-Explainer？"><a href="#谁开发了-Transformer-Explainer？" class="headerlink" title="谁开发了 Transformer Explainer？"></a>谁开发了 Transformer Explainer？</h1><p>Transformer Explainer 的作者包括 Aeree Cho， Grace C. Kim， Alexander Karpekov， Alec Helbling， Jay Wang， Seongmin Lee， Benjamin Hoover，以及佐治亚理工学院的 Polo Chau。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>NanoGPT 教程及训练推理</title>
    <link href="/2024/09/04/AI/NanoGPT/"/>
    <url>/2024/09/04/AI/NanoGPT/</url>
    
    <content type="html"><![CDATA[<p>这是目前最简单、最快的一个训练&#x2F;微调中等大小的GPT仓库。</p><span id="more"></span><p><img src="/img/ai/nanogpt/nanogpt.jpg" alt="nanoGPT"></p><h1 id="NanoGPT-中文教程"><a href="#NanoGPT-中文教程" class="headerlink" title="NanoGPT 中文教程"></a>NanoGPT 中文教程</h1><p>该项目是对<a href="https://github.com/karpathy/minGPT">minGPT</a> 项目的重构。项目虽然仍处于积极的开发阶段；但是目前其中的<code>train.py</code>文件在OpenWebText上已经可以复现GPT-2（124M）在8个A100（40GB）上训练四天的效果。此外，代码写的十分简单易读：<code>train.py</code>是一个300行的训练的模版，而 <code>model.py</code> 是一个300行的GPT模型定义的模版，该模板支持选择加载OpenAI的GPT-2权重。</p><p><img src="/img/ai/nanogpt/gpt2_124M_loss.png" alt="repro124m"></p><p>因为该仓库的代码实在非常简单，因此很容易根据您的需求进行应用、或者从零开始训练新模型以及微调预训练的检查点（例如，目前可用的最大的预训练模型是OpenAI开源的GPT-2 1.3B模型）。</p><h2 id="安装条件"><a href="#安装条件" class="headerlink" title="安装条件"></a>安装条件</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install torch numpy transformers datasets tiktoken wandb tqdm<br></code></pre></td></tr></table></figure><p>依赖的库：</p><ul><li><a href="https://pytorch.org/">pytorch</a> &lt;3</li><li><a href="https://numpy.org/install/">numpy</a> &lt;3</li><li><code>transformers</code> for huggingface transformers &lt;3 (用于加载 GPT-2 模型的检查点)</li><li><code>datasets</code> for huggingface datasets &lt;3 (如果您想下载并且处理OpenWebText数据集)</li><li><code>tiktoken</code> for OpenAI’s 最快的BEP编码算法 &lt;3</li><li><code>wandb</code> for optional logging &lt;3</li><li><code>tqdm</code> for 加载进度条 &lt;3</li></ul><h2 id="简易上手"><a href="#简易上手" class="headerlink" title="简易上手"></a>简易上手</h2><p>如果您不是专业从事于深度学习行业的人士，只是想感受GPT的魅力以及自己训练GPT的快感，那么最快的入门方法就是训练一个可以创造莎士比亚作品的GPT。首先，我们先下载一个1MB大小的文件，并将其从原始文本转换为一个大的整数流（将原始数据转化为一个embedding之后的整数流数据）：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python data/shakespeare_char/prepare.py<br></code></pre></td></tr></table></figure><p>这会在数据目录中创建<code>train.bin</code> and <code>val.bin</code> 文件，现在就是时候来训练你的GPT了。而你训练GPT的规模在很大程度上取决于你能提供的算力情况(是否有显卡以及显存的大小是多少)：</p><p>如果您的设备<strong>配置了显卡</strong>，那么很棒，我们可以使用在<a href="config/train_shakespeare_char.py">config&#x2F;train_shakespeare_char.py</a> config file提供的设置很快地训练一个小型GPT</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python train.py config/train_shakespeare_char.py<br></code></pre></td></tr></table></figure><p>如果您恰好有兴趣观看了代码的细节部分，您将会发现我们正在训练一个上下文大小高达256个字符、384个特征通道，的一个6层的且每层的heads数量有6个的Transformer。在一个A100型号的显卡中，此训练运行大约需要3分钟，最佳验证损失可以减小到1.4697。根据代码中的设置，模型检查点被写入<code>--out_dir</code>目录<code>out-shakespeare-char</code>中。因此在训练完成后，我们可以通过将验证脚本<code>sample.py</code>在最佳的模型进行文本的效果生成。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python sample.py --out_dir=out-shakespeare-char<br></code></pre></td></tr></table></figure><p>这会产生一些新的样例，例如:</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs txt">ANGELO:<br>And cowards it be strawn to my bed,<br>And thrust the gates of my threats,<br>Because he that ale away, and hang&#x27;d<br>An one with him.<br><br>DUKE VINCENTIO:<br>I thank your eyes against it.<br><br>DUKE VINCENTIO:<br>Then will answer him to save the malm:<br>And what have you tyrannous shall do this?<br><br>DUKE VINCENTIO:<br>If you have done evils of all disposition<br>To end his power, the day of thrust for a common men<br>That I leave, to fight with over-liking<br>Hasting in a roseman.<br></code></pre></td></tr></table></figure><p>哇，<code>¯\_(ツ)_/¯</code>. 对于一个只在GPU上训练了三分钟的用于角色扮演的GPT来说还真不错。 而如果是在此数据集上微调预训练好的GPT-2模型，有很大的可能会获得更好的结果的（详情见后面的微调部分）</p><p>如果**您只有一台MacBook或者其他更为便宜的电脑(没有显卡)**怎么办？不用慌 ,我们仍然可以训练一个GPT,只是我们要让事情低调一点，在这里我推荐使用最新版的每晚更新的pytorch，因为这有可能让您的代码变得更加高效。当没有显卡的时候，可以使用下面这个简单的训练脚本。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python train.py config/train_shakespeare_char.py --device=cpu --compile=False --eval_iters=20 --log_interval=1 --block_size=64 --batch_size=12 --n_layer=4 --n_head=4 --n_embd=128 --max_iters=2000 --lr_decay_iters=2000 --dropout=0.0<br></code></pre></td></tr></table></figure><p>此时，由于我们是在CPU而非GPU上运行，我们必须设置<code>--device=cpu</code>并且使用<code>--compile=False</code>关闭掉PyTorch 2.0版本的compile功能。 然后，当我们在测试时候时，得到的估计结果可以更不精确但是更快（<code>eval_iters=20</code>，将迭代的次数从200下降到20），此时我们使用的上下文大小范围只有64个字符，而不是256个字符，每次迭代的batchsize只有12个样本，而不是64个样本。我们还将使用一个更小的Transformer结构（4layer，4个head，128个嵌入大小），并将迭代次数响应地减少到2000（相应地，通常使用<code>--lr_decay_iters</code>将学习率衰减到max_iters左右）。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python sample.py --out_dir=out-shakespeare-char --device=cpu<br></code></pre></td></tr></table></figure><p>这样会生成下面这样的样本：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs txt">GLEORKEN VINGHARD III:<br>Whell&#x27;s the couse, the came light gacks,<br>And the for mought you in Aut fries the not high shee<br>bot thou the sought bechive in that to doth groan you,<br>No relving thee post mose the wear<br></code></pre></td></tr></table></figure><p>因为是只在cpu上训练了3分钟，因此能输出这样符合语法，和要求格式的样子算很不错了。如果您乐意等待更长的时间，请尽情去调整超参数，并且去增加网络的大小，使用<code>--block_size</code>去调整上下文的长度</p><p>最终，如果是在苹果的M系列处理器上进行实验(最新的pytorch版本)，请务必将添加<code>--device=mps</code>的设置，PyTorch会使用在芯片上的图形处理单元(GPU)来显著加快训练速度(2-3倍)，并且允许您使用更大的网络规模。您可以在 <a href="https://github.com/karpathy/nanoGPT/issues/28">Issue 28</a>找到更多相关的内容</p><h2 id="复现GPT-2"><a href="#复现GPT-2" class="headerlink" title="复现GPT-2"></a>复现GPT-2</h2><p>一些更专业的深度学习从业者也许会更关注如何去复现GPT-2的效果。因此，让我们开始，我们首先将数据集进行tokenize，以<a href="https://openwebtext2.readthedocs.io/en/latest/">OpenWebText</a>数据集(OpenAI的WebText的开放版本)为例：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python data/openwebtext/prepare.py<br></code></pre></td></tr></table></figure><p>这会下载并将 <a href="https://huggingface.co/datasets/openwebtext">OpenWebText</a> 数据集进行分词化.这将会创造一个保存了<code>train.bin</code>和<code>val.bin</code></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">torchrun --standalone --nproc_per_node=8 train.py config/train_gpt2.py<br></code></pre></td></tr></table></figure><p>如果您有集群环境可以使用，并且您拥有多个GPU节点，您可以使GPU在2个节点上进行，例如:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Run on the first (master) node with example IP 123.456.123.456:</span><br>torchrun --nproc_per_node=8 --nnodes=2 --node_rank=0 --master_addr=123.456.123.456 --master_port=1234 train.py<br><span class="hljs-comment"># Run on the worker node:</span><br>torchrun --nproc_per_node=8 --nnodes=2 --node_rank=1 --master_addr=123.456.123.456 --master_port=1234 train.py<br></code></pre></td></tr></table></figure><p>在您的计算机系统中对内部连接（例如使用iperf3工具）进行性能测试是一个很好的主意。如果您没有安装Infiniband技术，那么在上述启动命令前还应该添加<code>NCCL_IB_DISABLE=1</code>。这样您的多节点训练可以正常进行，但很可能速度会非常慢。默认情况下，检查点会定期写入到<code>--out_dir</code>指定的目录中。我们可以通过简单地执行<code>python sample.py</code>命令从模型中进行抽样。</p><p>最终，如果想在单个GPU上进行训练，您只需要简单的运行<code>python train.py</code>脚本即可。看看args中的这些参数，着脚本是如此的易读，易用以及是可迁移的。您可以根据您的需要在这些变量中进行随意地调整。</p><h2 id="基线"><a href="#基线" class="headerlink" title="基线"></a>基线</h2><p>OpenAI GPT-2的提供的模型保存点允许我们为openwebtext数据集建立一些基准测试。我们可以按照以下方式获得这些数值：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">python train.py eval_gpt2<br>python train.py eval_gpt2_medium<br>python train.py eval_gpt2_large<br>python train.py eval_gpt2_xl<br></code></pre></td></tr></table></figure><p>并且可以观察到在训练集和测试集上的损失:</p><table><thead><tr><th>model</th><th>params</th><th>train loss</th><th>val loss</th></tr></thead><tbody><tr><td>gpt2</td><td>124M</td><td>3.11</td><td>3.12</td></tr><tr><td>gpt2-medium</td><td>350M</td><td>2.85</td><td>2.84</td></tr><tr><td>gpt2-large</td><td>774M</td><td>2.66</td><td>2.67</td></tr><tr><td>gpt2-xl</td><td>1558M</td><td>2.56</td><td>2.54</td></tr></tbody></table><p>然而，我们必须要注意到一点，GPT-2实际上是在未开源的，甚至是从未发行过的WebText数据集上进行训练的，而OpenWebText只是对这个数据集的最大努力地复制。这意味着数据集之间的差异是显著存在的。事实上，我们使用GPT-2 (124M) 的检查点，利用OpenWebText数据集进行微调，不一会就能观察到损失会降低到2.85左右，对与复现来说，这是实际上是更为合适的基线。</p><h2 id="模型微调"><a href="#模型微调" class="headerlink" title="模型微调"></a>模型微调</h2><p>微调和训练的差别并不大，我们只需要保证要从一个预训练的模型进行初始化并且用一个更小的学习率进行训练即可。如果想了解如何在新的数据集上微调GPT模型，您可以参考shakespeare的例子：转到<code>data/shakespeare</code>目录并运行<code>prepare.py</code>，以下载tiny shakespeare数据集并使用GPT-2的OpenAI BPE分词器，将其处理成<code>train.bin</code>和<code>val.bin</code>文件。不像使用OpenWebText数据集从零开始训练，这会在几秒钟内完成。微调可能需要很少的时间，甚至是在单个GPU上仅需几分钟。我们可以像这样运行一个微调的例子：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">python train.py config/finetune_shakespeare.py<br></code></pre></td></tr></table></figure><p>这将加载写在<code>config/finetune_shakespeare.py</code>中的配置参数（虽然我没有太多调整它们）。基本上，我们使用<code>init_from</code>从一个GPT2的模型保存点初始化，并像通常一样进行训练，只是训练时间更短，学习率更小。如果您在训练过程中发现显存溢出的情况，您可以尝试减小模型大小（可选的有<code>&#39;gpt2&#39;</code>, <code>&#39;gpt2-medium&#39;</code>, <code>&#39;gpt2-large&#39;</code>, <code>&#39;gpt2-xl&#39;</code>），或者可能减小<code>block_size</code>（上下文长度）。最佳的模型保存点（验证损失最低）会在<code>out_dir</code>目录中，根据配置文件例如默认情况下会保存在<code>out-shakespeare</code>中。然后，你可以运行在<code>sample.py --out_dir=out-shakespeare</code>中的代码：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs txt">THEODORE:<br>Thou shalt sell me to the highest bidder: if I die,<br>I sell thee to the first; if I go mad,<br>I sell thee to the second; if I<br>lie, I sell thee to the third; if I slay,<br>I sell thee to the fourth: so buy or sell,<br>I tell thee again, thou shalt not sell my<br>possession.<br><br>JULIET:<br>And if thou steal, thou shalt not sell thyself.<br><br>THEODORE:<br>I do not steal; I sell the stolen goods.<br><br>THEODORE:<br>Thou know&#x27;st not what thou sell&#x27;st; thou, a woman,<br>Thou art ever a victim, a thing of no worth:<br>Thou hast no right, no right, but to be sold.<br></code></pre></td></tr></table></figure><p>Emmm，此时GPT似乎产生了一些不能解释（黑洞）的东西。我并没有真正对配置中的超参数进行太多调整，请随时尝试！</p><h2 id="采样推理"><a href="#采样推理" class="headerlink" title="采样推理"></a>采样推理</h2><p>使用<code>sample.py</code>脚本可以从OpenAI发布的预训练GPT-2模型或者从您自己训练好的模型中进行内容生成。例如这里您可以通过这样的方式从目前最大的<code>gpt2-xl</code> 模型中进行推理：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">python sample.py \<br>    --init_from=gpt2-xl \<br>    --start=<span class="hljs-string">&quot;What is the answer to life, the universe, and everything?&quot;</span> \<br>    --num_samples=5 --max_new_tokens=100<br></code></pre></td></tr></table></figure><p>If you’d like to sample from a model you trained, use the <code>--out_dir</code> to point the code appropriately. You can also prompt the model with some text from a file, e.g. <code>python sample.py --start=FILE:prompt.txt</code>.</p><h2 id="提高效率"><a href="#提高效率" class="headerlink" title="提高效率"></a>提高效率</h2><p>对于简单的模型基准测试和性能分析，<code>bench.py</code>可能会很有用。它与<code>train.py</code>中训练循环的核心部分所发生的事情相同，但省略了许多其他一些复杂的东西。</p><p>请注意，默认情况下代码使用的是<a href="https://pytorch.org/get-started/pytorch-2.0/">PyTorch 2.0</a>。在撰写本文时（2022年12月29日），这使得<code>torch.compile()</code>在每日更新版本中可用。<code>torch.compile()</code>所带来的提升是显著的，例如，将迭代时间从约250毫秒&#x2F;次迭代减少到135毫秒&#x2F;次迭代。PyTorch团队牛逼！</p><h2 id="可以做的事情"><a href="#可以做的事情" class="headerlink" title="可以做的事情"></a>可以做的事情</h2><ul><li>进行调研并使用FSDP代替DDP</li><li>在标准评估上评估了零样本的困惑度（例如LAMBADA? HELM? 等）</li><li>可以微调 finetuning script，我认为超参数设置得不太好</li><li>在训练过程中安排线性增加批量大小</li><li>合并其他嵌入（如旋转嵌入，alibi嵌入）</li><li>我认为应该在检查点中将优化缓冲区与模型参数分开</li></ul><h1 id="训练实践"><a href="#训练实践" class="headerlink" title="训练实践"></a>训练实践</h1><h2 id="训练西游记"><a href="#训练西游记" class="headerlink" title="训练西游记"></a>训练西游记</h2><p>照搬上面教程：</p><p><img src="/img/ai/nanogpt/west.png" alt="文件目录"></p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-7c17ff9f" role="button" aria-expanded="false" aria-controls="collapse-7c17ff9f">        <div class="fold-arrow">▶</div>训练脚本及测试      </div>      <div class="fold-collapse collapse" id="collapse-7c17ff9f">        <div class="fold-content">          <p><strong>prepare.py</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs py">input_file_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;west-journey.txt&#x27;</span>)<br></code></pre></td></tr></table></figure><p><strong>train_west_journey.py</strong></p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># train a miniature character-level shakespeare model</span><br><span class="hljs-comment"># good for debugging and playing on macbooks and such</span><br><br>out_dir = <span class="hljs-string">&#x27;out-west-journey&#x27;</span><br>eval_interval = <span class="hljs-number">250</span> <span class="hljs-comment"># keep frequent because we&#x27;ll overfit</span><br>eval_iters = <span class="hljs-number">200</span><br>log_interval = <span class="hljs-number">10</span> <span class="hljs-comment"># don&#x27;t print too too often</span><br><br><span class="hljs-comment"># we expect to overfit on this small dataset, so only save when val improves</span><br>always_save_checkpoint = <span class="hljs-literal">False</span><br><br>wandb_log = <span class="hljs-literal">False</span> <span class="hljs-comment"># override via command line if you like</span><br>wandb_project = <span class="hljs-string">&#x27;out-west-journey&#x27;</span><br>wandb_run_name = <span class="hljs-string">&#x27;mini-gpt&#x27;</span><br><br>dataset = <span class="hljs-string">&#x27;west-journey&#x27;</span><br>gradient_accumulation_steps = <span class="hljs-number">1</span><br>batch_size = <span class="hljs-number">64</span><br>block_size = <span class="hljs-number">256</span> <span class="hljs-comment"># context of up to 256 previous characters</span><br><br><span class="hljs-comment"># baby GPT model :)</span><br>n_layer = <span class="hljs-number">6</span><br>n_head = <span class="hljs-number">12</span><br>n_embd = <span class="hljs-number">384</span><br>dropout = <span class="hljs-number">0.1</span><br><br>learning_rate = <span class="hljs-number">1e-3</span> <span class="hljs-comment"># with baby networks can afford to go a bit higher</span><br>max_iters = <span class="hljs-number">10000</span><br>lr_decay_iters = <span class="hljs-number">10000</span> <span class="hljs-comment"># make equal to max_iters usually</span><br>min_lr = <span class="hljs-number">1e-4</span> <span class="hljs-comment"># learning_rate / 10 usually</span><br>beta2 = <span class="hljs-number">0.99</span> <span class="hljs-comment"># make a bit bigger because number of tokens per iter is small</span><br><br>warmup_iters = <span class="hljs-number">100</span> <span class="hljs-comment"># not super necessary potentially</span><br><br><span class="hljs-comment"># on macbook also add</span><br><span class="hljs-comment"># device = &#x27;cpu&#x27;  # run on cpu only</span><br><span class="hljs-comment"># compile = False # do not torch compile the model</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ python prepare.py<br>$ python train.py config/train_west_journey.py<br>$ python3 sample.py --out_dir=out-west-journey/<br>Overriding: out_dir = out-west-journey/<br>number of parameters: 12.36M<br>Loading meta from data/west-journey/meta.pkl...<br><br><br>家有三个小妖。他身一个，一人也不是面。他只是我生得到处，他怎么这等怎的？”行者笑道：“兄弟们，这个和尚，你两个在这里也会说话，也不曾同小可，待我往西天去拜佛上去。” 小妖道：“他却去了？”行者道：“你不曾去了？”小妖道：“洞里有个南南海菩萨说唐僧，名悟空行者，做不曾与我做。因了人是牛魔王，名悟能，姓孙，谁敢来历。”<br><br>行者道：“他怎么说？”妖王道：“他是两个孙悟空，到此处寻他！”大圣道：“原来是猪八戒，他怎么敢来历？”行者道：“实不敢擅来，说我这里话，一遍东土到我师父。那些人，你去寻 ，我那厢都来此请将来奉上。”行者道：“我那里来的？”小妖道：“差来的？”小妖道：“我奉 请出来。”小妖道：“是一个大王的大王，来的一个孙行者。”小妖道：“大王，那里有个小孙 ？”小妖道：“知，来的们先来。”小妖道：“前年我等出来问他甚么人家人是一个师兄，乃陈 下大王？”小妖道：“我祖为七八千年？”妖王道：“有个三千万，他那个和尚，他是我等大王 ，唤做猪羊，往西天取经的女儿。教他将草贩猪羊差往西天取经，往西打火的，问我们往那 里去？”小妖道：“那里去，山坡上就是一个甚么名木叉、火势，敢来，只管甚么孙行者假， 若是有些儿。<br>---------------<br><br>一二点点神，即时有一里远近，忽见一座高山。大圣道：“这小神，见他却不在这里，老孙看见他怎么不得？”玉帝道：“那个是那个大圣，下界来的是孙悟空来了。”大圣已息怒，叫声“ 这泼猴！也！这泼猴，好！他怎么见出名谁？”大圣道：“不要打！”大圣道：“你这等咒语， 心内说，教你去问我。”无奈，那些土地，只听得半个个即出大海边来，丢了手，将出一个妖精，那妖魔，一个个个个轮着一个拳头，道：“我不打你的泼猴，在那里见我这里面，想是甚名头？”行者道：“你那里走回来？”土地道：“你是东土大唐驾下差往西天取经的大雷音寺， 路过宝方，特来问我条路上去了。”行者才闪过，解开门来。那罗汉化了门，叫声“小神，快 去来！”慌得那土地藏慌了心惊道：“这弼马温柔天弄了！真是！你是打你的宝贝，你听我哄 我！”这大圣听言，心中大怒道：“这个孽畜！”这兄弟，这番真个浑身，往下一摸，好杀：果然不见！真个自天号，与大圣，万道：“吾意，你怎么走得？”大圣道：“你莫怕，我照顾！” 大圣笑道：“你这个嘴，我不是你的泼狲，在高山前，把一条，变作个花针儿，你也是你的。”行者道：“你这个原来是在那里？我如来是西方佛求经，名悟净。”土地道：“我乃西方大唐 王第<br>---------------<br><br><br><br>此去，只见那边有一座黑山，坡前面有一个女子。半空中间收了一个女儿，身穿一领青脸獠 牙，一行者，一个头戴一双布天冠。面似龙警，光亮如白光须。身云履轻飘飘飘飘荡，身穿 风飘荡。正是那一个是那里女子，止不住腮边泪滴泪，见了，十分开路，只叫：“女菩萨，我来了！我！看你，快教你我与我一个死！”那女怪不敢言，大圣才转睛，径往西上一个女怪。正自商议，忽然见他：<br><br>“女菩萨，贫僧往那里去？”女怪道：“我名唤做香火焰山，往那里去。”那女子即回头，又来 。那怪一个行者，心惊道：“郎君是我等往西海龙王，径至此，只有五百年，不出个洞。”那 怪道：“你是那个妖精，来的？”行者道：“我自何来？”龙王道：“他怎么是他？”行者道：“是他的，我的？”行者道：“你看是个妖精。”妖精道：“他有多年纪，每年吃了，不曾延年吃了 一个肉，就吃得吃了两个，也不得五做了几个，也吃了；又不用的吃了，只是吃了他一饭。 不知是死去降临，在此受他一同，他怎么就算计。今日他都是大徒弟，他怎么不教他驮，把 你这驮将来。”行者道：“若是我驮着他，我与你上去。”那怪道：“你是他，你就是了去得。”行者道：“莫怪，他有应了，我是问你。”八戒道：“你是甚么么妖精的<br>---------------<br><br><br>那条条经十回　正正行处，忽见一阵狂风滚，滚狂风出。行者道：“师父不济！这个是那里怪物？”八戒道：“这钯！这般一千般，比丘王，想是一个黑熊山中。”行者道：“师父，又有此 间乃齐天大圣，小弟子，你怎么认得？”八戒道：“想是天大圣，已成的一个胜神，我是遗下 降怪。那妖精，有此间乃海之精，乃于此山之中之处，想是月洞。<br>他知那时间乃是九年前宫仙。所以五月之辈，唤做妖精。今年前，原来是天仙，有降魔，知 道不知那个甚么妖精。”行者道：“在此镇元始初分，灵。”道：“我是一个元子，是天仙，一 所以为之形，乃是玉帝，曾与天之分，有此仙宫仙，做了五百年，二个小子，但一帝，，未 未曾降临凡胎，在天产后，又能知子？此乃凡间，他还有此有。”行者道：“不敢相瞒，我也 有一个女子，是老孙。他是他的仙的根，一根甘露结，止俗熟的名了，他也不论个。”仙女道：“我是你这宝贝，这般有此宝品，只有我的。”行者道：“既没有这一个宝贝，也不须之物。”众道：“想是不是了。”<br><br>仙童道：“是上仙果子，有甚么宝贝，不敢叫？”行者道：“”。”仙童道：“真个是。”玉帝看了，那仙童道：“，不敢看动，才叫做“仙童，若论了。”即忙取了我的一柄一下，拿了一根毫<br>---------------<br><br>唐僧等八戒，还起身来，各吃了一座黑松林，前面蓬莱山，忽见一座城池。长老见他，急脱 了三个女官进，便下树林内更不看，只见那：锦衣秀丽，千山头奇花丛。白鹤唳嫩，何多松 ；四片片片青。这石，深俗桃香，绿藻地铺；峭壁，五凤悬崖，一齐鸣。一座峰，树上有石 碣，每见众仙，“是那方是花果山住处，只是那里路的。”一个大字，却是一丈六丈二尺，抬 火眼，到当中间，又来到上细拿出一个个人。那大圣将身一个个女子，就变作一个青脸，锦 衣巾，腰间系着一领青毛，头的穿的来，敛衣衣出一领芭蕉，穿了褊衫，身穿的象，身穿一 领锦直裰，锦衣领金睛，穿一领领长衣。一行者笑道：“这个是个大徒弟，他倒是我的。”行 者笑道：“这和尚不知是。”道：“莫怪，他要打，待我过去。”，一齐上前相迎，走下手相见 ，那仙童子上前走出来。行者笑道：“不敢！再不敢不敢称问讯，问一声：“我不是那个甚么 来的？”道士陪笑道：<br><br>“你是那里来的？”行者道：“我乃东土大唐僧，往西天去的唐差往西天拜佛求经的徒弟，上有东土大唐驾下雷音，欲开路，特来问天尊仙公。”仙翁道：“你自幼修行，大胆少西天拜佛求 经，无个西方佛求经者。西方佛祖。大仙，特来奏上西天经，请上。”行者笑道：“这和尚<br>---------------<br><br><br>一时天宫阙天宫，天兵更不得见罪。一闻报玉帝传旨，封封天兵曹都天兵，封海水帘将。玉 帝传旨因齐天大天大圣，斗星牌，帅领着五岳天兵灵霄宝殿，无兵，天下界复赴会，称上方 生圣。<br><br>日前领时，天兵，迎至那妖猴王，那星君欣然，即对天王道：“何来？”星道：“在上，此见玉帝差。”水德星道：“有无兵，不受，今日到此。天王，不以报。”玉帝道：“那时是初时之时 ，乃齐天大圣二郎与哪吒，有四元帅奏。今蒙大圣有罪。”玉帝即敛云部、张天师会同兄都、五刚、四曜星、十神俱、四元帅，各宫后来，都拜此。不敢久，齐天大圣，下降妖，合掌奏 道：“今日差天兵，到此查勘。”又问：“那妖猴儿不少了。”行者道：“这厮乃凡人生之种，乃是天下界’，三个都称为何？”哪吒道：“也试学！”天师道：“‘我神通，只是混沌后之辈，封 为天，封天生小！”才驾筋斗云，径至宝山界洞外。有五百年三十个妖，都在那四宿星辰，早到了本宫门，照依然又到灵霄宝殿下，忽见那个白玉帝，宝象因也养马，叫天王，他叫做无 根，教他送与他怎生旨意助，上下雨的神神兵。”却说行者道：“你且不来你请我们来。”大圣吩咐八戒、沙僧，向前观看，忽见那白鹦哥的一个老君，坐在那里，口中有一个女子，一个<br>---------------<br><br>老孙自大圣，情除齐天大圣，那魔神土神。有神兵。”玉帝道：“言之物，天罗地亦不能，须 要调雨。奈我出云全。”玉帝教帅臣领旨，着悟空道：“此何？”天王道：“不正是。”大圣道：“那了云，没有些不会子，不伏老君放火哩。”玉帝道：“既是官差了。”天王道：“还差天兵，有兵，那个个‘胜神通之’，也不能助助力，须是大圣四雷电。”行者道：“那时子相我奉玉帝 旨，宣下界同，径至此。”行者笑道：“不须敢变化为这个自第四字，就有多少能。”<br><br>玉帝道：“此是须要吃一块火，如今如今三参佛，万寿，也不能取经，把老孙打打便弄。”天 王道：“你那个不认得？”行者道：“你知。我是玉帝，只说的不是何类者。因是玉帝差。”四 帝道：“我不知，内有多少差。西天门下界中有一个雷将，唤做“齐天大圣，请天兵，来此来 与我同入。”这星官儿相见道：“这泼猴！不是错了！人也不是！常时实说，善能降火焰山， 善能与你们处安同天尊之中，众神，众神，都是弟兄弟。<br><br>我有诚为证，比丘之二尊，同妻二将，老孙与他同去擒魔。”天王道：“既是上界，知此一则 神通也。”天王道：“怎敢敢擅住？”行者道：“终则帅领兵器，将明日辰收伏，二来此有二来 ，如何不可？”天王道：“令致令郎<br>---------------<br><br>“师兄，你生得道，我也拜你晓得。”八戒道：“他只知我看看见。”行者道：“哥，你莫胡说，再不会说！常时间，不会说语，你人言道，不知道，你又惹那里来。等我跑走出去看。”<br><br>行者道：“你睡在，等我再莫哭，等这里睡觉，不是看是这般变，等吓破人哩，你也弄风，只怕师父。他怎么说说？”八戒道：“我驮着，驮着你去。”行者道：“又不知一个，等我驮着你 ，你打出去。”八戒道：“你怎的？”行者道：“你打个钻风儿去了。”八戒道：“不打倒打诳语 。”樵子道：“我只在这里，看那个风儿没有，变生打样就是个。你再莫想。”行者道：“你曾 问甚么？”樵子道：“我只管不晓得，那里与你见！”行者道：“我吃你换关文儿，吃了罢。”樵子道：“委是你的吃的？”行者道：“我这一言语，连少了我也罢。”行者道：“有个本事！”那 樵夫低了一听说：“大王，不曾敢怎么不与我？”行者道：“你也晓得，你再惹我？”樵子道：“我虽是在家去了。”长老道：“我虽是是自家。我乃是我舍下次在此，有几个故人也。我常言 道，不知道，你说我这一则是我辈之意，故此不知之子，故名为不尽，二则是天延寿。”樵子笑道：“你这个猴子！常言道，十分终不阴阳，我也不是个大之意。”樵子道：“你<br>---------------<br><br><br><br>我等与三年前两个，在那妖精赌斗，他三十分胜。若那猴子十合，十分胜负。依我等三昧， 辨明。你师父，只做弟兄弟三十一会，二一日出洞，一夜，不得他怎么保师父？”八戒道：“ 我去，你与你回去请去。”行者道：“师父在那里？”八戒道：“哥哥，不曾会降妖。我的马哩 。”行者道：“也罢。”那呆子一见唐僧，都上前扯住。八戒道：<br><br>“徒弟呀，这等待我去看。”行者道：“是，这等是一定是那里儿？”八戒道：“那厮不曾成的，只管你去得，等我出来。”八戒道：“也罢了，你快快拿来。”行者道：“我驮下一路。”长老道：“我驮！”八戒道：“呆子！想是跌了。”行者道：“你八戒么？”八戒道：“不曾道：“你会会 不曾会，只是驮着。”师父道：“这个夯货未曾，你想是个。”行者道：“实是猪八戒、沙僧、 沙和尚，怎敢不肯跟我？”八戒道：“我待往西天去，看是！”八戒道：“哥哥啊，他那里是个 大唐僧？”行者道：“他就是这等惫懒，怎么得到此处？”八戒道：“你还不认人哩？”行者道：“你这些夯货，我们是弼马温，岂不会我么？我知道他的志心，教你赶我，交付与你一库去。这个风字，去与你令弟，你与我与我下去。”行者道：“你不知道，怎么说他怎的？”行者道：“我不打<br>---------------<br><br>这一向后，又有两个小孩儿，俱在后边下，取出来，在那里要怎的？只管说甚么人？是个家 人，我与他个。他可认得你，你却不得我家子一个！看看他是个长，说是个徒弟的。”正说间，只见他：“你不知道，说甚么甚么人相他？”行者道：“我是甚么人，甚与你去？”老者道：“是不曾值年了。”三藏道：“弟子乃牛魔王与他说与我识与他交战。他见，他怎么不能助力？”行者笑道：“你既是个大徒弟，不曾吩咐，曾与你去问他：‘三个，他怎么说他见？”三藏道：“贫僧乃西方，名悟空的仙，不曾吃他。”行者道：“有甚么不曾？”道：“他说我等在那里不曾惹动，他不曾问了？”老者道：“东土大唐僧乃东土大土路，特来请启宣召来的。”老者道：“ 有甚么话，不曾答甚事？”道：“有甚么人？”三藏道：“贫僧乃东土大唐差往西天拜佛求经者 ，上有一处，名凤仙郡。我师徒弟孙唤做孙悟空，唤做三藏。”那老者道：“他有三个徒弟， 那里有甚事？”行者道：“我不敢招了。”老者道：“我岂不教家是我们的。”三藏道：“你不来 的是？”老者道：“我们是东土大唐驾下差往西天取经的大雷音寺拜佛求经者。”行者道：“我 这一路间有一个雷音院，你倒是他老孙的？”三藏道：“不消说，我弟子，不曾与你做理<br>---------------<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="训练凡人修仙传"><a href="#训练凡人修仙传" class="headerlink" title="训练凡人修仙传"></a>训练凡人修仙传</h2><p>1000次，12层，效果如下：</p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-54fa9200" role="button" aria-expanded="false" aria-controls="collapse-54fa9200">        <div class="fold-arrow">▶</div>训练脚本及测试      </div>      <div class="fold-collapse collapse" id="collapse-54fa9200">        <div class="fold-content">          <div class="note note-primary">            <p>Overriding: out_dir &#x3D; out-human&#x2F;<br>number of parameters: 22.81M<br>Loading meta from data&#x2F;human&#x2F;meta.pkl…</p><p>“元磁神光！”<br>韩立只听了一声，就脸色一变的失声出口，同时心中法决一催。<br>顿时金色电光只是一闪，又一根金色电丝从指尖处激射而出，一闪即逝下，就没入韩立 身躯之中，不见了踪影。<br>下一刻，韩立面色一白之下，一声低喝，单手虚空一抓，一座尺许高的黑色山峰，从其 身躯中一飞而出，并一个闪动的在手中一迎而出。<br>黑色山峰毫不客气的往下一模糊的一扎。<br>一声接一声闷响！<br>黑色山峰、紫色符文手臂一模糊下，竟在狠狠一投而出，并立刻在金光闪过处，化为了 一座黑色山峰，狠狠的往高处一砸而去。<br>一声闷响！<br>黑色山峰一下寸寸的爆裂而开，并瞬间的爆裂而开。<br>一团乌光从乌光中激射而出，一下化为一个直径数十丈的黑色山峰，散发着惊人黑芒的 将整座山峰全都笼罩在了其中。</p><p>第十一卷 真仙降世 第两千一百一十七章 金光界</p><p>“你真想伤我，想不到可以直接打开此山？”女子也在此威能之下，发出了一声惊怒的尖 叫，仿佛下一刻，一下活过的样子。<br>而那只金色拳头一个闪动下，就一下一下到了女子手中，并狠狠一拳击在了黑色山峰上 。</p><hr><p>虽然韩立的修为不说，但除了这只魔兽外，其他人和十几名弟子，清秀的看到一个宽广 的圆形空间。在其中一处，则有一个男子站在那里，正有六七名修士，正在陪着一名面色冰 冷的姓中年修士，也一副神态恭敬的盯着他们。<br>“大哥，这是……”这名老者一到白家弟子面前，忽然一个淡淡的声音传出，似乎带有一丝 微弱之意，仿佛进入到了什么地方。<br>“不错。你们两个修士，正在闭关之中呢。”<br>“哼！这话是什么意思？看来我们二人都已经动了手脚了，竟然还等候大哥的样子。”白 芸馨面无表情的回了一句。<br>两名老者听到白家弟子这般一说，也不禁露出一丝苦笑，几步走了过去。<br>“两个弟子，我要你们两个，是不是将这些弟子全都灭杀，等大家不到千万为密，我们过去看看还不是什么遗憾之事。好了，我给两人带路！”白芸馨毫不犹豫的回道。<br>“这位是哪位前辈到此的，不过是听说这些弟子的消息，那位前辈是来自圣界的两名弟子了。”另外两名老者也一口同意了下来，急忙的赔罪道，同时脸上满是狡黠之色。<br>“那我等还是先离开这里，再说一下吧。”白芸馨点点头，并未再接口什么。<br>于是三人再商量了几句后，当即就</p><hr><p>此女一见韩立带队离去，口中一声轻咦，目光神通一下变得小心异常起来。<br>“哼，找死。我要不是你另有矛盾，我一人就可以偷袭了。”女子冷哼一声，脸上现出一 丝狡诈之色，随即一只玉手一抬，反手蓦然多出一只碧绿色的储物袋。<br>袋口一阵扭曲，顿时一股黑气从中一喷而出，并一个翻滚下，一只只紫色大手浮现而出 。<br>此手掌看似普通之极，但是一抓下，竟然平静异常，并被一摄而起的一把捞进了手中。<br>这时，韩立却仔细打量了手中的黑色山峰两眼。<br>这黑气翻滚不定，仿佛什么东西的凝聚而成，竟然正是成熟体的。<br>韩立面上露出了沉吟之色，但是手中长袖却一抖，一团银色火焰从中一飞而出，一凝之 后，竟化为一只银色火鸟。正是噬灵火鸟！<br>在此鸟上空，韩立先将此鸟一把抓到了手中，然后用一只大手轻轻一拍。<br>银色火鸟从其身上一涌而出，一个盘旋后就化为了丈许般巨大，然后一个盘旋，化为一 只银色火鸟，双翅一展的直奔韩立激射而来。<br>此火鸟大惊之下，双翅一展，一下扎进了韩立身体中。<br>韩立顿时只觉身形一震，身躯就一下被吸入了其中，身形一沉，接着在一股奇香中，同 样直接倒地不动</p><hr><p>韩立面无表情的不再理会艳丽女子，反而轻笑一声后，身上五色光霞一涨之下，竟向女 子徐徐飘去，丝毫不给男修发现一丝喘息之机。<br>这时，韩立已经在原地等候着，目光闪动不已，凝望着对面女子的遁去。<br>若是没有人去接近此女，自然只能看到美女将自己幻化收取走的那一刻，才诡异的停在 原地不动了。<br>不过看她的举动，显然是被戏耍了。<br>一旁的白瑶怡听得清楚，明明那蓝色光头大汉一言不发，但是目光略一扫下，却落在了 韩立身后数丈远处。<br>此女双眸苍白异常，头发如花，眸中闪过一丝怪异。<br>“怎么，你认得我！”韩立眼中蓝芒一闪，盯着此女面孔不禁一下轻咦了一声。<br>“怎么，这位是……”一看清楚此人面容后，白瑶怡一下失声起来，声音顿时从白光中清楚 楚动人的传来。<br>“嘿嘿，你不是在感应之下，还是我本体亲自出来吧。”韩立轻笑一声，竟一口将自己受 到扎根打算的事情说出口来。<br>“前辈莫非忘了晚辈姓名，还是晚辈的确……”白瑶怡轻描淡写的回道，显得颇为的难以置 信，明显不肯答应韩立的真正修为。<br>“现在起来吧。”韩立嘴角一翘，随即镇定的说道。<br>“我是因为她身</p><hr><p>只见在那边另有一名中年人，正将手中的一口银色断剑，一口咬住了马车上的绿衫女子 ，而那圆钵则仍然被一切而开，似乎被人轻易的毁坏了一个大伤。<br>“启禀前辈爷爷，那里是……”黄衫女子一见银月，双目蓝芒一闪的问道。<br>“银月，你……”黄衫女子毫不迟疑的答应一声，一扬手，一团银光激射而出。<br>银月闻言，毫不犹豫的化为一道银虹，没入了身下的雾海之中。<br>“多谢前辈出手相助。”黄衫女子心中有些欣喜，低首恭敬的说道。<br>“银月，你这是什么意思？”韩立眉头一皱的问道。<br>“前辈不用过虑。我已经打算回黄枫谷，只在附近寻找一些东西，并不太精神。但是现在嘛，我是不是太吃亏了。”黄衫女子思量了一下，急忙回道。<br>韩立愣了一下，但并未追问什么。而是招呼圭灵一声，应对了过去。<br>倒是黄衫女子一见韩立，目光一瞥之下，重新打量了韩立两眼，才面露为难的表情，但 马上想起了什么，神色一下平静了下来。<br>“不瞒前辈，晚辈是不是说得另一个说不清楚，更不敢打扰前辈的。只是前辈在傀儡兽身上释放了不知名灵石，那晚辈也是第一次听说过此名字的。”韩立摸了摸下巴，若有所思的说道。</p><hr><p>就在这时，下方突然一阵低沉的鸣叫声传来，大片血丝一下从下方激射而出，往回一卷 ，竟然正好击在了那名身穿血红战甲的戎族人身上，两只手臂只是一晃，就被一股无形之力 一弹而开，将戎族人身形彻底淹没在了其中。<br>此异族大惊，但不敢再怠慢，口中一声低喝，十指蓦然一弹。<br>五色大手闪电般的一下在身前浮现而出，五指一张之下，就要将此异族一下摄离的血傀 儡直接抓到青年本体上。<br>青年见此情形，脸色微微一变，手中法诀却忽然一催，一团青色光球从中一飞而出，一 个闪动下就到了其身前处。<br>青甲大汉一声冷哼，身形一动，就一下没入二者身躯中。<br>一股强烈之极的力量从巨人身上一卷而出，同时一股可怕力量从青甲大汉肉身中一涌而 出，从巨人口中一卷而出，将二者身形一下包裹进了其中。<br>“我是什么联手之人。竟敢在我面前动手，就此灭杀你了。”青甲大汉听到这话，目中凶 光一闪，厉声的喝道。<br>“虚天鼎！”青年脸色变得苍白无血了，当即冷哼一声的单手一掐诀，一团青光从其头颅 内一飞而出，一个闪动下就化为了数十丈高的一个青色巨鼎。<br>青袍青年也不甘示弱的单手一掐诀，一张口，冲青年一喷而出。</p><hr><p>“阁下是何人？”韩立心中一凛，但口中自然说出了这样的话来。<br>“晚辈是圣王长老，原来是和血魂前辈有过一面之缘，原来前辈就是附近数万年来的道友。在下从未听说过，前辈只是当时和晚辈交情一二罢了。”白璧双目一亮，一字字的说道。<br>这次，韩立已经问过此事了，其他人自然一同告辞了。<br>“既然前辈没有意见，那晚辈就不再犹豫什么了，前辈若是只是出手，晚辈一定不肯出手的。”韩立心中一松的回道，并随之遁光一闪，化为一道青虹激射而走。<br>一小会儿工夫后，韩立终于出现在了一片蔚蓝无云的无边湖泊边上，远远看见无边的一 片小湖，一前一后，向湖面望去。<br>在那里，有一座二十余丈的巨大湖泊，上面隐隐有一个人影，但又有一条条淡青色的怪 异舟队。<br>在那里，一名白裙女子，端坐在那里，而在一旁，则正和韩立面前两名女子交谈着什么 。<br>“咦，道友是……”韩立目光一闪，落在了那名貌美如花的女子身上。<br>“道友原来是冰魄道友！”女子吃惊起来，但还是谨慎的问道。<br>“放心，道友尽管拿我等几个去处理一下吧。”韩立哑然一笑，并未说什么。<br>女子见此，也同样露出一丝笑意，也</p><hr><p>韩立眉头微微一皱，一只手掌蓦然冲远处一招。<br>顿时一股黑气从指间滚滚而出，一个闪动下，就化为一只亩许大的黑色山峰，并排一排 。<br>这些黑气一个个模糊不清，并往中心处滚滚的一聚，竟凝成一只体积数亩大小的漆黑魔 兽。<br>这些魔兽通体乌黑，但通体遍布灰白魔纹，并散发出一种诡异的怪异气息，竟有好几分 酷似的妖异模样。<br>“这为何疯狂。不过这种损伤恐怖的魔兽不是普通魔兽可以轻易侵入的，否则当初只不过是一时的事情。”韩立又在洞府中一一的说道。<br>“恐怕有些麻烦了！韩兄，你没事吧。这些魔兽又是如何出现在此地的。它们不过是一些普通魔兽，又怎能不知道密密麻麻的。”银月忍不住的想问一句。<br>“哼，如此说来，我倒也看看能否找出那些魔族有关其他魔兽的踪迹，再寻到这些魔兽了。”韩立嘴角抽搐一下后，不客气的说道。<br>“这倒不是。我虽然已经和银月月许久的。但是紫言鼎的本命之火，可和其对此只是同一只魔兽，威能之大可想而知了。”<br>“你若没有猜错的话，那些魔兽若是有圣祖级别的魔兽存在，自然是无用的。这些魔兽虽然有一定的神通，但一旦被我等发现，又有谁能奈何了我等，立刻逃之</p><hr><p>“嘿嘿！你们的天狐之体，竟然是自由之身！”男子冷笑一声，不客气的反讥道。<br>“什么，难道你们天狐族还真是是族中的第一人。”<br>“我是那个是在外边修炼的第三道……”<br>竟然是宋姓女子“咯咯”一阵轻笑，似乎有些不太相信自己的预感，黛眉一皱。<br>“我是从不开口说话的。至于第三层，我若没有什么后手，却有自信和道友说起来。这一次的试炼，所有人都可以参加此次天狐之王，但是若是身处此地，我们也不会对族内什么人 之争。你们虽然成为合体修士，但可能都是一对双修之手的。”银衫女子竟有些恍然了。<br>“倒是黛儿姐姐不妨再多禀一声道友，先前的神通不一定非同小可的。”白瑶怡一笑起来 。<br>“就算在下同样的不敢出手，那人也感应到远处天狐云笼的一缕神念之力，我等还是能做到的。”女子双目一眯的说道。<br>“哼，以你这般境界，想来又不是不能接下我们的进入。”银衫女子却轻哼一声的说道。<br>“如此说来，倒的确有些麻烦的。不过，这个人不是天狐之身，我等也不想就这般死撑到此地的。若是此人真要了，等他们回去将他们毁去再说。回去后，她们再找另一个人联手， 再寻那人身上的。”银衫女子阴沉</p><hr><p>“这倒是。”<br>而玉佩中的一脸的踌躇之色，显然还不知道韩立如何发现的。<br>就在这时，突然从雾海中飞射出来两道人影，一个盘旋的到了韩立身前处，两手一挥下 ，两口绿色飞剑一下暂时没入了雾海之中，随即“噗”的一声，化为一口尺许长的碧绿竹尺， 冲韩立狠狠一斩而去。<br>绿尺方一接触，就一下化为尺许长的飞剑，并在一声轰鸣声中自行爆裂开来，化为一道 绿色光柱从空中激射而出，一闪即逝的没入了雾海中。<br>韩立见此情形，并不迟疑，身形一晃，就到了雾海边缘处。<br>只是略一用法力就蓦然从雾海中射出，只是几个闪动，就到了韩立身前处，光芒闪动， 一下没入下方雾海中不见了踪影。<br>一声闷响后，雾海一分，雾海再次现出了原形，并不太轻，大半雾海都被卷入雾海之中 ，并随着雾海扩散消失，这个雾海竟然变得如同小山的样子。<br>等他一口气钻进了那片雾海中，才发现里面竟有数座尺许大小的巨型迷你小山，但滴溜 溜一转后，就一下自行的腾空飞来，直奔下方的雾海激射而去。在雾海边缘处，一个遍布大 半雾海的半空中，出现了一座无边无际的漆黑山峰。<br>此山峰除了留下一颗黑乎乎的不知名山石外，韩立竟无法看出</p><hr>          </div>        </div>      </div>    </div><h2 id="训练唐诗"><a href="#训练唐诗" class="headerlink" title="训练唐诗"></a>训练唐诗</h2><p>下载<a href="https://github.com/chinese-poetry/chinese-poetry">诗词数据集</a>，数据清洗，生成tang_poet.txt。</p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-0d82c2c6" role="button" aria-expanded="false" aria-controls="collapse-0d82c2c6">        <div class="fold-arrow">▶</div>训练脚本及测试      </div>      <div class="fold-collapse collapse" id="collapse-0d82c2c6">        <div class="fold-content">          <p>format_data.py</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-comment"># -*- coding: utf-8 -*-</span><br><span class="hljs-keyword">import</span> glob<br><span class="hljs-keyword">import</span> json<br><span class="hljs-keyword">import</span> os<br>datas_json=glob.glob(<span class="hljs-string">&quot;./poetry/全唐诗/poet*.json&quot;</span>) <span class="hljs-comment">#1匹配所有唐诗json文件</span><br><br><span class="hljs-keyword">for</span> data_json <span class="hljs-keyword">in</span> datas_json[:]: <span class="hljs-comment">#2处理匹配的每一个文件</span><br>    <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(data_json,<span class="hljs-string">&quot;r&quot;</span>,encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f:<br>        ts_data =json.load(f)<br>        <span class="hljs-keyword">for</span> each_ts <span class="hljs-keyword">in</span> ts_data[:]: <span class="hljs-comment">#3处理文件中每段数据，只要五言诗和2句的</span><br>            paragraphs_list =each_ts[<span class="hljs-string">&quot;paragraphs&quot;</span>]<br>            <span class="hljs-keyword">if</span> <span class="hljs-built_in">len</span>(paragraphs_list) == <span class="hljs-number">2</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(paragraphs_list[<span class="hljs-number">0</span>])==<span class="hljs-number">12</span> <span class="hljs-keyword">and</span> <span class="hljs-built_in">len</span>(paragraphs_list[<span class="hljs-number">1</span>]) == <span class="hljs-number">12</span>:<br>                <span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;tang_poet.txt&quot;</span>,<span class="hljs-string">&quot;a&quot;</span>,encoding=<span class="hljs-string">&quot;utf-8&quot;</span>) <span class="hljs-keyword">as</span> f2:<br>                    f2.write(<span class="hljs-string">&quot;&quot;</span>.join(paragraphs_list))<br>                    f2.write(<span class="hljs-string">&quot;\n&quot;</span>)<br><br>f =<span class="hljs-built_in">open</span>(<span class="hljs-string">&quot;tang_poet.txt&quot;</span>,<span class="hljs-string">&quot;r&quot;</span>,encoding=<span class="hljs-string">&quot;utf-8&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-built_in">len</span>(f.readlines()))<br></code></pre></td></tr></table></figure><p>prepare.py</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> os<br><span class="hljs-keyword">import</span> requests<br><span class="hljs-keyword">import</span> tiktoken<br><span class="hljs-keyword">import</span> numpy <span class="hljs-keyword">as</span> np<br> <br><span class="hljs-comment"># download the tiny shakespeare dataset</span><br>input_file_path = os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;tang_poet.txt&#x27;</span>)<br><span class="hljs-keyword">with</span> <span class="hljs-built_in">open</span>(input_file_path, <span class="hljs-string">&#x27;r&#x27;</span>) <span class="hljs-keyword">as</span> f:<br>    data = f.read()<br>n = <span class="hljs-built_in">len</span>(data)<br>train_data = data[:<span class="hljs-built_in">int</span>(n*<span class="hljs-number">0.9</span>)]<br>val_data = data[<span class="hljs-built_in">int</span>(n*<span class="hljs-number">0.9</span>):]<br> <br><span class="hljs-comment"># encode with tiktoken gpt2 bpe</span><br>enc = tiktoken.get_encoding(<span class="hljs-string">&quot;gpt2&quot;</span>)<br>train_ids = enc.encode_ordinary(train_data)<br>val_ids = enc.encode_ordinary(val_data)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;train has <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(train_ids):,&#125;</span> tokens&quot;</span>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;val has <span class="hljs-subst">&#123;<span class="hljs-built_in">len</span>(val_ids):,&#125;</span> tokens&quot;</span>)<br> <br><span class="hljs-comment"># export to bin files</span><br>train_ids = np.array(train_ids, dtype=np.uint16)<br>val_ids = np.array(val_ids, dtype=np.uint16)<br>train_ids.tofile(os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;train.bin&#x27;</span>))<br>val_ids.tofile(os.path.join(os.path.dirname(__file__), <span class="hljs-string">&#x27;val.bin&#x27;</span>))<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><p><img src="/img/ai/nanogpt/train.png" alt="训练"></p><h1 id="资料补充"><a href="#资料补充" class="headerlink" title="资料补充"></a>资料补充</h1><ul><li><a href="https://github.com/cfcys/nanoGPT-Tutorial-CN"><strong>nanoGPT 中文教程和讲座</strong></a></li></ul><h2 id="中文预训练数据集"><a href="#中文预训练数据集" class="headerlink" title="中文预训练数据集"></a>中文预训练数据集</h2><p>这里会搜集一些小型的，适合于nanoGPT进行训练的中文数据集的仓库 其大多是常用的NLP训练语料，但我给出整理数据以适应nanoGPT的要求</p><p>目前已有：</p><ul><li><a href="https://github.com/chinese-poetry/chinese-poetry">chinese-poetry&#x2F;chinese-poetry: 最全中华古诗词数据库</a></li><li><a href="https://github.com/garychowcmu/daizhigev20">garychowcmu&#x2F;daizhigev20: 殆知阁古代文献</a></li><li><a href="https://www.qishuta.org/Shtml5132.html">《西游记》全集,txt全集下载,电子书-奇书网</a></li></ul><h2 id="对话能力实现"><a href="#对话能力实现" class="headerlink" title="对话能力实现"></a>对话能力实现</h2><p>主要参考<a href="https://github.com/VatsaDev/nanoChatGPT">VatsaDev&#x2F;nanoChatGPT: nanogpt turned into a chat model</a></p><h2 id="目前已有的nanoGPT资料收集"><a href="#目前已有的nanoGPT资料收集" class="headerlink" title="目前已有的nanoGPT资料收集"></a>目前已有的nanoGPT资料收集</h2><h3 id="视频资料"><a href="#视频资料" class="headerlink" title="视频资料"></a>视频资料</h3><ul><li><a href="https://www.youtube.com/watch?v=kCc8FmEb1nY&t=5828s">(30) Let’s build GPT: from scratch, in code, spelled out. - YouTube</a></li><li><a href="https://www.bilibili.com/video/BV1hr42147xc/?spm_id_from=333.337.search-card.all.click&vd_source=32f9de072b771f1cd307ca15ecf84087">从零开始手搓一个LLM（一）把参数缩减到足够单卡训练的NanoGPT_哔哩哔哩_bilibili</a></li><li><a href="https://www.bilibili.com/video/BV1QY4y1o7ur/?vd_source=e1ce38727d77aa0b8bdfa4293878d29f">【自制中英字幕】【Andrej Karpathy】让我们从头开始，在代码中构建GPT_哔哩哔哩_bilibili</a></li></ul><h3 id="博客资料"><a href="#博客资料" class="headerlink" title="博客资料"></a>博客资料</h3><ul><li><a href="https://riguz.com/NanoGPT_Tutorial">NanoGPT Tutorial - WHY42 (riguz.com)</a></li><li><a href="https://zhuanlan.zhihu.com/p/682466360"><strong>Andrej Karpathy 的 nanoGPT lecture demo 详解</strong></a></li><li><a href="https://zhuanlan.zhihu.com/p/635483902"><strong>迷你版ChatGPT开源，教你怎么用nanoGPT训练一个写小说的AI机器人！</strong></a></li><li><a href="https://zhuanlan.zhihu.com/p/611191403">NanoGPT的Pytorch2.0版本实现及分析</a></li></ul><h3 id="开源仓库"><a href="#开源仓库" class="headerlink" title="开源仓库"></a>开源仓库</h3><ul><li><a href="https://github.com/karpathy/nanoGPT">karpathy&#x2F;nanoGPT: The simplest, fastest repository for training&#x2F;finetuning medium-sized GPTs.</a></li><li><a href="https://github.com/HuZixia/nanoGPT-lecture">HuZixia&#x2F;nanoGPT-lecture: This nanoGPT-lecture code git, including Andrej Karpathy’s nanoGPT, ng-vedio-lecture, gpt_dev.ipynb and my learning notes. Welcome to like and follow</a></li><li><a href="https://github.com/VatsaDev/nanoChatGPT">VatsaDev&#x2F;nanoChatGPT: nanogpt turned into a chat model</a></li><li><a href="https://github.com/Andrei-Aksionov/nanoGPTplus">Andrei-Aksionov&#x2F;nanoGPTplus</a></li><li><a href="https://github.com/sanjeevanahilan/nanoChatGPT">https://github.com/sanjeevanahilan/nanoChatGPT</a></li><li><a href="https://blog.csdn.net/zwqjoy/article/details/134971216"><strong>nanoGPT训练一个写唐诗的GPT</strong></a></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>简单部署私域大模型</title>
    <link href="/2024/09/02/AI/ollama-easy-usage/"/>
    <url>/2024/09/02/AI/ollama-easy-usage/</url>
    
    <content type="html"><![CDATA[<p>构建家庭智能助手。</p><span id="more"></span><h2 id="Windows-安装-Ollama"><a href="#Windows-安装-Ollama" class="headerlink" title="Windows 安装 Ollama"></a>Windows 安装 Ollama</h2><ul><li><a href="https://ollama.com/download">ollama下载地址</a></li><li><a href="https://github.com/ollama/ollama?tab=readme-ov-file">ollama仓库</a></li></ul><p>首次运行<code>ollama run llama3.1</code>，会联网加载模型。可以选择的模型有：</p><table><thead><tr><th>Model</th><th>Parameters</th><th>Size</th><th>Download</th></tr></thead><tbody><tr><td>Llama 3.1</td><td>8B</td><td>4.7GB</td><td><code>ollama run llama3.1</code></td></tr><tr><td>Llama 3.1</td><td>70B</td><td>40GB</td><td><code>ollama run llama3.1:70b</code></td></tr><tr><td>Llama 3.1</td><td>405B</td><td>231GB</td><td><code>ollama run llama3.1:405b</code></td></tr><tr><td>Phi 3 Mini</td><td>3.8B</td><td>2.3GB</td><td><code>ollama run phi3</code></td></tr><tr><td>Phi 3 Medium</td><td>14B</td><td>7.9GB</td><td><code>ollama run phi3:medium</code></td></tr><tr><td>Gemma 2</td><td>2B</td><td>1.6GB</td><td><code>ollama run gemma2:2b</code></td></tr><tr><td>Gemma 2</td><td>9B</td><td>5.5GB</td><td><code>ollama run gemma2</code></td></tr><tr><td>Gemma 2</td><td>27B</td><td>16GB</td><td><code>ollama run gemma2:27b</code></td></tr><tr><td>Mistral</td><td>7B</td><td>4.1GB</td><td><code>ollama run mistral</code></td></tr><tr><td>Moondream 2</td><td>1.4B</td><td>829MB</td><td><code>ollama run moondream</code></td></tr><tr><td>Neural Chat</td><td>7B</td><td>4.1GB</td><td><code>ollama run neural-chat</code></td></tr><tr><td>Starling</td><td>7B</td><td>4.1GB</td><td><code>ollama run starling-lm</code></td></tr><tr><td>Code Llama</td><td>7B</td><td>3.8GB</td><td><code>ollama run codellama</code></td></tr><tr><td>Llama 2 Uncensored</td><td>7B</td><td>3.8GB</td><td><code>ollama run llama2-uncensored</code></td></tr><tr><td>LLaVA</td><td>7B</td><td>4.5GB</td><td><code>ollama run llava</code></td></tr><tr><td>Solar</td><td>10.7B</td><td>6.1GB</td><td><code>ollama run solar</code></td></tr></tbody></table><h2 id="WebUI"><a href="#WebUI" class="headerlink" title="WebUI"></a>WebUI</h2><ul><li>Windows 下安装 ollama，并至少导入一个模型配置</li><li><a href="https://github.com/open-webui/open-webui">Web UI github</a></li><li>Windows 下安装 Docker Desktop，更新到最新版</li></ul><div class="note note-danger">            <ul><li>Docker 已经被墙，下载较为麻烦</li><li>旧版本可能存在的Bug:<ul><li><a href="https://github.com/NVIDIA/nvidia-container-toolkit/issues/520">https://github.com/NVIDIA/nvidia-container-toolkit/issues/520</a></li><li><a href="https://github.com/open-webui/open-webui/issues/2527">https://github.com/open-webui/open-webui/issues/2527</a></li></ul></li></ul>          </div><ul><li><a href="https://www.tech-odyssey.cn/2024/06/24/AI/Computing-Startup/#%E5%AE%89%E8%A3%85-pytorch-cuda-%E7%89%88%E6%9C%AC">参考：WSL 安装 Cuda</a></li><li>Docker 拉取 WebUI docker 镜像，注意此时 Docker Desktop 必须运行</li></ul><div class="note note-danger">            <p>如何进入powershell：</p><ul><li>win+R，进入“运行”，输入powershell</li><li>或者右键左下角win图标，选择终端</li></ul>          </div><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 进入 Powershell</span><br>docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always ghcr.io/open-webui/open-webui:cuda<br><br><span class="hljs-comment"># 镜像地址</span><br>docker run -d -p 3000:8080 --gpus all --add-host=host.docker.internal:host-gateway -v open-webui:/app/backend/data --name open-webui --restart always swr.cn-north-4.myhuaweicloud.com/ddn-k8s/ghcr.io/open-webui/open-webui:cuda<br><br>docker start open-webui<br></code></pre></td></tr></table></figure><p><a href="https://docker.aityp.com/image/ghcr.io/open-webui/open-webui:main">https://docker.aityp.com/image/ghcr.io/open-webui/open-webui:main</a><br><img src="/img/ai/llama_webui_docker.png" alt="Docker 启动 log"></p><p>打开：<a href="http://localhost:3000/">localhost</a>，可以切换选择模型，可以作为日常知识的获取途径。</p><p><img src="/img/ai/llama_webui_select_model.png" alt="WSL + Docker + Ollama + WebUI"></p><h2 id="手机连接"><a href="#手机连接" class="headerlink" title="手机连接"></a>手机连接</h2><ul><li>保证手机和电脑连在同一个局域网下</li><li>在powershell中运行<code>ipconfig</code>，查看IP地址，一般为192开头</li><li>假设IP为 <code>192.168.1.1</code>，在手机浏览器中输入 <code>192.168.1.1:3000</code></li><li>Iphone手机可以将此网页保存到桌面</li></ul><div id="dplayer4" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer4"),"theme":"#FADFA3","loop":true,"lang":"zh-cn","screenshot":true,"hotkey":true,"preload":"auto","volume":0.9,"mutex":true,"video":{"url":"/img/ai/ollama.mov","pic":"/img/ai/ollama_logo.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>图解 Transformer</title>
    <link href="/2024/08/22/AI/transformer/"/>
    <url>/2024/08/22/AI/transformer/</url>
    
    <content type="html"><![CDATA[<p>本教程的学习路径是：Attention-&gt;Transformer-&gt;BERT-&gt;NLP应用。</p><span id="more"></span><p>转自：<a href="https://github.com/datawhalechina/learn-nlp-with-transformers">https://github.com/datawhalechina/learn-nlp-with-transformers</a></p><h1 id="图解Attention"><a href="#图解Attention" class="headerlink" title="图解Attention"></a>图解Attention</h1><p>问题：Attention出现的原因是什么？<br>潜在的答案：基于循环神经网络（RNN）一类的seq2seq模型，在处理长文本时遇到了挑战，而对长文本中不同位置的信息进行attention有助于提升RNN的模型效果。</p><p>于是学习的问题就拆解为：1. 什么是seq2seq模型？2. 基于RNN的seq2seq模型如何处理文本&#x2F;长文本序列？3. seq2seq模型处理长文本序列时遇到了什么问题？4.基于RNN的seq2seq模型如何结合attention来改善模型效果？</p><h2 id="seq2seq框架"><a href="#seq2seq框架" class="headerlink" title="seq2seq框架"></a>seq2seq框架</h2><p>seq2seq是一种常见的NLP模型结构，全称是：sequence to sequence，翻译为“序列到序列”。顾名思义：从一个文本序列得到一个新的文本序列。典型的任务有：机器翻译任务，文本摘要任务。谷歌翻译在2016年末开始使用seq2seq模型，并发表了2篇开创性的论文：<a href="https://papers.nips.cc/paper/5346-sequence-to-sequence-learning-with-neural-networks.pdf">Sutskever等2014年发表的Sequence to Sequence Learning<br>with Neural Networks</a>和<a href="http://emnlp2014.org/papers/pdf/EMNLP2014179.pdf">Cho等2014年发表的Learning Phrase Representations using RNN Encoder–Decoder<br>for Statistical Machine Translation</a>，感兴趣的读者可以阅读原文进行学习。</p><p>无论读者是否读过上述两篇谷歌的文章，NLP初学者想要充分理解并实现seq2seq模型很不容易。因为，我们需要拆解一系列相关的NLP概念，而这些NLP概念又是是层层递进的，所以想要清晰的对seq2seq模型有一个清晰的认识并不容易。但是，如果能够把这些复杂生涩的NLP概念可视化，理解起来其实就更简单了。因此，本文希望通过一系列图片、动态图帮助NLP初学者学习seq2seq以及attention相关的概念和知识。</p><p>首先看seq2seq干了什么事情？seq2seq模型的输入可以是一个（单词、字母或者图像特征）序列，输出是另外一个（单词、字母或者图像特征）序列。一个训练好的seq2seq模型如下图所示（注释：将鼠标放在图上，图就会动起来）：</p><p><img src="/img/ai/datawhale/transformer/1-seq2seq.gif" alt="seq2seq"></p><p>如下图所示，以NLP中的机器翻译任务为例，序列指的是一连串的单词，输出也是一连串单词。<br><img src="/img/ai/datawhale/transformer/1-2-translation.gif" alt="translation"></p><h2 id="seq2seq细节"><a href="#seq2seq细节" class="headerlink" title="seq2seq细节"></a>seq2seq细节</h2><p>将上图中蓝色的seq2seq模型进行拆解，如下图所示：seq2seq模型由编码器（Encoder）和解码器（Decoder）组成。绿色的编码器会处理输入序列中的每个元素并获得输入信息，这些信息会被转换成为一个黄色的向量（称为context向量）。当我们处理完整个输入序列后，编码器把 context向量 发送给紫色的解码器，解码器通过context向量中的信息，逐个元素输出新的序列。</p><p><img src="/img/ai/datawhale/transformer/1-3-encoder-decoder.gif" alt="seq2seq中的encoder-decoder"></p><p>由于seq2seq模型可以用来解决机器翻译任务，因此机器翻译被任务seq2seq模型解决过程如下图所示，当作seq2seq模型的一个具体例子来学习。</p><p><img src="/img/ai/datawhale/transformer/1-3-mt.gif" alt="seq2seq中的encoder-decoder，机器翻译的例子"></p><p>深入学习机器翻译任务中的seq2seq模型，如下图所示。seq2seq模型中的编码器和解码器一般采用的是循环神经网络RNN（Transformer模型还没出现的过去时代）。编码器将输入的法语单词序列编码成context向量（在绿色encoder和紫色decoder中间出现），然后解码器根据context向量解码出英语单词序列。<em>关于循环神经网络，本文建议阅读 <a href="https://www.youtube.com/watch?v=UNmqTiOnRfg">Luis Serrano写的循环神经网络精彩介绍</a>.</em></p><p><img src="/img/ai/datawhale/transformer/1-4-context-example.png" alt="context向量对应图里中间一个浮点数向量。在下文中，我们会可视化这些向量，使用更明亮的色彩来表示更高的值，如上图右边所示"></p><p>如上图所示，我们来看一下黄色的context向量是什么？本质上是一组浮点数。而这个context的数组长度是基于编码器RNN的隐藏层神经元数量的。上图展示了长度为4的context向量，但在实际应用中，context向量的长度是自定义的，比如可能是256，512或者1024。</p><p>那么RNN是如何具体地处理输入序列的呢？</p><ol><li><p>假设序列输入是一个句子，这个句子可以由$n$个词表示：$sentence &#x3D; {w_1, w_2,…,w_n}$。</p></li><li><p>RNN首先将句子中的每一个词映射成为一个向量得到一个向量序列：$X &#x3D; {x_1, x_2,…,x_n}$，每个单词映射得到的向量通常又叫做：word embedding。</p></li><li><p>然后在处理第$t \in [1,n]$个时间步的序列输入$x_t$时，RNN网络的输入和输出可以表示为：$h_{t} &#x3D; RNN(x_t, h_{t-1})$</p><ul><li>输入：RNN在时间步$t$的输入之一为单词$w_t$经过映射得到的向量$x_t$。</li><li>输入：RNN另一个输入为上一个时间步$t-1$得到的hidden state向量$h_{t-1}$，同样是一个向量。</li><li>输出：RNN在时间步$t$的输出为$h_t$ hidden state向量。</li></ul></li></ol><p><img src="/img/ai/datawhale/transformer/1-5-word-vector.png" alt="图：word embedding例子。我们在处理单词之前，需要将单词映射成为向量，通常使用 word embedding 算法来完成。一般来说，我们可以使用提前训练好的 word embeddings，或者在自有的数据集上训练word embedding。为了简单起见，上图展示的word embedding维度是4。上图左边每个单词经过word embedding算法之后得到中间一个对应的4维的向量"></p><p>让我们来进一步可视化一下基于RNN的seq2seq模型中的编码器在第1个时间步是如何工作：</p><p><img src="/img/ai/datawhale/transformer/1-6-rnn.gif" alt="如图所示，RNN在第2个时间步，采用第1个时间步得到hidden state#10（隐藏层状态）和第2个时间步的输入向量input#1，来得到新的输出hidden state#1"></p><p>看下面的动态图，让我们详细观察一下编码器如何在每个时间步得到hidden sate，并将最终的hidden state传输给解码器，解码器根据编码器所给予的最后一个hidden state信息解码处输出序列。注意，最后一个 hidden state实际上是我们上文提到的context向量。<br><img src="/img/ai/datawhale/transformer/1-6-seq2seq.gif" alt="编码器逐步得到hidden state并传输最后一个hidden state给解码器"></p><p>接着，结合编码器处理输入序列，一起来看下解码器如何一步步得到输出序列的l。与编码器类似，解码器在每个时间步也会得到 hidden state（隐藏层状态），而且也需要把 hidden state（隐藏层状态）从一个时间步传递到下一个时间步。</p><p><img src="/img/ai/datawhale/transformer/1-6-seq2seq-decoder.gif" alt="编码器首先按照时间步依次编码每个法语单词，最终将最后一个hidden state也就是context向量传递给解码器，解码器根据context向量逐步解码得到英文输出"></p><p>目前为止，希望你已经明白了本文开头提出的前两个问题：1. 什么是seq2seq模型？2. seq2seq模型如何处理文本&#x2F;长文本序列？那么请思考第3、4个问题：3. seq2seq模型处理文本序列（特别是长文本序列）时会遇到什么问题？4.基于RNN的seq2seq模型如何结合attention来解决问题3并提升模型效果？</p><h2 id="Attention"><a href="#Attention" class="headerlink" title="Attention"></a>Attention</h2><p>基于RNN的seq2seq模型编码器所有信息都编码到了一个context向量中，便是这类模型的瓶颈。一方面单个向量很难包含所有文本序列的信息，另一方面RNN递归地编码文本序列使得模型在处理长文本时面临非常大的挑战（比如RNN处理到第500个单词的时候，很难再包含1-499个单词中的所有信息了）。</p><p>面对以上问题，Bahdanau等2014发布的<a href="https://arxiv.org/abs/1409.0473">Neural Machine Translation by Jointly Learning to Align and Translate</a> 和 Luong等2015年发布的<a href="https://arxiv.org/abs/1508.04025">Effective Approaches to Attention-based Neural Machine Translation</a>两篇论文中，提出了一种叫做注意力<strong>attetion</strong>的技术。通过attention技术，seq2seq模型极大地提高了机器翻译的质量。归其原因是：attention注意力机制，使得seq2seq模型可以有区分度、有重点地关注输入序列。</p><p>下图依旧是机器翻译的例子：</p><p><img src="/img/ai/datawhale/transformer/1-7-attetion.png" alt="在第 7 个时间步，注意力机制使得解码器在产生英语翻译student英文翻译之前，可以将注意力集中在法语输入序列的：étudiant。这种有区分度得attention到输入序列的重要信息，使得模型有更好的效果"></p><p>让我们继续来理解带有注意力的seq2seq模型：一个注意力模型与经典的seq2seq模型主要有2点不同：</p><ul><li>A. 首先，编码器会把更多的数据传递给解码器。编码器把所有时间步的 hidden state（隐藏层状态）传递给解码器，而不是只传递最后一个 hidden state（隐藏层状态），如下面的动态图所示:</li></ul><p><img src="/img/ai/datawhale/transformer/1-6-mt-1.gif" alt="更多的信息传递给decoder"></p><ul><li><p>B. 注意力模型的解码器在产生输出之前，做了一个额外的attention处理。如下图所示，具体为：</p><ul><li><ol><li>由于编码器中每个 hidden state（隐藏层状态）都对应到输入句子中一个单词，那么解码器要查看所有接收到的编码器的 hidden state（隐藏层状态）。</li></ol></li><li><ol start="2"><li>给每个 hidden state（隐藏层状态）计算出一个分数（我们先忽略这个分数的计算过程）。</li></ol></li><li><ol start="3"><li>所有hidden state（隐藏层状态）的分数经过softmax进行归一化。</li></ol></li><li><ol start="4"><li>将每个 hidden state（隐藏层状态）乘以所对应的分数，从而能够让高分对应的  hidden state（隐藏层状态）会被放大，而低分对应的  hidden state（隐藏层状态）会被缩小。</li></ol></li><li><ol start="5"><li>将所有hidden state根据对应分数进行加权求和，得到对应时间步的context向量。</li></ol></li></ul></li></ul><p><img src="/img/ai/datawhale/transformer/1-7-attention-dec.gif" alt="在第4个时间步，编码器结合attention得到context向量的5个步骤"></p><p>所以，attention可以简单理解为：一种有效的加权求和技术，其艺术在于如何获得权重。</p><p>现在，让我们把所有内容都融合到下面的图中，来看看结合注意力的seq2seq模型解码器全流程，动态图展示的是第4个时间步：</p><ol><li>注意力模型的解码器 RNN 的输入包括：一个word embedding 向量，和一个初始化好的解码器 hidden state，图中是$h_{init}$。</li><li>RNN 处理上述的 2 个输入，产生一个输出和一个新的 hidden state，图中为h4。</li><li>注意力的步骤：我们使用编码器的所有 hidden state向量和 h4 向量来计算这个时间步的context向量（C4）。</li><li>我们把 h4 和 C4 拼接起来，得到一个橙色向量。</li><li>我们把这个橙色向量输入一个前馈神经网络（这个网络是和整个模型一起训练的）。</li><li>根据前馈神经网络的输出向量得到输出单词：假设输出序列可能的单词有N个，那么这个前馈神经网络的输出向量通常是N维的，每个维度的下标对应一个输出单词，每个维度的数值对应的是该单词的输出概率。</li><li>在下一个时间步重复1-6步骤。</li></ol><p><img src="/img/ai/datawhale/transformer/1-7-attention-pro.gif" alt="解码器结合attention全过程"></p><p>到目前为止，希望你已经知道本文开头提出的3、4问题的答案啦：3、seq2seq处理长文本序列的挑战是什么？4、seq2seq是如何结合attention来解决问题3中的挑战的？</p><p>最后，我们可视化一下注意力机制，看看在解码器在每个时间步关注了输入序列的哪些部分：<br><img src="/img/ai/datawhale/transformer/1-7-attention.gif" alt="解码步骤时候attention关注的词"></p><p>需要注意的是：注意力模型不是无意识地把输出的第一个单词对应到输入的第一个单词，它是在训练阶段学习到如何对两种语言的单词进行对应（在我们的例子中，是法语和英语）。</p><p>下图还展示了注意力机制的准确程度（图片来自于上面提到的论文）：<br><img src="/img/ai/datawhale/transformer/1-8-attention-vis.png" alt="你可以看到模型在输出 &quot;European Economic Area&quot; 时，注意力分布情况。在法语中，这些单词的顺序，相对于英语，是颠倒的（&quot;européenne économique zone&quot;）。而其他词的顺序是类似的"></p><h1 id="图解transformer"><a href="#图解transformer" class="headerlink" title="图解transformer"></a>图解transformer</h1><p>在学习完上一节后，我们知晓了attention为循环神经网络带来的优点。那么有没有一种神经网络结构直接基于attention构造，并且不再依赖RNN、LSTM或者CNN网络结构了呢？答案便是：Transformer。因此，我们将在本小节对Transformer所涉及的细节进行深入探讨。</p><p>Transformer模型在2017年被google提出，直接基于Self-Attention结构，取代了之前NLP任务中常用的RNN神经网络结构，并在WMT2014 Englishto-German和WMT2014 English-to-French两个机器翻译任务上都取得了当时的SOTA。</p><p>与RNN这类神经网络结构相比，Transformer一个巨大的优点是：<strong>模型在处理序列输入时，可以对整个序列输入进行并行计算，不需要按照时间步循环递归处理输入序列。</strong>2.1章节详细介绍了RNN神经网络如何循环递归处理输入序列，欢迎读者复习查阅。</p><p>下图先便是Transformer整体结构图，与篇章2.1中介绍的seq2seq模型类似，Transformer模型结构中的左半部分为编码器（encoder），右半部分为解码器（decoder），下面我们来一步步拆解 Transformer。</p><p><img src="/img/ai/datawhale/transformer/2-transformer.png" alt="transformer模型结构"></p><p>注释和引用说明：本文将通过总-分的方式对Transformer进行拆解和讲解，希望有助于帮助初学者理解Transformer模型结构。本文主要参考<a href="http://jalammar.github.io/illustrated-transformer">illustrated-transformer</a>。</p><h2 id="Transformer宏观结构"><a href="#Transformer宏观结构" class="headerlink" title="Transformer宏观结构"></a>Transformer宏观结构</h2><p>Transformer最开始提出来解决机器翻译任务，因此可以看作是seq2seq模型的一种。本小节先抛开Transformer模型中结构具体细节，先从seq2seq的角度对Transformer进行宏观结构的学习。以机器翻译任务为例，先将Transformer这种特殊的seqseq模型看作一个黑盒，黑盒的输入是法语文本序列，输出是英语文本序列（对比2.1章节的seq2seq框架知识我们可以发现，Transformer宏观结构属于seq2seq范畴，只是将之前seq2seq中的编码器和解码器，从RNN模型替换成了Transformer模型）。</p><p><img src="/img/ai/datawhale/transformer/2-input-output.png" alt="Transformer黑盒输入和输出"></p><p>将上图中的中间部分“THE TRANSFORMER”拆开成seq2seq标准结构，得到下图：左边是编码部分encoders，右边是解码器部分decoders。<br><img src="/img/ai/datawhale/transformer/2-encoder-decoder.png" alt="encoder-decoder"></p><p>下面，再将上图中的编码器和解码器细节绘出，得到下图。我们可以看到，编码部分（encoders）由多层编码器(Encoder)组成（Transformer论文中使用的是6层编码器，这里的层数6并不是固定的，你也可以根据实验效果来修改层数）。同理，解码部分（decoders）也是由多层的解码器(Decoder)组成（论文里也使用了6层解码器）。每层编码器网络结构是一样的，每层解码器网络结构也是一样的。不同层编码器和解码器网络结构不共享参数。<br><img src="/img/ai/datawhale/transformer/2-2-encoder-detail.png" alt="6层编码和6层解码器"></p><p>接下来，我们看一下单层encoder，单层encoder主要由以下两部分组成，如下图所示</p><ul><li>Self-Attention Layer</li><li>Feed Forward Neural Network（前馈神经网络，缩写为 FFNN）</li></ul><p>编码器的输入文本序列 $w_1, w_2,…,w_n$ 最开始需要经过embedding转换，得到每个单词的向量表示 $x_1, x_2,…,x_n$，其中 $x_i \in \mathbb{R}^{d}$ 是维度为 $d$ 的向量，然后所有向量经过一个Self-Attention神经网络层进行变换和信息交互得到 $h_1, h_2,…h_n$，其中 $h_i \in \mathbb{R}^{d}$ 是维度为 $d$ 的向量。self-attention层处理一个词向量的时候，不仅会使用这个词本身的信息，也会使用句子中其他词的信息（你可以类比为：当我们翻译一个词的时候，不仅会只关注当前的词，也会关注这个词的上下文的其他词的信息）。Self-Attention层的输出会经过前馈神经网络得到新的 $x_1, x_2,..,x_n$，依旧是 $n$ 个维度为 $d$ 的向量。这些向量将被送入下一层encoder，继续相同的操作。</p><p><img src="/img/ai/datawhale/transformer/2-encoder.png" alt="单层encoder"></p><p>与编码器对应，如下图，解码器在编码器的 self-attention 和 FFNN 中间插入了一个 Encoder-Decoder Attention 层，这个层帮助解码器聚焦于输入序列最相关的部分（类似于 seq2seq 模型中的 Attention）。</p><p><img src="/img/ai/datawhale/transformer/2-decoder.webp" alt="单层decoder"></p><p>总结一下，我们基本了解了 Transformer 由编码部分和解码部分组成，而编码部分和解码部分又由多个网络结构相同的编码层和解码层组成。每个编码层由 self-attention 和 FFNN 组成，每个解码层由 self-attention、FFN 和 encoder-decoder attention 组成。</p><p>以上便是Transformer的宏观结构啦，下面我们开始看宏观结构中的模型细节。</p><h2 id="Transformer结构细节"><a href="#Transformer结构细节" class="headerlink" title="Transformer结构细节"></a>Transformer结构细节</h2><p>了解了Transformer的宏观结构之后。下面，让我们来看看Transformer如何将输入文本序列转换为向量表示，又如何逐层处理这些向量表示得到最终的输出。</p><h3 id="输入处理"><a href="#输入处理" class="headerlink" title="输入处理"></a>输入处理</h3><h4 id="词向量"><a href="#词向量" class="headerlink" title="词向量"></a>词向量</h4><p>和常见的NLP 任务一样，我们首先会使用词嵌入算法（embedding algorithm），将输入文本序列的每个词转换为一个词向量。实际应用中的向量一般是 256 或者 512 维。但为了简化起见，我们这里使用4维的词向量来进行讲解。</p><p>如下图所示，假设我们的输入文本是序列包含了3个词，那么每个词可以通过词嵌入算法得到一个4维向量，于是整个输入被转化成为一个向量序列。在实际应用中，我们通常会同时给模型输入多个句子，如果每个句子的长度不一样，我们会选择一个合适的长度，作为输入文本序列的最大长度：如果一个句子达不到这个长度，那么就填充先填充一个特殊的“padding”词；如果句子超出这个长度，则做截断。最大序列长度是一个超参数，通常希望越大越好，但是更长的序列往往会占用更大的训练显存&#x2F;内存，因此需要在模型训练时候视情况进行决定。</p><p><img src="/img/ai/datawhale/transformer/2-x.png" alt="3个词和对应的词向量"></p><p>输入序列每个单词被转换成词向量表示还将加上位置向量来得到该词的最终向量表示。</p><h4 id="位置向量"><a href="#位置向量" class="headerlink" title="位置向量"></a>位置向量</h4><p>如下图所示，Transformer 模型对每个输入的词向量都加上了一个位置向量。这些向量有助于确定每个单词的位置特征，或者句子中不同单词之间的距离特征。词向量加上位置向量背后的直觉是：将这些表示位置的向量添加到词向量中，得到的新向量，可以为模型提供更多有意义的信息，比如词的位置，词之间的距离等。</p><p><img src="/img/ai/datawhale/transformer/2-position.png" alt="位置编码向量"></p><p>依旧假设词向量和位置向量的维度是4，我们在下图中展示一种可能的位置向量+词向量：</p><p><img src="/img/ai/datawhale/transformer/2-position2.png" alt="图：位置编码向量"></p><p>那么带有位置编码信息的向量到底遵循什么模式？原始论文中给出的设计表达式为：<br>$$<br>\begin{equation}\begin{split}<br>PE_{(pos,2i)} &#x3D; sin(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}})\\<br>\\<br>PE_{(pos,2i+1)} &#x3D; cos(\frac{pos}{10000^{\frac{2i}{d_{\text{model}}}}})<br>\end{split}\end{equation}<br>$$<br>上面表达式中的 $pos$ 代表词的位置，$d_{model}$ 代表位置向量的维度，$i \in [0, d_{model})$ 代表位置 $d_{model}$ 维位置向量第 $i$ 维。于是根据上述公式，我们可以得到第 $pos$ 位置的 $d_{model}$ 维位置向量。在下图中，我们画出了一种位置向量在第4、5、6、7维度、不同位置的的数值大小。横坐标表示位置下标，纵坐标表示数值大小。</p><p><img src="/img/ai/datawhale/transformer/2-2-pos-embedding.png" alt="位置编码在0-100位置，在4、5、6、7维的数值图示"></p><p>当然，上述公式不是唯一生成位置编码向量的方法。但这种方法的优点是：可以扩展到未知的序列长度。例如：当我们的模型需要翻译一个句子，而这个句子的长度大于训练集中所有句子的长度，这时，这种位置编码的方法也可以生成一样长的位置编码向量。</p><h3 id="编码器encoder"><a href="#编码器encoder" class="headerlink" title="编码器encoder"></a>编码器encoder</h3><p>编码部分的输入文本序列经过输入处理之后得到了一个向量序列，这个向量序列将被送入第1层编码器，第1层编码器输出的同样是一个向量序列，再接着送入下一层编码器：第1层编码器的输入是融合位置向量的词向量，<em>更上层编码器的输入则是上一层编码器的输出</em>。</p><p>下图展示了向量序列在单层encoder中的流动：融合位置信息的词向量进入self-attention层，self-attention的输出每个位置的向量再输入FFN神经网络得到每个位置的新向量。</p><p><img src="/img/ai/datawhale/transformer/2-x-encoder.png" alt="图：单层encoder的序列向量流动"></p><p>下面再看一个2个单词的例子：$x_1, x_2 \to z_1, z_2 \to r_1, r_2$</p><p><img src="/img/ai/datawhale/transformer/2-multi-encoder.webp" alt="一层传一层"></p><h3 id="Self-Attention层"><a href="#Self-Attention层" class="headerlink" title="Self-Attention层"></a>Self-Attention层</h3><p>下面来分析一下上图中Self-Attention层的具体机制。</p><h5 id="Self-Attention概览"><a href="#Self-Attention概览" class="headerlink" title="Self-Attention概览"></a>Self-Attention概览</h5><p>假设我们想要翻译的句子是：</p><figure class="highlight vbnet"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs vbnet">The animal didn<span class="hljs-comment">&#x27;t cross the street because it was too tired</span><br></code></pre></td></tr></table></figure><p>这个句子中的 <em>it</em> 是一个指代词，那么 <em>it</em> 指的是什么呢？它是指 <em>animal</em> 还是<em>street</em>？这个问题对人来说，是很简单的，但是对模型来说并不是那么容易。但是，如果模型引入了<em>Self Attention</em>机制之后，便能够让模型把it和animal关联起来了。同样的，当模型处理句子中其他词时，<em>Self Attentio</em>n机制也可以使得模型不仅仅关注当前位置的词，还会关注句子中其他位置的相关的词，进而可以更好地理解当前位置的词。</p><p>与2.1章节中提到的RNN对比一下：RNN 在处理序列中的一个词时，会考虑句子前面的词传过来的<em>hidden state</em>，而<em>hidden state</em>就包含了前面的词的信息；而<em>Self Attention</em>机制值得是，当前词会直接关注到自己句子中前后相关的所有词语，如下图 <em>it</em>的例子：</p><p><img src="/img/ai/datawhale/transformer/2-attention-word.png" alt="一个词和其他词的attention"></p><p>图：一个词和其他词的attention</p><p>上图所示的<em>it</em>是一个真实的例子，是当Transformer在第5层编码器编码“it”时的状态，可视化之后显示<em>it</em>有一部分注意力集中在了“The animal”上，并且把这两个词的信息融合到了”it”中。</p><h5 id="Self-Attention细节"><a href="#Self-Attention细节" class="headerlink" title="Self-Attention细节"></a>Self-Attention细节</h5><p>先通过一个简单的例子来理解一下：什么是“<strong>self-attention自注意力机制</strong>”？假设一句话包含两个单词：Thinking Machines。自注意力的一种理解是：Thinking-Thinking，Thinking-Machines，Machines-Thinking，Machines-Machines，共$2^2$种两两attention。那么具体如何计算呢？假设Thinking、Machines这两个单词经过词向量算法得到向量是$X_1, X_2$​：</p><p>$$<br>\begin{equation}\begin{split}<br>1:&amp;q_1 &#x3D; X_1 W^Q, q_2 &#x3D; X_2 W^Q\\<br>\\<br>&amp;k_1 &#x3D; X_1 W^K, k_2 &#x3D; X_2 W^K\\<br>\\<br>&amp;v_1 &#x3D; X_1 W^V, v_2 &#x3D; X_2 W^V\\<br>\\<br>&amp;W^Q, W^K, W^K \in \mathbb{R}^{d_x \times d_k}\\<br>\\<br>2-3:&amp;score_{11} &#x3D; \frac{q_1 \cdot q_1}{\sqrt{d_k}}\\<br>\\<br>&amp;score_{12} &#x3D; \frac{q_1 \cdot q_2}{\sqrt{d_k}}\\<br>\\<br>&amp;score_{21} &#x3D; \frac{q_2 \cdot q_1}{\sqrt{d_k}}\\<br>\\<br>&amp;score_{22} &#x3D; \frac{q_2 \cdot q_2}{\sqrt{d_k}}\\<br>\\<br>4:&amp;score_{11} &#x3D; \frac{e^{score_{11}}}{e^{score_{11}} + e^{score_{12}}}\\<br>\\<br>&amp;score_{12} &#x3D; \frac{e^{score_{12}}}{e^{score_{11}} + e^{score_{12}}}\\<br>\\<br>&amp;score_{21} &#x3D; \frac{e^{score_{21}}}{e^{score_{21}} + e^{score_{22}}}\\<br>\\<br>&amp;score_{22} &#x3D; \frac{e^{score_{22}}}{e^{score_{21}} + e^{score_{22}}} \\<br>\\<br>5-6:&amp;z_1 &#x3D; v_1 \times score_{11} + v_2 \times score_{12}\\<br>\\<br>&amp;z_2 &#x3D; v_1 \times score_{21} + v_2 \times score_{22}<br>\end{split}\end{equation}<br>$$</p><p>下面，我们将上诉self-attention计算的6个步骤进行可视化。</p><p>第1步：对输入编码器的词向量进行线性变换得到：Query向量: $q_1, q_2$，Key向量: $k_1, k_2$，Value向量: $v_1, v_2$。这3个向量是词向量分别和3个参数矩阵相乘得到的，而这个矩阵也是是模型要学习的参数。</p><p><img src="/img/ai/datawhale/transformer/2-qkv.png" alt="计算Query向量：$q_1, q_2$，Key向量: $k_1, k_2$，Value向量: $v_1, v_2$"></p><p>Query 向量，Key 向量，Value 向量是什么含义呢？</p><p>其实它们就是 3 个向量，给它们加上一个名称，可以让我们更好地理解 Self-Attention 的计算过程和逻辑。attention计算的逻辑常常可以描述为：<strong>query和key计算相关或者叫attention得分，然后根据attention得分对value进行加权求和。</strong></p><p>第2步：计算Attention Score（注意力分数）。假设我们现在计算第一个词<strong>Thinking</strong>的Attention Score（注意力分数），需要根据<strong>Thinking</strong> 对应的词向量，对句子中的其他词向量都计算一个分数。这些分数决定了我们在编码<strong>Thinking</strong>这个词时，需要对句子中其他位置的词向量的权重。</p><p>Attention score是根据”<strong>Thinking</strong>“对应的 Query 向量和其他位置的每个词的 Key 向量进行点积得到的。Thinking的第一个Attention Score就是$q_1$和$k_1$的内积，第二个分数就是$q_1$和$k_2$的点积。这个计算过程在下图中进行了展示，下图里的具体得分数据是为了表达方便而自定义的。</p><p><img src="/img/ai/datawhale/transformer/2-think.png" alt="Thinking的Attention Score计算"></p><p>第3步：把每个分数除以 $\sqrt{d_k}$，$d_{k}$是Key向量的维度。你也可以除以其他数，除以一个数是为了在反向传播时，求梯度时更加稳定。</p><p>第4步：接着把这些分数经过一个Softmax函数，Softmax可以将分数归一化，这样使得分数都是正数并且加起来等于1， 如下图所示。<br>这些分数决定了Thinking词向量，对其他所有位置的词向量分别有多少的注意力。</p><p><img src="/img/ai/datawhale/transformer/2-think2.png" alt="Thinking的Attention Score计算"></p><p>第5步：得到每个词向量的分数后，将分数分别与对应的Value向量相乘。这种做法背后的直觉理解就是：对于分数高的位置，相乘后的值就越大，我们把更多的注意力放到了它们身上；对于分数低的位置，相乘后的值就越小，这些位置的词可能是相关性不大的。</p><p>第6步：把第5步得到的Value向量相加，就得到了Self Attention在当前位置（这里的例子是第1个位置）对应的输出。</p><p>最后，在下图展示了 对第一个位置词向量计算Self Attention 的全过程。最终得到的当前位置（这里的例子是第一个位置）词向量会继续输入到前馈神经网络。注意：上面的6个步骤每次只能计算一个位置的输出向量，在实际的代码实现中，Self Attention的计算过程是使用矩阵快速计算的，一次就得到所有位置的输出向量。</p><p><img src="/img/ai/datawhale/transformer/2-sum.png" alt="Thinking经过attention之后的向量表示$z_1$"></p><h5 id="Self-Attention矩阵计算"><a href="#Self-Attention矩阵计算" class="headerlink" title="Self-Attention矩阵计算"></a>Self-Attention矩阵计算</h5><p>将self-attention计算6个步骤中的向量放一起，比如$X&#x3D;[x_1;x_2]$​，便可以进行矩阵计算啦。下面，依旧按步骤展示self-attention的矩阵计算方法。<br>$$<br>\begin{equation}\begin{split}<br>X &amp;&#x3D; [X_1;X_2]\\<br>\\<br>Q &amp;&#x3D; X W^Q\\<br>K &amp;&#x3D; X W^K\\<br>V&amp;&#x3D;X W^V \\<br>\\<br>Z &amp;&#x3D; softmax(\frac{QK^T}{\sqrt{d_k}}) V<br>\end{split}\end{equation}<br>$$</p><p>第1步：计算 Query，Key，Value 的矩阵。首先，我们把所有词向量放到一个矩阵X中，然后分别和3个权重矩阵$W^Q, W^K W^V$ 相乘，得到 Q，K，V 矩阵。矩阵X中的每一行，表示句子中的每一个词的词向量。Q，K，V 矩阵中的每一行表示 Query向量，Key向量，Value 向量，向量维度是$d_k$。</p><p><img src="/img/ai/datawhale/transformer/2-qkv-multi.png" alt="QKV矩阵乘法"></p><p>第2步：由于我们使用了矩阵来计算，我们可以把上面的第 2 步到第 6 步压缩为一步，直接得到 Self Attention 的输出。</p><p><img src="/img/ai/datawhale/transformer/2-attention-output.webp" alt="得到输出$Z$"></p><h4 id="多头注意力机制"><a href="#多头注意力机制" class="headerlink" title="多头注意力机制"></a>多头注意力机制</h4><p>Transformer 的论文通过增加多头注意力机制（一组注意力称为一个 attention head），进一步完善了Self-Attention。这种机制从如下两个方面增强了attention层的能力：</p><ul><li><strong>它扩展了模型关注不同位置的能力</strong>。在上面的例子中，第一个位置的输出$z_1$​包含了句子中其他每个位置的很小一部分信息，但$z_1$​仅仅是单个向量，所以可能仅由第1个位置的信息主导了。而当我们翻译句子：<code>The animal didn’t cross the street because it was too tired</code>时，我们不仅希望模型关注到”it”本身，还希望模型关注到”The”和“animal”，甚至关注到”tired”。这时，多头注意力机制会有帮助。</li><li><strong>多头注意力机制赋予attention层多个“子表示空间”</strong>。下面我们会看到，多头注意力机制会有多组$W^Q, W^K W^V$​ 的权重矩阵（在 Transformer 的论文中，使用了 8 组注意力),，因此可以将$X$​变换到更多种子空间进行表示。接下来我们也使用8组注意力头（attention heads））。每一组注意力的权重矩阵都是随机初始化的，但经过训练之后，每一组注意力的权重$W^Q, W^K W^V$​ 可以把输入的向量映射到一个对应的”子表示空间“。</li></ul><p><img src="/img/ai/datawhale/transformer/2-multi-head.png" alt="多头注意力机制"></p><p>在多头注意力机制中，我们为每组注意力设定单独的 WQ, WK, WV 参数矩阵。将输入X和每组注意力的WQ, WK, WV 相乘，得到8组 Q, K, V 矩阵。</p><p>接着，我们把每组 K, Q, V 计算得到每组的 Z 矩阵，就得到8个Z矩阵。</p><p><img src="/img/ai/datawhale/transformer/2-8z.webp" alt="8 个 Z 矩阵"></p><p>由于前馈神经网络层接收的是 1 个矩阵（其中每行的向量表示一个词），而不是 8 个矩阵，所以我们直接把8个子矩阵拼接起来得到一个大的矩阵，然后和另一个权重矩阵$W^O$相乘做一次变换，映射到前馈神经网络层所需要的维度。</p><p><img src="/img/ai/datawhale/transformer/2-to1.webp" alt="拼接8个子矩阵并进行映射变换"></p><p>总结一下就是：</p><ol><li>把8个矩阵 {Z0,Z1…,Z7} 拼接起来</li><li>把拼接后的矩阵和WO权重矩阵相乘</li><li>得到最终的矩阵Z，这个矩阵包含了所有 attention heads（注意力头） 的信息。这个矩阵会输入到FFNN (Feed Forward Neural Network)层。</li></ol><p>以上就是多头注意力的全部内容。最后将所有内容放到一张图中：</p><p><img src="/img/ai/datawhale/transformer/2-put-together.webp" alt="多头注意力机制的矩阵运算"></p><p>学习了多头注意力机制，让我们再来看下当我们前面提到的it例子，不同的attention heads （注意力头）对应的“it”attention了哪些内容。下图中的绿色和橙色线条分别表示2组不同的attentin heads：</p><p><img src="/img/ai/datawhale/transformer/2-it-attention.webp" alt="it 的 attention"></p><p>当我们编码单词”it”时，其中一个 attention head （橙色注意力头）最关注的是”the animal”，另外一个绿色 attention head 关注的是”tired”。因此在某种意义上，”it”在模型中的表示，融合了”animal”和”tire”的部分表达。</p><h4 id="Attention代码实例"><a href="#Attention代码实例" class="headerlink" title="Attention代码实例"></a>Attention代码实例</h4><p>下面的代码实现中，张量的第1维是 batch size，第 2 维是句子长度。代码中进行了详细注释和说明。</p><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MultiheadAttention</span>(nn.Module):<br>    <span class="hljs-comment"># n_heads：多头注意力的数量</span><br>    <span class="hljs-comment"># hid_dim：每个词输出的向量维度</span><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self, hid_dim, n_heads, dropout</span>):<br>        <span class="hljs-built_in">super</span>(MultiheadAttention, <span class="hljs-variable language_">self</span>).__init__()<br>        <span class="hljs-variable language_">self</span>.hid_dim = hid_dim<br>        <span class="hljs-variable language_">self</span>.n_heads = n_heads<br><br>        <span class="hljs-comment"># 强制 hid_dim 必须整除 h</span><br>        <span class="hljs-keyword">assert</span> hid_dim % n_heads == <span class="hljs-number">0</span><br>        <span class="hljs-comment"># 定义 W_q 矩阵</span><br>        <span class="hljs-variable language_">self</span>.w_q = nn.Linear(hid_dim, hid_dim)<br>        <span class="hljs-comment"># 定义 W_k 矩阵</span><br>        <span class="hljs-variable language_">self</span>.w_k = nn.Linear(hid_dim, hid_dim)<br>        <span class="hljs-comment"># 定义 W_v 矩阵</span><br>        <span class="hljs-variable language_">self</span>.w_v = nn.Linear(hid_dim, hid_dim)<br>        <span class="hljs-variable language_">self</span>.fc = nn.Linear(hid_dim, hid_dim)<br>        <span class="hljs-variable language_">self</span>.do = nn.Dropout(dropout)<br>        <span class="hljs-comment"># 缩放</span><br>        <span class="hljs-variable language_">self</span>.scale = torch.sqrt(torch.FloatTensor([hid_dim // n_heads]))<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, query, key, value, mask=<span class="hljs-literal">None</span></span>):<br>        <span class="hljs-comment"># 注意 Q，K，V的在句子长度这一个维度的数值可以一样，可以不一样。</span><br>        <span class="hljs-comment"># K: [64,10,300], 假设batch_size 为 64，有 10 个词，每个词的 Query 向量是 300 维</span><br>        <span class="hljs-comment"># V: [64,10,300], 假设batch_size 为 64，有 10 个词，每个词的 Query 向量是 300 维</span><br>        <span class="hljs-comment"># Q: [64,12,300], 假设batch_size 为 64，有 12 个词，每个词的 Query 向量是 300 维</span><br>        bsz = query.shape[<span class="hljs-number">0</span>]<br>        Q = <span class="hljs-variable language_">self</span>.w_q(query)<br>        K = <span class="hljs-variable language_">self</span>.w_k(key)<br>        V = <span class="hljs-variable language_">self</span>.w_v(value)<br>        <span class="hljs-comment"># 这里把 K Q V 矩阵拆分为多组注意力</span><br>        <span class="hljs-comment"># 最后一维就是是用 self.hid_dim // self.n_heads 来得到的，表示每组注意力的向量长度, 每个 head 的向量长度是：300/6=50</span><br>        <span class="hljs-comment"># 64 表示 batch size，6 表示有 6组注意力，10 表示有 10 词，50 表示每组注意力的词的向量长度</span><br>        <span class="hljs-comment"># K: [64,10,300] 拆分多组注意力 -&gt; [64,10,6,50] 转置得到 -&gt; [64,6,10,50]</span><br>        <span class="hljs-comment"># V: [64,10,300] 拆分多组注意力 -&gt; [64,10,6,50] 转置得到 -&gt; [64,6,10,50]</span><br>        <span class="hljs-comment"># Q: [64,12,300] 拆分多组注意力 -&gt; [64,12,6,50] 转置得到 -&gt; [64,6,12,50]</span><br>        <span class="hljs-comment"># 转置是为了把注意力的数量 6 放到前面，把 10 和 50 放到后面，方便下面计算</span><br>        Q = Q.view(bsz, -<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.n_heads, <span class="hljs-variable language_">self</span>.hid_dim //<br>                   <span class="hljs-variable language_">self</span>.n_heads).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>        K = K.view(bsz, -<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.n_heads, <span class="hljs-variable language_">self</span>.hid_dim //<br>                   <span class="hljs-variable language_">self</span>.n_heads).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br>        V = V.view(bsz, -<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.n_heads, <span class="hljs-variable language_">self</span>.hid_dim //<br>                   <span class="hljs-variable language_">self</span>.n_heads).permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>)<br><br>        <span class="hljs-comment"># 第 1 步：Q 乘以 K的转置，除以scale</span><br>        <span class="hljs-comment"># [64,6,12,50] * [64,6,50,10] = [64,6,12,10]</span><br>        <span class="hljs-comment"># attention：[64,6,12,10]</span><br>        attention = torch.matmul(Q, K.permute(<span class="hljs-number">0</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>, <span class="hljs-number">2</span>)) / <span class="hljs-variable language_">self</span>.scale<br><br>        <span class="hljs-comment"># 如果 mask 不为空，那么就把 mask 为 0 的位置的 attention 分数设置为 -1e10，这里用“0”来指示哪些位置的词向量不能被attention到，比如padding位置，当然也可以用“1”或者其他数字来指示，主要设计下面2行代码的改动。</span><br>        <span class="hljs-keyword">if</span> mask <span class="hljs-keyword">is</span> <span class="hljs-keyword">not</span> <span class="hljs-literal">None</span>:<br>            attention = attention.masked_fill(mask == <span class="hljs-number">0</span>, -<span class="hljs-number">1e10</span>)<br><br>        <span class="hljs-comment"># 第 2 步：计算上一步结果的 softmax，再经过 dropout，得到 attention。</span><br>        <span class="hljs-comment"># 注意，这里是对最后一维做 softmax，也就是在输入序列的维度做 softmax</span><br>        <span class="hljs-comment"># attention: [64,6,12,10]</span><br>        attention = <span class="hljs-variable language_">self</span>.do(torch.softmax(attention, dim=-<span class="hljs-number">1</span>))<br><br>        <span class="hljs-comment"># 第三步，attention结果与V相乘，得到多头注意力的结果</span><br>        <span class="hljs-comment"># [64,6,12,10] * [64,6,10,50] = [64,6,12,50]</span><br>        <span class="hljs-comment"># x: [64,6,12,50]</span><br>        x = torch.matmul(attention, V)<br><br>        <span class="hljs-comment"># 因为 query 有 12 个词，所以把 12 放到前面，把 50 和 6 放到后面，方便下面拼接多组的结果</span><br>        <span class="hljs-comment"># x: [64,6,12,50] 转置-&gt; [64,12,6,50]</span><br>        x = x.permute(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>, <span class="hljs-number">1</span>, <span class="hljs-number">3</span>).contiguous()<br>        <span class="hljs-comment"># 这里的矩阵转换就是：把多组注意力的结果拼接起来</span><br>        <span class="hljs-comment"># 最终结果就是 [64,12,300]</span><br>        <span class="hljs-comment"># x: [64,12,6,50] -&gt; [64,12,300]</span><br>        x = x.view(bsz, -<span class="hljs-number">1</span>, <span class="hljs-variable language_">self</span>.n_heads * (<span class="hljs-variable language_">self</span>.hid_dim // <span class="hljs-variable language_">self</span>.n_heads))<br>        x = <span class="hljs-variable language_">self</span>.fc(x)<br>        <span class="hljs-keyword">return</span> x<br><br><br><span class="hljs-comment"># batch_size 为 64，有 12 个词，每个词的 Query 向量是 300 维</span><br>query = torch.rand(<span class="hljs-number">64</span>, <span class="hljs-number">12</span>, <span class="hljs-number">300</span>)<br><span class="hljs-comment"># batch_size 为 64，有 12 个词，每个词的 Key 向量是 300 维</span><br>key = torch.rand(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>, <span class="hljs-number">300</span>)<br><span class="hljs-comment"># batch_size 为 64，有 10 个词，每个词的 Value 向量是 300 维</span><br>value = torch.rand(<span class="hljs-number">64</span>, <span class="hljs-number">10</span>, <span class="hljs-number">300</span>)<br>attention = MultiheadAttention(hid_dim=<span class="hljs-number">300</span>, n_heads=<span class="hljs-number">6</span>, dropout=<span class="hljs-number">0.1</span>)<br>output = attention(query, key, value)<br><span class="hljs-comment">## output: torch.Size([64, 12, 300])</span><br><span class="hljs-built_in">print</span>(output.shape)<br><br></code></pre></td></tr></table></figure><h4 id="残差连接"><a href="#残差连接" class="headerlink" title="残差连接"></a>残差连接</h4><p>到目前为止，我们计算得到了self-attention的输出向量。而单层encoder里后续还有两个重要的操作：残差链接、标准化。</p><p>编码器的每个子层（Self Attention 层和 FFNN）都有一个残差连接和层标准化（layer-normalization），如下图所示。</p><p><img src="/img/ai/datawhale/transformer/2-resnet.png" alt="残差连接"></p><p>将 Self-Attention 层的层标准化（layer-normalization）和涉及的向量计算细节都进行可视化，如下所示：</p><p><img src="/img/ai/datawhale/transformer/2-lyn.png" alt="标准化细节"></p><p>编码器和和解码器的子层里面都有层标准化（layer-normalization）。假设一个 Transformer 是由 2 层编码器和两层解码器组成的，将全部内部细节展示起来如下图所示。</p><p><img src="/img/ai/datawhale/transformer/2-2layer.png" alt="2层Transformer示意图"></p><h2 id="解码器"><a href="#解码器" class="headerlink" title="解码器"></a>解码器</h2><p>现在我们已经介绍了编码器中的大部分概念，我们也基本知道了编码器的原理。现在让我们来看下， 编码器和解码器是如何协同工作的。</p><p>编码器一般有多层，第一个编码器的输入是一个序列文本，最后一个编码器输出是一组序列向量，这组序列向量会作为解码器的K、V输入，其中K&#x3D;V&#x3D;解码器输出的序列向量表示。这些注意力向量将会输入到每个解码器的Encoder-Decoder Attention层，这有助于解码器把注意力集中到输入序列的合适位置，如下图所示。</p><p><img src="/img/ai/datawhale/transformer/transformer_decoding_1.gif"></p><p>解码（decoding ）阶段的每一个时间步都输出一个翻译后的单词（这里的例子是英语翻译），解码器当前时间步的输出又重新作为输入Q和编码器的输出K、V共同作为下一个时间步解码器的输入。然后重复这个过程，直到输出一个结束符。如下图所示：</p><p><img src="/img/ai/datawhale/transformer/2-decoder.gif" alt="decoder动态图"></p><p>解码器中的 Self Attention 层，和编码器中的 Self Attention 层的区别：</p><ol><li>在解码器里，Self Attention 层只允许关注到输出序列中早于当前位置之前的单词。具体做法是：在 Self Attention 分数经过 Softmax 层之前，屏蔽当前位置之后的那些位置（将attention score设置成-inf）。</li><li>解码器 Attention层是使用前一层的输出来构造Query 矩阵，而Key矩阵和 Value矩阵来自于编码器最终的输出。</li></ol><h2 id="线性层和softmax"><a href="#线性层和softmax" class="headerlink" title="线性层和softmax"></a>线性层和softmax</h2><p>Decoder 最终的输出是一个向量，其中每个元素是浮点数。我们怎么把这个向量转换为单词呢？这是线性层和softmax完成的。</p><p>线性层就是一个普通的全连接神经网络，可以把解码器输出的向量，映射到一个更大的向量，这个向量称为 logits 向量：假设我们的模型有 10000 个英语单词（模型的输出词汇表），此 logits 向量便会有 10000 个数字，每个数表示一个单词的分数。</p><p>然后，Softmax 层会把这些分数转换为概率（把所有的分数转换为正数，并且加起来等于 1）。然后选择最高概率的那个数字对应的词，就是这个时间步的输出单词。</p><p><img src="/img/ai/datawhale/transformer/2-linear.png" alt="线性层"></p><h2 id="损失函数"><a href="#损失函数" class="headerlink" title="损失函数"></a>损失函数</h2><p>Transformer训练的时候，需要将解码器的输出和label一同送入损失函数，以获得loss，最终模型根据loss进行方向传播。这一小节，我们用一个简单的例子来说明训练过程的loss计算：把“merci”翻译为“thanks”。</p><p>我们希望模型解码器最终输出的概率分布，会指向单词 ”thanks“（在“thanks”这个词的概率最高）。但是，一开始模型还没训练好，它输出的概率分布可能和我们希望的概率分布相差甚远，如下图所示，正确的概率分布应该是“thanks”单词的概率最大。但是，由于模型的参数都是随机初始化的，所示一开始模型预测所有词的概率几乎都是随机的。</p><p><img src="/img/ai/datawhale/transformer/2-loss.webp" alt="概率分布"></p><p>只要Transformer解码器预测了组概率，我们就可以把这组概率和正确的输出概率做对比，然后使用反向传播来调整模型的权重，使得输出的概率分布更加接近整数输出。</p><p>那我们要怎么比较两个概率分布呢？：我们可以简单的用两组概率向量的的空间距离作为loss（向量相减，然后求平方和，再开方），当然也可以使用交叉熵(cross-entropy)]和KL 散度(Kullback–Leibler divergence)。读者可以进一步检索阅读相关知识，损失函数的知识不在本小节展开。</p><p>由于上面仅有一个单词的例子太简单了，我们可以再看一个复杂一点的句子。句子输入是：“je suis étudiant” ，输出是：“i am a student”。这意味着，我们的transformer模型解码器要多次输出概率分布向量：</p><ul><li>每次输出的概率分布都是一个向量，长度是 vocab_size（前面约定最大vocab size，也就是向量长度是 6，但实际中的vocab size更可能是 30000 或者 50000）</li><li>第1次输出的概率分布中，最高概率对应的单词是 “i”</li><li>第2次输出的概率分布中，最高概率对应的单词是 “am”</li><li>以此类推，直到第 5 个概率分布中，最高概率对应的单词是 “&lt;eos&gt;”，表示没有下一个单词了</li></ul><p>于是我们目标的概率分布长下面这个样子：</p><p><img src="/img/ai/datawhale/transformer/2-target.png" alt="目标概率分布"></p><p>我们用例子中的句子训练模型，希望产生图中所示的概率分布<br>我们的模型在一个足够大的数据集上，经过足够长时间的训练后，希望输出的概率分布如下图所示：</p><p><img src="/img/ai/datawhale/transformer/2-trained.webp" alt="模型训练后输出的多个概率分布"></p><p>我们希望模型经过训练之后可以输出的概率分布也就对应了正确的翻译。当然，如果你要翻译的句子是训练集中的一部分，那输出的结果并不能说明什么。我们希望模型在没见过的句子上也能够准确翻译。</p><p>额外提一下greedy decoding和beam search的概念：</p><ul><li>Greedy decoding：由于模型每个时间步只产生一个输出，我们这样看待：模型是从概率分布中选择概率最大的词，并且丢弃其他词。这种方法叫做贪婪解码（greedy decoding）。</li><li>Beam search：每个时间步保留k个最高概率的输出词，然后在下一个时间步，根据上一个时间步保留的k个词来确定当前应该保留哪k个词。假设k&#x3D;2，第一个位置概率最高的两个输出的词是”I“和”a“，这两个词都保留，然后根据第一个词计算第2个位置的词的概率分布，再取出第2个位置上2个概率最高的词。对于第3个位置和第4个位置，我们也重复这个过程。这种方法称为集束搜索(beam search)。</li></ul><h1 id="图解BERT"><a href="#图解BERT" class="headerlink" title="图解BERT"></a>图解BERT</h1><p>在学习完Transformer之后，我们来学习一下将Transformer模型结构发扬光大的一个经典模型：BERT。</p><p>站在2021年来看，2018年是自然语言处理技术的一个转折点，运用深度学习技术处理文本的能力通过预训练模型被极大的发挥了出来。同时，伴随着NLP开源社区的贡献，很多强大的模型被封装成组件，让NLP初学者也有机会在各种NLP任务上取得非常好的效果。在众多NLP预训练模型里，最经典的基本就是BERT和GPT了，因此本文将开始对BERT（单篇文章的citation已经接近2万）的学习。</p><p>BERT在2018年被提出，BERT模型一出现就打破了多个自然语言处理任务的最好记录。BERT的论文发布不久后，BERT团队公开了模型的代码，并提供了基于大规模新书数据集预训练完成的模型下载。BERT的模型代码和模型参数的开源，使得任何一个NLP从业者，都可以基于这个强大的模型组件搭建自己的NLP系统，也节省了从零开始训练语言处理模型所需要的时间、精力、知识和资源。</p><p>那么BERT具体干了一件什么事情呢？如下图所示，BERT首先在大规模无监督语料上进行预训练，然后在预训练好的参数基础上增加一个与任务相关的神经网络层，并在该任务的数据上进行微调训，最终取得很好的效果。BERT的这个训练过程可以简述为：预训练+微调（finetune），已经成为最近几年最流行的NLP解决方案的范式。</p><p><img src="/img/ai/datawhale/transformer/3-bert.webp" alt="BERT训练和微调"></p><h2 id="BERT句子分类"><a href="#BERT句子分类" class="headerlink" title="BERT句子分类"></a>BERT句子分类</h2><p>要想很好的理解BERT，最好先理解一下BERT的使用场景，明确一下输入和输出，最后再详细学习BERT的内在模型结构和训练方法。因此，在介绍模型本身涉及的BERT相关概念之前，让我们先看看如何直接应用BERT。</p><ul><li>下载在无监督语料上预训练好的BERT模型，一般来说对应了3个文件：BERT模型配置文件（用来确定Transformer的层数，隐藏层大小等），BERT模型参数，BERT词表（BERT所能处理的所有token）。</li><li>针对特定任务需要，在BERT模型上增加一个任务相关的神经网络，比如一个简单的分类器，然后在特定任务监督数据上进行微调训练。（微调的一种理解：学习率较小，训练epoch数量较少，对模型整体参数进行轻微调整）</li></ul><p>先来看一下如何使用BERT进行句子分类，<br>假设我们的句子分类任务是：判断一个邮件是“垃圾邮件”或者“非垃圾邮件”，如下图所示。当然除了垃圾邮件判断，也可以是其他NLP任务，比如：</p><ul><li>输入：电影或者产品的评价。输出：判断这个评价是正面的还是负面的。</li><li>输入：两句话。输出：两句话是否是同一个意思。</li></ul><p><img src="/img/ai/datawhale/transformer/3-trash.png" alt="垃圾邮件分类"></p><p>图：垃圾邮件分类</p><p>如下图所示，为了能够使用BERT进行句子分类，我们在BERT模型上增加一个简单的classifier层，由于这一层神经网络参数是新添加的，一开始只能随机初始化它的参数，所以需要用对应的监督数据来训练这个classifier。由于classifier是连接在BERT模型之上的，训练的时候也可以更新BERT的参数。</p><p><img src="/img/ai/datawhale/transformer/3-bert-cls.png" alt="BERT句子分类"></p><h2 id="模型结构"><a href="#模型结构" class="headerlink" title="模型结构"></a>模型结构</h2><p>通过上面的例子，了解了如何使用BERT，接下来让我们更深入地了解一下它的工作原理。BERT原始论文提出了BERT-base和BERT—large两个模型，base的参数量比large少一些，可以形象的表示为下图的样子。</p><p><img src="/img/ai/datawhale/transformer/3-bert-bl.webp" alt="BERT base和large"></p><p>回顾一下篇章2.2的Transformer，BERT模型结构基本上就是Transformer的encoder部分，BERT-base对应的是12层encoder，BERT-large对应的是24层encoder。</p><p><img src="/img/ai/datawhale/transformer/3-bert-encoder.webp" alt="BERT-base为12层的encoder"></p><h2 id="模型输入"><a href="#模型输入" class="headerlink" title="模型输入"></a>模型输入</h2><p>接着看一下模型的输入和输出：BERT模型输入有一点特殊的地方是在一句话最开始拼接了一个[CLS] token，如下图所示。这个特殊的[CLS] token经过BERT得到的向量表示通常被用作当前的句子表示。除了这个特殊的[CLS] token，其余输入的单词类似篇章2.2的Transformer。BERT将一串单词作为输入，这些单词在多层encoder中不断向上流动，每一层都会经过 Self-Attention和前馈神经网络。</p><p><img src="/img/ai/datawhale/transformer/3-bert-input.png" alt="模型输入"></p><h2 id="模型输出"><a href="#模型输出" class="headerlink" title="模型输出"></a>模型输出</h2><p>BERT输入的所有token经过BERT编码后，会在每个位置输出一个大小为 hidden_size（在 BERT-base中是 768）的向量。</p><p><img src="/img/ai/datawhale/transformer/3-bert-output.png" alt="BERT output"></p><p>对于上面提到的句子分类的例子，我们直接使用第1个位置的向量输出（对应的是[CLS]）传入classifier网络，然后进行分类任务，如下图所示。</p><p><img src="/img/ai/datawhale/transformer/3-bert-clss.webp" alt="BERT 接分类器"></p><h2 id="预训练任务：Masked-Language-Model"><a href="#预训练任务：Masked-Language-Model" class="headerlink" title="预训练任务：Masked Language Model"></a>预训练任务：Masked Language Model</h2><p>知道了模型输入、输出、Transformer结构，那么BERT是如何无监督进行训练的呢？如何得到有效的词、句子表示信息呢？以往的NLP预训练通常是基于语言模型进行的，比如给定语言模型的前3个词，让模型预测第4个词。但是，BERT是基于Masked language model进行预训练的：将输入文本序列的部分（15%）单词随机Mask掉，让BERT来预测这些被Mask的词语。如下图所示：<br><img src="/img/ai/datawhale/transformer/3-bert-mask.webp" alt="BERT mask"></p><p>这种训练方式最早可以追溯到Word2Vec时代，典型的Word2Vec算法便是：基于词C两边的A、B和D、E词来预测出词C。</p><h2 id="预训练任务：相邻句子判断"><a href="#预训练任务：相邻句子判断" class="headerlink" title="预训练任务：相邻句子判断"></a>预训练任务：相邻句子判断</h2><p>除了masked language model，BERT在预训练时，还引入了一个新的任务：判断两个句子是否是相邻句子。如下图所示：输入是sentence A和sentence B，经过BERT编码之后，使用[CLS] token的向量表示来预测两个句子是否是相邻句子。</p><p><img src="/img/ai/datawhale/transformer/3-bert-2sent.webp" alt="2个句子任务"></p><p>注意事项：为了本文的描述方便，在前面的叙述中，均省略了BERT tokenize的过程，但读者朋友需要注意BERT实际上使用的是WordPieces作为最小的处理单元（采用的是wordpiece算法分词）：token，而不是使用单词本身。在 WordPiece中，有些词会被拆分成更小的部分。关于WordPiece分词，本文不过多展开，感兴趣的读者可以阅读和学习<a href="https://towardsdatascience.com/a-comprehensive-guide-to-subword-tokenisers-4bbd3bad9a7c">subword tokenizer</a>。另外，判断两个句子是否相邻这个任务在后来的研究中逐渐被淡化了，比如roberta模型在被提出的时候就不再使用该任务进行预训练了。</p><h2 id="BERT的应用"><a href="#BERT的应用" class="headerlink" title="BERT的应用"></a>BERT的应用</h2><p>BERT论文展示了BERT在多种任务上的应用，如下图所示。可以用来判断两个句子是否相似，判断单个句子的情感，用来做抽取式问答，用来做序列标注。</p><p><img src="/img/ai/datawhale/transformer/3-bert-app.png" alt="BERT应用"></p><h2 id="BERT特征提取"><a href="#BERT特征提取" class="headerlink" title="BERT特征提取"></a>BERT特征提取</h2><p>由于BERT模型可以得到输入序列所对应的所有token的向量表示，因此不仅可以使用最后一层BERT的输出连接上任务网络进行微调，还可以直接使用这些token的向量当作特征。比如，可以直接提取每一层encoder的token表示当作特征，输入现有的特定任务神经网络中进行训练。</p><p><img src="/img/ai/datawhale/transformer/3-bert-feature.png" alt="BERT特征提取"></p><p>那么我们是使用最后一层的向量表示，还是前几层的，还是都使用呢？下图给出了一种试验结果：</p><p><img src="/img/ai/datawhale/transformer/3-bert-fea.webp" alt="BERT特征选择"></p><h2 id="拓展阅读"><a href="#拓展阅读" class="headerlink" title="拓展阅读"></a>拓展阅读</h2><h3 id="对比CNN"><a href="#对比CNN" class="headerlink" title="对比CNN"></a>对比CNN</h3><p>对于那些有计算机视觉背景的人来说，根据BERT的编码过程，会联想到计算机视觉中使用VGGNet等网络的卷积神经网络+全连接网络做分类任务，如下图所示，基本训练方法和过程是类似的。</p><p><img src="/img/ai/datawhale/transformer/3-cnn.png" alt="CNN"></p><h3 id="词嵌入（Embedding）进展"><a href="#词嵌入（Embedding）进展" class="headerlink" title="词嵌入（Embedding）进展"></a>词嵌入（Embedding）进展</h3><h4 id="回顾词嵌入"><a href="#回顾词嵌入" class="headerlink" title="回顾词嵌入"></a>回顾词嵌入</h4><p>单词不能直接输入机器学习模型，而需要某种数值表示形式，以便模型能够在计算中使用。通过Word2Vec，我们可以使用一个向量（一组数字）来恰当地表示单词，并捕捉单词的语义以及单词和单词之间的关系（例如，判断单词是否相似或者相反，或者像 “Stockholm” 和 “Sweden” 这样的一对词，与 “Cairo” 和 “Egypt”这一对词，是否有同样的关系）以及句法、语法关系（例如，”had” 和 “has” 之间的关系与 “was” 和 “is” 之间的关系相同）。</p><p>人们很快意识到，相比于在小规模数据集上和模型一起训练词嵌入，更好的一种做法是，在大规模文本数据上预训练好词嵌入，然后拿来使用。因此，我们可以下载由 Word2Vec 和 GloVe 预训练好的单词列表，及其词嵌入。下面是单词 “stick” 的 Glove 词嵌入向量的例子（词嵌入向量长度是 200）。</p><p><img src="/img/ai/datawhale/transformer/3-wordvector.webp" alt="wrod vector"></p><p>单词 “stick” 的 Glove 词嵌入embedding向量表示：一个由200个浮点数组成的向量（四舍五入到小数点后两位）。</p><p>由于这些向量都很长，且全部是数字，所以在文章中我使用以下基本形状来表示向量：</p><p><img src="/img/ai/datawhale/transformer/3-single-vector.png" alt="vector"></p><h4 id="语境问题"><a href="#语境问题" class="headerlink" title="语境问题"></a>语境问题</h4><p>如果我们使用 Glove 的词嵌入表示方法，那么不管上下文是什么，单词 “stick” 都只表示为一个向量。一些研究人员指出，像 “stick” 这样的词有多种含义。为什么不能根据它使用的上下文来学习对应的词嵌入呢？这样既能捕捉单词的语义信息，又能捕捉上下文的语义信息。于是，语境化的词嵌入模型应运而生：ELMo。</p><p><img src="/img/ai/datawhale/transformer/3-elmo.webp" alt="ELMO"></p><p>语境化的词嵌入，可以根据单词在句子语境中的含义，赋予不同的词嵌入。</p><p>ELMo没有对每个单词使用固定的词嵌入，而是在为每个词分配词嵌入之前，查看整个句子，融合上下文信息。它使用在特定任务上经过训练的双向LSTM来创建这些词嵌入。</p><p><img src="/img/ai/datawhale/transformer/3-elmo-emb.png" alt="ELMO embedding"></p><p>ELMo 在语境化的预训练这条道路上迈出了重要的一步。ELMo LSTM 会在一个大规模的数据集上进行训练，然后我们可以将它作为其他语言处理模型的一个部分，来处理自然语言任务。</p><p>那么 ELMo 的秘密是什么呢？</p><p>ELMo 通过训练，预测单词序列中的下一个词，从而获得了语言理解能力，这项任务被称为语言建模。要实现 ELMo 很方便，因为我们有大量文本数据，模型可以从这些数据中学习，而不需要额外的标签。</p><p><img src="/img/ai/datawhale/transformer/3-elmo-pre.webp" alt="ELMO 训练"></p><p>ELMo预训练过程是一个典型的语言模型：以 “Let’s stick to” 作为输入，预测下一个最有可能的单词。当我们在大规模数据集上训练时，模型开始学习语言的模式。例如，在 “hang” 这样的词之后，模型将会赋予 “out” 更高的概率（因为 “hang out” 是一个词组），而不是输出 “camera”。</p><p>在上图中，我们可以看到 ELMo 头部上方展示了 LSTM 的每一步的隐藏层状态向量。在这个预训练过程完成后，这些隐藏层状态在词嵌入过程中派上用场。</p><p><img src="/img/ai/datawhale/transformer/3-elmo-pre1.png" alt="ELMO 训练 stick"></p><p>ELMo 通过将LSTM模型的隐藏层表示向量（以及初始化的词嵌入）以某种方式（向量拼接之后加权求和）结合在一起，实现了带有语境化的词嵌入。</p><p><img src="/img/ai/datawhale/transformer/3-elmo-pre2.webp" alt="ELMO 训练 stick"></p><h4 id="Transformer：超越LSTM"><a href="#Transformer：超越LSTM" class="headerlink" title="Transformer：超越LSTM"></a>Transformer：超越LSTM</h4><p>随着Transformer论文和代码的发布，以及它在机器翻译等任务上取得的成果，开始让人们认为它是LSTM的替代品。一部分原因是：1. 因为 Transformer 可以比 LSTM 更好地处理长期依赖，2. Transformer可以对输入进行并行运算。</p><p>2017年，基于Transformer的Encoder-Decoder展示了它在机器翻译上的威力。但怎么才能用它来做文本分类呢？你怎么才能使用它来预训练一个语言模型，并能够在其他任务上进行微调（下游任务是指那些能够利用预训练模型的监督学习任务）？</p><h4 id="OpenAI-Transformer：预训练一个Transformer-Decoder进行语言建模"><a href="#OpenAI-Transformer：预训练一个Transformer-Decoder进行语言建模" class="headerlink" title="OpenAI Transformer：预训练一个Transformer Decoder进行语言建模"></a>OpenAI Transformer：预训练一个Transformer Decoder进行语言建模</h4><p>沿着LSTM语言模型预训练的路子，将LSTM替换成Transformer结构后（相当于），直接语言模型预训练的参数给予下游任务监督数据进行微调，与最开始用于翻译seq2seq的Transformer对比来看，相当于只使用了Decoder部分。有了Transformer结构和语言模型任务设计，直接使用大规模未标记的数据不断得预测下一个词：只需要把 7000 本书的文字依次扔给模型 ，然后让它不断学习生成下一个词即可。</p><p><img src="/img/ai/datawhale/transformer/3-openai-next.webp" alt="open ai模型预测下一个词"></p><p>现在，OpenAI Transformer 已经经过了预训练，它的网络层藏书经过很多次调整，可以很好地用向量表示文本了，我们开始使用它来处理下游任务。让我们先看下句子分类任务（把电子邮件分类为 ”垃圾邮件“ 或者 ”非垃圾邮件“）：</p><p><img src="/img/ai/datawhale/transformer/3-openai-down.png" alt="open ai模型下游任务"></p><p>对于形形色色的NLP任务，OpenAI 的论文列出了一些列输入变换方法，可以处理不同任务类型的输入。下面这张图片来源于论文，展示了处理不同任务的模型结构和对应输入变换。</p><p><img src="/img/ai/datawhale/transformer/3-openai-method.webp" alt="open ai微调"></p><h4 id="BERT：Decoder到Encoder"><a href="#BERT：Decoder到Encoder" class="headerlink" title="BERT：Decoder到Encoder"></a>BERT：Decoder到Encoder</h4><p>OpenAI Transformer为我们提供了一个基于Transformer的预训练网络。但是在把LSTM换成Transformer 的过程中，有些东西丢失了。比如之前的ELMo的语言模型是双向的，但 OpenAI Transformer 只训练了一个前向的语言模型。我们是否可以构建一个基于 Transformer 的语言模型，它既向前看，又向后看（用技术术语来说 - 融合上文和下文的信息）？答案就是BERT：基于双向Transformer的encoder，在Masked language model上进行预训练，最终在多项NLP下游任务中取得了SOTA效果。</p><h1 id="图解GPT"><a href="#图解GPT" class="headerlink" title="图解GPT"></a>图解GPT</h1><p>除了BERT以外，另一个预训练模型GPT也给NLP领域带来了不少轰动，本节也对GPT做一个详细的讲解。</p><p>OpenAI提出的<a href="https://openai.com/blog/better-language-models/">GPT-2模型</a>能够写出连贯并且高质量的文章，比之前语言模型效果好很多。GPT-2是基于Transformer搭建的，相比于之前的NLP语言模型的区别是：基于Transformer大模型、，在巨大的数据集上进行了预训练。在本章节中，我们将对GPT-2的结构进行分析，对GPT-2的应用进行学习，同时还会深入解析所涉及的self-attention结构。本文可以看作是篇章2.2图解Transformer、2.3图解BERT的一个补充。</p><p>这篇文章翻译自<a href="http://jalammar.github.io/illustrated-gpt2">GPT2</a>。</p><h2 id="语言模型和GPT-2"><a href="#语言模型和GPT-2" class="headerlink" title="语言模型和GPT-2"></a>语言模型和GPT-2</h2><h3 id="什么是语言模型"><a href="#什么是语言模型" class="headerlink" title="什么是语言模型"></a>什么是语言模型</h3><p>本文主要描述和对比2种语言模型：</p><ul><li>自编码（auto-encoder）语言模型</li><li>自回归（auto-regressive）语言模型</li></ul><p>先看自编码语言模型。<br>自编码语言模型典型代表就是篇章2.3所描述的BERT。如下图所示，自编码语言模型通过随机Mask输入的部分单词，然后预训练的目标是预测被Mask的单词，不仅可以融入上文信息，还可以自然的融入下文信息。</p><p><img src="/img/ai/datawhale/transformer/3-bert-mask.webp" alt="BERT mask"></p><p>自编码语言模型的优缺点：</p><ul><li>优点：自然地融入双向语言模型，同时看到被预测单词的上文和下文</li><li>缺点：训练和预测不一致。训练的时候输入引入了[Mask]标记，但是在预测阶段往往没有这个[Mask]标记，导致预训练阶段和Fine-tuning阶段不一致。</li></ul><p>接着我们来看看什么是常用的自回归（auto-regressive）语言模型：语言模型根据输入句子的一部分文本来预测下一个词。日常生活中最常见的语言模型就是输入法提示，它可以根据你输入的内容，提示下一个单词。</p><p><img src="/img/ai/datawhale/transformer/4-word2vec.webp" alt="词之间的关系"></p><p>图：输入提示</p><p>自回归语言模型的优点和缺点：</p><ul><li>优点：对于生成类的NLP任务，比如文本摘要，机器翻译等，从左向右的生成内容，天然和自回归语言模型契合。</li><li>缺点：由于一般是从左到右（当然也可能从右到左），所以只能利用上文或者下文的信息，不能同时利用上文和下文的信息。</li></ul><p>GPT-2属于自回归语言模型，相比于手机app上的输入提示，GPT-2更加复杂，功能也更加强大。因为，OpenAI的研究人员从互联网上爬取了40GB的WebText数据集，并用该数据集训练了GPT-2模型。我们可以直接在<a href="https://gpt2.apps.allenai.org/?text=Joel">AllenAI GPT-2 Explorer网站</a>上试用GPT-2模型。<br><img src="/./pictrues/./img/ai/datawhale/transformer/2-4-gpt-2-autoregression-2.gif" alt="gpt2 output">图：自回归GPT-2</p><p><img src="/img/ai/datawhale/transformer/4-gpt-his.webp" alt="GPT发展"></p><h3 id="基于Transformer的语言模型"><a href="#基于Transformer的语言模型" class="headerlink" title="基于Transformer的语言模型"></a>基于Transformer的语言模型</h3><p>正如我们在图解Transformer所学习的，原始的Transformer模型是由 Encoder部分和Decoder部分组成的，它们都是由多层transformer堆叠而成的。原始Transformer的seq2seq结构很适合机器翻译，因为机器翻译正是将一个文本序列翻译为另一种语言的文本序列。</p><p><img src="/img/ai/datawhale/transformer/4-transformer.webp" alt="原始Transformer结构"></p><p>但如果要使用Transformer来解决语言模型任务，并不需要完整的Encoder部分和Decoder部分，于是在原始Transformer之后的许多研究工作中，人们尝试只使用Transformer Encoder或者Decoder，并且将它们堆得层数尽可能高，然后使用大量的训练语料和大量的计算资源（数十万美元用于训练这些模型）进行预训练。比如BERT只使用了Encoder部分进行masked language model（自编码）训练，GPT-2便是只使用了Decoder部分进行自回归（auto regressive）语言模型训练。<br><img src="/img/ai/datawhale/transformer/4-gpt-bert.webp" alt="GPT、BERT、Transformer-XL"></p><p><img src="/img/ai/datawhale/transformer/4-gpt-his2.webp" alt="层数越来越多的GPT2模型"></p><h3 id="Transformer进化"><a href="#Transformer进化" class="headerlink" title="Transformer进化"></a>Transformer进化</h3><p>Transformer的Encoder进化成了BERT，Decoder进化成了GPT2。</p><p>首先看Encoder部分。</p><p><img src="/img/ai/datawhale/transformer/4-encoder.webp" alt="encoder"></p><p>图：encoder</p><p>原始的Transformer论文中的Encoder部分接受特定长度的输入（如 512 个 token）。如果一个输入序列比这个限制短，我们可以使用pad填充序列的其余部分。如篇章2.3所讲，BERT直接使用了Encoder部分。</p><p>再回顾下Decoder部分<br>与Encoder相比，Decoder部分多了一个Encoder-Decoder self-attention层，使Decoder可以attention到Encoder编码的特定的信息。</p><p><img src="/img/ai/datawhale/transformer/4-decoder.webp" alt="decoder"></p><p>Decoder中的的 Masked Self-Attention会屏蔽未来的token。具体来说，它不像 BERT那样直接将输入的单词随机改为mask，而是通过改变Self-Attention的计算，来屏蔽未来的单词信息。</p><p>例如，我们想要计算位置4的attention，我们只允许看到位置4以前和位置4的token。</p><p><img src="/img/ai/datawhale/transformer/4-decoder1.webp" alt="decoder只能看到以前和现在的token"></p><p>由于GPT2基于Decoder构建，所以BERT和GPT的一个重要区别来了：由于BERT是基于Encoder构建的，BERT使用是Self Attention层，而GPT2基于Decoder构建，GPT-2 使用masked Self Attention。一个正常的 Self Attention允许一个位置关注到它两边的信息，而masked Self Attention只让模型看到左边的信息：</p><p><img src="/img/ai/datawhale/transformer/4-mask.png" alt="self attention vs mask self attention"></p><p>那么GPT2中的Decoder长什么样子呢？先要说一下<a href="https://arxiv.org/pdf/1801.10198.pdf">Generating Wikipedia by Summarizing Long Sequences</a>这篇文章，它首先提出基于Transformer-Decoder部分进行语言模型训练。由于去掉了Encoder部分，于是Encoder-Decoder self attention也不再需要，新的Transformer-Decoder模型如下图所示：</p><p><img src="/img/ai/datawhale/transformer/4-trans-decoder.webp" alt="transformer-decoder"></p><p>随后OpenAI的GPT2也使用的是上图的Transformer-Decoder结构。</p><h3 id="GPT2概述"><a href="#GPT2概述" class="headerlink" title="GPT2概述"></a>GPT2概述</h3><p>现在来拆解一个训练好的GPT-2，看看它是如何工作的。</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-1.png" alt="拆解GPT2"></p><p>GPT-2能够处理1024 个token。每个token沿着自己的路径经过所有的Decoder层。试用一个训练好的GPT-2模型的最简单方法是让它自己生成文本（这在技术上称为：生成无条件文本）。或者，我们可以给它一个提示，让它谈论某个主题（即生成交互式条件样本）。</p><p>在漫无目的情况下，我们可以简单地给它输入一个特殊的&lt;s&gt;初始token，让它开始生成单词。如下图所示：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-start.webp" alt="拆解GPT2初始token"></p><p>由于模型只有一个输入，因此只有一条活跃路径。&lt;s&gt; token在所有Decoder层中依次被处理，然后沿着该路径生成一个向量。根据这个向量和模型的词汇表给所有可能的词计算出一个分数。在下图的例子中，我们选择了概率最高的 the。下一步，我们把第一步的输出添加到我们的输入序列，然后让模型做下一个预测。</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-the.gif" alt="拆解GPT2"></p><p>请注意，第二条路径是此计算中唯一活动的路径。GPT-2 的每一层都保留了它对第一个 token所编码的信息，而且会在处理第二个 token 时直接使用它：GPT-2 不会根据第2个 token 重新计算第一个 token。</p><p>不断重复上述步骤，就可以生成更多的单词了。</p><h3 id="GPT2详解"><a href="#GPT2详解" class="headerlink" title="GPT2详解"></a>GPT2详解</h3><h4 id="输入编码"><a href="#输入编码" class="headerlink" title="输入编码"></a>输入编码</h4><p>现在我们更深入了解和学习GPT，先看从输入开始。与之前我们讨论的其他 NLP 模型一样，GPT-2 在嵌入矩阵中查找输入的单词的对应的 embedding 向量。如下图所示：每一行都是词的 embedding：这是一个数值向量，可以表示一个词并捕获一些含义。这个向量的大小在不同的 GPT-2 模型中是不同的。最小的模型使用的 embedding 大小是 768。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-token.png" alt="token embedding"></p><p>于是在开始时，我们会在嵌入矩阵查找第一个 token &lt;s&gt; 的 embedding。在把这个 embedding 传给模型的第一个模块之前，我们还需要融入位置编码（参考篇章2.2详解Transformer），这个位置编码能够指示单词在序列中的顺序。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-pos.webp" alt="位置编码"></p><p><img src="/img/ai/datawhale/transformer/4-gpt-token-pos.png" alt="token+position"></p><p>于是输入的处理：得到词向量+位置编码</p><h4 id="多层Decoder"><a href="#多层Decoder" class="headerlink" title="多层Decoder"></a>多层Decoder</h4><p>第一层Decoder现在可以处理 &lt;s&gt; token所对应的向量了：首先通过 Self Attention 层，然后通过全连接神经网络。一旦Transformer 的第1个Decoder处理了&lt;s&gt; token，依旧可以得到一个向量，这个结果向量会再次被发送到下一层Decoder。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-fllow.webp" alt="向上流动"></p><h4 id="Decoder中的Self-Attention"><a href="#Decoder中的Self-Attention" class="headerlink" title="Decoder中的Self-Attention"></a>Decoder中的Self-Attention</h4><p>Decoder中包含了Masked Self-Attention，由于Mask的操作可以独立进行，于是我们先独立回顾一下self-attention操作。语言严重依赖于上下文。给个例子：</p><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs">机器人第2定律：机器人必须服从人给予 它 的命令，当 该命令 与 第一定律 冲突时例外。<br></code></pre></td></tr></table></figure><p>例句中包含了多个代词。如果不结合它们所指的上下文，就无法理解或者处理这些词。当一个模型处理这个句子，它必须能够知道：</p><ul><li>它 指的是机器人</li><li>该命令 指的是这个定律的前面部分，也就是 人给予 它 的命令</li><li>第一定律 指的是机器人第一定律</li></ul><p>self-attention所做的事情是：它通过对句子片段中每个词的相关性打分，并将这些词的表示向量根据相关性加权求和，从而让模型能够将词和其他相关词向量的信息融合起来。</p><p>举个例子，如下图所示，最顶层的Decoder中的 Self Attention 层在处理单词 <code>it</code> 的时候关注到<code>a robot</code>。于是self-attention传递给后续神经网络的<code>it</code> 向量，是3个单词对应的向量和它们各自分数的加权和。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-it.webp" alt="it的attention"></p><p><strong>Self-Attention 过程</strong></p><p>Self-Attention 沿着句子中每个 token 进行处理，主要组成部分包括 3 个向量。</p><ul><li>Query：Query 向量是由当前词的向量表示获得，用于对其他所有单词（使用这些单词的 key 向量）进行评分。</li><li>Key：Key 向量由句子中的所有单词的向量表示获得，可以看作一个标识向量。</li><li>Value：Value 向量在self-attention中与Key向量其实是相同的。</li></ul><p><img src="/img/ai/datawhale/transformer/4-gpt-query.webp" alt="query"></p><p>一个粗略的类比是把它看作是在一个文件柜里面搜索，Query 向量是一个便签，上面写着你正在研究的主题，而 Key 向量就像是柜子里的文件夹的标签。当你将便签与标签匹配时，我们取出匹配的那些文件夹的内容，这些内容就是 Value 向量。但是你不仅仅是寻找一个 Value 向量，而是找到一系列Value 向量。</p><p>将 Query 向量与每个文件夹的 Key 向量相乘，会为每个文件夹产生一个分数（从技术上来讲：点积后面跟着 softmax）。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-score.webp" alt="score"></p><p>我们将每个 Value 向量乘以对应的分数，然后求和，就得到了 Self Attention 的输出。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-out.webp" alt="Self Attention 的输出"></p><p>这些加权的 Value 向量会得到一个向量，比如上图，它将 50% 的注意力放到单词 robot 上，将 30% 的注意力放到单词 a，将 19% 的注意力放到单词 it。</p><p>而所谓的Masked self attention指的的是：将mask位置对应的的attention score变成一个非常小的数字或者0，让其他单词再self attention的时候（加权求和的时候）不考虑这些单词。</p><p><strong>模型输出</strong></p><p>当模型顶部的Decoder层产生输出向量时（这个向量是经过 Self Attention 层和神经网络层得到的），模型会将这个向量乘以一个巨大的嵌入矩阵（vocab size x embedding size）来计算该向量和所有单词embedding向量的相关得分。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-out1.webp" alt="顶部的模块产生输出"></p><p>回忆一下，嵌入矩阵中的每一行都对应于模型词汇表中的一个词。这个相乘的结果，被解释为模型词汇表中每个词的分数，经过softmax之后被转换成概率。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-out3.webp" alt="token概率"></p><p>我们可以选择最高分数的 token（top_k&#x3D;1），也可以同时考虑其他词（top k）。假设每个位置输出k个token，假设总共输出n个token，那么基于n个单词的联合概率选择的输出序列会更好。</p><p><img src="/img/ai/datawhale/transformer/4-gpt-out4.webp" alt="top k选择输出"></p><p>这样，模型就完成了一次迭代，输出一个单词。模型会继续迭代，直到所有的单词都已经生成，或者直到输出了表示句子末尾的 token。</p><h2 id="详解Self-Attention"><a href="#详解Self-Attention" class="headerlink" title="详解Self-Attention"></a>详解Self-Attention</h2><p>现在我们基本知道了 GPT-2 是如何工作的。如果你想知道 Self Attention 层里面到底发生了什么，那么文章接下来的额外部分就是为你准备的，我添加这个额外的部分，来使用更多可视化解释 Self Attention，</p><p>在这里指出文中一些过于简化的说法：</p><ul><li>我在文中交替使用 token 和 词。但实际上，GPT-2 使用 Byte Pair Encoding 在词汇表中创建 token。这意味着 token 通常是词的一部分。</li><li>我们展示的例子是在推理模式下运行。这就是为什么它一次只处理一个 token。在训练时，模型将会针对更长的文本序列进行训练，并且同时处理多个 token。同样，在训练时，模型会处理更大的 batch size，而不是推理时使用的大小为 1 的 batch size。</li><li>为了更加方便地说明原理，我在本文的图片中一般会使用行向量。但有些向量实际上是列向量。在代码实现中，你需要注意这些向量的形式。</li><li>Transformer 使用了大量的层归一化（layer normalization），这一点是很重要的。我们在图解Transformer中已经提及到了一部分这点，但在这篇文章，我们会更加关注 Self Attention。</li><li>有时我需要更多的框来表示一个向量，例如下面这幅图：</li></ul><p><img src="/img/ai/datawhale/transformer/4-gpt-sum.webp" alt="输入与输出维度"></p><h3 id="可视化Self-Attention"><a href="#可视化Self-Attention" class="headerlink" title="可视化Self-Attention"></a>可视化Self-Attention</h3><p>在这篇文章的前面，我们使用了这张图片来展示：Self Attention如何处理单词 <code>it</code>。</p><p><img src="/img/ai/datawhale/transformer/4-att-it.png" alt="it的attention"></p><p>在这一节，我们会详细介绍如何实现这一点。请注意，我们会讲解清楚每个单词都发生了什么。这就是为什么我们会展示大量的单个向量，而实际的代码实现，是通过巨大的矩阵相乘来完成的。</p><p>让我们看看一个简单的Transformer，假设它一次只能处理 4 个 token。</p><p>Self-Attention 主要通过 3 个步骤来实现：</p><ul><li>为每个路径创建 Query、Key、Value 矩阵。</li><li>对于每个输入的 token，使用它的 Query 向量为所有其他的 Key 向量进行打分。</li><li>将 Value 向量乘以它们对应的分数后求和。</li></ul><p><img src="/img/ai/datawhale/transformer/4-att-3.webp" alt="3步"></p><p>(1) 创建 Query、Key 和 Value 向量</p><p>让我们关注第一条路径。我们会使用它的 Query 向量，并比较所有的 Key 向量。这会为每个 Key 向量产生一个分数。Self Attention 的第一步是为每个 token 的路径计算 3 个向量。</p><p><img src="/img/ai/datawhale/transformer/4-att-31.webp" alt="第1步"></p><p>(2) 计算分数</p><p>现在我们有了这些向量，我们只对步骤 2 使用 Query 向量和 Value 向量。因为我们关注的是第一个 token 的向量，我们将第一个 token 的 Query 向量和其他所有的 token 的 Key 向量相乘，得到 4 个 token 的分数。</p><p><img src="/img/ai/datawhale/transformer/4-att-32.webp" alt="第2步"></p><p>(3) 计算和</p><p>我们现在可以将这些分数和 Value 向量相乘。在我们将它们相加后，一个具有高分数的 Value 向量会占据结果向量的很大一部分。</p><p><img src="/img/ai/datawhale/transformer/4-att-33.webp" alt="第3步"></p><p>分数越低，Value 向量就越透明。这是为了说明，乘以一个小的数值会稀释 Value 向量。</p><p>如果我们对每个路径都执行相同的操作，我们会得到一个向量，可以表示每个 token，其中包含每个 token 合适的上下文信息。这些向量会输入到 Transformer 模块的下一个子层（前馈神经网络）。</p><p><img src="/img/ai/datawhale/transformer/4-att-34.webp" alt="汇总"></p><h3 id="图解Masked-Self-attention"><a href="#图解Masked-Self-attention" class="headerlink" title="图解Masked Self-attention"></a>图解Masked Self-attention</h3><p>现在，我们已经了解了 Transformer 的 Self Attention 步骤，现在让我们继续研究 masked Self Attention。Masked Self Attention 和 Self Attention 是相同的，除了第 2 个步骤。</p><p>现在假设模型有2个 token 作为输入，我们正在观察（处理）第二个 token。在这种情况下，最后 2 个 token 是被屏蔽（masked）的。所以模型会干扰评分的步骤。它总是把未来的 token 评分设置为0，因此模型不能看到未来的词，如下图所示：</p><p><img src="/img/ai/datawhale/transformer/4-mask.webp" alt="masked self attention"></p><p>这个屏蔽（masking）经常用一个矩阵来实现，称为 attention mask矩阵。依旧以4个单词的序列为例（例如：robot must obay orders）。在一个语言建模场景中，这个序列会分为 4 个步骤处理：每个步骤处理一个词（假设现在每个词就是是一个token）。另外，由于模型是以 batch size 的形式工作的，我们可以假设这个简单模型的 batch size 为4，它会将4个序列生成任务作为一个 batch 处理，如下图所示，左边是输入，右边是label。</p><p><img src="/img/ai/datawhale/transformer/4-mask-matrix.webp" alt="batch形式的输入和输出"></p><p>在矩阵的形式中，我们使用Query 矩阵和 Key 矩阵相乘来计算分数。将其可视化如下。但注意，单词无法直接进行矩阵运算，所以下图的单词还需要对应成一个向量。</p><p><img src="/img/ai/datawhale/transformer/4-mask-q.webp" alt="Query和Keys的相关矩阵"></p><p>在做完乘法之后，我们加上三角形的 attention mask。它将我们想要屏蔽的单元格设置为负无穷大或者一个非常大的负数（例如 GPT-2 中的 负十亿）：</p><p><img src="/img/ai/datawhale/transformer/4-mask-s.webp" alt="加上attetnion的mask"></p><p>然后对每一行应用 softmax，会产生实际的分数，我们会将这些分数用于 Self Attention。</p><p><img src="/img/ai/datawhale/transformer/4-mask-soft.webp" alt="softmax"></p><p>这个分数表的含义如下：</p><ul><li>当模型处理数据集中的第 1 个数据（第 1 行），其中只包含着一个单词 （robot），它将 100% 的注意力集中在这个单词上。</li><li>当模型处理数据集中的第 2 个数据（第 2 行），其中包含着单词（robot must）。当模型处理单词 must，它将 48% 的注意力集中在 robot，将 52% 的注意力集中在 must。</li><li>诸如此类，继续处理后面的单词。</li></ul><p>到目前为止，我们就搞明白了mask self attention啦。</p><h3 id="GPT2中的Self-Attention"><a href="#GPT2中的Self-Attention" class="headerlink" title="GPT2中的Self-Attention"></a>GPT2中的Self-Attention</h3><p>让我们更详细地了解 GPT-2的masked self attention。</p><p><em>模型预测的时候：每次处理一个 token</em></p><p>但我们用模型进行预测的时候，模型在每次迭代后只添加一个新词，那么对于已经处理过的token来说，沿着之前的路径重新计算 Self Attention 是低效的。那么GPT-2是如何实现高效处理的呢？</p><p>先处理第一个token a，如下图所示（现在暂时忽略 &lt;s&gt;）。</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-self.png" alt="gpt2第一个token"></p><p>GPT-2 保存 token <code>a</code> 的 Key 向量和 Value 向量。每个 Self Attention 层都持有这个 token 对应的 Key 向量和 Value 向量：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-a.png" alt="gpt2的词a"></p><p>现在在下一个迭代，当模型处理单词 robot，它不需要生成 token a 的 Query、Value 以及 Key 向量。它只需要重新使用第一次迭代中保存的对应向量：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-r.png" alt="gpt2的词robot"></p><p><code>(1) 创建 Query、Key 和 Value 矩阵</code></p><p>让我们假设模型正在处理单词 <code>it</code>。进入Decoder之前，这个 token 对应的输入就是 <code>it</code> 的 embedding 加上第 9 个位置的位置编码：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it.webp" alt="处理it"></p><p>Transformer 中每个层都有它自己的参数矩阵（在后文中会拆解展示）。embedding向量我们首先遇到的权重矩阵是用于创建 Query、Key、和 Value 向量的。</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it1.webp" alt="处理it"></p><p>Self-Attention 将它的输入乘以权重矩阵（并添加一个 bias 向量，此处没有画出）。</p><p>这个相乘会得到一个向量，这个向量是 Query、Key 和 Value 向量的拼接。<br><img src="/img/ai/datawhale/transformer/4-gpt2-it2.webp" alt="Query、Key 和 Value"></p><p>得到Query、Key和Value向量之后，我们将其拆分multi-head，如下图所示。其实本质上就是将一个大向量拆分为多个小向量。</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it3.png" alt="multi head"></p><p>为了更好的理解multi head，我们将其进行如下展示：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it4.webp" alt="multi head"></p><p><code>(2) 评分</code></p><p>我们现在可以继续进行评分，假设我们只关注一个 attention head（其他的 attention head 也是在进行类似的操作）。</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it5.webp" alt="打分"></p><p>现在，这个 token 可以根据其他所有 token 的 Key 向量进行评分（这些 Key 向量是在前面一个迭代中的第一个 attention head 计算得到的）：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it6.webp" alt="加权和"></p><p><code>(3) 求和</code></p><p>正如我们之前所看的那样，我们现在将每个 Value 向量乘以对应的分数，然后加起来求和，得到第一个 attention head 的 Self Attention 结果：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it7.webp" alt="处理it"></p><p><code>合并 attention heads</code></p><p>multi head对应得到多个加权和向量，我们将他们都再次拼接起来：</p><p><img src="/img/ai/datawhale/transformer/4-gpt2-it8.webp" alt="拼接multi head多个加权和向量"></p><p>再将得到的向量经过一个线性映射得到想要的维度，随后输入全连接网络。</p><p><code>(4) 映射（投影）</code></p><p>我们将让模型学习如何将拼接好的 Self Attention 结果转换为前馈神经网络能够处理的输入。在这里，我们使用第二个巨大的权重矩阵，将 attention heads 的结果映射到 Self Attention 子层的输出向量：</p><p><img src="/img/ai/datawhale/transformer/4-project.png" alt="映射"></p><p>通过以上步骤，我们产生了一个向量，我们可以把这个向量传给下一层：</p><p><img src="/img/ai/datawhale/transformer/4-vector.webp" alt="传给下一层"></p><h3 id="GPT-2-全连接神经网络"><a href="#GPT-2-全连接神经网络" class="headerlink" title="GPT-2 全连接神经网络"></a>GPT-2 全连接神经网络</h3><p><code>第 1 层</code></p><p>全连接神经网络是用于处理 Self Attention 层的输出，这个输出的表示包含了合适的上下文。全连接神经网络由两层组成。第一层是模型大小的 4 倍（由于 GPT-2 small 是 768，因此这个网络会有3072个神经元）。</p><p><img src="/img/ai/datawhale/transformer/4-full.gif" alt="全连接层"></p><p>没有展示 bias 向量</p><p><code>第 2 层. 把向量映射到模型的维度</code></p><p>第 2 层把第一层得到的结果映射回模型的维度（在 GPT-2 small 中是 768）。这个相乘的结果是 Transformer 对这个 token 的输出。</p><p><img src="/img/ai/datawhale/transformer/4-full.webp" alt="全连接层"></p><p>没有展示 bias 向量</p><p>总结一下，我们的输入会遇到下面这些权重矩阵：</p><p><img src="/img/ai/datawhale/transformer/4-sum.png" alt="总结"></p><p>每个模块都有它自己的权重。另一方面，模型只有一个 token embedding 矩阵和一个位置编码矩阵。</p><p><img src="/img/ai/datawhale/transformer/4-sum1.png" alt="总结"></p><p>如果你想查看模型的所有参数，我在这里对它们进行了统计：</p><p><img src="/img/ai/datawhale/transformer/4-sum2.png" alt="总结"><br>由于某些原因，它们加起来是 124 M，而不是 117 M。我不确定这是为什么，但这个就是在发布的代码中展示的大小（如果我错了，请纠正我）。</p><h2 id="语言模型应用"><a href="#语言模型应用" class="headerlink" title="语言模型应用"></a>语言模型应用</h2><p>只有 Decoder 的 Transformer 在语言模型之外一直展现出不错的效果。它已经被成功应用在了许多应用中，我们可以用类似上面的可视化来描述这些成功应用。让我们看看这些应用，作为这篇文章的结尾。</p><h3 id="机器翻译"><a href="#机器翻译" class="headerlink" title="机器翻译"></a>机器翻译</h3><p>进行机器翻译时，Encoder 不是必须的。我们可以用只有 Decoder 的 Transformer 来解决同样的任务：</p><p><img src="/img/ai/datawhale/transformer/4-trans.png" alt="翻译"></p><h3 id="生成摘要"><a href="#生成摘要" class="headerlink" title="生成摘要"></a>生成摘要</h3><p>这是第一个只使用 Decoder 的 Transformer 来训练的任务。它被训练用于阅读一篇维基百科的文章（目录前面去掉了开头部分），然后生成摘要。文章的实际开头部分用作训练数据的标签：<br><img src="/img/ai/datawhale/transformer/4-wiki.png" alt="摘要"></p><p>论文里针对维基百科的文章对模型进行了训练，因此这个模型能够总结文章，生成摘要：</p><p><img src="/img/ai/datawhale/transformer/4-wiki1.webp" alt="摘要">图</p><h3 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h3><p>在 Sample Efficient Text Summarization Using a Single Pre-Trained Transformer(<a href="https://arxiv.org/abs/1905.08836">https://arxiv.org/abs/1905.08836</a>) 中，一个只有 Decoder 的 Transformer 首先在语言模型上进行预训练，然后微调进行生成摘要。结果表明，在数据量有限制时，它比预训练的 Encoder-Decoder Transformer 能够获得更好的结果。</p><p>GPT-2 的论文也展示了在语言模型进行预训练的生成摘要的结果。</p><h3 id="音乐生成"><a href="#音乐生成" class="headerlink" title="音乐生成"></a>音乐生成</h3><p>Music Transformer(<a href="https://magenta.tensorflow.org/music-transformer">https://magenta.tensorflow.org/music-transformer</a>) 论文使用了只有 Decoder 的 Transformer 来生成具有表现力的时序和动态性的音乐。音乐建模 就像语言建模一样，只需要让模型以无监督的方式学习音乐，然后让它采样输出（前面我们称这个为 漫步）。</p><p>你可能会好奇在这个场景中，音乐是如何表现的。请记住，语言建模可以把字符、单词、或者单词的一部分（token），表示为向量。在音乐表演中（让我们考虑一下钢琴），我们不仅要表示音符，还要表示速度–衡量钢琴键被按下的力度。</p><p><img src="/img/ai/datawhale/transformer/4-music.webp" alt="音乐生成"></p><p>一场表演就是一系列的 one-hot 向量。一个 midi 文件可以转换为下面这种格式。论文里使用了下面这种输入序列作为例子：</p><p><img src="/img/ai/datawhale/transformer/4-music1.png" alt="音乐生成"></p><p>这个输入系列的 one-hot 向量表示如下：</p><p><img src="/img/ai/datawhale/transformer/4-music2.png" alt="音乐生成"></p><p>我喜欢论文中的音乐 Transformer 展示的一个 Self Attention 的可视化。我在这基础之上添加了一些注释：</p><p><img src="/img/ai/datawhale/transformer/4-music3.png" alt="音乐生成"></p><p>这段音乐有一个反复出现的三角形轮廓。Query 矩阵位于后面的一个峰值，它注意到前面所有峰值的高音符，以知道音乐的开头。这幅图展示了一个 Query 向量（所有 attention 线的来源）和前面被关注的记忆（那些受到更大的softmax 概率的高亮音符）。attention 线的颜色对应不同的 attention heads，宽度对应于 softmax 概率的权重。</p><h2 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h2><p>现在，我们结束了 GPT-2 的旅程，以及对其父模型（只有 Decoder 的 Transformer）的探索。我希望你看完这篇文章后，能对 Self Attention 有一个更好的理解，也希望你能对 Transformer 内部发生的事情有更多的理解。</p><h1 id="附加资料"><a href="#附加资料" class="headerlink" title="附加资料"></a>附加资料</h1><ul><li><a href="https://arxiv.org/abs/1706.03762">《Attention Is All You Need》</a></li><li><a href="https://ai.googleblog.com/2017/08/transformer-novel-neural-network.html">《Transformer: A Novel Neural Network Architecture for Language Understanding》</a></li><li><a href="https://ai.googleblog.com/2017/06/accelerating-deep-learning-research.html">《Tensor2Tensor announcement》</a></li><li><a href="https://www.youtube.com/watch?v=rBCqOTEfxvg">视频 Łukasz Kaiser’s talk来理解模型和其中的细节</a></li><li><a href="https://colab.research.google.com/github/tensorflow/tensor2tensor/blob/master/tensor2tensor/notebooks/hello_t2t.ipynb%E3%80%82">代码 Jupyter Notebook provided as part of the Tensor2Tensor repo</a></li><li><a href="https://github.com/tensorflow/tensor2tensor">Tensor2Tensor repo</a></li></ul><h2 id="更多"><a href="#更多" class="headerlink" title="更多"></a>更多</h2><ul><li><a href="https://blog.roboflow.com/what-is-a-transformer/">What is a Transformer?</a></li><li><a href="https://towardsdatascience.com/transformers-141e32e69591">How Transformers Work</a></li><li><a href="https://vectorize.io/what-is-a-transformer-in-gen-ai/">What is a transformer in gen AI?</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>AMD GPU KMD 代码分析</title>
    <link href="/2024/08/19/amdgpu-kmd/"/>
    <url>/2024/08/19/amdgpu-kmd/</url>
    
    <content type="html"><![CDATA[<p>地址：<a href="https://github.com/ROCm/ROCK-Kernel-Driver">https://github.com/ROCm/ROCK-Kernel-Driver</a></p><span id="more"></span><h2 id="驱动"><a href="#驱动" class="headerlink" title="驱动"></a>驱动</h2><p><a href="/img/gpu/amd/amdgpu_load.xmind">Total Xmind</a></p><details><summary>流程示意图</summary><pre><code class=" mermaid">flowchart TB    amdgpu_driver_load_kms --&gt; amdgpu_device_init --&gt;  amdgpu_device_ip_early_init    subgraph amdgpu_device_ip_early_init        direction TB        amdgpu_discovery_set_ip_blocks --&gt; amdgpu_amdkfd_device_probe        amdgpu_amdkfd_device_probe --&gt; early_init        subgraph early_init            direction TB            uvd_v7_0_early_init  --&gt; ... --&gt; vce_v4_0_early_init        end    end    amdgpu_device_init --&gt; amdgpu_device_ip_init        amdgpu_device_ip_init --&gt; sw_init    subgraph sw_init        direction TB        gmc_v9_0_sw_init --&gt; gmc_v9_0_mc_init --&gt; amdgpu_bo_init --&gt; gmc_v9_0_gart_init --&gt; vega20_ih_sw_init --&gt; psp_sw_init --&gt; pp_sw_init --&gt; gfx_v9_0_sw_init --&gt; uvd_v7_0_sw_init --&gt; vce_v4_0_sw_init    end    amdgpu_device_ip_init --&gt; hw_init    subgraph hw_init        direction TB        gmc_v9_0_hw_init --&gt; psp_hw_init --&gt; dm_hw_init --&gt; gfx_v9_0_hw_init --&gt; sdma_v4_0_hw_init --&gt; vce_v4_0_hw_init    end    amdgpu_device_ip_init --&gt; amdgpu_amdkfd_device_init --&gt; kgd2kfd_device_init    subgraph kgd2kfd_device_init        direction TB        kfd_gtt_sa_init --&gt; kfd_doorbell_init --&gt; device_queue_manager_init    end    amdgpu_device_init --&gt; amdgpu_device_ip_late_init</code></pre></details>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-28ab9646" role="button" aria-expanded="false" aria-controls="collapse-28ab9646">        <div class="fold-arrow">▶</div>AMD GPU kmd load function and log      </div>      <div class="fold-collapse collapse" id="collapse-28ab9646">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br><span class="line">189</span><br><span class="line">190</span><br><span class="line">191</span><br><span class="line">192</span><br><span class="line">193</span><br><span class="line">194</span><br><span class="line">195</span><br><span class="line">196</span><br><span class="line">197</span><br><span class="line">198</span><br><span class="line">199</span><br><span class="line">200</span><br><span class="line">201</span><br><span class="line">202</span><br><span class="line">203</span><br><span class="line">204</span><br><span class="line">205</span><br><span class="line">206</span><br><span class="line">207</span><br><span class="line">208</span><br><span class="line">209</span><br><span class="line">210</span><br><span class="line">211</span><br><span class="line">212</span><br><span class="line">213</span><br><span class="line">214</span><br><span class="line">215</span><br><span class="line">216</span><br><span class="line">217</span><br><span class="line">218</span><br><span class="line">219</span><br><span class="line">220</span><br><span class="line">221</span><br><span class="line">222</span><br><span class="line">223</span><br><span class="line">224</span><br><span class="line">225</span><br><span class="line">226</span><br><span class="line">227</span><br><span class="line">228</span><br><span class="line">229</span><br><span class="line">230</span><br><span class="line">231</span><br><span class="line">232</span><br><span class="line">233</span><br><span class="line">234</span><br><span class="line">235</span><br><span class="line">236</span><br><span class="line">237</span><br><span class="line">238</span><br><span class="line">239</span><br><span class="line">240</span><br><span class="line">241</span><br><span class="line">242</span><br><span class="line">243</span><br><span class="line">244</span><br><span class="line">245</span><br><span class="line">246</span><br><span class="line">247</span><br><span class="line">248</span><br><span class="line">249</span><br><span class="line">250</span><br><span class="line">251</span><br><span class="line">252</span><br><span class="line">253</span><br><span class="line">254</span><br><span class="line">255</span><br><span class="line">256</span><br><span class="line">257</span><br><span class="line">258</span><br><span class="line">259</span><br><span class="line">260</span><br><span class="line">261</span><br><span class="line">262</span><br><span class="line">263</span><br><span class="line">264</span><br><span class="line">265</span><br><span class="line">266</span><br><span class="line">267</span><br><span class="line">268</span><br><span class="line">269</span><br><span class="line">270</span><br><span class="line">271</span><br><span class="line">272</span><br><span class="line">273</span><br><span class="line">274</span><br><span class="line">275</span><br><span class="line">276</span><br><span class="line">277</span><br><span class="line">278</span><br><span class="line">279</span><br><span class="line">280</span><br><span class="line">281</span><br><span class="line">282</span><br><span class="line">283</span><br><span class="line">284</span><br><span class="line">285</span><br><span class="line">286</span><br><span class="line">287</span><br><span class="line">288</span><br><span class="line">289</span><br><span class="line">290</span><br><span class="line">291</span><br><span class="line">292</span><br><span class="line">293</span><br><span class="line">294</span><br><span class="line">295</span><br><span class="line">296</span><br><span class="line">297</span><br><span class="line">298</span><br><span class="line">299</span><br><span class="line">300</span><br><span class="line">301</span><br><span class="line">302</span><br><span class="line">303</span><br><span class="line">304</span><br><span class="line">305</span><br><span class="line">306</span><br><span class="line">307</span><br><span class="line">308</span><br><span class="line">309</span><br><span class="line">310</span><br><span class="line">311</span><br><span class="line">312</span><br><span class="line">313</span><br><span class="line">314</span><br><span class="line">315</span><br><span class="line">316</span><br><span class="line">317</span><br><span class="line">318</span><br><span class="line">319</span><br><span class="line">320</span><br><span class="line">321</span><br><span class="line">322</span><br><span class="line">323</span><br><span class="line">324</span><br><span class="line">325</span><br><span class="line">326</span><br><span class="line">327</span><br><span class="line">328</span><br><span class="line">329</span><br><span class="line">330</span><br><span class="line">331</span><br><span class="line">332</span><br><span class="line">333</span><br><span class="line">334</span><br><span class="line">335</span><br><span class="line">336</span><br><span class="line">337</span><br><span class="line">338</span><br><span class="line">339</span><br><span class="line">340</span><br><span class="line">341</span><br><span class="line">342</span><br><span class="line">343</span><br><span class="line">344</span><br><span class="line">345</span><br><span class="line">346</span><br><span class="line">347</span><br><span class="line">348</span><br><span class="line">349</span><br><span class="line">350</span><br><span class="line">351</span><br><span class="line">352</span><br><span class="line">353</span><br><span class="line">354</span><br><span class="line">355</span><br><span class="line">356</span><br><span class="line">357</span><br><span class="line">358</span><br><span class="line">359</span><br><span class="line">360</span><br><span class="line">361</span><br><span class="line">362</span><br><span class="line">363</span><br><span class="line">364</span><br><span class="line">365</span><br><span class="line">366</span><br><span class="line">367</span><br><span class="line">368</span><br><span class="line">369</span><br><span class="line">370</span><br><span class="line">371</span><br><span class="line">372</span><br><span class="line">373</span><br><span class="line">374</span><br><span class="line">375</span><br><span class="line">376</span><br><span class="line">377</span><br><span class="line">378</span><br><span class="line">379</span><br><span class="line">380</span><br><span class="line">381</span><br><span class="line">382</span><br><span class="line">383</span><br><span class="line">384</span><br><span class="line">385</span><br><span class="line">386</span><br><span class="line">387</span><br><span class="line">388</span><br><span class="line">389</span><br><span class="line">390</span><br><span class="line">391</span><br><span class="line">392</span><br><span class="line">393</span><br><span class="line">394</span><br><span class="line">395</span><br><span class="line">396</span><br><span class="line">397</span><br><span class="line">398</span><br><span class="line">399</span><br><span class="line">400</span><br><span class="line">401</span><br><span class="line">402</span><br><span class="line">403</span><br><span class="line">404</span><br><span class="line">405</span><br><span class="line">406</span><br><span class="line">407</span><br><span class="line">408</span><br><span class="line">409</span><br><span class="line">410</span><br><span class="line">411</span><br><span class="line">412</span><br><span class="line">413</span><br><span class="line">414</span><br><span class="line">415</span><br><span class="line">416</span><br><span class="line">417</span><br><span class="line">418</span><br><span class="line">419</span><br><span class="line">420</span><br><span class="line">421</span><br><span class="line">422</span><br><span class="line">423</span><br><span class="line">424</span><br><span class="line">425</span><br><span class="line">426</span><br><span class="line">427</span><br><span class="line">428</span><br><span class="line">429</span><br><span class="line">430</span><br><span class="line">431</span><br><span class="line">432</span><br><span class="line">433</span><br><span class="line">434</span><br><span class="line">435</span><br><span class="line">436</span><br><span class="line">437</span><br><span class="line">438</span><br><span class="line">439</span><br><span class="line">440</span><br><span class="line">441</span><br><span class="line">442</span><br><span class="line">443</span><br><span class="line">444</span><br></pre></td><td class="code"><pre><code class="hljs c">amd/amdgpu/amdgpu_drv.c: amdgpu_init()<br>[<span class="hljs-number">22906.629931</span>] [drm] amdgpu kernel modesetting enabled.<br>[<span class="hljs-number">22906.629932</span>] [drm] amdgpu test <span class="hljs-keyword">for</span> PM4 packet version: <span class="hljs-number">5.18</span><span class="hljs-number">.13</span><br>[<span class="hljs-number">22906.629932</span>] [drm] OS DRM version: <span class="hljs-number">5.4</span><span class="hljs-number">.0</span><br>--&gt; amdgpu_register_atpx_handler()<br>--&gt; amdgpu_acpi_detect()<br>--&gt; amd/amdgpu/amdgpu_amdkfd.c: amdgpu_amdkfd_init()<br>    --&gt; amd/amdkfd/kfd_module.c: kgd2kfd_init()<br>        --&gt; &lt;<span class="hljs-keyword">if</span> <span class="hljs-title function_">IS_ENABLED</span><span class="hljs-params">(CONFIG_HSA_AMD)</span>&gt;: amd/amdkfd/kfd_module.c: <span class="hljs-title function_">kfd_init</span><span class="hljs-params">()</span><br>            --&gt; amd/amdkfd/kfd_chardev.c: <span class="hljs-title function_">kfd_chardev_init</span><span class="hljs-params">()</span><br>                --&gt; <span class="hljs-title function_">register_chrdev</span><span class="hljs-params">(<span class="hljs-number">0</span>, kfd_dev_name, &amp;kfd_fops)</span><br>                --&gt; <span class="hljs-title function_">class_create</span><span class="hljs-params">(THIS_MODULE, kfd_dev_name)</span><br>                --&gt; <span class="hljs-title function_">device_create</span><span class="hljs-params">(kfd_class, <span class="hljs-literal">NULL</span>, MKDEV(kfd_char_dev_major, <span class="hljs-number">0</span>), <span class="hljs-literal">NULL</span>, kfd_dev_name)</span><br>            --&gt; amd/amdkfd/kfd_topology.c: <span class="hljs-title function_">kfd_topology_init</span><span class="hljs-params">()</span><br>                --&gt; &lt;<span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> CONFIG_ACPI&gt;: ret = kfd_create_crat_image_acpi(&amp;crat_image, &amp;image_size)</span><br>                    [22906.630016] amdgpu: CRAT table not found<br>                --&gt; amd/amdkfd/kfd_crat.c: <span class="hljs-title function_">kfd_create_crat_image_virtual</span><span class="hljs-params">(&amp;crat_image, &amp;image_size, COMPUTE_UNIT_CPU, <span class="hljs-literal">NULL</span>, proximity_domain)</span><br>                    [22906.630017] [244191] amdgpu: CRAT size is 128<br>                    --&gt; amd/amdkfd/kfd_crat.c: <span class="hljs-title function_">kfd_create_vcrat_image_cpu</span><span class="hljs-params">(pcrat_image, size)</span><br>                        [22906.630018] amdgpu: Virtual CRAT table created <span class="hljs-keyword">for</span> CPU<br>                --&gt; amd/amdkfd/kfd_crat.c: <span class="hljs-title function_">kfd_parse_crat_table</span><span class="hljs-params">(crat_image, &amp;temp_topology_device_list, proximity_domain)</span><br>                    [22906.630019] [244191] amdgpu: Parsing CRAT table with 1 nodes<br>                    --&gt; <span class="hljs-title function_">kfd_parse_subtype</span><span class="hljs-params">()</span><br>                        --&gt; <span class="hljs-title function_">kfd_parse_subtype_cu</span><span class="hljs-params">()</span><br>                            [22906.630019] [244191] amdgpu: Found CU entry in CRAT table with proximity_domain=<span class="hljs-number">0</span> caps=<span class="hljs-number">0</span><br>                            --&gt; kfd_populated_cu_info_cpu()<br>                                [<span class="hljs-number">22906.630020</span>] [<span class="hljs-number">244191</span>] amdgpu: CU CPU: cores=<span class="hljs-number">12</span> id_base=<span class="hljs-number">0</span><br>                --&gt; kfd_debug_print_topology()<br>                    [<span class="hljs-number">22906.630027</span>] amdgpu: Topology: Add CPU node<br>            --&gt; kfd_ipc_init()<br>            --&gt; kfd_process_create_wq()<br>            --&gt; kfd_init_peer_direct()<br>                [<span class="hljs-number">22906.630082</span>] [<span class="hljs-number">244191</span>] amdgpu: Try to initialize PeerDirect support<br>                [<span class="hljs-number">22906.631966</span>] [<span class="hljs-number">244191</span>] amdgpu: PeerDirect interface was not detected<br>            --&gt; kfd_procfs_init()<br>            --&gt; kfd_debugfs_init()<br>            --&gt; &lt;<span class="hljs-meta">#<span class="hljs-keyword">ifndef</span> DEFINE_SRCU&gt;: kfd_init_processes_srcu()</span><br>    --&gt; amdgpu_amdkfd_gpuvm_init_mem_limits()<br>        [<span class="hljs-number">22906.631979</span>] [<span class="hljs-number">244191</span>] amdgpu: Kernel memory limit <span class="hljs-number">12427</span>M, TTM limit <span class="hljs-number">4971</span>M<br>--&gt; pci_register_driver(&amp;amdgpu_kms_pci_driver)<br> <br> <br> <br> <br> <br><span class="hljs-type">static</span> <span class="hljs-keyword">struct</span> pci_driver amdgpu_kms_pci_driver = &#123;<br>    .name = DRIVER_NAME,<br>    .id_table = pciidlist,<br>    .probe = amdgpu_pci_probe,<br>    .remove = amdgpu_pci_remove,<br>    .shutdown = amdgpu_pci_shutdown,<br>    .driver.pm = &amp;amdgpu_pm_ops,<br>    .err_handler = &amp;amdgpu_pci_err_handler,<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> HAVE_PCI_DRIVER_DEV_GROUPS</span><br>    .dev_groups = amdgpu_sysfs_groups,<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>&#125;;<br> <br> <br>amd/amdgpu/amdgpu_drv.c: amdgpu_pci_probe()<br>--&gt; drm_aperture_remove_conflicting_pci_framebuffers()<br>    --&gt; _kcl_remove_conflicting_pci_framebuffers()<br>        --&gt; remove_conflicting_pci_framebuffers()<br>            [<span class="hljs-number">22906.632001</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: remove_conflicting_pci_framebuffers: bar <span class="hljs-number">0</span>: <span class="hljs-number">0x2400000000</span> -&gt; <span class="hljs-number">0x27ffffffff</span><br>            [<span class="hljs-number">22906.632001</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: remove_conflicting_pci_framebuffers: bar <span class="hljs-number">2</span>: <span class="hljs-number">0x2200000000</span> -&gt; <span class="hljs-number">0x22001fffff</span><br>            [<span class="hljs-number">22906.632002</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: remove_conflicting_pci_framebuffers: bar <span class="hljs-number">5</span>: <span class="hljs-number">0xf7b00000</span> -&gt; <span class="hljs-number">0xf7b7ffff</span><br>--&gt; ...<br>--&gt; amd/amdgpu/amdgpu_kms.c: amdgpu_driver_load_kms()<br>    --&gt; amd/amdgpu/amdgpu_device.c: amdgpu_device_init()<br>        [<span class="hljs-number">22906.632089</span>] [drm] initializing kernel <span class="hljs-title function_">modesetting</span> <span class="hljs-params">(VEGA20 <span class="hljs-number">0x1002</span>:<span class="hljs-number">0x66AF</span> <span class="hljs-number">0x1002</span>:<span class="hljs-number">0x081E</span> <span class="hljs-number">0xC1</span>)</span>.<br>        [22906.632099] [drm] <span class="hljs-keyword">register</span> mmio base: 0xF7B00000<br>        [22906.632100] [drm] <span class="hljs-keyword">register</span> mmio size: 524288<br>        --&gt; <span class="hljs-title function_">amdgpu_device_ip_early_init</span><span class="hljs-params">()</span><br>            --&gt; <span class="hljs-title function_">amdgpu_discovery_set_ip_blocks</span><span class="hljs-params">()</span><br>                --&gt; <span class="hljs-title function_">amdgpu_discovery_set_common_ip_blocks</span><span class="hljs-params">()</span><br>                --&gt; ...<br>                --&gt; <span class="hljs-title function_">amdgpu_discovery_set_sdma_ip_blocks</span><span class="hljs-params">()</span><br>                    --&gt; <span class="hljs-title function_">amdgpu_device_ip_block_add</span><span class="hljs-params">(adev, &amp;sdma_v4_0_ip_block)</span><br>                --&gt; <span class="hljs-title function_">amdgpu_discovery_set_mm_ip_blocks</span><span class="hljs-params">()</span><br>                    --&gt; <span class="hljs-title function_">amdgpu_device_ip_block_add</span><span class="hljs-params">(adev, &amp;uvd_v7_0_ip_block)</span>;<br>                --&gt; amdgpu_discovery_set_mes_ip_blocks()<br>                    --&gt; amdgpu_device_ip_block_add()<br>                        [<span class="hljs-number">22906.632143</span>] [drm] add ip block number <span class="hljs-number">0</span> &lt;soc15_common&gt;<br>                        [<span class="hljs-number">22906.632143</span>] [drm] add ip block number <span class="hljs-number">1</span> &lt;gmc_v9_0&gt;<br>                        [<span class="hljs-number">22906.632144</span>] [drm] add ip block number <span class="hljs-number">2</span> &lt;vega20_ih&gt;<br>                        [<span class="hljs-number">22906.632144</span>] [drm] add ip block number <span class="hljs-number">3</span> &lt;psp&gt;<br>                        [<span class="hljs-number">22906.632144</span>] [drm] add ip block number <span class="hljs-number">4</span> &lt;powerplay&gt;<br>                        [<span class="hljs-number">22906.632145</span>] [drm] add ip block number <span class="hljs-number">5</span> &lt;dm&gt;<br>                        [<span class="hljs-number">22906.632145</span>] [drm] add ip block number <span class="hljs-number">6</span> &lt;gfx_v9_0&gt;<br>                        [<span class="hljs-number">22906.632146</span>] [drm] add ip block number <span class="hljs-number">7</span> &lt;sdma_v4_0&gt;<br>                        [<span class="hljs-number">22906.632146</span>] [drm] add ip block number <span class="hljs-number">8</span> &lt;uvd_v7_0&gt;<br>                        [<span class="hljs-number">22906.632147</span>] [drm] add ip block number <span class="hljs-number">9</span> &lt;vce_v4_0&gt;<br>            --&gt; amdgpu_amdkfd_device_probe() ★<br>            --&gt; adev-&gt;ip_blocks[i].version-&gt;funcs-&gt;early_init()<br>                --&gt; uvd_v7_0_ip_funcs.early_init() = uvd_v7_0_early_init()<br>                    --&gt; uvd_v7_0_set_ring_funcs()<br>                        [<span class="hljs-number">22906.726994</span>] [drm] UVD(<span class="hljs-number">0</span>) is enabled in VM mode<br>                        [<span class="hljs-number">22906.726995</span>] [drm] UVD(<span class="hljs-number">1</span>) is enabled in VM mode<br>                        uvd_v7_0_set_enc_ring_funcs()<br>                        [<span class="hljs-number">22906.726995</span>] [drm] UVD(<span class="hljs-number">0</span>) ENC is enabled in VM mode<br>                        [<span class="hljs-number">22906.726995</span>] [drm] UVD(<span class="hljs-number">1</span>) ENC is enabled in VM mode<br>                --&gt; vce_v4_0_ip_funcs.early_init() = vce_v4_0_early_init()<br>                    --&gt; vce_v4_0_set_ring_funcs()<br>                        [<span class="hljs-number">22906.726996</span>] [drm] VCE enabled in VM mode<br>            --&gt; amdgpu_get_bios()<br>                [<span class="hljs-number">22906.726968</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: Fetched VBIOS from ROM BAR<br>            --&gt; amdgpu_atombios_init()<br>                --&gt; amdgpu_atom_parse()<br>                [<span class="hljs-number">22906.726969</span>] amdgpu: ATOM BIOS: <span class="hljs-number">113</span>-D3600200<span class="hljs-number">-106</span><br>        --&gt; amdgpu_gmc_tmz_set()<br>            [<span class="hljs-number">22906.726996</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: Trusted Memory Zone (TMZ) feature not supported<br>        --&gt; amdgpu_device_doorbell_init()<br>        --&gt; amdgpu_device_ip_init()<br>            --&gt; amdgpu_ras_init()<br>                --&gt; amdgpu_ras_check_supported()<br>                    [<span class="hljs-number">22906.727016</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: MEM ECC is not presented.<br>                    [<span class="hljs-number">22906.727016</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: SRAM ECC is not presented.<br>                [<span class="hljs-number">22906.727019</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: RAS INFO: ras initialized successfully, hardware ability[<span class="hljs-number">4</span>] ras_mask[<span class="hljs-number">4</span>]<br>            --&gt; adev-&gt;ip_blocks[i].version-&gt;funcs-&gt;sw_init((<span class="hljs-type">void</span> *)adev)<br>                gmc_v9_0_ip_funcs.sw_init = gmc_v9_0_sw_init()<br>                --&gt; amdgpu_vm_adjust_size()<br>                    [<span class="hljs-number">22906.727024</span>] [drm] vm size is <span class="hljs-number">262144</span> GB, <span class="hljs-number">4</span> levels, block size is <span class="hljs-number">9</span>-bit, fragment size is <span class="hljs-number">9</span>-bit<br>                --&gt; gmc_v9_0_mc_init()<br>                    --&gt; gmc_v9_0_vram_gtt_location()<br>                        --&gt; amdgpu_gmc_vram_location(adev, mc, base);<br>                            [<span class="hljs-number">22906.727028</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: VRAM: <span class="hljs-number">16368</span>M <span class="hljs-number">0x0000008000000000</span> - <span class="hljs-number">0x00000083FEFFFFFF</span> (<span class="hljs-number">16368</span>M used)<br>                        --&gt; amdgpu_gmc_gart_location(adev, mc);<br>                            [<span class="hljs-number">22906.727028</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: GART: <span class="hljs-number">512</span>M <span class="hljs-number">0x0000000000000000</span> - <span class="hljs-number">0x000000001FFFFFFF</span><br>                        --&gt; amdgpu_gmc_agp_location(adev, mc);<br>                            [<span class="hljs-number">22906.727029</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: AGP: <span class="hljs-number">267894784</span>M <span class="hljs-number">0x0000008400000000</span> - <span class="hljs-number">0x0000FFFFFFFFFFFF</span><br>                --&gt; amdgpu_bo_init()<br>                        [<span class="hljs-number">22906.727033</span>] [drm] Detected VRAM RAM=<span class="hljs-number">16368</span>M, BAR=<span class="hljs-number">16384</span>M<br>                        [<span class="hljs-number">22906.727034</span>] [drm] RAM width <span class="hljs-number">4096b</span>its HBM\<br>                    --&gt; amdgpu_ttm_init()<br>                        [<span class="hljs-number">22906.730061</span>] [drm] amdgpu: <span class="hljs-number">16368</span>M of VRAM memory ready<br>                        [<span class="hljs-number">22906.730062</span>] [drm] amdgpu: <span class="hljs-number">15985</span>M of GTT memory ready.<br>                --&gt; gmc_v9_0_gart_init()<br>                    --&gt; amdgpu_gart_init()<br>                        [<span class="hljs-number">22906.730070</span>] [drm] GART: num cpu pages <span class="hljs-number">131072</span>, num gpu pages <span class="hljs-number">131072</span><br>                vega20_ih_ip_funcs.sw_init = vega20_ih_sw_init()<br>                --&gt; amdgpu_irq_init()<br>                    [<span class="hljs-number">22906.730197</span>] [<span class="hljs-number">244191</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: using MSI/MSI-X.<br>                psp_ip_funcs.sw_init = psp_sw_init()<br>                --&gt; psp_get_runtime_db_entry()<br>                    [<span class="hljs-number">22906.730299</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: PSP runtime database doesn<span class="hljs-number">&#x27;</span>t exist<br>                    [<span class="hljs-number">22906.730305</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: PSP runtime database doesn<span class="hljs-number">&#x27;</span>t exist<br>                pp_ip_funcs.sw_init = pp_sw_init()<br>                --&gt; hwmgr_sw_init()<br>                    [<span class="hljs-number">22906.730357</span>] amdgpu: [powerplay] hwmgr_sw_init smu backed is vega20_smu<br>                gfx_v9_0_ip_funcs.sw_init = gfx_v9_0_sw_init()<br>                --&gt; gfx_v9_0_mec_init()<br>                    --&gt; amdgpu_gfx_compute_queue_acquire()<br>                        [<span class="hljs-number">22906.730665</span>] [<span class="hljs-number">244191</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: mec <span class="hljs-built_in">queue</span> bitmap weight=<span class="hljs-number">8</span><br>                uvd_v7_0_ip_funcs.sw_init = uvd_v7_0_sw_init()<br>                --&gt; amdgpu_uvd_sw_init()<br>                    [<span class="hljs-number">22906.731269</span>] [drm] Found UVD firmware ENC: <span class="hljs-number">1.2</span> DEC: <span class="hljs-number">.43</span> Family ID: <span class="hljs-number">19</span><br>                [<span class="hljs-number">22906.731284</span>] [drm] PSP loading UVD firmware<br>                vce_v4_0_ip_funcs.sw_init = vce_v4_0_sw_init()<br>                --&gt; amdgpu_vce_sw_init()<br>                    [<span class="hljs-number">22906.732037</span>] [drm] Found VCE firmware Version: <span class="hljs-number">57.6</span> Binary ID: <span class="hljs-number">4</span><br>                [<span class="hljs-number">22906.732061</span>] [drm] PSP loading VCE firmware<br>            --&gt; adev-&gt;ip_blocks[i].version-&gt;funcs-&gt;hw_init((<span class="hljs-type">void</span> *)adev)<br>                gmc_v9_0_ip_funcs.hw_init = gmc_v9_0_hw_init()<br>                --&gt; gmc_v9_0_gart_enable()<br>                    [<span class="hljs-number">22906.730140</span>] [drm] PCIE GART of <span class="hljs-number">512</span>M enabled.<br>                    [<span class="hljs-number">22906.730140</span>] [drm] PTB located at <span class="hljs-number">0x0000008000000000</span><br> <br>                psp_ip_funcs.hw_init = psp_hw_init()<br>                --&gt; psp_load_fw()<br>                    --&gt; psp_hw_start()<br>                        --&gt; psp_tmr_load()<br>                            [<span class="hljs-number">22906.752341</span>] [drm] reserve <span class="hljs-number">0x400000</span> from <span class="hljs-number">0x83fec00000</span> <span class="hljs-keyword">for</span> PSP TMR<br>                    --&gt; psp_hdcp_initialize()<br>                        [<span class="hljs-number">22906.886713</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: HDCP: optional hdcp ta ucode is not available<br>                    --&gt; psp_dtm_initialize()<br>                        [<span class="hljs-number">22906.886716</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: DTM: optional dtm ta ucode is not available<br>                    --&gt; psp_rap_initialize()<br>                        [<span class="hljs-number">22906.886719</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: RAP: optional rap ta ucode is not available<br>                    --&gt; psp_securedisplay_initialize()<br>                        [<span class="hljs-number">22906.886721</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: SECUREDISPLAY: securedisplay ta ucode is not available<br> <br>                amdgpu_dm_funcs.hw_init = dm_hw_init()<br>                --&gt; amdgpu_dm_init()<br>                    --&gt; dc_create(&amp;init_data)<br>                        --&gt; dc_construct(dc, init_params)<br>                            --&gt; dc_clk_mgr_create(dc-&gt;ctx, dc-&gt;res_pool-&gt;pp_smu, dc-&gt;res_pool-&gt;dccg)<br>                                --&gt; dceXXX_clk_mgr_construct()<br>                                    --&gt; ...<br>                                    --&gt; vbios_funcs.get_spread_spectrum_info = bios_parser_get_spread_spectrum_info()<br>                                    --&gt; get_ss_info_v4_1()<br>                                        [<span class="hljs-number">22906.890253</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:gpuclk_ss_percentage (unit of <span class="hljs-number">0.001</span> percent): <span class="hljs-number">0</span><br>                                        [<span class="hljs-number">22906.890388</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:AS_SIGNAL_TYPE_DISPLAY_PORT ss_percentage: <span class="hljs-number">450</span><br>                            --&gt; create_links(dc, init_params-&gt;num_virtual_links)<br>                                --&gt; link_create()<br>                                    --&gt; dc_link_construct(link, init_params))<br>                                        --&gt; dc_link_construct_legacy()<br>                                            --&gt; link-&gt;dc-&gt;res_pool-&gt;funcs-&gt;link_enc_create(dc_ctx, &amp;enc_init_data)<br>                                                .link_enc_create = dceXXX_link_encoder_create<br>                                                --&gt; dceXXX_link_encoder_construct()<br>                                                    --&gt; bp_funcs-&gt;get_encoder_cap_info(enc110-&gt;base.ctx-&gt;dc_bios, enc110-&gt;base.id, &amp;bp_cap_info)<br>                                                        vbios_funcs.get_encoder_cap_info = bios_parser_get_encoder_cap_info()<br>                                                        bios_parser_get_encoder_cap_info()<br>                                                        [<span class="hljs-number">22906.890474</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:record-&gt;encodercaps <span class="hljs-number">0xf</span> <span class="hljs-keyword">for</span> object_id <span class="hljs-number">0xd</span><br>                                                        [<span class="hljs-number">22906.890476</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:  info-&gt;DP_IS_USB_C <span class="hljs-number">0</span><br>                                                        [<span class="hljs-number">22906.890501</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:record-&gt;encodercaps <span class="hljs-number">0xf</span> <span class="hljs-keyword">for</span> object_id <span class="hljs-number">0xf</span><br>                                                        [<span class="hljs-number">22906.890503</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:  info-&gt;DP_IS_USB_C <span class="hljs-number">0</span><br>                                                        [<span class="hljs-number">22906.890527</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:record-&gt;encodercaps <span class="hljs-number">0xf</span> <span class="hljs-keyword">for</span> object_id <span class="hljs-number">0xf</span><br>                                                        [<span class="hljs-number">22906.890529</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:  info-&gt;DP_IS_USB_C <span class="hljs-number">0</span><br>                                                        [<span class="hljs-number">22906.890553</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:record-&gt;encodercaps <span class="hljs-number">0xf</span> <span class="hljs-keyword">for</span> object_id <span class="hljs-number">0xd</span><br>                                                        [<span class="hljs-number">22906.890555</span>] [<span class="hljs-number">244191</span>] amdgpu: [BIOS]:  info-&gt;DP_IS_USB_C <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22906.890570</span>] [drm] Display Core initialized with v3<span class="hljs-number">.2</span><span class="hljs-number">.212</span>!<br> <br>                gfx_v9_0_ip_funcs.hw_init = gfx_v9_0_hw_init()<br>                --&gt; gfx_v9_0_cp_resume()<br>                    --&gt; gfx_v9_0_kcq_resume()<br>                        --&gt; amdgpu_gfx_enable_kcq()<br>                            [<span class="hljs-number">22906.894733</span>] [drm] kiq ring mec <span class="hljs-number">2</span> pipe <span class="hljs-number">1</span> q <span class="hljs-number">0</span><br> <br>                sdma_v4_0_ip_funcs.hw_init = sdma_v4_0_hw_init()<br>                --&gt; amdgpu_dpm_set_powergating_by_smu()<br>                    --&gt; p_dpm_funcs.set_powergating_by_smu = pp_set_powergating_by_smu()<br>                        --&gt; pp_dpm_powergate_uvd()<br>                            --&gt; <span class="hljs-keyword">if</span> (hwmgr-&gt;hwmgr_func-&gt;powergate_uvd == <span class="hljs-literal">NULL</span>)<br>                                vega20_hwmgr_funcs.powergate_uvd = vega20_power_gate_uvd()<br>                                vega20_power_gate_uvd()<br>                                --&gt; vega20_enable_disable_uvd_dpm()<br>                                    [<span class="hljs-number">22906.936879</span>] [<span class="hljs-number">244191</span>] amdgpu: [powerplay] [EnableDisableUVDDPM] feature DPM UVD already enabled!<br>                uvd_v6_0_ip_funcs.hw_init = uvd_v6_0_hw_init()<br>                [<span class="hljs-number">22906.937023</span>] [drm] UVD and UVD ENC initialized successfully.<br> <br>                <span class="hljs-comment">// --&gt; amdgpu_dpm_set_powergating_by_smu()</span><br>                <span class="hljs-comment">//     --&gt; p_dpm_funcs.set_powergating_by_smu = pp_set_powergating_by_smu()</span><br>                <span class="hljs-comment">//         --&gt; pp_dpm_powergate_vce()</span><br>                <span class="hljs-comment">//             --&gt; vega20_hwmgr_funcs.powergate_vce = vega20_power_gate_vce()</span><br>                <span class="hljs-comment">//                 --&gt; vega20_enable_disable_vce_dpm()</span><br>                <span class="hljs-comment">//                     [22907.135666] [244191] amdgpu: [powerplay] [EnableDisableVCEDPM] feature VCE DPM already enabled!</span><br>                vce_v4_0_ip_funcs.hw_init = vce_v4_0_hw_init()<br>                [<span class="hljs-number">22907.135956</span>] [drm] VCE initialized successfully.<br> <br>                <span class="hljs-comment">// smu_v11_0_i2c_algo.master_xfer = smu_v11_0_i2c_xfer</span><br>                <span class="hljs-comment">// smu_v11_0_i2c_xfer()</span><br>                <span class="hljs-comment">//     smu_v11_0_i2c_write_data()</span><br>                <span class="hljs-comment">//         smu_v11_0_i2c_transmit()</span><br>                <span class="hljs-comment">//             smu_v11_0_i2c_poll_tx_status()</span><br>                <span class="hljs-comment">//             [22907.141263] [drm] TX was terminated, IC_TX_ABRT_SOURCE val is:1000001</span><br>                <span class="hljs-comment">//         [22907.141357] [drm:smu_v11_0_i2c_xfer.cold [amdgpu]] *ERROR* Received I2C_NAK_7B_ADDR_NOACK !!!</span><br>                <span class="hljs-comment">//     [22907.141410] [drm:smu_v11_0_i2c_xfer [amdgpu]] *ERROR* WriteI2CData() - I2C error occurred :1</span><br> <br>            --&gt; amdgpu_ras_recovery_init()<br>                --&gt; amdgpu_ras_eeprom_init()<br>                    [<span class="hljs-number">22907.142252</span>] [drm:amdgpu_ras_eeprom_init [amdgpu]] *ERROR* Failed to read EEPROM table header, res:<span class="hljs-number">-5</span><br>                [<span class="hljs-number">22907.142811</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: Failed to initialize ras recovery! (<span class="hljs-number">-5</span>)<br>            --&gt; amdgpu_amdkfd_device_init()<br>                --&gt; kgd2kfd_device_init()<br>                    [<span class="hljs-number">22907.144489</span>] kfd kfd: amdgpu: Allocated <span class="hljs-number">3969056</span> bytes on gart<br>                    --&gt; kfd_gtt_sa_init()<br>                        [<span class="hljs-number">22907.144490</span>] [<span class="hljs-number">244191</span>] amdgpu: gtt_sa_num_of_chunks = <span class="hljs-number">7752</span>, gtt_sa_bitmap = <span class="hljs-number">000000005240393f</span><br>                    --&gt; kfd_doorbell_init()<br>                        [<span class="hljs-number">22907.144498</span>] [<span class="hljs-number">244191</span>] amdgpu: Doorbell initialization:<br>                        [<span class="hljs-number">22907.144499</span>] [<span class="hljs-number">244191</span>] amdgpu: doorbell base           == <span class="hljs-number">0x2200002000</span><br>                        [<span class="hljs-number">22907.144499</span>] [<span class="hljs-number">244191</span>] amdgpu: doorbell_base_dw_offset      == <span class="hljs-number">0x00000800</span><br>                        [<span class="hljs-number">22907.144499</span>] [<span class="hljs-number">244191</span>] amdgpu: doorbell_process_limit  == <span class="hljs-number">0x000000FF</span><br>                        [<span class="hljs-number">22907.144500</span>] [<span class="hljs-number">244191</span>] amdgpu: doorbell_kernel_offset  == <span class="hljs-number">0x2200002000</span><br>                        [<span class="hljs-number">22907.144500</span>] [<span class="hljs-number">244191</span>] amdgpu: doorbell aperture size  == <span class="hljs-number">0x00200000</span><br>                        [<span class="hljs-number">22907.144501</span>] [<span class="hljs-number">244191</span>] amdgpu: doorbell kernel address == <span class="hljs-number">00000000</span>ec5ee4d9<br>                    --&gt; device_queue_manager_init()<br>                        [<span class="hljs-number">22907.144543</span>] [<span class="hljs-number">244191</span>] amdgpu: Loading device <span class="hljs-built_in">queue</span> manager<br>                        --&gt; initialize_nocpsch()/initialize_cpsch()<br>                            [<span class="hljs-number">22907.144638</span>] [<span class="hljs-number">244191</span>] amdgpu: num of pipes: <span class="hljs-number">4</span><br>                            --&gt; init_sdma_bitmaps()<br>                                [<span class="hljs-number">22907.144638</span>] amdgpu: sdma_bitmap: ffff<br>                        --&gt; init_mqd_managers()<br>                            --&gt; asic_ops-&gt;mqd_manager_init = mqd_manager_init_v9()<br>                                mqd_manager_init_v9()<br>                                    mqd-&gt;load_mqd = kfd_hiq_load_mqd_kiq;<br>                                    kfd_hiq_load_mqd_kiq()<br>                                        gfx_v9_kfd2kgd.hiq_mqd_load = kgd_gfx_v9_hiq_mqd_load()<br>                        --&gt; dqm-&gt;ops.create_queue = create_queue_nocpsch;<br>                        --&gt; dqm-&gt;ops.start = start_cpsch;<br>                    --&gt; kfd_resume(kfd)<br>                        --&gt; kfd-&gt;dqm-&gt;ops.start(kfd-&gt;dqm)<br>                            <span class="hljs-comment">// dqm-&gt;ops.start = start_cpsch;</span><br>                            start_cpsch()<br>                            --&gt; pm_init()<br>                                --&gt; kernel_queue_init()<br>                                    --&gt; kq_initialize()<br>                                        [<span class="hljs-number">22907.144642</span>] [<span class="hljs-number">244191</span>] amdgpu: Initializing <span class="hljs-built_in">queue</span> type <span class="hljs-number">2</span> size <span class="hljs-number">2048</span><br>                                        --&gt; kfd_get_kernel_doorbell()<br>                                            [<span class="hljs-number">22907.144642</span>] [<span class="hljs-number">244191</span>] amdgpu: Get kernel <span class="hljs-built_in">queue</span> doorbell<br>                                                                doorbell offset   == <span class="hljs-number">0x00000800</span><br>                                                                doorbell index    == <span class="hljs-number">0x0</span><br>                                        --&gt; kfd_gtt_sa_allocate() * <span class="hljs-number">4</span><br>                                            [<span class="hljs-number">22907.144643</span>] [<span class="hljs-number">244191</span>] amdgpu: Allocated mem_obj = <span class="hljs-number">00000000</span>c6362840 <span class="hljs-keyword">for</span> size = <span class="hljs-number">2048</span><br>                                            [<span class="hljs-number">22907.144644</span>] [<span class="hljs-number">244191</span>] amdgpu: Found = <span class="hljs-number">0</span><br>                                            [<span class="hljs-number">22907.144644</span>] [<span class="hljs-number">244191</span>] amdgpu: gpu_addr = <span class="hljs-number">00000000</span>ef7ebed7, cpu_addr = <span class="hljs-number">0000000052309</span>c93<br>                                            [<span class="hljs-number">22907.144645</span>] [<span class="hljs-number">244191</span>] amdgpu: range_start = <span class="hljs-number">0</span>, range_end = <span class="hljs-number">3</span><br>                                            [<span class="hljs-number">22907.144645</span>] [<span class="hljs-number">244191</span>] amdgpu: Allocated mem_obj = <span class="hljs-number">000000007</span>ae05bdc <span class="hljs-keyword">for</span> size = <span class="hljs-number">4096</span><br>                                            [<span class="hljs-number">22907.144646</span>] [<span class="hljs-number">244191</span>] amdgpu: Found = <span class="hljs-number">4</span><br>                                            [<span class="hljs-number">22907.144646</span>] [<span class="hljs-number">244191</span>] amdgpu: gpu_addr = <span class="hljs-number">000000008</span>cbe4b16, cpu_addr = <span class="hljs-number">000000008</span>ec6d2d0<br>                                            [<span class="hljs-number">22907.144647</span>] [<span class="hljs-number">244191</span>] amdgpu: range_start = <span class="hljs-number">4</span>, range_end = <span class="hljs-number">11</span><br>                                            [<span class="hljs-number">22907.144647</span>] [<span class="hljs-number">244191</span>] amdgpu: Allocated mem_obj = <span class="hljs-number">000000001</span>c98cd7f <span class="hljs-keyword">for</span> size = <span class="hljs-number">4</span><br>                                            [<span class="hljs-number">22907.144648</span>] [<span class="hljs-number">244191</span>] amdgpu: Found = <span class="hljs-number">12</span><br>                                            [<span class="hljs-number">22907.144648</span>] [<span class="hljs-number">244191</span>] amdgpu: gpu_addr = <span class="hljs-number">00000000f</span>dd101a7, cpu_addr = <span class="hljs-number">00000000704</span>ebcb5<br>                                            [<span class="hljs-number">22907.144648</span>] [<span class="hljs-number">244191</span>] amdgpu: Single bit<br>                                            [<span class="hljs-number">22907.144649</span>] [<span class="hljs-number">244191</span>] amdgpu: Allocated mem_obj = <span class="hljs-number">0000000023</span>ca5260 <span class="hljs-keyword">for</span> size = <span class="hljs-number">8</span><br>                                            [<span class="hljs-number">22907.144649</span>] [<span class="hljs-number">244191</span>] amdgpu: Found = <span class="hljs-number">13</span><br>                                            [<span class="hljs-number">22907.144650</span>] [<span class="hljs-number">244191</span>] amdgpu: gpu_addr = <span class="hljs-number">0000000076</span>cf5431, cpu_addr = <span class="hljs-number">0000000034</span>d2bd4c<br>                                            [<span class="hljs-number">22907.144650</span>] [<span class="hljs-number">244191</span>] amdgpu: Single bit<br>                                        --&gt; <span class="hljs-keyword">if</span> (init_queue(&amp;kq-&gt;<span class="hljs-built_in">queue</span>, &amp;prop) != <span class="hljs-number">0</span>)<br>                                        <span class="hljs-comment">// update_mqd()</span><br>                                        <span class="hljs-comment">// [22907.144651] [244191] amdgpu: cp_hqd_pq_control 0x508</span><br>                                        <span class="hljs-comment">// restore_mqd()</span><br>                                        <span class="hljs-comment">// [22907.144652] [244191] amdgpu: cp_hqd_pq_doorbell_control 0x2000</span><br>                                        [<span class="hljs-number">22907.144652</span>] [<span class="hljs-number">244191</span>] amdgpu: Assigning hiq to hqd<br>                                        --&gt; kq-&gt;mqd_mgr-&gt;load_mqd(kq-&gt;mqd_mgr, kq-&gt;<span class="hljs-built_in">queue</span>-&gt;mqd, kq-&gt;<span class="hljs-built_in">queue</span>-&gt;pipe, kq-&gt;<span class="hljs-built_in">queue</span>-&gt;<span class="hljs-built_in">queue</span>, &amp;kq-&gt;<span class="hljs-built_in">queue</span>-&gt;properties, <span class="hljs-literal">NULL</span>);<br>                                            <span class="hljs-comment">// mqd-&gt;load_mqd = kfd_hiq_load_mqd_kiq;</span><br>                                            --&gt; <span class="hljs-keyword">return</span> mm-&gt;dev-&gt;kfd2kgd-&gt;hiq_mqd_load(mm-&gt;dev-&gt;adev, mqd, pipe_id,<br>                                                                queue_id, p-&gt;doorbell_off);<br>                                                <span class="hljs-comment">// gfx_v9_kfd2kgd.hiq_mqd_load = kgd_gfx_v9_hiq_mqd_load()</span><br>                                                kgd_gfx_v9_hiq_mqd_load()<br>                                                [<span class="hljs-number">22907.144654</span>] [<span class="hljs-number">244191</span>] amdgpu: kfd: <span class="hljs-built_in">set</span> HIQ, mec:<span class="hljs-number">2</span>, pipe:<span class="hljs-number">0</span>, <span class="hljs-built_in">queue</span>:<span class="hljs-number">0.</span><br>                                                --&gt; amdgpu_ring_write(kiq_ring, PACKET3(PACKET3_MAP_QUEUES, <span class="hljs-number">5</span>));<br>                                                --&gt; amdgpu_ring_write(kiq_ring,<br>                                                            PACKET3_MAP_QUEUES_QUEUE_SEL(<span class="hljs-number">0</span>) | <span class="hljs-comment">/* Queue_Sel */</span><br>                                                            PACKET3_MAP_QUEUES_VMID(m-&gt;cp_hqd_vmid) | <span class="hljs-comment">/* VMID */</span><br>                                                            PACKET3_MAP_QUEUES_QUEUE(queue_id) |<br>                                                            PACKET3_MAP_QUEUES_PIPE(pipe) |<br>                                                            PACKET3_MAP_QUEUES_ME((mec - <span class="hljs-number">1</span>)) |<br>                                                            PACKET3_MAP_QUEUES_QUEUE_TYPE(<span class="hljs-number">0</span>) | <span class="hljs-comment">/*queue_type: normal compute queue */</span><br>                                                            PACKET3_MAP_QUEUES_ALLOC_FORMAT(<span class="hljs-number">0</span>) | <span class="hljs-comment">/* alloc format: all_on_one_pipe */</span><br>                                                            PACKET3_MAP_QUEUES_ENGINE_SEL(<span class="hljs-number">1</span>) | <span class="hljs-comment">/* engine_sel: hiq */</span><br>                                                            PACKET3_MAP_QUEUES_NUM_QUEUES(<span class="hljs-number">1</span>)); <span class="hljs-comment">/* num_queues: must be 1 */</span><br>                                                --&gt; amdgpu_ring_write(kiq_ring,<br>                                                            PACKET3_MAP_QUEUES_DOORBELL_OFFSET(doorbell_off));<br>                                                --&gt; amdgpu_ring_write(kiq_ring, m-&gt;cp_mqd_base_addr_lo);<br>                                                --&gt; amdgpu_ring_write(kiq_ring, m-&gt;cp_mqd_base_addr_hi);<br>                                                --&gt; amdgpu_ring_write(kiq_ring, m-&gt;cp_hqd_pq_wptr_poll_addr_lo);<br>                                                --&gt; amdgpu_ring_write(kiq_ring, m-&gt;cp_hqd_pq_wptr_poll_addr_hi);<br>                                                --&gt; amdgpu_ring_commit(kiq_ring);<br>                                        --&gt; print_queue()<br>                                            [<span class="hljs-number">22907.144655</span>] [<span class="hljs-number">244191</span>] amdgpu: Printing <span class="hljs-built_in">queue</span>:<br>                                            [<span class="hljs-number">22907.144656</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Type: <span class="hljs-number">2</span><br>                                            [<span class="hljs-number">22907.144656</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Size: <span class="hljs-number">2048</span><br>                                            [<span class="hljs-number">22907.144656</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue percent: <span class="hljs-number">100</span><br>                                            [<span class="hljs-number">22907.144657</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Address: <span class="hljs-number">0xCD1000</span><br>                                            [<span class="hljs-number">22907.144657</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Id: <span class="hljs-number">0</span><br>                                            [<span class="hljs-number">22907.144658</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Process Vmid: <span class="hljs-number">0</span><br>                                            [<span class="hljs-number">22907.144658</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Read Pointer: <span class="hljs-number">0x0000000000cd2800</span><br>                                            [<span class="hljs-number">22907.144658</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Write Pointer: <span class="hljs-number">0x0000000000cd2a00</span><br>                                            [<span class="hljs-number">22907.144659</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Doorbell Pointer: <span class="hljs-number">0x00000000ec5ee4d9</span><br>                                            [<span class="hljs-number">22907.144659</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Doorbell Offset: <span class="hljs-number">2048</span><br>                                            [<span class="hljs-number">22907.144660</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue MQD Address: <span class="hljs-number">0x000000009cf9a951</span><br>                                            [<span class="hljs-number">22907.144660</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue MQD Gart: <span class="hljs-number">0x48F000</span><br>                                            [<span class="hljs-number">22907.144661</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Process Address: <span class="hljs-number">0xffffffffffffffea</span><br>                                            [<span class="hljs-number">22907.144661</span>] [<span class="hljs-number">244191</span>] amdgpu: Queue Device Address: <span class="hljs-number">0x00000000bf68ccc7</span><br> <br>                            --&gt; set_sched_resources()<br>                                [<span class="hljs-number">22907.144662</span>] [<span class="hljs-number">244191</span>] amdgpu: Scheduling resources:<br>                                            vmid mask: <span class="hljs-number">0</span>x    FF00<br>                                            <span class="hljs-built_in">queue</span> mask: <span class="hljs-number">0xFCFCFCFC</span><br>                                --&gt; pm_send_set_resources()<br>                                    --&gt; kq_acquire_packet_buffer()<br>                                        [<span class="hljs-number">22907.144663</span>] [<span class="hljs-number">244191</span>] amdgpu: rptr: <span class="hljs-number">0</span><br>                                        [<span class="hljs-number">22907.144663</span>] [<span class="hljs-number">244191</span>] amdgpu: wptr: <span class="hljs-number">0</span><br>                                        [<span class="hljs-number">22907.144664</span>] [<span class="hljs-number">244191</span>] amdgpu: queue_address <span class="hljs-number">0x0000000052309c93</span><br>                                    --&gt; kq_submit_packet()<br>                                        --&gt; write_kernel_doorbell()<br>                                            [<span class="hljs-number">22907.144665</span>] [<span class="hljs-number">244191</span>] amdgpu: writing <span class="hljs-number">8</span> to doorbell address <span class="hljs-number">00000000</span>ec5ee4d9<br>                            [<span class="hljs-number">22907.144665</span>] [<span class="hljs-number">244191</span>] amdgpu: Allocating fence memory<br> <br>                        --&gt; kfd_gtt_sa_allocate()<br>                            [<span class="hljs-number">22907.144666</span>] [<span class="hljs-number">244191</span>] amdgpu: Allocated mem_obj = <span class="hljs-number">00000000f</span>2493a7d <span class="hljs-keyword">for</span> size = <span class="hljs-number">8</span><br>                            [<span class="hljs-number">22907.144666</span>] [<span class="hljs-number">244191</span>] amdgpu: Found = <span class="hljs-number">14</span><br>                            [<span class="hljs-number">22907.144666</span>] [<span class="hljs-number">244191</span>] amdgpu: gpu_addr = <span class="hljs-number">000000008e289627</span>, cpu_addr = <span class="hljs-number">00000000</span>d0a54834<br>                            [<span class="hljs-number">22907.144667</span>] [<span class="hljs-number">244191</span>] amdgpu: Single bit<br> <br>                    --&gt; amdgpu_amdkfd_get_local_mem_info()<br>                        [<span class="hljs-number">22907.144668</span>] [<span class="hljs-number">244191</span>] amdgpu: Address base: <span class="hljs-number">0x0000002400000000</span> public <span class="hljs-number">0x3ff000000</span> private <span class="hljs-number">0x0</span><br>                    --&gt; kfd_topology_add_device()<br>                        [<span class="hljs-number">22907.144679</span>] [<span class="hljs-number">244191</span>] amdgpu: Adding new GPU (ID: <span class="hljs-number">0x44d3</span>) to topology<br>                        --&gt; kfd_create_crat_image_virtual()<br>                            --&gt; kfd_create_vcrat_image_gpu()<br>                                --&gt; kfd_fill_gpu_memory_affinity()<br>                                    [<span class="hljs-number">22907.144681</span>] [<span class="hljs-number">244191</span>] amdgpu: Fill gpu memory affinity - type <span class="hljs-number">0x1</span> size <span class="hljs-number">0x3ff000000</span><br>                                --&gt; kfd_fill_gpu_direct_io_link_to_cpu()<br>                                    --&gt; kfd_find_numa_node_in_srat()<br>                                        [<span class="hljs-number">22907.144683</span>] amdgpu: SRAT table not found<br>                                [<span class="hljs-number">22907.144683</span>] amdgpu: Virtual CRAT table created <span class="hljs-keyword">for</span> GPU<br>                        --&gt; kfd_parse_crat_table()<br>                            [<span class="hljs-number">22907.144684</span>] [<span class="hljs-number">244191</span>] amdgpu: Parsing CRAT table with <span class="hljs-number">1</span> nodes<br>                            --&gt; kfd_parse_subtype()<br>                                --&gt; kfd_parse_subtype_cu()<br>                                    [<span class="hljs-number">22907.144685</span>] [<span class="hljs-number">244191</span>] amdgpu: Found CU entry in CRAT table with proximity_domain=<span class="hljs-number">1</span> caps=<span class="hljs-number">0</span><br>                                    --&gt; kfd_populated_cu_info_gpu()<br>                                        [<span class="hljs-number">22907.144685</span>] [<span class="hljs-number">244191</span>] amdgpu: CU GPU: id_base=<span class="hljs-number">-2147479552</span><br>                                --&gt; kfd_parse_subtype_mem()<br>                                    [<span class="hljs-number">22907.144685</span>] [<span class="hljs-number">244191</span>] amdgpu: Found memory entry in CRAT table with proximity_domain=<span class="hljs-number">1</span><br>                                --&gt; kfd_parse_subtype_iolink()<br>                                    [<span class="hljs-number">22907.144686</span>] [<span class="hljs-number">244191</span>] amdgpu: Found IO link entry in CRAT table with id_from=<span class="hljs-number">1</span>, id_to <span class="hljs-number">0</span><br>                        --&gt; kfd_fill_cache_non_crat_info()<br>                            [<span class="hljs-number">22907.144696</span>] [<span class="hljs-number">244191</span>] amdgpu: Added [<span class="hljs-number">109</span>] GPU cache entries<br>                        --&gt; kfd_fill_mem_clk_max_info()<br>                            --&gt; amdgpu_amdkfd_get_local_mem_info()<br>                                [<span class="hljs-number">22907.144790</span>] [<span class="hljs-number">244191</span>] amdgpu: Address base: <span class="hljs-number">0x0000002400000000</span> public <span class="hljs-number">0x3ff000000</span> private <span class="hljs-number">0x0</span><br>                        --&gt; kfd_debug_print_topology()<br>                            [<span class="hljs-number">22907.144800</span>] amdgpu: Topology: Add dGPU node [<span class="hljs-number">0x66af</span>:<span class="hljs-number">0x1002</span>]<br>                    [<span class="hljs-number">22907.144801</span>] kfd kfd: amdgpu: added device <span class="hljs-number">1002</span>:<span class="hljs-number">66</span>af<br>                    [<span class="hljs-number">22907.144801</span>] [<span class="hljs-number">244191</span>] amdgpu: Starting kfd with the following scheduling policy <span class="hljs-number">0</span><br>        [<span class="hljs-number">22907.144811</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: SE <span class="hljs-number">4</span>, SH per SE <span class="hljs-number">1</span>, CU per SH <span class="hljs-number">16</span>, active_cu_number <span class="hljs-number">60</span><br>        --&gt; amdgpu_device_ip_late_init()<br>                adev-&gt;ip_blocks[i].version-&gt;funcs-&gt;late_init<br>                gmc_v9_0_ip_funcs.late_init() = gmc_v9_0_late_init<br>                gmc_v9_0_late_init()<br>                --&gt; amdgpu_gmc_allocate_vm_inv_eng()<br>                    [<span class="hljs-number">22907.144863</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring gfx uses VM inv eng <span class="hljs-number">0</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144864</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.0</span><span class="hljs-number">.0</span> uses VM inv eng <span class="hljs-number">1</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144864</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.1</span><span class="hljs-number">.0</span> uses VM inv eng <span class="hljs-number">4</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144865</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.2</span><span class="hljs-number">.0</span> uses VM inv eng <span class="hljs-number">5</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144865</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.3</span><span class="hljs-number">.0</span> uses VM inv eng <span class="hljs-number">6</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144866</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.0</span><span class="hljs-number">.1</span> uses VM inv eng <span class="hljs-number">7</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144866</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.1</span><span class="hljs-number">.1</span> uses VM inv eng <span class="hljs-number">8</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144867</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.2</span><span class="hljs-number">.1</span> uses VM inv eng <span class="hljs-number">9</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144867</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring comp_1<span class="hljs-number">.3</span><span class="hljs-number">.1</span> uses VM inv eng <span class="hljs-number">10</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144868</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring kiq_2<span class="hljs-number">.1</span><span class="hljs-number">.0</span> uses VM inv eng <span class="hljs-number">11</span> on hub <span class="hljs-number">0</span><br>                    [<span class="hljs-number">22907.144868</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring sdma0 uses VM inv eng <span class="hljs-number">0</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144868</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring page0 uses VM inv eng <span class="hljs-number">1</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144869</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring sdma1 uses VM inv eng <span class="hljs-number">4</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144870</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring page1 uses VM inv eng <span class="hljs-number">5</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144870</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring uvd_0 uses VM inv eng <span class="hljs-number">6</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144870</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring uvd_enc_0<span class="hljs-number">.0</span> uses VM inv eng <span class="hljs-number">7</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144871</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring uvd_enc_0<span class="hljs-number">.1</span> uses VM inv eng <span class="hljs-number">8</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144871</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring uvd_1 uses VM inv eng <span class="hljs-number">9</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144872</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring uvd_enc_1<span class="hljs-number">.0</span> uses VM inv eng <span class="hljs-number">10</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144872</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring uvd_enc_1<span class="hljs-number">.1</span> uses VM inv eng <span class="hljs-number">11</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144873</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring vce0 uses VM inv eng <span class="hljs-number">12</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144873</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring vce1 uses VM inv eng <span class="hljs-number">13</span> on hub <span class="hljs-number">1</span><br>                    [<span class="hljs-number">22907.144874</span>] amdgpu <span class="hljs-number">0000</span>:<span class="hljs-number">03</span>:<span class="hljs-number">00.0</span>: amdgpu: ring vce2 uses VM inv eng <span class="hljs-number">14</span> on hub <span class="hljs-number">1</span><br> <br>        --&gt; amdgpu_pmu_init()<br>            --&gt; init_pmu_entry_by_type_and_add()<br>                [<span class="hljs-number">22907.151940</span>] amdgpu: Detected AMDGPU DF Counters. <span class="hljs-meta"># of Counters = 8.</span><br>                [<span class="hljs-number">22907.151950</span>] amdgpu: Detected AMDGPU <span class="hljs-number">2</span> Perf Events.<br><span class="hljs-comment">// [22907.152889] [drm] Initialized amdgpu 3.48.0 20150101 for 0000:03:00.0 on minor 1</span><br><span class="hljs-comment">// [22907.155820] [drm] Cannot find any crtc or sizes</span><br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="队列创建"><a href="#队列创建" class="headerlink" title="队列创建"></a>队列创建</h2><details><summary>流程示意图</summary><pre><code class=" mermaid">flowchart TB    subgraph kfdtest        direction TB        id0[&quot;HSAKMT_STATUS Create()&quot;] --&gt; id1[&quot;memset()&quot;] --&gt; id2[&quot;hsaKmtCreateQueue()                Params:        NodeId,        type,        DEFAULT_QUEUE_PERCENTAGE,        DEFAULT_PRIORITY,        m_QueueBuf-&gt;As&lt;unsigned int*&gt;(),        m_QueueBuf-&gt;Size(),        NULL,        &amp;m_Resources&quot;]    end    subgraph Thunk        direction TB        id3[&quot;handle_concrete_asic();&quot;] --&gt; id4[&quot;args.read_pointer_address = QueueResource-&gt;QueueRptrValue;            args.write_pointer_address = QueueResource-&gt;QueueWptrValue;            args.ring_base_address = (uintptr_t)QueueAddress;            args.ring_size = QueueSizeInBytes;            args.queue_percentage = QueuePercentage;            args.queue_priority = priority_map[Priority+3];&quot;] --&gt; id5[&quot;kmtIoctl(kfd_fd, AMDKFD_IOC_CREATE_QUEUE, &amp;args)&quot;]    end    subgraph Driver        direction TB        subgraph kfd_ioctl_create_queue            direction TB            set_queue_properties_from_user --&gt; kfd_process_device_data_by_id --&gt; kfd_bind_process_to_device --&gt; pqm_create_queue            subgraph pqm_create_queue                direction TB                kfd_get_process_device_data --&gt; init_user_queue --&gt; kfd_process_drain_interrupts --&gt; create_queue --&gt; create_queue_cpsch                subgraph create_queue_cpsch                    direction TB                    allocate_doorbell --&gt; init_mqd --&gt; list_add --&gt; increment_queue_count --&gt; execute_queues_cpsch --&gt; deallocate_doorbell                end            end        end    end    kfdtest --&gt; Thunk    Thunk --&gt; Driver    style id2 text-align:left    style id4 text-align:left</code></pre></details><details><summary>execute_queues_cpsch 流程</summary><pre><code class=" mermaid">flowchart TB    subgraph execute_queues_cpsch        direction TB        subgraph unmap_queues_cpsch            direction TB            pm_send_unmap_queue --&gt; pm_send_query_status --&gt; amdkfd_fence_wait_timeout --&gt; pm_release_ib        end        subgraph map_queues_cpsch            direction TB            subgraph pm_send_runlist                direction TB                pm_create_runlist_ib --&gt; kq_acquire_packet_buffer --&gt; pm_runlist_v9 --&gt; kq_submit_packet            end        end        unmap_queues_cpsch --&gt; map_queues_cpsch    end</code></pre></details>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-9d3fcfc2" role="button" aria-expanded="false" aria-controls="collapse-9d3fcfc2">        <div class="fold-arrow">▶</div>AMD GPU Queue create      </div>      <div class="fold-collapse collapse" id="collapse-9d3fcfc2">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// ----------------------------------------------------------------------------------------------------------------------------------</span><br><span class="hljs-comment">//                            kfdtest</span><br><span class="hljs-comment">// ----------------------------------------------------------------------------------------------------------------------------------</span><br><span class="hljs-class"><span class="hljs-keyword">class</span> <span class="hljs-title">BaseQueue</span></span><br><span class="hljs-class">--&gt;</span> HSAKMT_STATUS <span class="hljs-title function_">Create</span><span class="hljs-params">(<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> NodeId, <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> size = DEFAULT_QUEUE_SIZE, HSAuint64 *pointers = <span class="hljs-literal">NULL</span>)</span>;<br>    --&gt; <span class="hljs-built_in">memset</span>(&amp;m_Resources, <span class="hljs-number">0</span>, <span class="hljs-keyword">sizeof</span>(m_Resources));<br>    --&gt; hsaKmtCreateQueue(NodeId, type, DEFAULT_QUEUE_PERCENTAGE, DEFAULT_PRIORITY, m_QueueBuf-&gt;As&lt;<span class="hljs-type">unsigned</span> <span class="hljs-type">int</span>*&gt;(), m_QueueBuf-&gt;Size(), <span class="hljs-literal">NULL</span>, &amp;m_Resources);<br><span class="hljs-comment">// ----------------------------------------------------------------------------------------------------------------------------------</span><br><span class="hljs-comment">//                            Thunk</span><br><span class="hljs-comment">// ----------------------------------------------------------------------------------------------------------------------------------</span><br>        --&gt; <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">kfd_ioctl_create_queue_args</span> <span class="hljs-title">args</span> =</span> &#123;<span class="hljs-number">0</span>&#125;;<br>        --&gt; handle_concrete_asic(q, &amp;args, NodeId, Event, QueueResource-&gt;ErrorReason);<br>        --&gt; args.read_pointer_address = QueueResource-&gt;QueueRptrValue;<br>            args.write_pointer_address = QueueResource-&gt;QueueWptrValue;<br>            args.ring_base_address = (<span class="hljs-type">uintptr_t</span>)QueueAddress;<br>            args.ring_size = QueueSizeInBytes;<br>            args.queue_percentage = QueuePercentage;<br>            args.queue_priority = priority_map[Priority+<span class="hljs-number">3</span>];<br>        --&gt; err = kmtIoctl(kfd_fd, AMDKFD_IOC_CREATE_QUEUE, &amp;args);<br><span class="hljs-comment">// ----------------------------------------------------------------------------------------------------------------------------------</span><br><span class="hljs-comment">//                            Driver</span><br><span class="hljs-comment">// ----------------------------------------------------------------------------------------------------------------------------------</span><br>            --&gt; <span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">kfd_ioctl_create_queue</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> file *filep, <span class="hljs-keyword">struct</span> kfd_process *p, <span class="hljs-type">void</span> *data)</span><br>                --&gt; <span class="hljs-title function_">set_queue_properties_from_user</span><span class="hljs-params">(&amp;q_properties, args)</span>;<br>                    --&gt; q_properties-&gt;is_interop = <span class="hljs-literal">false</span>;<br>                        q_properties-&gt;is_gws = <span class="hljs-literal">false</span>;<br>                        q_properties-&gt;queue_percent = args-&gt;queue_percentage;<br>                        q_properties-&gt;priority = args-&gt;queue_priority;<br>                        q_properties-&gt;queue_address = args-&gt;ring_base_address;<br>                        q_properties-&gt;queue_size = args-&gt;ring_size;<br>                        q_properties-&gt;read_ptr = (<span class="hljs-type">uint32_t</span> *) args-&gt;read_pointer_address;<br>                        q_properties-&gt;write_ptr = (<span class="hljs-type">uint32_t</span> *) args-&gt;write_pointer_address;<br>                        q_properties-&gt;eop_ring_buffer_address = args-&gt;eop_buffer_address;<br>                        q_properties-&gt;eop_ring_buffer_size = args-&gt;eop_buffer_size;<br>                        q_properties-&gt;ctx_save_restore_area_address = args-&gt;ctx_save_restore_address;<br>                        q_properties-&gt;ctx_save_restore_area_size = args-&gt;ctx_save_restore_size;<br>                        q_properties-&gt;ctl_stack_size = args-&gt;ctl_stack_size;<br>                        <span class="hljs-comment">//...</span><br>                --&gt; kfd_process_device_data_by_id()<br>                --&gt; kfd_bind_process_to_device()<br>                --&gt; pqm_create_queue(&amp;p-&gt;pqm, dev, filep, &amp;q_properties, &amp;queue_id, <span class="hljs-literal">NULL</span>, <span class="hljs-literal">NULL</span>, <span class="hljs-literal">NULL</span>, &amp;doorbell_offset_in_process);<br>                    --&gt; <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">kfd_process_device</span> *<span class="hljs-title">pdd</span> =</span> kfd_get_process_device_data()<br>                        <span class="hljs-comment">// PM4Queue.hpp: Type is  HSA_QUEUE_COMPUTE --&gt; KFD_IOC_QUEUE_TYPE_COMPUTE --&gt; KFD_QUEUE_TYPE_COMPUTE</span><br>                        <span class="hljs-comment">// SDMAQueue.hpp: Type is HSA_QUEUE_SDMA    --&gt; KFD_IOC_QUEUE_TYPE_SDMA    --&gt; KFD_QUEUE_TYPE_SDMA</span><br>                    --&gt; init_user_queue(pqm, dev, &amp;q, properties, f, *qid);<br>                    --&gt; kfd_process_drain_interrupts(pdd);<br>                    --&gt; retval = dev-&gt;dqm-&gt;ops.create_queue(dev-&gt;dqm, q, &amp;pdd-&gt;qpd, q_data, restore_mqd, restore_ctl_stack);<br>                        <span class="hljs-comment">// dqm-&gt;ops.create_queue = create_queue_cpsch;</span><br>                        --&gt; create_queue_cpsch()<br>                            --&gt; allocate_doorbell()<br>                            --&gt; mqd_mgr-&gt;init_mqd(mqd_mgr, &amp;q-&gt;mqd, q-&gt;mqd_mem_obj, &amp;q-&gt;gart_mqd_addr, &amp;q-&gt;properties);<br>                            --&gt; list_add(&amp;q-&gt;<span class="hljs-built_in">list</span>, &amp;qpd-&gt;queues_list);<br>                            --&gt; increment_queue_count(dqm, qpd, q);<br>                            --&gt; execute_queues_cpsch(dqm, KFD_UNMAP_QUEUES_FILTER_DYNAMIC_QUEUES, <span class="hljs-number">0</span>, USE_DEFAULT_GRACE_PERIOD);<br>                                --&gt; retval = unmap_queues_cpsch(dqm, filter, filter_param, grace_period, <span class="hljs-literal">false</span>);<br>                                    --&gt; retval = pm_send_unmap_queue(&amp;dqm-&gt;packet_mgr, filter, filter_param, reset);<br>                                    --&gt; pm_send_query_status(&amp;dqm-&gt;packet_mgr, dqm-&gt;fence_gpu_addr, KFD_FENCE_COMPLETED);<br>                                    --&gt; retval = amdkfd_fence_wait_timeout(dqm-&gt;fence_addr, KFD_FENCE_COMPLETED, queue_preemption_timeout_ms);<br>                                    --&gt; pm_release_ib(&amp;dqm-&gt;packet_mgr);<br>                                --&gt; map_queues_cpsch(dqm);<br>                                    --&gt; pm_send_runlist(&amp;dqm-&gt;packet_mgr, &amp;dqm-&gt;queues);<br>                                        --&gt; retval = pm_create_runlist_ib(pm, dqm_queues, &amp;rl_gpu_ib_addr, &amp;rl_ib_size);<br>                                        --&gt; retval = kq_acquire_packet_buffer(pm-&gt;priv_queue, ket_size_dwords, &amp;rl_buffer);<br>                                        --&gt; retval = pm-&gt;pmf-&gt;runlist(pm, rl_buffer, rl_gpu_ib_addr, rl_ib_size / <span class="hljs-keyword">sizeof</span>(<span class="hljs-type">uint32_t</span>), <span class="hljs-literal">false</span>);<br>                                            --&gt; pm_runlist_v9()<br>                                        --&gt; kq_submit_packet(pm-&gt;priv_queue);<br>                                            --&gt; write_kernel_doorbell()<br>                                                --&gt; writel(value, db);<br>                                                    --&gt; __io_bw();<br>                                                        __raw_writel((u32 __force)__cpu_to_le32(value), addr);<br>                                                        __io_aw();<br>                                    --&gt; dqm-&gt;active_runlist = <span class="hljs-literal">true</span>;<br>                            --&gt; deallocate_doorbell(qpd, q);<br> <br> <br><span class="hljs-comment">/** Ioctl table */</span><br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdkfd_ioctl_desc</span> <span class="hljs-title">amdkfd_ioctls</span>[] =</span> &#123;<br>    <span class="hljs-comment">//...</span><br>    AMDKFD_IOCTL_DEF(AMDKFD_IOC_CREATE_QUEUE,<br>            kfd_ioctl_create_queue, <span class="hljs-number">0</span>),<br>    <span class="hljs-comment">//...</span><br>&#125;<br> <br>amdgpu_amdkfd_device_init()<br>--&gt; adev-&gt;kfd.init_complete = kgd2kfd_device_init(adev-&gt;kfd.dev, adev_to_drm(adev), &amp;gpu_resources);<br>    --&gt; kfd-&gt;dqm = device_queue_manager_init(kfd);<br>        --&gt; <span class="hljs-keyword">case</span> KFD_SCHED_POLICY_HWS_NO_OVERSUBSCRIPTION:<br>                <span class="hljs-comment">/* initialize dqm for cp scheduling */</span><br>                dqm-&gt;ops.create_queue = create_queue_cpsch;<br>                dqm-&gt;ops.initialize = initialize_cpsch;<br>                dqm-&gt;ops.start = start_cpsch;<br>                dqm-&gt;ops.stop = stop_cpsch;<br>                dqm-&gt;ops.pre_reset = pre_reset;<br>                dqm-&gt;ops.destroy_queue = destroy_queue_cpsch;<br>                dqm-&gt;ops.update_queue = update_queue;<br>                dqm-&gt;ops.register_process = register_process;<br>                dqm-&gt;ops.unregister_process = unregister_process;<br>                dqm-&gt;ops.uninitialize = uninitialize;<br>                dqm-&gt;ops.create_kernel_queue = create_kernel_queue_cpsch;<br>                dqm-&gt;ops.destroy_kernel_queue = destroy_kernel_queue_cpsch;<br>                dqm-&gt;ops.set_cache_memory_policy = set_cache_memory_policy;<br>                dqm-&gt;ops.process_termination = process_termination_cpsch;<br>                dqm-&gt;ops.evict_process_queues = evict_process_queues_cpsch;<br>                dqm-&gt;ops.restore_process_queues = restore_process_queues_cpsch;<br>                dqm-&gt;ops.get_wave_state = get_wave_state;<br>                dqm-&gt;ops.reset_queues = reset_queues_cpsch;<br>                dqm-&gt;ops.get_queue_checkpoint_info = get_queue_checkpoint_info;<br>                dqm-&gt;ops.checkpoint_mqd = checkpoint_mqd;<br>                <span class="hljs-keyword">break</span>;<br>    --&gt; kfd_resume()<br>        --&gt; kfd-&gt;dqm-&gt;ops.start(kfd-&gt;dqm);<br>            --&gt; retval = pm_init(&amp;dqm-&gt;packet_mgr, dqm);<br>                --&gt; pm-&gt;priv_queue = kernel_queue_init(dqm-&gt;dev, KFD_QUEUE_TYPE_HIQ);<br>                    --&gt; kq_initialize(kq, dev, type, KFD_KERNEL_QUEUE_SIZE)<br>                        --&gt; kq-&gt;mqd_mgr-&gt;init_mqd(kq-&gt;mqd_mgr, &amp;kq-&gt;<span class="hljs-built_in">queue</span>-&gt;mqd,<br>                                                    kq-&gt;<span class="hljs-built_in">queue</span>-&gt;mqd_mem_obj,<br>                                                    &amp;kq-&gt;<span class="hljs-built_in">queue</span>-&gt;gart_mqd_addr,<br>                                                    &amp;kq-&gt;<span class="hljs-built_in">queue</span>-&gt;properties);<br>        --&gt; set_sched_resources(dqm)<br>            --&gt; <span class="hljs-keyword">return</span> pm_send_set_resources(&amp;dqm-&gt;packet_mgr, &amp;res);<br>                --&gt; retval = pm-&gt;pmf-&gt;set_resources(pm, buffer, res);<br>                    --&gt; pm_set_resources_v9()<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="初始化"><a href="#初始化" class="headerlink" title="初始化"></a>初始化</h2>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-8a164987" role="button" aria-expanded="false" aria-controls="collapse-8a164987">        <div class="fold-arrow">▶</div>MEC firmware      </div>      <div class="fold-collapse collapse" id="collapse-8a164987">        <div class="fold-content">          <p>MEC，又称 Ucode，或者microcode，是 CP 的重要 firmware。</p><p>在AMD GPU的初始化过程中，CP（Command Processor）模块的初始化是一个关键步骤，它涉及加载和配置微代码（microcode）以支持指令调度、命令解析、DMA（Direct Memory Access）以及图形和计算任务的管理。以下是该流程的详细介绍，包括KMD（Kernel Mode Driver）如何将Ucode写入CP模块的步骤。</p><ol><li><p><strong>CP模块初始化概述</strong></p><p> CP模块是AMD GPU的一个重要组件，主要负责以下任务：</p><ul><li>管理和调度指令（包括图形和计算命令）</li><li>处理和解析命令流（Command Stream）</li><li>协调硬件调度单元（Hardware Scheduler）</li><li>管理上下文切换和线程预处理（Thread Preemption）</li></ul><p> 在初始化时，CP模块需要被配置好其微代码，以便正确解析和调度由内核驱动（KMD）或用户驱动（UMD）发送的指令流。</p></li><li><p><strong>微代码（Microcode）的作用</strong></p><p> 微代码是CP模块执行的固件程序，它定义了CP模块如何解释并调度各种图形和计算任务。微代码通常包含以下几类指令：</p><ul><li>图形指令解析和调度逻辑</li><li>计算指令和DMA传输的管理</li><li>上下文切换（Context Switching）和优先级调度策略</li></ul><p> 在KMD初始化CP时，通常会先通过驱动程序将微代码加载到GPU的内存中，然后通过特定寄存器配置微代码的执行位置。</p></li><li><p><strong>CP模块的初始化流程</strong><br> 以下是一个典型的AMD GPU CP模块初始化流程：</p><ol><li><p><strong>微代码加载</strong>：</p><ul><li>驱动程序会将微代码文件（例如<code>gfx_cp.bin</code>）加载到系统内存中。这个文件通常通过KMD或固件接口（Firmware Interface）进行获取，包含预编译好的指令集合。</li></ul></li><li><p><strong>微代码传输到GPU内存</strong>：</p><ul><li>驱动程序通过MMIO（Memory-Mapped I&#x2F;O）或PCIe访问机制，将微代码从系统内存传输到GPU的内存（通常是显存或CP模块本地存储器中）。</li></ul></li><li><p><strong>CP微代码配置</strong>：</p><ul><li>驱动程序通过配置CP的寄存器来指定微代码的位置和大小。例如，通过以下寄存器进行配置：<ul><li><strong>CP_MEC_ME1_UCODE_ADDR</strong>：指定CP微代码的加载地址。</li><li><strong>CP_MEC_ME1_UCODE_DATA</strong>：逐字节或逐段将微代码数据写入指定地址。</li></ul></li><li>在配置时，通常需要先指定微代码基地址（例如显存或本地寄存器的地址），然后循环地写入微代码内容。对于CP模块，微代码加载通常采用单字（32-bit）或双字（64-bit）方式。</li></ul></li><li><p><strong>微代码加载确认和校验</strong>：</p><ul><li>驱动程序在完成微代码写入后，会配置相关寄存器标志位以启动微代码。例如：<ul><li>设置 <strong>CP_MEC_CNTL</strong> 寄存器的启动位（start bit）来触发CP模块执行微代码。</li></ul></li><li>驱动程序会通过读取寄存器状态（如检查校验和寄存器）来确认微代码是否加载成功。</li></ul></li><li><p><strong>命令处理配置</strong>：</p><ul><li>一旦微代码被成功加载和校验，CP模块会被配置为接收和解析来自KMD的图形或计算命令流。此时，KMD会配置相应的调度策略和上下文切换策略。</li></ul></li></ol></li><li><p><strong>KMD如何写入微代码（Ucode）</strong><br> KMD（Kernel Mode Driver）在进行CP模块的微代码初始化时，会采用以下具体步骤：</p><ol><li><p><strong>获取微代码数据</strong>：</p><ul><li>从驱动中定义的静态数组（或从设备固件库中）获取微代码的数据。微代码通常以二进制格式存在于驱动程序中，文件名可能是 <code>gfx_cp.bin</code> 或者通过加载固件接口（Firmware Loader）动态获取。</li></ul></li><li><p><strong>设置CP微代码写入地址</strong>：</p><ul><li>配置 <code>CP_MEC_ME1_UCODE_ADDR</code> 或 <code>CP_ME_RAM_WADDR</code> 等寄存器，以指向CP模块内部RAM或GPU内存中微代码的目标写入地址。</li></ul></li><li><p><strong>逐字写入微代码数据</strong>：</p><ul><li>使用循环结构逐字（word by word）地将微代码数据写入 <code>CP_MEC_ME1_UCODE_DATA</code> 或 <code>CP_ME_RAM_DATA</code> 寄存器。每次写入后，地址指针会自动递增。</li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; microcode_size; i++) &#123;<br>    WREG32(CP_ME_RAM_WADDR, i);  <span class="hljs-comment">// 设置CP RAM的写入地址</span><br>    WREG32(CP_ME_RAM_DATA, microcode_data[i]);  <span class="hljs-comment">// 写入微代码数据</span><br>&#125;<br></code></pre></td></tr></table></figure></li><li><p><strong>启动微代码执行</strong>：</p><ul><li>配置 <code>CP_RB_CNTL</code> 或 <code>CP_MEC_CNTL</code> 寄存器，以启动CP模块开始执行微代码。</li></ul></li><li><p><strong>校验加载状态</strong>：</p><ul><li>驱动程序通过读取 <code>CP_ME_STATUS</code> 或类似的状态寄存器来确认微代码是否正确启动和执行。</li></ul></li></ol></li><li><p><strong>关键寄存器的说明</strong><br> 在CP模块微代码加载过程中，以下寄存器通常需要配置：</p><ul><li><strong>CP_ME_RAM_WADDR</strong>：指向微代码在CP模块中的起始地址。</li><li><strong>CP_ME_RAM_DATA</strong>：用来写入微代码的具体数据。</li><li><strong>CP_MEC_CNTL</strong>：控制CP模块的启动和停止。</li><li><strong>CP_RB_CNTL</strong>：用于配置Ring Buffer和命令调度策略。</li><li><strong>CP_MEC_ME1_UCODE_ADDR &#x2F; CP_MEC_ME1_UCODE_DATA</strong>：配置MEC（Micro Engine Controller）微代码的加载地址和数据。</li></ul></li></ol><p>AMD GPU的CP模块初始化涉及复杂的微代码加载和配置过程。KMD通常通过内核模式驱动程序将微代码从系统内存传输到GPU内存中，再通过配置相关寄存器来启动微代码的执行。正确的微代码加载和配置对于GPU指令解析和任务调度至关重要。在实际开发中，可以使用调试工具（如<code>amdgpu-pro</code>或<code>gdb</code>）来检查CP模块的寄存器状态，以确保微代码正确加载并成功运行。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br><span class="line">171</span><br><span class="line">172</span><br><span class="line">173</span><br><span class="line">174</span><br><span class="line">175</span><br><span class="line">176</span><br><span class="line">177</span><br><span class="line">178</span><br><span class="line">179</span><br><span class="line">180</span><br><span class="line">181</span><br><span class="line">182</span><br><span class="line">183</span><br><span class="line">184</span><br><span class="line">185</span><br><span class="line">186</span><br><span class="line">187</span><br><span class="line">188</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">gfx_v9_0_early_init</span><span class="hljs-params">(<span class="hljs-type">void</span> *handle)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_device</span> *<span class="hljs-title">adev</span> =</span> (<span class="hljs-keyword">struct</span> amdgpu_device *)handle;<br><br>    adev-&gt;gfx.funcs = &amp;gfx_v9_0_gfx_funcs;<br><br>    adev-&gt;gfx.num_gfx_rings = GFX9_NUM_GFX_RINGS;<br>    adev-&gt;gfx.num_compute_rings = min(amdgpu_gfx_get_num_kcq(adev),<br>                    AMDGPU_MAX_COMPUTE_RINGS);<br>    gfx_v9_0_set_spm_funcs(adev);<br>    gfx_v9_0_set_kiq_pm4_funcs(adev);<br>    gfx_v9_0_set_ring_funcs(adev);<br>    gfx_v9_0_set_irq_funcs(adev);<br>    gfx_v9_0_set_gds_init(adev);<br>    gfx_v9_0_set_rlc_funcs(adev);<br><span class="hljs-meta">#<span class="hljs-keyword">if</span> HYGON_KMD_SUPPORT</span><br>    gfx_v9_0_set_rd_stream(adev);<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>    <span class="hljs-comment">/* init rlcg reg access ctrl */</span><br>    gfx_v9_0_init_rlcg_reg_access_ctrl(adev);<br><br>    <span class="hljs-keyword">return</span> gfx_v9_0_init_microcode(adev);<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">gfx_v9_0_init_microcode</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev)</span><br>&#123;<br>    <span class="hljs-type">char</span> ucode_prefix[<span class="hljs-number">30</span>];<br>    <span class="hljs-type">int</span> r;<br><br>    DRM_DEBUG(<span class="hljs-string">&quot;\n&quot;</span>);<br><br>    amdgpu_ucode_ip_version_decode(adev, GC_HWIP, ucode_prefix, <span class="hljs-keyword">sizeof</span>(ucode_prefix));<br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> HYGON_KMD_VEGA20</span><br>    <span class="hljs-comment">/* No CPG in Arcturus */</span><br>    <span class="hljs-keyword">if</span> (adev-&gt;gfx.num_gfx_rings) &#123;<br>        r = gfx_v9_0_init_cp_gfx_microcode(adev, ucode_prefix);<br>        <span class="hljs-keyword">if</span> (r)<br>            <span class="hljs-keyword">return</span> r;<br>    &#125;<br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br>    r = gfx_v9_0_init_rlc_microcode(adev, ucode_prefix);<br>    <span class="hljs-keyword">if</span> (r)<br>        <span class="hljs-keyword">return</span> r;<br><br>    r = gfx_v9_0_init_cp_compute_microcode(adev, ucode_prefix);<br>    <span class="hljs-keyword">if</span> (r)<br>        <span class="hljs-keyword">return</span> r;<br><br>    <span class="hljs-keyword">return</span> r;<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">gfx_v9_0_init_cp_compute_microcode</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev,</span><br><span class="hljs-params">                    <span class="hljs-type">const</span> <span class="hljs-type">char</span> *chip_name)</span><br>    &#123;<br>    <span class="hljs-type">char</span> fw_name[<span class="hljs-number">30</span>];<br>    <span class="hljs-type">int</span> err;<br><br>    <span class="hljs-built_in">snprintf</span>(fw_name, <span class="hljs-keyword">sizeof</span>(fw_name), <span class="hljs-string">&quot;hydcu/%s_mec.bin&quot;</span>, chip_name);<br>    err = request_firmware(&amp;adev-&gt;gfx.mec_fw, fw_name, adev-&gt;dev);<br>    <span class="hljs-keyword">if</span> (err)<br>        <span class="hljs-keyword">goto</span> out;<br>    amdgpu_gfx_cp_init_microcode(adev, AMDGPU_UCODE_ID_CP_MEC1);<br>    amdgpu_gfx_cp_init_microcode(adev, AMDGPU_UCODE_ID_CP_MEC1_JT);<br><br>    <span class="hljs-keyword">if</span> (gfx_v9_0_load_mec2_fw_bin_support(adev)) &#123;<br>        <span class="hljs-built_in">snprintf</span>(fw_name, <span class="hljs-keyword">sizeof</span>(fw_name), <span class="hljs-string">&quot;hydcu/%s_mec2.bin&quot;</span>, chip_name);<br><br>        <span class="hljs-comment">/* ignore failures to load */</span><br>        err = amdgpu_ucode_request(adev, &amp;adev-&gt;gfx.mec2_fw, fw_name);<br>        <span class="hljs-keyword">if</span> (!err) &#123;<br>            amdgpu_gfx_cp_init_microcode(adev, AMDGPU_UCODE_ID_CP_MEC2);<br>            amdgpu_gfx_cp_init_microcode(adev, AMDGPU_UCODE_ID_CP_MEC2_JT);<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            err = <span class="hljs-number">0</span>;<br>            amdgpu_ucode_release(&amp;adev-&gt;gfx.mec2_fw);<br>        &#125;<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        adev-&gt;gfx.mec2_fw_version = adev-&gt;gfx.mec_fw_version;<br>        adev-&gt;gfx.mec2_feature_version = adev-&gt;gfx.mec_feature_version;<br>    &#125;<br><br><br>    gfx_v9_0_check_if_need_gfxoff(adev);<br>    gfx_v9_0_check_fw_write_wait(adev);<br><br>out:<br>    <span class="hljs-keyword">if</span> (err)<br>        amdgpu_ucode_release(&amp;adev-&gt;gfx.mec_fw);<br>    <span class="hljs-keyword">return</span> err;<br>&#125;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">amdgpu_gfx_cp_init_microcode</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev,</span><br><span class="hljs-params">                <span class="hljs-type">uint32_t</span> ucode_id)</span><br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">gfx_firmware_header_v1_0</span> *<span class="hljs-title">cp_hdr</span>;</span><br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">gfx_firmware_header_v2_0</span> *<span class="hljs-title">cp_hdr_v2_0</span>;</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_firmware_info</span> *<span class="hljs-title">info</span> =</span> <span class="hljs-literal">NULL</span>;<br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">firmware</span> *<span class="hljs-title">ucode_fw</span>;</span><br>    <span class="hljs-type">unsigned</span> <span class="hljs-type">int</span> fw_size;<br><br>    <span class="hljs-keyword">switch</span> (ucode_id) &#123;<br><span class="hljs-comment">//</span><br>    <span class="hljs-keyword">case</span> AMDGPU_UCODE_ID_CP_MEC1:<br>        cp_hdr = (<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> gfx_firmware_header_v1_0 *)<br>            adev-&gt;gfx.mec_fw-&gt;data;<br>        adev-&gt;gfx.mec_fw_version =<br>            le32_to_cpu(cp_hdr-&gt;header.ucode_version);<br>        adev-&gt;gfx.mec_feature_version =<br>            le32_to_cpu(cp_hdr-&gt;ucode_feature_version);<br>        ucode_fw = adev-&gt;gfx.mec_fw;<br>        fw_size = le32_to_cpu(cp_hdr-&gt;header.ucode_size_bytes) -<br>            le32_to_cpu(cp_hdr-&gt;jt_size) * <span class="hljs-number">4</span>;<br>        <span class="hljs-keyword">break</span>;<br>    <span class="hljs-keyword">case</span> AMDGPU_UCODE_ID_CP_MEC1_JT:<br>        cp_hdr = (<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> gfx_firmware_header_v1_0 *)<br>            adev-&gt;gfx.mec_fw-&gt;data;<br>        ucode_fw = adev-&gt;gfx.mec_fw;<br>        fw_size = le32_to_cpu(cp_hdr-&gt;jt_size) * <span class="hljs-number">4</span>;<br>        <span class="hljs-keyword">break</span>;<br><span class="hljs-comment">//</span><br>    <span class="hljs-keyword">default</span>:<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br><br>    <span class="hljs-keyword">if</span> (adev-&gt;firmware.load_type == AMDGPU_FW_LOAD_PSP) &#123;<br>        info = &amp;adev-&gt;firmware.ucode[ucode_id];<br>        info-&gt;ucode_id = ucode_id;<br>        info-&gt;fw = ucode_fw;<br>        adev-&gt;firmware.fw_size += ALIGN(fw_size, PAGE_SIZE);<br>    &#125;<br>&#125;<br><br>gfx_v9_0_hw_init() --&gt; gfx_v9_0_cp_resume() --&gt; gfx_v9_0_cp_compute_load_microcode();<br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">gfx_v9_0_cp_compute_load_microcode</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev)</span><br>&#123;<br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">gfx_firmware_header_v1_0</span> *<span class="hljs-title">mec_hdr</span>;</span><br>    <span class="hljs-type">const</span> __le32 *fw_data;<br>    <span class="hljs-type">unsigned</span> i;<br>    u32 tmp;<br><br>    <span class="hljs-keyword">if</span> (!adev-&gt;gfx.mec_fw)<br>        <span class="hljs-keyword">return</span> -EINVAL;<br><br>    gfx_v9_0_cp_compute_enable(adev, <span class="hljs-literal">false</span>);<br><br>    mec_hdr = (<span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> gfx_firmware_header_v1_0 *)adev-&gt;gfx.mec_fw-&gt;data;<br>    amdgpu_ucode_print_gfx_hdr(&amp;mec_hdr-&gt;header);<br><br>    fw_data = (<span class="hljs-type">const</span> __le32 *)<br>        (adev-&gt;gfx.mec_fw-&gt;data +<br>        le32_to_cpu(mec_hdr-&gt;header.ucode_array_offset_bytes));<br>    tmp = <span class="hljs-number">0</span>;<br>    tmp = REG_SET_FIELD(tmp, CP_CPC_IC_BASE_CNTL, VMID, <span class="hljs-number">0</span>);<br>    tmp = REG_SET_FIELD(tmp, CP_CPC_IC_BASE_CNTL, CACHE_POLICY, <span class="hljs-number">0</span>);<br>    WREG32_SOC15(GC, <span class="hljs-number">0</span>, mmCP_CPC_IC_BASE_CNTL, tmp);<br><br>    WREG32_SOC15(GC, <span class="hljs-number">0</span>, mmCP_CPC_IC_BASE_LO,<br>        adev-&gt;gfx.mec.mec_fw_gpu_addr &amp; <span class="hljs-number">0xFFFFF000</span>);<br>    WREG32_SOC15(GC, <span class="hljs-number">0</span>, mmCP_CPC_IC_BASE_HI,<br>        upper_32_bits(adev-&gt;gfx.mec.mec_fw_gpu_addr));<br><br>    <span class="hljs-comment">/* MEC1 */</span><br>    WREG32_SOC15(GC, <span class="hljs-number">0</span>, mmCP_MEC_ME1_UCODE_ADDR,<br>            mec_hdr-&gt;jt_offset);<br>    <span class="hljs-keyword">for</span> (i = <span class="hljs-number">0</span>; i &lt; mec_hdr-&gt;jt_size; i++)<br>        WREG32_SOC15(GC, <span class="hljs-number">0</span>, mmCP_MEC_ME1_UCODE_DATA,<br>            le32_to_cpup(fw_data + mec_hdr-&gt;jt_offset + i));<br><br>    WREG32_SOC15(GC, <span class="hljs-number">0</span>, mmCP_MEC_ME1_UCODE_ADDR,<br>            adev-&gt;gfx.mec_fw_version);<br>    <span class="hljs-comment">/* Todo : Loading MEC2 firmware is only necessary if MEC2 should run different microcode than MEC1. */</span><br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">gfx_v9_0_cp_compute_enable</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">bool</span> enable)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (enable) &#123;<br>        WREG32_SOC15_RLC(GC, <span class="hljs-number">0</span>, mmCP_MEC_CNTL, <span class="hljs-number">0</span>);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        WREG32_SOC15_RLC(GC, <span class="hljs-number">0</span>, mmCP_MEC_CNTL,<br>            (CP_MEC_CNTL__MEC_ME1_HALT_MASK | CP_MEC_CNTL__MEC_ME2_HALT_MASK));<br>        adev-&gt;gfx.kiq.ring.sched.ready = <span class="hljs-literal">false</span>;<br>    &#125;<br>    udelay(<span class="hljs-number">50</span>);<br>&#125;<br><br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="内存管理"><a href="#内存管理" class="headerlink" title="内存管理"></a>内存管理</h2><p>常见概念介绍：</p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-d3d58547" role="button" aria-expanded="false" aria-controls="collapse-d3d58547">        <div class="fold-arrow">▶</div>GMC Global Memory Controller      </div>      <div class="fold-collapse collapse" id="collapse-d3d58547">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_gmc</span> &#123;</span><br>    <span class="hljs-comment">/* FB（帧缓冲区）的物理地址和大小（供 CPU 映射使用）。</span><br><span class="hljs-comment">     * 这与 `vram_start` 和 `vram_end` 字段不同，后者是 GPU 视角的地址，</span><br><span class="hljs-comment">     * 而 `aper_base` 是 CPU 视角的物理地址。</span><br><span class="hljs-comment">     */</span><br>    <span class="hljs-type">resource_size_t</span> aper_size;         <span class="hljs-comment">// FB 孔径的大小</span><br>    <span class="hljs-type">resource_size_t</span> aper_base;         <span class="hljs-comment">// FB 孔径的起始地址（CPU 视角）</span><br><br>    <span class="hljs-comment">/* 对于某些显存 &lt;= 32MB 的芯片，需要在 MC（内存控制器）中</span><br><span class="hljs-comment">     * 修改 VRAM 大小以适应帧缓冲区位置。</span><br><span class="hljs-comment">     */</span><br>    u64 mc_vram_size;                  <span class="hljs-comment">// 显存（VRAM）大小（MC 视角）</span><br>    u64 visible_vram_size;             <span class="hljs-comment">// CPU 可见的显存大小</span><br><br>    <span class="hljs-comment">/* AGP（加速图形端口）孔径的起始和结束地址（MC 地址空间中）。</span><br><span class="hljs-comment">     * 驱动程序通过设置 MC_VM_AGP_BOT/TOP 寄存器在 MC 地址空间中找到一个 AGP 区域。</span><br><span class="hljs-comment">     * 在 VMID0 上，逻辑地址等于 MC 地址。AGP 孔径映射到物理总线地址或 IOVA 地址。</span><br><span class="hljs-comment">     * AGP 主要用于模拟帧缓冲区或者作为系统内存中的页表（主要用于 APU）。</span><br><span class="hljs-comment">     */</span><br>    u64 agp_size;                      <span class="hljs-comment">// AGP 孔径大小</span><br>    u64 agp_start;                     <span class="hljs-comment">// AGP 孔径起始地址</span><br>    u64 agp_end;                       <span class="hljs-comment">// AGP 孔径结束地址</span><br><br>    <span class="hljs-comment">/* GART（图形地址重映射表）孔径的起始和结束地址（MC 地址空间中）。</span><br><span class="hljs-comment">     * 驱动程序通过设置 VM_CONTEXT0_PAGE_TABLE_START/END_ADDR 寄存器在 MC 地址空间中</span><br><span class="hljs-comment">     * 找到一个 GART 区域。对于 VMID0 的逻辑地址，在 GART 区域中的地址通过 GPU VM</span><br><span class="hljs-comment">     * 的 GART 页表转换，访问分页的系统内存。</span><br><span class="hljs-comment">     */</span><br>    u64 gart_size;                     <span class="hljs-comment">// GART 孔径大小</span><br>    u64 gart_start;                    <span class="hljs-comment">// GART 孔径起始地址</span><br>    u64 gart_end;                      <span class="hljs-comment">// GART 孔径结束地址</span><br><br>    <span class="hljs-comment">/* 当前 GPU 设备的帧缓冲区孔径。不同于 `fb_start`，</span><br><span class="hljs-comment">     * 该字段只表示本地 GPU 设备的孔径范围。</span><br><span class="hljs-comment">     * 如果驱动程序使用 FB 孔径访问显存，则 `fb_start` 从</span><br><span class="hljs-comment">     * MC_VM_FB_LOCATION_BASE 中获取（由 vbios 设置）。</span><br><span class="hljs-comment">     * 如果驱动程序使用 GART 表访问 VMID0 的帧缓冲区，</span><br><span class="hljs-comment">     * 驱动程序会在 VMID0 虚拟地址空间中找到一个 SYSVM 孔径，</span><br><span class="hljs-comment">     * 其中第一部分是显存，第二部分是 GART（映射到系统内存）。</span><br><span class="hljs-comment">    */</span><br>    u64 vram_start;                    <span class="hljs-comment">// 本地 GPU 显存孔径起始地址</span><br>    u64 vram_end;                      <span class="hljs-comment">// 本地 GPU 显存孔径结束地址</span><br><br>    <span class="hljs-comment">/* FB（帧缓冲区）区域。在单 GPU 配置中，它等同于本地显存区域。</span><br><span class="hljs-comment">     * 在 XGMI（多 GPU 集群）配置中，该区域覆盖同一集群中所有 GPU。</span><br><span class="hljs-comment">     * 集群中的每个 GPU 具有相同的 FB 视图，GPU0 的显存从偏移 (0 * 段大小) 开始，</span><br><span class="hljs-comment">     * GPU1 从偏移 (1 * 段大小) 开始，以此类推。</span><br><span class="hljs-comment">     */</span><br>    u64 fb_start;                      <span class="hljs-comment">// 帧缓冲区起始地址</span><br>    u64 fb_end;                        <span class="hljs-comment">// 帧缓冲区结束地址</span><br><br>    <span class="hljs-type">unsigned</span> vram_width;               <span class="hljs-comment">// 显存总线宽度（位宽）</span><br>    u64 real_vram_size;                <span class="hljs-comment">// 实际可用的显存大小</span><br>    <span class="hljs-type">int</span> vram_mtrr;                     <span class="hljs-comment">// MTRR（内存类型范围寄存器）设置</span><br>    u64 mc_mask;                       <span class="hljs-comment">// 内存控制器的地址掩码</span><br><br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">firmware</span> *<span class="hljs-title">fw</span>;</span>         <span class="hljs-comment">// MC 固件指针</span><br>    <span class="hljs-type">uint32_t</span> fw_version;               <span class="hljs-comment">// 固件版本号</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_irq_src</span> <span class="hljs-title">vm_fault</span>;</span>    <span class="hljs-comment">// 虚拟内存故障源</span><br>    <span class="hljs-type">uint32_t</span> vram_type;                <span class="hljs-comment">// 显存类型（GDDR5、HBM 等）</span><br>    <span class="hljs-type">uint8_t</span> vram_vendor;               <span class="hljs-comment">// 显存供应商（例如三星、海力士等）</span><br>    <span class="hljs-type">uint32_t</span> ecc_status;               <span class="hljs-comment">// ECC（错误纠正码）状态</span><br>    <span class="hljs-type">uint32_t</span> srbm_soft_reset;          <span class="hljs-comment">// SRBM（系统请求总线管理器）软复位寄存器</span><br>    <span class="hljs-type">bool</span> prt_warning;                  <span class="hljs-comment">// PRT（部分资源事务）警告标志</span><br><br>    <span class="hljs-type">uint32_t</span> sdpif_register;           <span class="hljs-comment">// SDPIF（串行数据处理接口）寄存器</span><br><br>    <span class="hljs-comment">/* 各种孔径（用于多 GPU 配置时的地址分配） */</span><br>    u64 shared_aperture_start;         <span class="hljs-comment">// 共享孔径起始地址</span><br>    u64 shared_aperture_end;           <span class="hljs-comment">// 共享孔径结束地址</span><br>    u64 private_aperture_start;        <span class="hljs-comment">// 私有孔径起始地址</span><br>    u64 private_aperture_end;          <span class="hljs-comment">// 私有孔径结束地址</span><br><br>    <span class="hljs-comment">/* 用于保护并发的无效化操作 */</span><br>    <span class="hljs-type">spinlock_t</span> invalidate_lock;        <span class="hljs-comment">// 自旋锁，保护并发内存无效化操作</span><br>    <span class="hljs-type">bool</span> translate_further;            <span class="hljs-comment">// 是否需要进一步地址转换</span><br><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">kfd_vm_fault_info</span> *<span class="hljs-title">vm_fault_info</span>;</span>  <span class="hljs-comment">// 虚拟内存故障信息</span><br>    <span class="hljs-type">atomic_t</span> vm_fault_info_updated;           <span class="hljs-comment">// 故障信息更新标志</span><br><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_gmc_fault</span> <span class="hljs-title">fault_ring</span>[<span class="hljs-title">AMDGPU_GMC_FAULT_RING_SIZE</span>];</span>  <span class="hljs-comment">// 内存故障环形缓冲区</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> &#123;</span><br>        <span class="hljs-type">uint64_t</span> idx:AMDGPU_GMC_FAULT_RING_ORDER;       <span class="hljs-comment">// 故障环形缓冲区索引</span><br>    &#125; fault_hash[AMDGPU_GMC_FAULT_HASH_SIZE];           <span class="hljs-comment">// 故障哈希表</span><br>    <span class="hljs-type">uint64_t</span> last_fault:AMDGPU_GMC_FAULT_RING_ORDER;    <span class="hljs-comment">// 上次内存故障索引</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">ifdef</span> HYGON_KMD_SUPPORT</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_gmc_va_hash</span> <span class="hljs-title">va_hash_table</span>[<span class="hljs-title">MAX_VA_HASH_SIZE</span>];</span>  <span class="hljs-comment">// VA（虚拟地址）哈希表（Hygon 芯片支持）</span><br><span class="hljs-meta">#<span class="hljs-keyword">endif</span></span><br><br>    <span class="hljs-type">bool</span> tmz_enabled;                           <span class="hljs-comment">// 是否启用 TMZ（受信内存区）</span><br><br>    <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_gmc_funcs</span> *<span class="hljs-title">gmc_funcs</span>;</span>   <span class="hljs-comment">// GMC 功能函数指针</span><br><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_xgmi</span> <span class="hljs-title">xgmi</span>;</span>                    <span class="hljs-comment">// XGMI（GPU 互联）结构体</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_irq_src</span> <span class="hljs-title">ecc_irq</span>;</span>              <span class="hljs-comment">// ECC 中断源</span><br>    <span class="hljs-type">int</span> noretry;                                <span class="hljs-comment">// 重试机制控制</span><br><br>    <span class="hljs-type">uint32_t</span> vmid0_page_table_block_size;       <span class="hljs-comment">// VMID0 页表块大小</span><br>    <span class="hljs-type">uint32_t</span> vmid0_page_table_depth;            <span class="hljs-comment">// VMID0 页表深度</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_bo</span> *<span class="hljs-title">pdb0_bo</span>;</span>                  <span class="hljs-comment">// VMID0 的页目录基址块</span><br>    <span class="hljs-type">void</span> *ptr_pdb0;                             <span class="hljs-comment">// 页目录基址块的 CPU 映射地址</span><br><br>    u64 noretry_flags;                          <span class="hljs-comment">// 内存事务重试标志</span><br>&#125;;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * GPU 全局内存控制器（GMC）结构体、函数及辅助工具。</span><br><span class="hljs-comment"> */</span><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_gmc_funcs</span> &#123;</span><br>    <span class="hljs-comment">/* 通过 MMIO（内存映射 I/O）刷新 VM（虚拟内存） TLB（页表缓冲区） */</span><br>    <span class="hljs-type">void</span> (*flush_gpu_tlb)(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">uint32_t</span> vmid,<br>                <span class="hljs-type">uint32_t</span> vmhub, <span class="hljs-type">uint32_t</span> flush_type);<br><br>    <span class="hljs-comment">/* 通过 PASID（进程地址空间 ID）刷新 VM TLB */</span><br>    <span class="hljs-type">int</span> (*flush_gpu_tlb_pasid)(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">uint16_t</span> pasid,<br>                    <span class="hljs-type">uint32_t</span> flush_type, <span class="hljs-type">bool</span> all_hub);<br><br>    <span class="hljs-comment">/* 通过 GPU 指令环（ring buffer）刷新 VM TLB */</span><br>    <span class="hljs-type">uint64_t</span> (*emit_flush_gpu_tlb)(<span class="hljs-keyword">struct</span> amdgpu_ring *ring, <span class="hljs-type">unsigned</span> vmid,<br>                    <span class="hljs-type">uint64_t</span> pd_addr);<br><br>    <span class="hljs-comment">/* 修改 VMID（虚拟内存 ID）到 PASID（进程地址空间 ID）的映射关系 */</span><br>    <span class="hljs-type">void</span> (*emit_pasid_mapping)(<span class="hljs-keyword">struct</span> amdgpu_ring *ring, <span class="hljs-type">unsigned</span> vmid,<br>                <span class="hljs-type">unsigned</span> pasid);<br><br>    <span class="hljs-comment">/* 启用/禁用 PRT（部分资源事务）支持 */</span><br>    <span class="hljs-type">void</span> (*set_prt)(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">bool</span> enable);<br><br>    <span class="hljs-comment">/* 将内存类型（mtype）映射到硬件标志 */</span><br>    <span class="hljs-type">uint64_t</span> (*map_mtype)(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">uint32_t</span> flags);<br><br>    <span class="hljs-comment">/* 获取给定 MC（内存控制器）地址的页目录条目（PDE） */</span><br>    <span class="hljs-type">void</span> (*get_vm_pde)(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">int</span> level,<br>            u64 *dst, u64 *flags);<br><br>    <span class="hljs-comment">/* 获取用于 BO（缓冲对象）VA（虚拟地址）映射的 PTE（页表项）标志 */</span><br>    <span class="hljs-type">void</span> (*get_vm_pte)(<span class="hljs-keyword">struct</span> amdgpu_device *adev,<br>            <span class="hljs-keyword">struct</span> amdgpu_bo_va_mapping *mapping,<br>            <span class="hljs-type">uint64_t</span> *flags);<br>&#125;;<br></code></pre></td></tr></table></figure><p><code>struct amdgpu_gmc</code> 是 AMDGPU 驱动中用于表示 AMD GPU 全局内存控制器（Global Memory Controller, GMC）配置的结构体。该结构体主要负责管理 GPU 内存的各种配置和状态，包括 VRAM（视频内存）、GART（图形地址重映射表）、AGP（加速图形端口）等。每个字段都有其特定用途，用于处理 GPU 内存分配、访问、和故障管理等任务。</p><ol><li><strong>内存孔径字段（Aperture Fields）:</strong><ul><li><strong>aper_base</strong> 和 <strong>aper_size</strong>：<ul><li>代表从 CPU 角度看到的帧缓冲区（Frame Buffer, FB）孔径的物理地址和大小。这与 GPU 视角的地址不同，后者由 <code>vram_start</code>&#x2F;<code>vram_end</code> 表示。</li></ul></li><li><strong>vram_start</strong> 和 <strong>vram_end</strong>：<ul><li>定义 GPU 本地 VRAM 的起始和结束地址。</li></ul></li><li><strong>fb_start</strong> 和 <strong>fb_end</strong>：<ul><li>描述 Frame Buffer 区域的起始和结束地址。在多 GPU 设置中（例如 XGMI 集群），该区域覆盖所有 GPU 的显存，每个 GPU 可能会有不同的偏移量。</li></ul></li><li><strong>agp_start、agp_end、agp_size</strong>：<ul><li>指定 AGP（加速图形端口）孔径，主要用于早期 GPU 或集成 APU 的内存访问。</li></ul></li><li><strong>gart_start、gart_end、gart_size</strong>：<ul><li>描述 GART（图形地址重映射表）孔径，用于访问分页的系统内存（例如在虚拟内存场景下）。</li></ul></li></ul></li><li><strong>内存大小和属性字段:</strong><ul><li><strong>mc_vram_size</strong>：<ul><li>指定从内存控制器（Memory Controller, MC）视角看到的 VRAM 大小。</li></ul></li><li><strong>visible_vram_size</strong>：<ul><li>定义 CPU 可见的 VRAM 大小，这可能小于或等于 <code>mc_vram_size</code>。</li></ul></li><li><strong>real_vram_size</strong>：<ul><li>表示 GPU 实际可用的 VRAM 总大小。</li></ul></li><li><strong>vram_width</strong>：<ul><li>表示 VRAM 的总宽度（位宽），影响显存带宽。</li></ul></li></ul></li><li><strong>故障处理（Fault Handling）字段:</strong><ul><li><strong>vm_fault</strong>：<ul><li>描述虚拟内存（VM）故障的来源。</li></ul></li><li><strong>vm_fault_info</strong> 和 <strong>vm_fault_info_updated</strong>：<ul><li>存储虚拟内存故障的详细信息，并跟踪故障信息的更新。</li></ul></li><li><strong>fault_ring</strong>：<ul><li>用于记录和处理 GPU 内存故障的环形缓冲区。</li></ul></li></ul></li><li><strong>孔径共享和地址转换字段:</strong><ul><li><strong>shared_aperture_start</strong> 和 <strong>shared_aperture_end</strong>：<ul><li>多设备共享的孔径范围，用于 XGMI 等多 GPU 互联场景。</li></ul></li><li><strong>private_aperture_start</strong> 和 <strong>private_aperture_end</strong>：<ul><li>该设备独有的孔径范围。</li></ul></li><li><strong>translate_further</strong>：<ul><li>布尔类型，指示地址转换是否需要进一步进行。</li></ul></li></ul></li><li><strong>固件和配置信息:</strong><ul><li><strong>fw</strong> 和 <strong>fw_version</strong>：<ul><li>指向 MC 固件和固件版本号。</li></ul></li><li><strong>ecc_status</strong>：<ul><li>记录 ECC（错误纠正码）状态，用于检查显存中是否发生了位错误。</li></ul></li><li><strong>tmz_enabled</strong>：<ul><li>指示是否启用了 TMZ（受信内存区），这是一种用于保护特定内存区域的安全功能。</li></ul></li></ul></li><li><strong>锁和同步字段:</strong><ul><li><strong>invalidate_lock</strong>：<ul><li>自旋锁，用于保护内存无效化操作的并发访问。</li></ul></li></ul></li><li><strong>页表配置字段:</strong><ul><li><strong>vmid0_page_table_block_size</strong> 和 <strong>vmid0_page_table_depth</strong>：<ul><li>VMID0 页表的配置设置，决定页表的粒度和深度。</li></ul></li></ul></li><li><strong>多 GPU 和互联支持字段:</strong><ul><li><strong>xgmi</strong>：<ul><li>表示 XGMI（高速 GPU 互联）结构体，用于管理多 GPU 的互联配置和状态。</li></ul></li></ul></li><li><strong>其他字段:</strong><ul><li><strong>sdpif_register</strong>：<ul><li>SDPIF（串行数据处理接口）寄存器，用于与其他组件通信。</li></ul></li><li><strong>noretry</strong> 和 <strong>noretry_flags</strong>：<ul><li>内存事务重试机制的控制字段。</li></ul></li></ul></li></ol><p><code>amdgpu_gmc</code> 结构体被设计用于详细描述 AMD GPU 内存的各个部分，包括显存、系统内存和地址重映射表的配置。它可以管理不同 GPU 之间的内存地址空间，并为不同内存类型分配特定的地址范围。此外，它还包含故障处理字段以记录内存访问错误，并且支持多 GPU 的内存地址转换和互联配置。这些字段确保 GPU 内存管理的高效性和可靠性，是实现高性能计算和图形处理的基础。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-7c6792e1" role="button" aria-expanded="false" aria-controls="collapse-7c6792e1">        <div class="fold-arrow">▶</div>Direct Rendering Manager (DRM)      </div>      <div class="fold-collapse collapse" id="collapse-7c6792e1">        <div class="fold-content">          <p><strong>DRM</strong> 是 Linux 内核中的一个子系统，负责管理图形硬件设备。它为图形处理器（GPU）和显示设备提供低级别的图形资源管理和硬件加速支持。主要用于显示服务器（如 X11 或 Wayland）和图形库（如 Mesa 3D）与 GPU 之间的交互。</p><ol><li><strong>内存管理</strong>:<ul><li>DRM 管理 GPU 使用的显存（VRAM）和系统内存（GTT）。它处理内存的分配、映射和释放，确保 GPU 和 CPU 可以高效地共享和使用内存资源。</li></ul></li><li><strong>上下文管理</strong>:<ul><li>DRM 支持图形上下文的创建和管理，使多个图形应用程序可以同时运行并独立渲染其内容。这对于多任务处理和确保应用程序之间的隔离至关重要。</li></ul></li><li><strong>图形硬件控制</strong>:<ul><li>DRM 直接与图形硬件（如 GPU、显示控制器）交互，执行低级别操作，如显示模式设置（Mode Setting）、 Frame Buffer 管理（Framebuffer Management）、硬件加速命令的排队和执行等。</li></ul></li><li><strong>安全和访问控制</strong>:<ul><li>DRM 提供了对图形硬件的安全访问控制，确保只有授权的应用程序能够访问 GPU 资源。这在多用户环境中非常重要。</li></ul></li><li><strong>显示管理</strong>:<ul><li>DRM 包含了显示管理的功能，包括管理多个显示器、设置显示模式（分辨率、刷新率等）、处理热插拔事件等。它为图形栈中的更高级别组件（如 X Server 或 Wayland Compositor）提供了统一的接口。</li></ul></li></ol><p>DRM 的组件</p><ul><li><strong>DRM 驱动程序</strong>:<ul><li>这是特定于硬件的内核模块，负责与特定的 GPU 和显示硬件交互。每个支持 DRM 的 GPU 都有一个相应的 DRM 驱动程序，例如 <code>amdgpu</code>（AMD GPU）、<code>i915</code>（Intel GPU）、<code>nouveau</code>（NVIDIA 开源驱动）等。</li></ul></li><li><strong>GEM (Graphics Execution Manager)</strong>:<ul><li>这是 DRM 的一部分，负责内存对象的管理，特别是图形缓冲区的分配、映射和释放。</li></ul></li><li><strong>KMS (Kernel Mode Setting)</strong>:<ul><li>KMS 是 DRM 的一个子系统，用于在内核中设置显示模式（分辨率、颜色深度、刷新率等），而不是由用户空间应用程序设置。KMS 确保显示管理的安全性和稳定性，尤其是在多用户系统中。</li></ul></li></ul><p>DRM 的实际应用</p><p>在 Linux 系统中，DRM 是现代图形栈的核心组成部分。它提供了 GPU 资源的底层管理，支持 OpenGL、Vulkan 和其他图形 API 的硬件加速，确保图形应用程序能够高效运行。显示服务器如 X11 和 Wayland，图形库如 Mesa 3D，都依赖于 DRM 提供的功能来与 GPU 进行交互。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-f1c92c02" role="button" aria-expanded="false" aria-controls="collapse-f1c92c02">        <div class="fold-arrow">▶</div>TTM (Translation Table Manager)      </div>      <div class="fold-collapse collapse" id="collapse-f1c92c02">        <div class="fold-content">          <p>TTM 一个内存管理子系统，最初由 Tungsten Graphics 开发，目的是为 Linux 内核中的图形设备提供统一的内存管理。TTM 主要处理显存（VRAM）和系统内存（GART 或者系统RAM）之间的数据交换。它可以动态地管理和分配这些内存区域，支持显卡的高效使用。TTM 具有以下几个关键功能：</p><ul><li>内存管理：为图形硬件分配内存，支持在显存和系统内存之间的动态切换。</li><li>分页：在显存不足的情况下，TTM 允许将一些内存页面从显存转移到系统内存，从而腾出显存空间。</li><li>地址映射：通过使用页表和其他映射技术，TTM 可以将物理内存映射到 GPU 可访问的虚拟地址空间。</li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-715cf005" role="button" aria-expanded="false" aria-controls="collapse-715cf005">        <div class="fold-arrow">▶</div>GEM (Graphics Execution Manager)      </div>      <div class="fold-collapse collapse" id="collapse-715cf005">        <div class="fold-content">          <p>GEM 是 Linux 内核中用于图形内存管理的一个框架，特别是用于与图形处理单元（GPU）交互。GEM 主要由 Intel 为其 i915 DRM 驱动程序开发，但后来被其他驱动程序采用或借鉴，用于管理 GPU 上的图形内存。</p><ol><li><strong>图形内存对象管理</strong>:<ul><li>GEM 负责分配、管理和释放 GPU 使用的图形内存对象。这些对象可以包括缓冲区（例如 Frame Buffer ）、纹理、顶点缓冲区等，这些都是 GPU 进行图形渲染的基础。</li></ul></li><li><strong>内存映射</strong>:<ul><li>GEM 允许用户空间程序将 GPU 内存映射到 CPU 地址空间。这意味着用户空间程序可以直接访问和修改 GPU 内存内容，例如更新纹理数据或将渲染结果从 GPU 传输回 CPU 进行后续处理。</li></ul></li><li><strong>同步与缓冲区共享</strong>:<ul><li>在一个系统中，多个进程或线程可能需要访问同一块 GPU 内存。GEM 提供了同步机制，确保这些访问是安全且有序的。</li><li>GEM 还允许共享缓冲区对象，这意味着不同的进程或 GPU 阶段可以共享和重用相同的图形内存对象，提高资源利用率和性能。</li></ul></li><li><strong>用户空间接口</strong>:<ul><li>GEM 提供了一组 ioctl（输入输出控制）接口，供用户空间程序调用。这些接口包括内存对象的创建、销毁、映射和同步操作等，使得用户空间程序能够与内核中的 GEM 模块交互，管理 GPU 内存。</li></ul></li><li><strong>调度与执行管理</strong>:<ul><li>GEM 在某些情况下也负责调度图形命令的执行，确保 GPU 可以高效地处理多个渲染任务。它通过管理图形命令流和确保内存对象的可用性来优化 GPU 的使用。</li></ul></li></ol><p>GEM 的引入极大地简化了 GPU 内存管理，使得图形应用程序可以更容易地管理 GPU 资源。通过提供一个通用的内存管理框架，GEM 使得不同的 GPU 驱动程序可以更一致地管理内存，减少了在不同硬件和驱动程序之间进行移植时的复杂性。在 Linux 内核中，除了 GEM 之外，还有其他用于 GPU 内存管理的机制，例如 <strong>TTM（Translation Table Maps）</strong>。TTM 是另一个内存管理框架，主要由 AMD 开发，并在一些开源驱动中使用。</p><ul><li><strong>GEM vs. TTM</strong>:<ul><li><strong>GEM</strong>：较简单，适用于较轻量级的图形内存管理任务，特别是在资源管理需求较低的环境中。</li><li><strong>TTM</strong>：更复杂，支持更高级的功能，如内存分页和交换，更适合需要大量内存管理的高性能图形应用程序。</li></ul></li></ul><p>一些 GPU 驱动程序可能会基于这两者的组合来实现最优的内存管理方案。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-db7fe252" role="button" aria-expanded="false" aria-controls="collapse-db7fe252">        <div class="fold-arrow">▶</div>PTE（Page Table Entry，页表项）和 PDE（Page Directory Entry，页目录项）      </div>      <div class="fold-collapse collapse" id="collapse-db7fe252">        <div class="fold-content">          <p>ROCm 中的 SVM 实现主要存在于 Thunk 中的用户模式下。分配内存时，Thunk 使用 mmap (…, PROT_NONE, …) 为内存分配虚拟地址空间。GPU 可以处理 48 位虚拟地址。缓冲区应映射到主机（如果它是主机可访问的缓冲区）和所有适用 GPU 上的该虚拟地址。</p><p>KFD 内存分配 ioctl 有一个用于虚拟地址的参数 <code>kfd_ioctl_alloc_memory_of_gpu_args.va_addr</code>。也就是说，Thunk 应该在要求 KFD 分配内存之前分配虚拟地址空间。KFD 在分配时将虚拟地址与内存关联起来。内存的未来映射应该使用该虚拟地址。如果适用，主机映射由 Thunk 使用 mmap(va_addr, …, MAP_FIXED, …) 完成，在第一个参数中指定先前分配的虚拟地址。</p><p>通过 ROCm API 分配的内存应映射到所有设备（主机和目标）上的相同虚拟地址。可以在设备上使用相同的指针来引用相同的内存。包含指针的数据结构可以在设备之间共享。</p><ul><li>MC 地址和 GPU 的物理地址：在为 GPU 编写驱动程序代码时，区分 MC（GPU 的内存控制器）和物理地址非常重要。GPU 物理地址从零开始，一直到最大视频内存大小。另一方面，MC 地址具有 48 位地址空间。内存孔径地址范围寄存器大多在 MC 地址空间中定义。通过定义这些寄存器的值，可以确定虚拟内存地址空间。<ul><li>F400000000 MC 地址在 VBIOS 中定义，当 GPU 自行启动时，应将该值写入寄存器 MC_VM_FB_LOCATION_BASE，驱动程序将该值读出为“系统定义值”，并且该值应该是预定义的。因此，该值不是 GPU 硬件中的硬编码值，您可以根据需要更改该值。</li><li>如何根据 MC 地址计算 GPU 的物理地址，可以按照以下公式计算物理地址：<strong>FB 的物理地址 &#x3D; (McAddr - ‘FB aperture start address’) + PHYS_FB_OFFSET</strong><ul><li>McAddr：在本例中为 MC 地址 F4_0000_0008。</li><li>FB aperture start address：由寄存器 MC_VM_FB_LOCATION_BASE 定义的 F4_0000_0000</li><li>PHYS_FB_OFFSET：它定义了 UMA 地址中视频内存的物理偏移量，因此在独立 GPU 中它应始终为 0。</li></ul></li><li>因此，您可以得到 (F4_0000_0008) 的物理地址为 (F4_0000_0008 – F4_0000_0000) + 0 &#x3D; 0x8</li></ul></li></ul><p>在填充页表的时候需要用到物理地址来组成PTE和PDE，所以了解如何计算物理地址很重要，但请注意有些寄存器是定义在MC地址中的，有些是定义在物理地址中的，不要混淆。</p><p>系统孔径（Aperture）：系统孔径由两部分组成， Frame Buffer 孔径和 AGP 孔径。大多数情况下，系统孔径与 Frame Buffer 孔径一致，即“本地 Frame Buffer ”或“视频内存”。孔径由两个寄存器“mmMC_VM_SYSTEM_APERTURE_LOW_ADDR”和“mmMC_VM_SYSTEM_APERTURE_HIGH_ADDR”定义。</p><p>MC 地址布局不是固定的，它实际上取决于使用情况和不同的平台。对于 Linux，地址布局有两个孔径，系统孔径和 Gart 孔径。</p><ul><li>系统孔径从 F400000000 开始，到视频内存的最大大小结束。</li><li>Gart 孔径目前定义在系统孔径之后，但同样，这不是硬件定义的值，您可以根据需要更改布局。您可以在“孔径”以外的任何地方定义，并且不要与其他孔径重叠。</li></ul><p>GPU MC 地址空间由两部分组成，高位部分（0xFFFF_8000_0000_0000, 0xFFFF_FFFF_FFFF_FFF），低位部分（0x0000_0000_0000_0000, 0x0000_7FFF_FFFF_FFFF），范围由 48 位地址空间第 47 位的有符号扩展定义，当第 47 位 &#x3D;&#x3D; 0 时，可以将 0 扩展至 64 位，并应获得低位部分的上限，当第 47 位 &#x3D;&#x3D; 1 时，可以将 1 扩展至 64 位，并应获得高位地址的下限。这两部分之间的地址称为“洞”，当 GPU 接收到洞内的任何地址时，它都是无效地址。</p><p>“Memory Address Space.xls”中引用了 Remote GPU FB 孔径，这是 VBIOS 和 SYSTEM BIOS 中额外支持在 gpu 中导出“Large-Bar”的，“Large-Bar”是指主机可以访问本地 Frame Buffer 的概念，这意味着 PCIE bar 空间是 64bit，系统可以分配一个覆盖本地 Frame Buffer 的地址空间。在这种模式下，GPU 可以通过 PCIE 相互访问，因为本地 Frame Buffer 对彼此是可见的。</p><p>GART 页表 在Linux开源驱动中，Gart表位于“可见内存”中。Gart表是一级页表。PAGE_TABLE_DEPTH定义为实际级别减一。</p><p>但有一个例外，这就是“LDS孔径”和“私有（临时）孔径”，有配置寄存器来指定这两个孔径，因此在计算着色器中，可以通过“FLAT*”指令访问这两个孔径。 分配给“LDS孔径”和“私有孔径”一部分的“洞”内的地址可以直接在“FLAT*”指令中使用，GPU可以通过该地址访问LDS或私有孔径。</p><p>GPUVM 使用模型 在 GPU 中，有 16 个称为 VMID 的 vm 域，VMID0 称为“系统域”，只有内核模式驱动程序可以使用 VMID0，它被配置为“gart 模型”，但其他 VMID 都暴露给用户模式驱动程序，从使用模型来看，VMID1 到 VMID15 是相等的。</p><p>虽然 GPU 是可配置的，但您可以为每个 VMID 分配不同的 vm 空间，但通常情况下，您会平等地配置其余 15 个 VMID。</p><p> Frame Buffer 用于显示，并且 gart 表必须在内部可见，固件则不是，固件应在驱动程序初始化 PSP 模块时上传到专用 ROM 上。 “VF 可见 Frame Buffer ”，VF 指的是虚拟功能，这是虚拟化中的一个概念。</p><p>“HDP”代表“主机数据路径”，它是主机在不知道 Frame Buffer 中实际内存布局的情况下访问 Frame Buffer 的方式。</p><p>VMID使用及分配策略 除0以外的VMID被视为平等，在开源linux驱动中，VMID1~VMID7分配给图形使用，VMID8~VMID15分配给计算使用，但这不是硬件限制，您可以重新定义使用。</p><p>页表级别也可以从1级到4级配置，所以也取决于使用情况，在Linux开源驱动中，您可以为每个VMID分配64GB的虚拟地址，因为如果覆盖太大的虚拟空间，页表将非常大，从而消耗视频内存。</p><p>所以，综上所述，VMID0是为启用GART表而设计的系统域，页表是一级，GART空间的大小是可配置的。 VMID1~VMID15 是用户模式虚拟机，每个虚拟机都有 64GB 的虚拟内存空间，同样，这是根据使用情况可配置的，gfx 驱动中是 64GB，但是 Rocm 驱动从 rocm 2.0 开始为用户启用了整个 48 位虚拟内存空间。用户模式驱动可以分配本地 Frame Buffer 或 gart 空间，更新到 PTE 中。</p><p>页表中有两种类型的块：</p><ul><li>页目录块 (PDB)</li><li>页表块 (PTB)</li></ul><p>在这些类型的块中，有两种类型的条目：</p><ul><li>PDB 中的页目录条目 (PDE)</li><li>PTB 中的页表条目 (PTE) 页表由一定数量的级别构成，最底层是页表块，其上每一级都是页目录块。</li></ul><p>PDB 由一组 64 位页面目录条目 (PDE) 组成。中间 PDB（不是最顶层的 PDB）最多应有 512 个 PDE；也就是说，它们最多占用单个对齐的 4kb 内存页面。最顶层的 PDB 可以小或大，以表示所需的虚拟地址空间；最顶层的 PDB 可以占用多个 4kb 内存页面，但组成页面必须相邻。每个 PDE 指向 8 个 PDE 或 8 个 PTE 的缓存行的物理基址，具体取决于其在页表层次结构中的位置。</p><p><img src="/img/gpu/amd/pte.png" alt="PTE"></p><p>出于代码和寄存器文档命名目的，PDE 级别进一步描述如下：</p><ul><li>PDE0 - 指向 8 个 PTE 的起始缓存行</li><li>PDE1 - 指向 8 个 PDE0 的起始缓存行</li><li>PDE2 - 指向 8 个 PDE1 的起始缓存行</li></ul><p>64 位 PDE 的格式为：</p><p>关联页表块大小为 0 的传统页表块 (PTB) 包含 512 个 64 位页表条目 (PTE)，占用 4KB 内存空间。每个 PTE 指向一个 4KB 可寻址内存页，PTB 中的所有 512 个 PTE 共同寻址 2MB 内存空间（512 x 4KB &#x3D; 2MB）。</p><p><img src="/img/gpu/amd/format.png" alt="PTE"></p><p>定义在：amdgpu-5.7.0-0\amd\amdgpu\amdgpu_vm.h</p><ul><li>M – Mtype</li><li>F – 进一步转换</li><li>L – 日志</li><li>P - PTE</li><li>SW – 软件</li><li>T – 平铺 (PRT)</li><li>W - 写入</li><li>R - 读取</li><li>X - 执行</li><li>Z - tmZ</li><li>C – 可缓存&#x2F;监听</li><li>S - 系统</li><li>V - 有效</li></ul><p>64 位 PTE 的格式为：</p><p>MTYPE 旨在控制基于描述符或指针的内存访问的 TC 缓存行为。此寄存器中指定的 Mtype 适用于没有关联描述符来指定 mtype 的内存访问。KMD 旨在根据寻址模式为非零 VMID 编程默认 mtype。对于 GPUVM32 和 64 寻址模式，KMD 应将默认 mtype 编程为 cached_NON_Coherent(NC)，对于 HSA32 和 64 寻址模式，默认 mtype 编程为 Cached Coherent(CC)。VMID 0 的 Mtype 编程为 Uncached。</p><p>以下是 GPU 上的 mType 值：</p><ul><li>0 - NC；缓存，非连贯</li><li>1 - WC；写入组合</li><li>2 - CC；缓存，连贯</li><li>3 - UC；未缓存的</li></ul><p><strong>V 位：</strong>V 位控制 PTE 是否为有效的 GPUVM 页面，如果将 V 位设置为 0，GPU MC 应该请求 ATC（IOMMU）进行进一步转换，因为它是主机页面而不是 GPU 页面，这用于实现共享虚拟内存。</p><p><strong>C 位：</strong>指示内存类型是监听还是非监听。在 Linux 驱动程序中，根据页面是否缓存来设置位。</p><p><strong>S 位：</strong>指示页面地址是否引用主机页面。在 Linux 驱动程序中，在为 GPU 访问分配主机页面时，始终在 PTE 中启用此位。</p><p>详细剖析见：</p><ul><li><a href="https://www.cnblogs.com/binlovetech/p/17571929.html">一步一图带你构建 Linux 页表体系 —— 详解虚拟内存如何与物理内存进行映射</a></li><li><a href="https://www.cnblogs.com/binlovetech/p/16914715.html">一步一图带你深入理解 Linux 物理内存管理</a></li></ul><p>PTE（Page Table Entry，页表项）和 PDE（Page Directory Entry，页目录项）是虚拟内存管理系统中用于内存地址转换的重要概念，尤其是在 x86 架构和类似的内存管理单元（MMU）中广泛使用。在现代操作系统中，虚拟内存通过分页机制实现，将虚拟地址空间映射到物理地址空间。这种映射通常分为多级，即通过多个层次的表逐步解析虚拟地址，最终找到对应的物理地址。</p><p>PTE:</p><ul><li><strong>页表项</strong>是虚拟内存系统中最低级别的映射条目，用于将虚拟页面映射到物理页面。</li><li><strong>结构</strong>：PTE 通常包含以下信息：<ul><li><strong>物理页框地址</strong>：指向物理内存中的一个页面的起始地址。</li><li><strong>状态标志</strong>：如有效位（valid bit）、可读&#x2F;可写标志（read&#x2F;write bit）、用户&#x2F;内核模式标志（user&#x2F;kernel mode bit）等。</li><li><strong>特权和缓存控制</strong>：可能包含一些关于该页面特权级别的标志和缓存控制位。</li></ul></li><li><strong>功能</strong>：当 CPU 需要访问某个虚拟地址时，PTE 会被查找到，以获取该地址对应的物理地址，从而进行实际的数据访问。</li></ul><p>PDE:</p><ul><li><strong>页目录项</strong>是在多级分页结构中用于指向下一级页表的条目，通常是第一级映射。</li><li><strong>结构</strong>：PDE 通常包含以下信息：<ul><li><strong>页表基地址</strong>：指向下一级页表的物理地址。</li><li><strong>状态标志</strong>：类似 PTE，也有一些控制和状态标志，如有效位、权限标志等。</li></ul></li><li><strong>功能</strong>：PDE 的作用是指向页表（即包含 PTE 的数据结构）。在多级分页机制中，CPU 会先查找 PDE 来确定具体使用哪个页表，然后再通过该页表中的 PTE 找到最终的物理地址。</li></ul><p>多级页表管理:</p><ul><li><strong>一级分页（单级页表）</strong>：整个虚拟地址空间通过一个单一的页表映射到物理地址。</li><li><strong>多级分页（例如两级或四级页表）</strong>：虚拟地址通过多个级别的表来逐步解析。最常见的是两级或四级页表结构。<ul><li><strong>二级页表</strong>：包含页目录（Page Directory）和页表（Page Table）。虚拟地址首先通过页目录项（PDE）找到页表，然后通过页表项（PTE）找到对应的物理页框。</li><li><strong>四级页表</strong>：进一步扩展，添加了页全局目录（Page Global Directory，PGD）和页上级目录（Page Upper Directory，PUD），用于处理更大的虚拟地址空间。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-1ea41ce4" role="button" aria-expanded="false" aria-controls="collapse-1ea41ce4">        <div class="fold-arrow">▶</div>BO（Buffer Object）      </div>      <div class="fold-collapse collapse" id="collapse-1ea41ce4">        <div class="fold-content">          <p>BO 是在图形驱动程序中用于管理内存缓冲区的抽象对象。在 AMD 的驱动程序中，BO 通常与图形资源（如纹理、 Frame Buffer 、顶点缓冲区等）相关联。这些缓冲区对象通过 TTM 或其他内存管理机制来管理和分配实际的内存资源。BO 具备以下特性：</p><ul><li>内存分配：通过 BO 接口，图形驱动程序可以为各种图形资源分配和管理内存。</li><li>引用计数：BO 通常带有引用计数机制，以确保在缓冲区不再需要时可以安全地释放内存。</li><li>内存映射：BO 可以被映射到用户空间，使得应用程序可以直接访问这些图形资源。</li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-c03e4a67" role="button" aria-expanded="false" aria-controls="collapse-c03e4a67">        <div class="fold-arrow">▶</div>GART（Graphics Address Remapping Table）      </div>      <div class="fold-collapse collapse" id="collapse-c03e4a67">        <div class="fold-content">          <p>GART 是一个关键的内存管理机制，主要用于在系统内存（通常是主机的 RAM）和 GPU（图形处理单元）的地址空间之间进行地址映射和管理。</p><ol><li><strong>地址映射</strong>:<ul><li>GART 是一种内存管理单元（MMU），用于将系统内存中的物理地址映射到 GPU 虚拟地址空间（GPUVA）。这种映射允许 GPU 直接访问系统内存中的数据，而不必将所有数据都存储在有限的显存（VRAM）中。</li><li><strong>通过 GART，系统内存的一部分被虚拟化为 GPU 可以访问的地址范围，从而扩展了 GPU 的可用内存空间。</strong></li></ul></li><li><strong>页面调度与切换</strong>:<ul><li>GART 支持对大页面和小页面的管理，使得 GPU 能够灵活地访问系统内存中的不同大小的内存块。</li><li>当 GPU 需要访问不在显存中的数据时，GART 可以通过页表切换将这些数据从系统内存加载到 GPU 可访问的地址空间。</li></ul></li><li><strong>内存一致性与缓存</strong>:<ul><li>GART 负责确保 CPU 和 GPU 之间的数据一致性。它通过控制地址映射，确保当 CPU 修改了某些系统内存区域后，GPU 能够及时看到这些修改。</li><li>GART 还涉及到缓存控制，确保在不同情况下正确处理缓存一致性问题。</li></ul></li></ol><p>在 AMD GPU 架构中，GART 通常用于以下场景：</p><ul><li><strong>共享内存资源</strong>：当 GPU 需要频繁访问大量的系统内存数据时，使用 GART 允许这些数据直接映射到 GPU 的地址空间，而无需不断地在 VRAM 和系统内存之间移动数据。</li><li><strong>数据传输</strong>：在数据传输过程中，GART 可以有效地管理从系统内存到 GPU 地址空间的数据路径，提高数据传输效率。<br>用</li></ul><p>在实际的应用场景中，GART 被用于管理那些无法全部放入 VRAM 的数据，尤其是在需要处理大量数据或当 VRAM 资源受限的情况下。例如，在大型图形应用程序或游戏中，GART 允许 GPU 访问那些需要动态加载和处理的资源，如纹理、几何数据等。</p>        </div>      </div>    </div><p>以下是具体细节的KMD代码实现分析：</p><h3 id="内存申请"><a href="#内存申请" class="headerlink" title="内存申请"></a>内存申请</h3>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-c0745a51" role="button" aria-expanded="false" aria-controls="collapse-c0745a51">        <div class="fold-arrow">▶</div>kfd_ioctl_alloc_memory_of_gpu      </div>      <div class="fold-collapse collapse" id="collapse-c0745a51">        <div class="fold-content">          <p><img src="/img/gpu/amd/kfd_ioctl_alloc_memory_of_gpu.png" alt="kfd_ioctl_alloc_memory_of_gpu"></p><p>用于在 GPU 虚拟内存（GPUVM）中分配内存。该函数处理内存的分配、初始化和管理，确保 GPU 和 CPU 之间的内存映射和访问符合预期。</p><p>参数解析</p><ul><li><strong><code>adev</code></strong>: 指向 <code>amdgpu_device</code> 结构体的指针，表示当前的 AMD GPU 设备。</li><li><strong><code>va</code></strong>: 虚拟地址，表示分配的内存在 GPU 虚拟地址空间中的位置。</li><li><strong><code>size</code></strong>: 要分配的内存的大小，以字节为单位。</li><li><strong><code>drm_priv</code></strong>: 表示与当前进程相关的 DRM 私有数据，通常是一个指向 <code>amdgpu_vm</code>（虚拟内存）结构的指针。</li><li><strong><code>mem</code></strong>: 指向指针的指针，函数返回时会指向一个已分配的 <code>kgd_mem</code> 结构体，表示分配的 GPU 内存。</li><li><strong><code>offset</code></strong>: 指向 64 位整数的指针，函数返回时会包含与分配的内存相关的偏移量（通常用于 mmap）。</li><li><strong><code>flags</code></strong>: 内存分配标志，指示如何分配内存（例如分配到 VRAM、GTT 等）。</li><li><strong><code>criu_resume</code></strong>: 布尔值，指示是否在 CRIU 恢复上下文中分配内存。</li></ul><p>主要执行流程</p><ol><li><strong>虚拟内存初始化</strong>:<ul><li>函数首先从 <code>drm_priv</code> 中提取出 <code>amdgpu_vm</code>（虚拟内存管理）结构。</li><li>根据 <code>flags</code> 确定分配内存的类型（VRAM、GTT、用户指针等），并设置相应的内存分配标志。</li></ul></li><li><strong>分配内存区域</strong>:<ul><li>如果标志表明内存应分配在 VRAM 中，函数会设置 <code>domain</code> 和 <code>alloc_domain</code> 为 VRAM，并根据标志确定其他分配选项，如 CPU 访问要求等。</li><li>如果标志指示内存应分配在 GTT（显卡地址转换表）中，函数会相应设置 <code>domain</code> 和 <code>alloc_domain</code> 为 GTT。</li><li>函数还会处理其他特殊情况，如用户指针（<code>USERPTR</code>）或 <code>DOORBELL</code> 内存。</li></ul></li><li><strong>分配 <code>kgd_mem</code> 结构</strong>:<ul><li>函数为 <code>kgd_mem</code> 结构分配内存，并初始化它的一些基本字段，如分配标志和同步对象。</li></ul></li><li><strong>内存预留与分配</strong>:<ul><li>函数会调用 <code>amdgpu_amdkfd_reserve_mem_limit</code> 预留内存限制，以确保足够的内存可供分配。</li><li>使用 <code>amdgpu_gem_object_create</code> 创建实际的缓冲区对象（<code>BO</code>），这代表了分配的 GPU 内存。</li></ul></li><li><strong>内存映射与管理</strong>:<ul><li>如果是用户指针内存（<code>USERPTR</code>），函数会初始化用户页表。</li><li>如果是 <code>DOORBELL</code> 或 <code>MMIO_REMAP</code> 内存，函数会将 BO 固定在 GTT 中。</li><li>最后，函数会将偏移量返回给调用者，以便于后续的内存映射。</li></ul></li><li><strong>错误处理与回滚</strong>:<ul><li>函数包含多个错误处理路径。如果在内存分配或初始化过程中遇到问题，它会清理已分配的资源，并返回相应的错误代码。</li></ul></li></ol><p>关键概念</p><ul><li><strong>BO (Buffer Object)</strong>: 在图形驱动程序中用于表示 GPU 上的内存缓冲区。</li><li><strong>GTT (Graphics Translation Table)</strong>: 用于管理系统内存与 GPU 显存之间的映射。</li><li><strong>VRAM</strong>: 显存，GPU 上的高速内存，用于存储需要快速访问的数据，如纹理、 Frame Buffer 等。</li><li><strong>User Pointer (USERPTR)</strong>: 允许用户空间的指针直接映射到 GPU 的地址空间，通常用于高效的数据共享。</li></ul><p>该函数的作用</p><p>这个函数的作用是确保在适当的内存域（VRAM、GTT 等）中分配 GPU 内存，并处理复杂的内存映射需求，同时提供足够的灵活性以应对不同的内存分配场景（如用户指针、DOORBELL 等）。它是 AMD GPU 驱动程序中的一个重要部分，确保了 GPU 内存的高效管理和使用。</p>        </div>      </div>    </div><h3 id="内存映射"><a href="#内存映射" class="headerlink" title="内存映射"></a>内存映射</h3>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-b897114f" role="button" aria-expanded="false" aria-controls="collapse-b897114f">        <div class="fold-arrow">▶</div>kfd_ioctl_map_memory_to_gpu      </div>      <div class="fold-collapse collapse" id="collapse-b897114f">        <div class="fold-content">          <p><img src="/img/gpu/amd/kfd_ioctl_map_memory_to_gpu.png" alt="kfd_ioctl_map_memory_to_gpu"></p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-7757a5f2" role="button" aria-expanded="false" aria-controls="collapse-7757a5f2">        <div class="fold-arrow">▶</div>PDE Update      </div>      <div class="fold-collapse collapse" id="collapse-7757a5f2">        <div class="fold-content">          <p><img src="/img/gpu/amd/pde.png" alt="pde"></p><p><img src="/img/gpu/amd/amdgpu_vm_update_pdes.png" alt="amdgpu_vm_update_pdes"></p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br></pre></td><td class="code"><pre><code class="hljs c">amdgpu_vm_pde_update --&gt; vm-&gt;update_funcs-&gt;update --&gt; amdgpu_vm_sdma_update --&gt; amdgpu_vm_sdma_set_ptes / amdgpu_vm_sdma_copy_ptes<br><br><span class="hljs-comment">// amdgpu_vm_pt_clear --&gt; vm-&gt;update_funcs-&gt;update --&gt; amdgpu_vm_sdma_update</span><br><span class="hljs-comment">// amdgpu_vm_pte_update_flags --&gt; vm-&gt;update_funcs-&gt;update --&gt; amdgpu_vm_sdma_update</span><br><br><span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_vm_update_funcs</span> <span class="hljs-title">amdgpu_vm_sdma_funcs</span> =</span> &#123;<br>    .map_table = amdgpu_vm_sdma_map_table,<br>    .prepare = amdgpu_vm_sdma_prepare,<br>    .update = amdgpu_vm_sdma_update,<br>    .commit = amdgpu_vm_sdma_commit<br>&#125;;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_vm_sdma_set_ptes - helper to call the right asic function</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @p: see amdgpu_vm_update_params definition</span><br><span class="hljs-comment"> * @bo: PD/PT to update</span><br><span class="hljs-comment"> * @pe: byte offset of the PDE/PTE, relative to start of PDB/PTB</span><br><span class="hljs-comment"> * @addr: dst addr to write into pe</span><br><span class="hljs-comment"> * @count: number of page entries to update</span><br><span class="hljs-comment"> * @incr: increase next addr by incr bytes</span><br><span class="hljs-comment"> * @flags: hw access flags</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Traces the parameters and calls the right asic functions</span><br><span class="hljs-comment"> * to setup the page table using the DMA.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">amdgpu_vm_sdma_set_ptes</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_vm_update_params *p,</span><br><span class="hljs-params">                                    <span class="hljs-keyword">struct</span> amdgpu_bo *bo, <span class="hljs-type">uint64_t</span> pe,</span><br><span class="hljs-params">                                    <span class="hljs-type">uint64_t</span> addr, <span class="hljs-type">unsigned</span> count,</span><br><span class="hljs-params">                                    <span class="hljs-type">uint32_t</span> incr, <span class="hljs-type">uint64_t</span> flags)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_ib</span> *<span class="hljs-title">ib</span> =</span> p-&gt;job-&gt;ibs;<br><br>    pe += amdgpu_gmc_sign_extend(amdgpu_bo_gpu_offset_no_check(bo));<br>    trace_amdgpu_vm_set_ptes(pe, addr, count, incr, flags, p-&gt;immediate);<br>    <span class="hljs-keyword">if</span> (count &lt; <span class="hljs-number">3</span>) &#123;<br>        amdgpu_vm_write_pte(p-&gt;adev, ib, pe, addr | flags,<br>                    count, incr);<br>    &#125; <span class="hljs-keyword">else</span> &#123;<br>        amdgpu_vm_set_pte_pde(p-&gt;adev, ib, pe, addr,<br>                    count, incr, flags);<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_vm_sdma_copy_ptes - copy the PTEs from mapping</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @p: see amdgpu_vm_update_params definition</span><br><span class="hljs-comment"> * @bo: PD/PT to update</span><br><span class="hljs-comment"> * @pe: addr of the page entry</span><br><span class="hljs-comment"> * @count: number of page entries to copy</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Traces the parameters and calls the DMA function to copy the PTEs.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">amdgpu_vm_sdma_copy_ptes</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_vm_update_params *p,</span><br><span class="hljs-params">                                    <span class="hljs-keyword">struct</span> amdgpu_bo *bo, <span class="hljs-type">uint64_t</span> pe,</span><br><span class="hljs-params">                                    <span class="hljs-type">unsigned</span> count)</span><br>&#123;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_ib</span> *<span class="hljs-title">ib</span> =</span> p-&gt;job-&gt;ibs;<br>    <span class="hljs-type">uint64_t</span> src = ib-&gt;gpu_addr;<br><br>    src += p-&gt;num_dw_left * <span class="hljs-number">4</span>;<br><br>    pe += amdgpu_gmc_sign_extend(amdgpu_bo_gpu_offset_no_check(bo));<br>    trace_amdgpu_vm_copy_ptes(pe, src, count, p-&gt;immediate);<br><br>    amdgpu_vm_copy_pte(p-&gt;adev, ib, pe, src, count);<br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> amdgpu_vm_copy_pte(adev, ib, pe, src, count) ((adev)-&gt;vm_manager.vm_pte_funcs-&gt;copy_pte((ib), (pe), (src), (count)))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> amdgpu_vm_write_pte(adev, ib, pe, value, count, incr) ((adev)-&gt;vm_manager.vm_pte_funcs-&gt;write_pte((ib), (pe), (value), (count), (incr)))</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> amdgpu_vm_set_pte_pde(adev, ib, pe, addr, count, incr, flags) ((adev)-&gt;vm_manager.vm_pte_funcs-&gt;set_pte_pde((ib), (pe), (addr), (count), (incr), (flags)))</span><br><br><span class="hljs-type">static</span> <span class="hljs-type">const</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">amdgpu_vm_pte_funcs</span> <span class="hljs-title">sdma_v4_0_vm_pte_funcs</span> =</span> &#123;<br>    .copy_pte_num_dw = <span class="hljs-number">7</span>,<br>    .copy_pte = sdma_v4_0_vm_copy_pte,<br><br>    .write_pte = sdma_v4_0_vm_write_pte,<br>    .set_pte_pde = sdma_v4_0_vm_set_pte_pde,<br>&#125;;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * sdma_v4_0_vm_copy_pte - update PTEs by copying them from the GART</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @ib: indirect buffer to fill with commands</span><br><span class="hljs-comment"> * @pe: addr of the page entry</span><br><span class="hljs-comment"> * @src: src addr to copy from</span><br><span class="hljs-comment"> * @count: number of page entries to update</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Update PTEs by copying them from the GART using sDMA (VEGA10).</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">sdma_v4_0_vm_copy_pte</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ib *ib,</span><br><span class="hljs-params">                                    <span class="hljs-type">uint64_t</span> pe, <span class="hljs-type">uint64_t</span> src,</span><br><span class="hljs-params">                                    <span class="hljs-type">unsigned</span> count)</span><br>&#123;<br>    <span class="hljs-type">unsigned</span> bytes = count * <span class="hljs-number">8</span>;<br><br>    ib-&gt;ptr[ib-&gt;length_dw++] = SDMA_PKT_HEADER_OP(SDMA_OP_COPY) |<br>        SDMA_PKT_HEADER_SUB_OP(SDMA_SUBOP_COPY_LINEAR);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = bytes - <span class="hljs-number">1</span>;<br>    ib-&gt;ptr[ib-&gt;length_dw++] = <span class="hljs-number">0</span>; <span class="hljs-comment">/* src/dst endian swap */</span><br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(src);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(src);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(pe);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(pe);<br><br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * sdma_v4_0_vm_write_pte - update PTEs by writing them manually</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @ib: indirect buffer to fill with commands</span><br><span class="hljs-comment"> * @pe: addr of the page entry</span><br><span class="hljs-comment"> * @value: dst addr to write into pe</span><br><span class="hljs-comment"> * @count: number of page entries to update</span><br><span class="hljs-comment"> * @incr: increase next addr by incr bytes</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Update PTEs by writing them manually using sDMA (VEGA10).</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">sdma_v4_0_vm_write_pte</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ib *ib, <span class="hljs-type">uint64_t</span> pe,</span><br><span class="hljs-params">                                    <span class="hljs-type">uint64_t</span> value, <span class="hljs-type">unsigned</span> count,</span><br><span class="hljs-params">                                    <span class="hljs-type">uint32_t</span> incr)</span><br>&#123;<br>    <span class="hljs-type">unsigned</span> ndw = count * <span class="hljs-number">2</span>;<br><br>    ib-&gt;ptr[ib-&gt;length_dw++] = SDMA_PKT_HEADER_OP(SDMA_OP_WRITE) |<br>        SDMA_PKT_HEADER_SUB_OP(SDMA_SUBOP_WRITE_LINEAR);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(pe);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(pe);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = ndw - <span class="hljs-number">1</span>;<br>    <span class="hljs-keyword">for</span> (; ndw &gt; <span class="hljs-number">0</span>; ndw -= <span class="hljs-number">2</span>) &#123;<br>        ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(value);<br>        ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(value);<br>        value += incr;<br>    &#125;<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * sdma_v4_0_vm_set_pte_pde - update the page tables using sDMA</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @ib: indirect buffer to fill with commands</span><br><span class="hljs-comment"> * @pe: addr of the page entry</span><br><span class="hljs-comment"> * @addr: dst addr to write into pe</span><br><span class="hljs-comment"> * @count: number of page entries to update</span><br><span class="hljs-comment"> * @incr: increase next addr by incr bytes</span><br><span class="hljs-comment"> * @flags: access flags</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Update the page tables using sDMA (VEGA10).</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">sdma_v4_0_vm_set_pte_pde</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ib *ib,</span><br><span class="hljs-params">                    <span class="hljs-type">uint64_t</span> pe,</span><br><span class="hljs-params">                    <span class="hljs-type">uint64_t</span> addr, <span class="hljs-type">unsigned</span> count,</span><br><span class="hljs-params">                    <span class="hljs-type">uint32_t</span> incr, <span class="hljs-type">uint64_t</span> flags)</span><br>&#123;<br>    <span class="hljs-comment">/* for physically contiguous pages (vram) */</span><br>    ib-&gt;ptr[ib-&gt;length_dw++] = SDMA_PKT_HEADER_OP(SDMA_OP_PTEPDE);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(pe); <span class="hljs-comment">/* dst addr */</span><br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(pe);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(flags); <span class="hljs-comment">/* mask */</span><br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(flags);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(addr); <span class="hljs-comment">/* value */</span><br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(addr);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = incr; <span class="hljs-comment">/* increment size */</span><br>    ib-&gt;ptr[ib-&gt;length_dw++] = <span class="hljs-number">0</span>;<br>    ib-&gt;ptr[ib-&gt;length_dw++] = count - <span class="hljs-number">1</span>; <span class="hljs-comment">/* number of entries */</span><br>&#125;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-32ef457a" role="button" aria-expanded="false" aria-controls="collapse-32ef457a">        <div class="fold-arrow">▶</div>TLB Flush      </div>      <div class="fold-collapse collapse" id="collapse-32ef457a">        <div class="fold-content">          <blockquote><p>当缓存中未写入的数据量达到一定水平时，控制器会定期将缓存数据写入驱动器。此写入过程称为“刷新”。<br>控制器使用两种算法来刷新缓存：基于需求和基于年龄。控制器使用基于需求的算法，直到缓存数据量低于缓存刷新阈值。默认情况下，当 80% 的缓存正在使用时，刷新开始。<br>在系统管理器中，您可以设置“启动需求缓存刷新”阈值，以最好地支持环境中使用的 I&#x2F;O 类型。在主要进行写入操作的环境中，您应该将“启动需求缓存刷新”百分比设置为较高，以增加任何新的写入请求都可以由缓存处理而无需转到磁盘的可能性。高百分比设置会限制缓存刷新的次数，以便更多数据保留在缓存中，从而增加更多缓存命中的机会。<br>在 I&#x2F;O 不稳定（数据突发）的环境中，您可以使用较低的缓存刷新，以便系统在数据突发之间频繁刷新缓存。在处理各种负载的多样化 I&#x2F;O 环境中，或者当负载类型未知时，将阈值设置为 50% 是一个不错的中间值。请注意，如果选择的启动百分比低于 80%，则可能会看到性能下降，因为主机读取所需的数据可能不可用。选择较低的百分比还会增加维持缓存级别所需的磁盘写入次数，从而增加系统开销。<br>基于年龄的算法指定写入数据在有资格刷新到磁盘之前可以保留在缓存中的时间段。控制器使用基于年龄的算法，直到达到缓存刷新阈值。默认值为 10 秒，但此时间段仅在非活动期间计算。您无法在系统管理器中修改刷新时间；相反，您必须使用命令行界面 (CLI) 中的“设置存储阵列”命令。</p></blockquote><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">gfx_v9_0_kiq_invalidate_tlbs</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ring *kiq_ring,</span><br><span class="hljs-params">    <span class="hljs-type">uint16_t</span> pasid, <span class="hljs-type">uint32_t</span> flush_type,</span><br><span class="hljs-params">    <span class="hljs-type">bool</span> all_hub)</span><br>&#123;<br>    amdgpu_ring_write(kiq_ring, PACKET3(PACKET3_INVALIDATE_TLBS, <span class="hljs-number">0</span>));<br>    amdgpu_ring_write(kiq_ring,<br>        PACKET3_INVALIDATE_TLBS_DST_SEL(<span class="hljs-number">1</span>) |<br>        PACKET3_INVALIDATE_TLBS_ALL_HUB(all_hub) |<br>        PACKET3_INVALIDATE_TLBS_PASID(pasid) |<br>        PACKET3_INVALIDATE_TLBS_FLUSH_TYPE(flush_type));<br>&#125;<br></code></pre></td></tr></table></figure><p><img src="/img/gpu/amd/amdgpu_amdkfd_flush_gpu_tlb_pasid.png" alt="amdgpu_amdkfd_flush_gpu_tlb_pasid"></p><p>amdgpu_amdkfd_flush_gpu_tlb_pasid –&gt; amdgpu_gmc_flush_gpu_tlb_pasid –&gt; gmc_v9_0_flush_gpu_tlb_pasid –&gt; gfx_v9_0_kiq_invalidate_tlbs</p><p>其中，kfd_ioctl_unmap_memory_from_gpu &#x2F; svm_range_unmap_from_gpus  采用 TLB_FLUSH_HEAVYWEIGHT 策略</p><p>第二路径：<br>gmc_v9_0_flush_gpu_tlb_pasid –&gt; gfx_v9_0_kiq_invalidate_tlbs</p><p>gmc_v9_0_flush_gpu_tlb_pasid –&gt; gmc_v9_0_flush_gpu_tlb（无pasid flush）</p><p>gmc_v9_0_hw_init –&gt; gmc_v9_0_flush_gpu_tlb</p><p><strong>amdgpu_gmc_flush_gpu_tlb</strong> –&gt; gmc_v9_0_flush_gpu_tlb</p><p><img src="/img/gpu/amd/amdgpu_gmc_flush_gpu_tlb.png" alt="amdgpu_gmc_flush_gpu_tlb"></p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-9a1c5b83" role="button" aria-expanded="false" aria-controls="collapse-9a1c5b83">        <div class="fold-arrow">▶</div>KMD Intialization      </div>      <div class="fold-collapse collapse" id="collapse-9a1c5b83">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">int</span> amdgpu_tmz = <span class="hljs-number">-1</span>; <span class="hljs-comment">/* auto */</span><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * DOC: tmz (int)</span><br><span class="hljs-comment"> * Trusted Memory Zone (TMZ) is a method to protect data being written</span><br><span class="hljs-comment"> * to or read from memory.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The default value: 0 (off).  <span class="hljs-doctag">TODO:</span> change to auto till it is completed.</span><br><span class="hljs-comment"> */</span><br>MODULE_PARM_DESC(tmz, <span class="hljs-string">&quot;Enable TMZ feature (-1 = auto (default), 0 = off, 1 = on)&quot;</span>);<br>module_param_named(tmz, amdgpu_tmz, <span class="hljs-type">int</span>, <span class="hljs-number">0444</span>);<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_gmc_tmz_set -- check and set if a device supports TMZ</span><br><span class="hljs-comment"> * @adev: amdgpu_device pointer</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Check and set if an the device @adev supports Trusted Memory</span><br><span class="hljs-comment"> * Zones (TMZ).</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">amdgpu_gmc_tmz_set</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev)</span><br>&#123;<br>    <span class="hljs-keyword">switch</span> (adev-&gt;asic_type) &#123;<br>    <span class="hljs-keyword">default</span>:<br>        adev-&gt;gmc.tmz_enabled = <span class="hljs-literal">false</span>;<br>        dev_info(adev-&gt;dev, <span class="hljs-string">&quot;Trusted Memory Zone (TMZ) feature not supported\n&quot;</span>);<br>        <span class="hljs-keyword">break</span>;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-d02d7b34" role="button" aria-expanded="false" aria-controls="collapse-d02d7b34">        <div class="fold-arrow">▶</div>Indirect Frame Buffer      </div>      <div class="fold-collapse collapse" id="collapse-d02d7b34">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_ib_schedule - schedule an IB (Indirect Buffer) on the ring</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @ring: ring index the IB is associated with</span><br><span class="hljs-comment"> * @num_ibs: number of IBs to schedule</span><br><span class="hljs-comment"> * @ibs: IB objects to schedule</span><br><span class="hljs-comment"> * @job: job to schedule</span><br><span class="hljs-comment"> * @f: fence created during this submission</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Schedule an IB on the associated ring (all asics).</span><br><span class="hljs-comment"> * Returns 0 on success, error on failure.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * On SI, there are two parallel engines fed from the primary ring,</span><br><span class="hljs-comment"> * the CE (Constant Engine) and the DE (Drawing Engine).  Since</span><br><span class="hljs-comment"> * resource descriptors have moved to memory, the CE allows you to</span><br><span class="hljs-comment"> * prime the caches while the DE is updating register state so that</span><br><span class="hljs-comment"> * the resource descriptors will be already in cache when the draw is</span><br><span class="hljs-comment"> * processed.  To accomplish this, the userspace driver submits two</span><br><span class="hljs-comment"> * IBs, one for the CE and one for the DE.  If there is a CE IB (called</span><br><span class="hljs-comment"> * a CONST_IB), it will be put on the ring prior to the DE IB.  Prior</span><br><span class="hljs-comment"> * to SI there was just a DE IB.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_ib_schedule</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ring *ring, <span class="hljs-type">unsigned</span> num_ibs,</span><br><span class="hljs-params">                        <span class="hljs-keyword">struct</span> amdgpu_ib *ibs, <span class="hljs-keyword">struct</span> amdgpu_job *job,</span><br><span class="hljs-params">                        <span class="hljs-keyword">struct</span> dma_fence **f)</span><br>&#123;<br>    <span class="hljs-comment">/* Setup initial TMZiness and send it off.</span><br><span class="hljs-comment">    */</span><br>    secure = <span class="hljs-literal">false</span>;<br>    <span class="hljs-keyword">if</span> (job &amp;&amp; ring-&gt;funcs-&gt;emit_frame_cntl) &#123;<br>        secure = ib-&gt;flags &amp; AMDGPU_IB_FLAGS_SECURE;<br>        amdgpu_ring_emit_frame_cntl(ring, <span class="hljs-literal">true</span>, secure);<br>    &#125;<br>&#125;<br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> amdgpu_ring_emit_frame_cntl(r, b, s) (r)-&gt;funcs-&gt;emit_frame_cntl((r), (b), (s))</span><br><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> PACKET3_FRAME_CONTROL   0x90</span><br><span class="hljs-meta">#           <span class="hljs-keyword">define</span> FRAME_TM     (1 &lt;&lt; 0)</span><br><span class="hljs-meta">#           <span class="hljs-keyword">define</span> FRAME_CMD(x) ((x) &lt;&lt; 28)</span><br>            <span class="hljs-comment">/*</span><br><span class="hljs-comment">             * x=0: tmz_begin</span><br><span class="hljs-comment">             * x=1: tmz_end</span><br><span class="hljs-comment">             */</span><br><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">gfx_v9_0_ring_emit_frame_cntl</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ring *ring, <span class="hljs-type">bool</span> start,</span><br><span class="hljs-params">                                            <span class="hljs-type">bool</span> secure)</span><br>&#123;<br>    <span class="hljs-type">uint32_t</span> v = secure ? FRAME_TMZ : <span class="hljs-number">0</span>;<br><br>    amdgpu_ring_write(ring, PACKET3(PACKET3_FRAME_CONTROL, <span class="hljs-number">0</span>));<br>    amdgpu_ring_write(ring, v | FRAME_CMD(start ? <span class="hljs-number">0</span> : <span class="hljs-number">1</span>));<br>&#125;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-432e828f" role="button" aria-expanded="false" aria-controls="collapse-432e828f">        <div class="fold-arrow">▶</div>TTM Buffer copy      </div>      <div class="fold-collapse collapse" id="collapse-432e828f">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_ttm_copy_mem_to_mem - Helper function for copy</span><br><span class="hljs-comment"> * @adev: amdgpu device</span><br><span class="hljs-comment"> * @src: buffer/address where to read from</span><br><span class="hljs-comment"> * @dst: buffer/address where to write to</span><br><span class="hljs-comment"> * @size: number of bytes to copy</span><br><span class="hljs-comment"> * @tmz: if a secure copy should be used</span><br><span class="hljs-comment"> * @resv: resv object to sync to</span><br><span class="hljs-comment"> * @f: Returns the last fence if multiple jobs are submitted.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * The function copies @size bytes from &#123;src-&gt;mem + src-&gt;offset&#125; to</span><br><span class="hljs-comment"> * &#123;dst-&gt;mem + dst-&gt;offset&#125;. src-&gt;bo and dst-&gt;bo could be same BO for a</span><br><span class="hljs-comment"> * move and different for a BO to BO copy.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_ttm_copy_mem_to_mem</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev,</span><br><span class="hljs-params">                                <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> amdgpu_copy_mem *src,</span><br><span class="hljs-params">                                <span class="hljs-type">const</span> <span class="hljs-keyword">struct</span> amdgpu_copy_mem *dst,</span><br><span class="hljs-params">                                <span class="hljs-type">uint64_t</span> size, <span class="hljs-type">bool</span> tmz,</span><br><span class="hljs-params">                                <span class="hljs-keyword">struct</span> dma_resv *resv,</span><br><span class="hljs-params">                                <span class="hljs-keyword">struct</span> dma_fence **f)</span><br><br>--&gt; <span class="hljs-title function_">amdgpu_copy_buffer</span><span class="hljs-params">()</span> --&gt; <span class="hljs-title function_">amdgpu_emit_copy_buffer</span><span class="hljs-params">()</span> --&gt; <span class="hljs-title function_">sdma_v4_0_emit_copy_buffer</span><span class="hljs-params">()</span><br></code></pre></td></tr></table></figure><p><img src="/img/gpu/amd/amdgpu_ttm_copy_mem_to_mem.png" alt="amdgpu_ttm_copy_mem_to_mem"></p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-b83a4609" role="button" aria-expanded="false" aria-controls="collapse-b83a4609">        <div class="fold-arrow">▶</div>SDMA Copy Buffer      </div>      <div class="fold-collapse collapse" id="collapse-b83a4609">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/*define for tmz field*/</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> SDMA_PKT_COPY_LINEAR_HEADER_tmz_offset 0</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> SDMA_PKT_COPY_LINEAR_HEADER_tmz_mask   0x00000001</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> SDMA_PKT_COPY_LINEAR_HEADER_tmz_shift  18</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> SDMA_PKT_COPY_LINEAR_HEADER_TMZ(x) (((x) &amp; SDMA_PKT_COPY_LINEAR_HEADER_tmz_mask) &lt;&lt; SDMA_PKT_COPY_LINEAR_HEADER_tmz_shift)</span><br><br><span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_copy_buffer</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ring *ring, <span class="hljs-type">uint64_t</span> src_offset,</span><br><span class="hljs-params">                        <span class="hljs-type">uint64_t</span> dst_offset, <span class="hljs-type">uint32_t</span> byte_count,</span><br><span class="hljs-params">                        <span class="hljs-keyword">struct</span> dma_resv *resv,</span><br><span class="hljs-params">                        <span class="hljs-keyword">struct</span> dma_fence **fence, <span class="hljs-type">bool</span> direct_submit,</span><br><span class="hljs-params">                        <span class="hljs-type">bool</span> vm_needs_flush, <span class="hljs-type">bool</span> tmz)</span><br><br>--&gt; <span class="hljs-title function_">amdgpu_emit_copy_buffer</span><span class="hljs-params">(adev, &amp;job-&gt;ibs[<span class="hljs-number">0</span>], src_offset,</span><br><span class="hljs-params">                                dst_offset, cur_size_in_bytes, tmz)</span>;<br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> amdgpu_emit_copy_buffer(adev, ib, s, d, b, t) (adev)-&gt;mman.buffer_funcs-&gt;emit_copy_buffer((ib),  (s), (d), (b), (t))</span><br><br><span class="hljs-type">void</span> (*emit_copy_buffer)(<span class="hljs-keyword">struct</span> amdgpu_ib *ib,<br>                        <span class="hljs-comment">/* src addr in bytes */</span><br>                        <span class="hljs-type">uint64_t</span> src_offset,<br>                        <span class="hljs-comment">/* dst addr in bytes */</span><br>                        <span class="hljs-type">uint64_t</span> dst_offset,<br>                        <span class="hljs-comment">/* number of byte to transfer */</span><br>                        <span class="hljs-type">uint32_t</span> byte_count,<br>                        <span class="hljs-type">bool</span> tmz);<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * sdma_v4_0_emit_copy_buffer - copy buffer using the sDMA engine</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @ib: indirect buffer to copy to</span><br><span class="hljs-comment"> * @src_offset: src GPU address</span><br><span class="hljs-comment"> * @dst_offset: dst GPU address</span><br><span class="hljs-comment"> * @byte_count: number of bytes to xfer</span><br><span class="hljs-comment"> * @tmz: if a secure copy should be used</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Copy GPU buffers using the DMA engine (VEGA10/12).</span><br><span class="hljs-comment"> * Used by the amdgpu ttm implementation to move pages if</span><br><span class="hljs-comment"> * registered as the asic copy callback.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">sdma_v4_0_emit_copy_buffer</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_ib *ib,</span><br><span class="hljs-params">                                        <span class="hljs-type">uint64_t</span> src_offset,</span><br><span class="hljs-params">                                        <span class="hljs-type">uint64_t</span> dst_offset,</span><br><span class="hljs-params">                                        <span class="hljs-type">uint32_t</span> byte_count,</span><br><span class="hljs-params">                                        <span class="hljs-type">bool</span> tmz)</span><br>&#123;<br>    ib-&gt;ptr[ib-&gt;length_dw++] = SDMA_PKT_HEADER_OP(SDMA_OP_COPY) |<br>        SDMA_PKT_HEADER_SUB_OP(SDMA_SUBOP_COPY_LINEAR) |<br>        SDMA_PKT_COPY_LINEAR_HEADER_TMZ(tmz ? <span class="hljs-number">1</span> : <span class="hljs-number">0</span>);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = byte_count - <span class="hljs-number">1</span>;<br>    ib-&gt;ptr[ib-&gt;length_dw++] = <span class="hljs-number">0</span>; <span class="hljs-comment">/* src/dst endian swap */</span><br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(src_offset);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(src_offset);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = lower_32_bits(dst_offset);<br>    ib-&gt;ptr[ib-&gt;length_dw++] = upper_32_bits(dst_offset);<br>&#125;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-33e598f1" role="button" aria-expanded="false" aria-controls="collapse-33e598f1">        <div class="fold-arrow">▶</div>TTM GART Bind      </div>      <div class="fold-collapse collapse" id="collapse-33e598f1">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">amdgpu_ttm_gart_bind</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev,</span><br><span class="hljs-params">     <span class="hljs-keyword">struct</span> ttm_buffer_object *tbo,</span><br><span class="hljs-params">     <span class="hljs-type">uint64_t</span> flags)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (amdgpu_bo_encrypted(abo))<br>        flags |= AMDGPU_PTE_TMZ;<br>&#125;<br><br>--&gt; amdgpu_gart_bind(adev, gtt-&gt;offset, page_idx, gtt-&gt;ttm.dma_address, flags);<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_gart_bind - bind pages into the gart page table</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @adev: amdgpu_device pointer</span><br><span class="hljs-comment"> * @offset: offset into the GPU&#x27;s gart aperture</span><br><span class="hljs-comment"> * @pages: number of pages to bind</span><br><span class="hljs-comment"> * @dma_addr: DMA addresses of pages</span><br><span class="hljs-comment"> * @flags: page table entry flags</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Binds the requested pages to the gart page table</span><br><span class="hljs-comment"> * (all asics).</span><br><span class="hljs-comment"> * Returns 0 for success, -EINVAL for failure.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">amdgpu_gart_bind</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">uint64_t</span> offset,</span><br><span class="hljs-params">                    <span class="hljs-type">int</span> pages, <span class="hljs-type">dma_addr_t</span> *dma_addr,</span><br><span class="hljs-params">                    <span class="hljs-type">uint64_t</span> flags)</span><br><br>--&gt; <span class="hljs-title function_">amdgpu_gart_map</span><span class="hljs-params">(adev, offset, pages, dma_addr, flags, adev-&gt;gart.ptr)</span>; --&gt; amdgpu_gmc_set_pte_pde(adev, dst, t, page_base, flags);<br></code></pre></td></tr></table></figure><p><img src="/img/gpu/amd/amdgpu_gart_map.png" alt="amdgpu_gart_map"></p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-12442369" role="button" aria-expanded="false" aria-controls="collapse-12442369">        <div class="fold-arrow">▶</div>TTM Map Buffer to GART      </div>      <div class="fold-collapse collapse" id="collapse-12442369">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_ttm_map_buffer - Map memory into the GART windows</span><br><span class="hljs-comment"> * @bo: buffer object to map</span><br><span class="hljs-comment"> * @mem: memory object to map</span><br><span class="hljs-comment"> * @mm_cur: range to map</span><br><span class="hljs-comment"> * @window: which GART window to use</span><br><span class="hljs-comment"> * @ring: DMA ring to use for the copy</span><br><span class="hljs-comment"> * @tmz: if we should setup a TMZ enabled mapping</span><br><span class="hljs-comment"> * @size: in number of bytes to map, out number of bytes mapped</span><br><span class="hljs-comment"> * @addr: resulting address inside the MC address space</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Setup one of the GART windows to access a specific piece of memory or return</span><br><span class="hljs-comment"> * the physical address for local memory.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_ttm_map_buffer</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> ttm_buffer_object *bo,</span><br><span class="hljs-params">                                    <span class="hljs-keyword">struct</span> ttm_resource *mem,</span><br><span class="hljs-params">                                    <span class="hljs-keyword">struct</span> amdgpu_res_cursor *mm_cur,</span><br><span class="hljs-params">                                    <span class="hljs-type">unsigned</span> window, <span class="hljs-keyword">struct</span> amdgpu_ring *ring,</span><br><span class="hljs-params">                                    <span class="hljs-type">bool</span> tmz, <span class="hljs-type">uint64_t</span> *size, <span class="hljs-type">uint64_t</span> *addr)</span><br><br>--&gt; <span class="hljs-title function_">amdgpu_gart_map</span><span class="hljs-params">(adev, <span class="hljs-number">0</span>, num_pages, dma_addr, flags, cpu_addr)</span>;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_gart_map - map dma_addresses into GART entries</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @adev: amdgpu_device pointer</span><br><span class="hljs-comment"> * @offset: offset into the GPU&#x27;s gart aperture</span><br><span class="hljs-comment"> * @pages: number of pages to bind</span><br><span class="hljs-comment"> * @dma_addr: DMA addresses of pages</span><br><span class="hljs-comment"> * @flags: page table entry flags</span><br><span class="hljs-comment"> * @dst: CPU address of the gart table</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Map the dma_addresses into GART entries (all asics).</span><br><span class="hljs-comment"> * Returns 0 for success, -EINVAL for failure.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">void</span> <span class="hljs-title function_">amdgpu_gart_map</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">uint64_t</span> offset,</span><br><span class="hljs-params">                    <span class="hljs-type">int</span> pages, <span class="hljs-type">dma_addr_t</span> *dma_addr, <span class="hljs-type">uint64_t</span> flags,</span><br><span class="hljs-params">                    <span class="hljs-type">void</span> *dst)</span><br><br>--&gt; <span class="hljs-title function_">amdgpu_gmc_set_pte_pde</span><span class="hljs-params">(adev, dst, t, page_base, flags)</span>;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_gmc_set_pte_pde - update the page tables using CPU</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @adev: amdgpu_device pointer</span><br><span class="hljs-comment"> * @cpu_pt_addr: cpu address of the page table</span><br><span class="hljs-comment"> * @gpu_page_idx: entry in the page table to update</span><br><span class="hljs-comment"> * @addr: dst addr to write into pte/pde</span><br><span class="hljs-comment"> * @flags: access flags</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Update the page tables using CPU.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_gmc_set_pte_pde</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-type">void</span> *cpu_pt_addr,</span><br><span class="hljs-params">                            <span class="hljs-type">uint32_t</span> gpu_page_idx, <span class="hljs-type">uint64_t</span> addr,</span><br><span class="hljs-params">                            <span class="hljs-type">uint64_t</span> flags)</span><br>&#123;<br>    <span class="hljs-type">void</span> __iomem *ptr = (<span class="hljs-type">void</span> *)cpu_pt_addr;<br>    <span class="hljs-type">uint64_t</span> value;<br><br>    <span class="hljs-comment">/*</span><br><span class="hljs-comment">    * The following is for PTE only. GART does not have PDEs.</span><br><span class="hljs-comment">    */</span><br>    value = addr &amp; <span class="hljs-number">0x0000FFFFFFFFF000</span>ULL;<br>    value |= flags;<br>    writeq(value, ptr + (gpu_page_idx * <span class="hljs-number">8</span>));<br><br>    <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>&#125;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-3eef66d4" role="button" aria-expanded="false" aria-controls="collapse-3eef66d4">        <div class="fold-arrow">▶</div>GEM encryption      </div>      <div class="fold-collapse collapse" id="collapse-3eef66d4">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// amdgpu-5.7.0-0\include\uapi\drm\amdgpu_drm.h:</span><br><br><span class="hljs-comment">/* Flag that BO will be encrypted and that the TMZ bit should be</span><br><span class="hljs-comment"> * set in the PTEs when mapping this buffer via GPUVM or</span><br><span class="hljs-comment"> * accessing it with various hw blocks</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> AMDGPU_GEM_CREATE_ENCRYPTED  (1 &lt;&lt; 10)</span><br><br><span class="hljs-comment">/* Flag the IB as secure (TMZ)</span><br><span class="hljs-comment"> */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> AMDGPU_IB_FLAGS_SECURE  (1 &lt;&lt; 5)</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> AMDGPU_IDS_FLAGS_TMZ            0x4</span><br><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_bo_encrypted - test if the BO is encrypted</span><br><span class="hljs-comment"> * @bo: pointer to a buffer object</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Return true if the buffer object is encrypted, false otherwise.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">bool</span> <span class="hljs-title function_">amdgpu_bo_encrypted</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_bo *bo)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> bo-&gt;flags &amp; AMDGPU_GEM_CREATE_ENCRYPTED;<br>&#125;<br><br><span class="hljs-comment">/*</span><br><span class="hljs-comment"> * GEM ioctls.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_gem_create_ioctl</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> drm_device *dev, <span class="hljs-type">void</span> *data,</span><br><span class="hljs-params">                            <span class="hljs-keyword">struct</span> drm_file *filp)</span> &#123;<br>    <span class="hljs-keyword">if</span> (!amdgpu_is_tmz(adev) &amp;&amp; (flags &amp; AMDGPU_GEM_CREATE_ENCRYPTED)) &#123;<br>        DRM_NOTE_ONCE(<span class="hljs-string">&quot;Cannot allocate secure buffer since TMZ is disabled\n&quot;</span>);<br>        <span class="hljs-keyword">return</span> -EINVAL;<br>    &#125;<br>&#125;<br><br><span class="hljs-type">static</span> <span class="hljs-keyword">inline</span> <span class="hljs-type">bool</span> <span class="hljs-title function_">amdgpu_is_tmz</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev)</span><br>&#123;<br>       <span class="hljs-keyword">return</span> adev-&gt;gmc.tmz_enabled;<br>&#125;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-2a25062f" role="button" aria-expanded="false" aria-controls="collapse-2a25062f">        <div class="fold-arrow">▶</div>BO PTE update      </div>      <div class="fold-collapse collapse" id="collapse-2a25062f">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">/* RV+ */</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> AMDGPU_PTE_TMZ  (1ULL &lt;&lt; 3)</span><br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_vm_bo_update - update all BO mappings in the vm page table</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @adev: amdgpu_device pointer</span><br><span class="hljs-comment"> * @bo_va: requested BO and VM object</span><br><span class="hljs-comment"> * @clear: if true clear the entries</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Fill in the page table entries for @bo_va.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Returns:</span><br><span class="hljs-comment"> * 0 for success, -EINVAL for failure.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_vm_bo_update</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_device *adev, <span class="hljs-keyword">struct</span> amdgpu_bo_va *bo_va,</span><br><span class="hljs-params">                        <span class="hljs-type">bool</span> clear)</span><br>&#123;<br>    <span class="hljs-keyword">if</span> (bo) &#123;<br>        flags = amdgpu_ttm_tt_pte_flags(adev, bo-&gt;tbo.ttm, mem);<br><br>    <span class="hljs-keyword">if</span> (amdgpu_bo_encrypted(bo))<br>        flags |= AMDGPU_PTE_TMZ;<br><br>    <span class="hljs-comment">// ...</span><br>    --&gt; amdgpu_vm_update_range --&gt; amdgpu_vm_ptes_update<br>&#125;<br><br><span class="hljs-comment">/**</span><br><span class="hljs-comment"> * amdgpu_vm_ptes_update - make sure that page tables are valid</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * @params: see amdgpu_vm_update_params definition</span><br><span class="hljs-comment"> * @start: start of GPU address range</span><br><span class="hljs-comment"> * @end: end of GPU address range</span><br><span class="hljs-comment"> * @dst: destination address to map to, the next dst inside the function</span><br><span class="hljs-comment"> * @flags: mapping flags</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Update the page tables in the range @start - @end.</span><br><span class="hljs-comment"> *</span><br><span class="hljs-comment"> * Returns:</span><br><span class="hljs-comment"> * 0 for success, -EINVAL for failure.</span><br><span class="hljs-comment"> */</span><br><span class="hljs-type">int</span> <span class="hljs-title function_">amdgpu_vm_ptes_update</span><span class="hljs-params">(<span class="hljs-keyword">struct</span> amdgpu_vm_update_params *params,</span><br><span class="hljs-params">                            <span class="hljs-type">uint64_t</span> start, <span class="hljs-type">uint64_t</span> end,</span><br><span class="hljs-params">                            <span class="hljs-type">uint64_t</span> dst, <span class="hljs-type">uint64_t</span> flags, <span class="hljs-keyword">struct</span> list_head *free_list)</span><br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-fcf67c0f" role="button" aria-expanded="false" aria-controls="collapse-fcf67c0f">        <div class="fold-arrow">▶</div>GDS set      </div>      <div class="fold-collapse collapse" id="collapse-fcf67c0f">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> GDS_VM_PROTECTION_FAULT__TMZ__SHIFT</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> GDS_VM_PROTECTION_FAULT__TMZ_MASK</span><br><br><span class="hljs-comment">// addressBlock: mmhub_l1tlb_vml1dec:1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB0_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB1_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB2_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB3_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB4_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB5_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB6_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TLB7_STATUS_DEFAULT                                 0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> mmVML1_1_MC_VM_MX_L1_TMZ_CNTL_DEFAULT                                    0x00000000</span><br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="拓展"><a href="#拓展" class="headerlink" title="拓展"></a>拓展</h2><ul><li><a href="https://blog.csdn.net/tugouxp/article/details/132819114"><strong>AMD GPU 内核驱动分析(一)总览</strong></a><ul><li><a href="https://blog.csdn.net/tugouxp/category_11951030.html">GPU</a></li><li><a href="https://edu.csdn.net/skill/cuda">CSDN CUDA 课程</a></li></ul></li><li><a href="https://blog.csdn.net/lsshao/article/details/122688688">虚拟内存和物理内存：从CPU和GPU交互的角度出发</a></li><li><a href="https://happyseeker.github.io/kernel/2016/07/22/memory-management-from-graphic-card-view.html">显卡内存管理机制及驱动实现(Intel gma500为例)</a></li><li><a href="https://blog.csdn.net/kunhe0512/article/details/132533305">GPU中统一内存最新机制解析</a></li><li><a href="https://adtxl.com/index.php/archives/316.html">Linux内存管理（19）IOMMU</a></li><li><a href="https://xiaolincoding.com/os/3_memory/linux_mem.html">深入理解 Linux 虚拟内存管理</a></li><li><a href="https://xiaolincoding.com/os/3_memory/linux_mem2.html">深入理解 Linux 物理内存管理</a></li><li><a href="https://www.cnblogs.com/wujianming-110117/p/17845376.html"><strong>显存架构，虚拟与物理内存</strong></a></li><li><a href="https://navycloud.github.io/2018/07/27/on-demand-scheduling/">AMD GPU虚拟化的按需调度策略</a></li><li><a href="https://blog.csdn.net/qq_40937426/article/details/127857533">Linux drm内存管理(一) 浅谈TTM与GEM，为什么我们需要TTM和GEM？</a></li><li><a href="https://blog.csdn.net/qq_40937426/article/details/128338947"><strong>Linux drm内存管理(二) TTM内存管理基础概念</strong></a></li><li><a href="https://blog.csdn.net/sty01z/article/details/134694799">drm 驱动系列 - 第三章 gem 内存管理</a></li><li><a href="https://blog.csdn.net/bai915290475/article/details/137436275">DRM内部结构之内存管理（二）</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>GPU</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>KMD</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>2024 清华 LLM 公开课 - 笔记</title>
    <link href="/2024/08/14/AI/Qinghua-Note/"/>
    <url>/2024/08/14/AI/Qinghua-Note/</url>
    
    <content type="html"><![CDATA[<p>深入介绍人工智能(AI)，重点介绍大型语言模型(LLM)的前沿发展，深入了解人工智能领域的历史、关键技术和现有挑战。</p><span id="more"></span><h1 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h1><ul><li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li><li><a href="#%E4%BB%8B%E7%BB%8D">介绍</a></li><li><a href="#1-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%AF%BC%E8%AE%BA">1 大语言模型导论</a><ul><li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E5%8E%86%E5%8F%B2">人工智能历史</a><ul><li><a href="#%E5%AE%9A%E4%B9%89">定义</a></li><li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E6%A6%82%E5%BF%B5%E5%8C%96">人工智能的概念化</a></li><li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%8F%91%E5%B1%95">人工智能的发展</a><ul><li><a href="#%E7%AC%A6%E5%8F%B7%E6%99%BA%E8%83%BD">符号智能</a></li><li><a href="#%E4%B8%93%E7%94%A8%E6%99%BA%E8%83%BD">专用智能</a></li><li><a href="#%E9%80%9A%E7%94%A8%E6%99%BA%E8%83%BD">通用智能</a></li></ul></li></ul></li><li><a href="#%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD">通用人工智能</a><ul><li><a href="#%E9%80%9A%E7%94%A8%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%9A%84%E5%AE%9A%E4%B9%89">通用人工智能的定义</a></li><li><a href="#%E4%BB%8E%E4%B8%93%E7%94%A8%E6%99%BA%E8%83%BD%E5%88%B0%E9%80%9A%E7%94%A8%E6%99%BA%E8%83%BD">从专用智能到通用智能</a></li><li><a href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B">大语言模型</a><ul><li><a href="#%E4%B8%8B%E4%B8%80%E4%B8%AAtoken%E9%A2%84%E6%B5%8B">下一个token预测</a></li><li><a href="#%E8%AE%AD%E7%BB%83">训练</a></li><li><a href="#%E6%8E%A8%E7%90%86">推理</a></li><li><a href="#%E6%80%BB%E7%BB%93">总结</a></li></ul></li><li><a href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95">大语言模型训练方法</a><ul><li><a href="#%E8%87%AA%E7%9B%91%E7%9D%A3%E9%A2%84%E8%AE%AD%E7%BB%83">自监督预训练</a></li><li><a href="#%E6%A0%87%E6%B3%A8%E5%BE%AE%E8%B0%83">标注微调</a></li><li><a href="#%E4%BB%8E%E4%BA%BA%E7%B1%BB%E5%8F%8D%E9%A6%88%E4%B8%AD%E5%AD%A6%E4%B9%A0">从人类反馈中学习</a></li></ul></li><li><a href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E6%88%90%E5%8A%9F%E7%9A%84%E5%85%B3%E9%94%AE">大语言模型成功的关键</a><ul><li><a href="#%E6%83%85%E5%A2%83%E4%B8%8A%E4%B8%8B%E6%96%87%E5%AD%A6%E4%B9%A0">情境（上下文）学习</a></li><li><a href="#%E9%81%B5%E5%BE%AA%E6%8C%87%E4%BB%A4">遵循指令</a></li><li><a href="#%E6%80%9D%E7%BB%B4%E9%93%BE">思维链</a></li></ul></li><li><a href="#%E6%BD%9C%E5%8A%9B%E5%92%8C%E6%8C%91%E6%88%98">潜力和挑战</a></li></ul></li><li><a href="#%E6%9C%AA%E6%9D%A5">未来</a><ul><li><a href="#%E4%BA%BA%E5%B7%A5%E6%99%BA%E8%83%BD%E7%A7%91%E5%AD%A6">人工智能科学</a></li><li><a href="#%E6%99%BA%E8%83%BD%E8%AE%A1%E7%AE%97%E7%B3%BB%E7%BB%9F">智能计算系统</a></li><li><a href="#%E5%B9%BF%E6%B3%9B%E5%BA%94%E7%94%A8%E4%BA%8E%E5%90%84%E4%B8%AA%E9%A2%86%E5%9F%9F">广泛应用于各个领域</a></li><li><a href="#%E6%80%BB%E7%BB%93-1">总结</a></li></ul></li></ul></li><li><a href="#2-%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86">2 神经网络基础知识</a><ul><li><a href="#%E7%AE%80%E5%8D%95%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">简单神经网络</a><ul><li><a href="#%E7%A5%9E%E7%BB%8F%E5%85%83">神经元</a></li><li><a href="#%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">神经网络</a></li><li><a href="#%E5%A4%9A%E5%B1%82%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">多层神经网络</a></li><li><a href="#%E4%B8%BA%E4%BB%80%E4%B9%88%E9%9C%80%E8%A6%81%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0">为什么需要激活函数</a></li><li><a href="#%E5%85%B8%E5%9E%8B%E7%9A%84%E6%BF%80%E6%B4%BB%E5%87%BD%E6%95%B0">典型的激活函数</a></li></ul></li><li><a href="#%E5%A6%82%E4%BD%95%E8%AE%AD%E7%BB%83%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">如何训练神经网络</a><ul><li><a href="#%E8%AE%AD%E7%BB%83%E7%9B%AE%E6%A0%87">训练目标</a></li><li><a href="#%E9%9A%8F%E6%9C%BA%E6%A2%AF%E5%BA%A6%E4%B8%8B%E9%99%8D">随机梯度下降</a></li><li><a href="#%E6%A2%AF%E5%BA%A6%E5%92%8C%E5%8F%8D%E5%90%91%E4%BC%A0%E6%92%AD">梯度和反向传播</a></li></ul></li><li><a href="#%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">循环神经网络</a><ul><li><a href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B">语言模型</a></li><li><a href="#%E7%94%A8%E4%BA%8E%E8%AF%AD%E8%A8%80%E5%BB%BA%E6%A8%A1%E7%9A%84%E5%BE%AA%E7%8E%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">用于语言建模的循环神经网络</a></li></ul></li><li><a href="#%E5%8D%B7%E7%A7%AF%E7%A5%9E%E7%BB%8F%E7%BD%91%E7%BB%9C">卷积神经网络</a><ul><li><a href="#%E5%AF%B9%E6%AF%94">对比</a></li></ul></li><li><a href="#seq2seq-%E5%92%8C-transformer">seq2seq 和 transformer</a><ul><li><a href="#%E6%9C%BA%E5%99%A8%E7%BF%BB%E8%AF%91%E4%B8%AD%E7%9A%84-seq2seq">机器翻译中的 seq2seq</a></li><li><a href="#transformer">transformer</a></li><li><a href="#decoder-only-%E5%92%8C-encoder-decoder">decoder-only 和 encoder-decoder</a></li></ul></li></ul></li><li><a href="#3-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E5%9F%BA%E7%A1%80%E7%9F%A5%E8%AF%86">3 大语言模型基础知识</a><ul><li><a href="#%E8%BF%81%E7%A7%BB%E5%AD%A6%E4%B9%A0">迁移学习</a></li><li><a href="#%E8%AF%AD%E8%A8%80%E5%BB%BA%E6%A8%A1%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83">语言建模的预训练</a><ul><li><a href="#word2vec">word2vec</a></li><li><a href="#%E4%B8%8A%E4%B8%8B%E6%96%87%E7%9B%B8%E5%85%B3%E7%9A%84%E8%AF%8D%E8%AF%AD%E8%A1%A8%E7%A4%BA">上下文相关的词语表示</a></li></ul></li><li><a href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B%E5%92%8C%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B">预训练模型和大语言模型</a><ul><li><a href="#%E9%A2%84%E8%AE%AD%E7%BB%83%E6%A8%A1%E5%9E%8B">预训练模型</a></li><li><a href="#%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B-1">大语言模型</a></li><li><a href="#%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E7%89%B9%E6%80%A7%E5%92%8C%E5%8A%9F%E8%83%BD">语言模型的特性和功能</a></li></ul></li></ul></li><li><a href="#4-%E5%A4%A7%E8%AF%AD%E8%A8%80%E6%A8%A1%E5%9E%8B%E7%9A%84%E8%AE%AD%E7%BB%83%E6%96%B9%E6%B3%95">4 大语言模型的训练方法</a><ul><li><a href="#%E5%A4%A7%E6%A8%A1%E5%9E%8B%E7%9A%84%E6%99%AE%E5%8F%8A">大模型的普及</a><ul><li><a href="#tokenization">tokenization</a></li><li><a href="#%E8%BF%87%E5%8E%BB%E7%9A%84%E9%A2%84%E8%AE%AD%E7%BB%83%E5%B5%8C%E5%85%A5">过去的预训练嵌入</a></li></ul></li><li><a href="#transformer-1">transformer</a><ul><li><a href="#gpt">gpt</a></li></ul></li></ul></li><li><a href="#%E5%8F%82%E8%80%83">参考</a></li></ul><h1 id="介绍"><a href="#介绍" class="headerlink" title="介绍"></a>介绍</h1><p>课程将讨论人工智能的未来趋势，帮助学生参与由人工智能驱动的技术变革浪潮。</p><ul><li><a href="https://www.openbmb.cn/home">OpenBMB 官网</a></li><li><a href="https://github.com/OpenBMB">OpenBMB Github</a></li><li><a href="https://www.bilibili.com/video/BV1pf421z757/">OpenBMB 公开课</a></li><li><a href="https://modelbest.feishu.cn/wiki/D2tFw8Pcsi5CIzkaHNacLK64npg">MiniCPM 部署指南</a></li><li><a href="https://github.com/ggerganov/llama.cpp/commit/d565bb2fd5a2a58b9924a7a34e77a87c78c52137">llama.cpp 支持 MiniCPM</a></li><li><a href="https://edu.csdn.net/course/detail/39736">CSDN 课程</a></li></ul><p>笔记包含下述标签：</p><div class="note note-primary">            <p>讲义引用的观点</p>          </div><div class="note note-danger">            <p>课程笔记</p>          </div><h1 id="1-大语言模型导论"><a href="#1-大语言模型导论" class="headerlink" title="1 大语言模型导论"></a>1 大语言模型导论</h1><h2 id="人工智能历史"><a href="#人工智能历史" class="headerlink" title="人工智能历史"></a>人工智能历史</h2><p>人工智能已经成为我们日常生活中必不可少的组成部分，极大地提高了我们的日常活动和工作效率: <strong>人脸识别、自动驾驶、语音识别与合成、推荐系统、信息检索</strong>。人工智能促进了知识的有效获取和新思想的探索，在我们社会的进步中发挥着至关重要的作用。</p><div class="note note-primary">            <p>人工智能本质上是每个人的<strong>生产力倍增器</strong>。它将使我们最好的科学家变得更好，使科学加快很多。<strong>人工智能将帮助我们在一个大脑中储存更多的知识，并发现新的联系，新的想法</strong> —— 山姆 · 奥特曼</p><p>我们致力于解决智能问题，<strong>推动科学发展，造福人类</strong> —— Demis Hassabis</p><p>人工智能是人类正在研究的最重要的事情之一，它比电或火更深刻 —— Sundar Pichai</p>          </div><h3 id="定义"><a href="#定义" class="headerlink" title="定义"></a>定义</h3><ul><li>目前，人工智能的定义缺乏共识</li><li>从广义上讲，<strong>人工智能是机器，特别是计算机系统所表现出的智能。它是计算机科学的一个研究领域，开发和研究方法和软件，使机器能够感知环境，并利用学习和智能采取行动，最大限度地提高实现既定目标的机会</strong></li></ul><div class="note note-primary">            <p>长期以来，人类一直对人工智能的概念着迷。根据希腊神话的记载，塔洛斯是一个巨大的青铜自动机，用来保护克里特岛上的欧罗巴免受海盗和入侵者的侵害。这是西方文学中最早对机器人的描述之一。据《列子 · 唐文》(列⼦ · 汤问)记载，工匠严石(偃师)向穆王(周穆王)展示了一个能唱歌跳舞的自主木偶。这是中国文学中最早描述机器人的作品之一。</p>          </div><h3 id="人工智能的概念化"><a href="#人工智能的概念化" class="headerlink" title="人工智能的概念化"></a>人工智能的概念化</h3><p>图灵(Alan Mathison Turing)，计算机科学和人工智能之父。1950年，图灵发表了一篇开创性的论文，题为《计算机器与智能》。在书中，他问道：<strong>机器能思考吗？</strong>从而引入了<strong>思考机器</strong>的概念，作为人工智能的基本概念。</p><div class="note note-danger">            <p>图灵和冯 · 诺伊曼，现代计算机科学两位重要奠基人。</p>          </div><p><strong>图灵测试</strong>是由图灵在他的论文《计算机器与智能》中介绍的。这是一种评估机器是否具有智能的方法。</p><div class="note note-primary">            <p>在图灵测试中，考官同时向人和机器提出问题。考官被要求辨别哪个是人，哪个是机器。如果考官不能区分它们，则认为机器通过了测试，显示出人类水平的智能。</p>          </div><div class="note note-danger">            <p>图灵测试从<strong>外部评判</strong>机器具不具备智能，计算机尽量“伪装”为人类，欺骗测试者，类似<strong>黑盒测试</strong>。<br>冯 · 诺伊曼也有相关研究：《计算机与人脑》</p>          </div><p>Dartmouth 研讨会：1956年夏天在达特茅斯学院举行，该研讨会为人工智能作为一门学科的研究奠定了基础。达特茅斯工作室的科学家约翰 · 麦卡锡、马文 · 明斯基、艾伦 · 纽维尔和赫伯特 · 西蒙获得了“图灵奖”。</p><div class="note note-danger">            <p>提出有价值，有引领意义的问题。</p>          </div><h3 id="人工智能的发展"><a href="#人工智能的发展" class="headerlink" title="人工智能的发展"></a>人工智能的发展</h3><p><img src="/img/ai/openbmb/lecture1/1.png" alt="人工智能的关键问题:赋予机器执行复杂任务所需的知识"></p><div class="note note-danger">            <p>基于对AI挑战的未知，不同阶段都有低谷和高潮</p>          </div><h4 id="符号智能"><a href="#符号智能" class="headerlink" title="符号智能"></a>符号智能</h4><p>基于符号和规则的早期范式，这种范式使用预定义的<strong>符号和规则</strong>来表示知识，允许进一步的信息分析和推理</p><p><img src="/img/ai/openbmb/lecture1/2.png" alt="Symbolic Intelligence"></p><p>局限性：构建一个涵盖无限知识的知识库具有挑战性，并且并非所有知识都可以明确地用结构化三元组表示。基于符号智能的系统不能处理知识库未涵盖的任务。</p><p><img src="/img/ai/openbmb/lecture1/3.png" alt="专家系统无法解决知识库未涵盖的问题"></p><div class="note note-danger">            <p>机器翻译和人脸识别，符号智能无法穷尽式的描述和解决</p>          </div><h4 id="专用智能"><a href="#专用智能" class="headerlink" title="专用智能"></a>专用智能</h4><p>特定任务的经典范式：这种范式通常从特定于任务的数据中训练数据驱动的机器学习模型，并将任务知识存储在特定于任务的小模型的参数中。</p><p><img src="/img/ai/openbmb/lecture1/4.png" alt="Narrow Intelligence"></p><p>局限性：为特定任务注释数据的成本很高，而且<strong>专用智能无法解决标注数据未涵盖的任务</strong>。</p><p><img src="/img/ai/openbmb/lecture1/5.png" alt="为特定任务设计的训练数据和小模型不能推广到数据分布之外的问题"></p><div class="note note-danger">            <p><strong>我们总是要定义任务</strong>，然后我们搜集数据，然后训练模型归纳，再应用于解决专用的任务<br>模型的泛化能力很差，只能在范围内工作，无法举一反三</p>          </div><h4 id="通用智能"><a href="#通用智能" class="headerlink" title="通用智能"></a>通用智能</h4><p>通用能力的未来范式：该范式采用自监督训练从大量未标记数据集中学习，将知识存储在大规模模型参数中</p><p><img src="/img/ai/openbmb/lecture1/6.png" alt="General Intelligence"></p><p>优势：未标记数据具有成本效益，易于获取；大尺度参数有利于一般知识的学习和存储。</p><p><img src="/img/ai/openbmb/lecture1/7.png" alt="大型语言模型通过对大规模未标记数据进行自监督预训练来学习一般知识"></p><div class="note note-danger">            <p>整个互联网的知识都可以学习，更强的泛化能力</p>          </div><h2 id="通用人工智能"><a href="#通用人工智能" class="headerlink" title="通用人工智能"></a>通用人工智能</h2><p>通用人工智能的曙光：</p><ul><li>LLM 的性能随着计算成本的增加而不断提高</li><li>在许多任务中，现有的 LLM，如 GPT-3.5&#x2F;4，已经取得了比人类更好的性能，预示着通用人工智能的曙光</li></ul><p><img src="/img/ai/openbmb/lecture1/8.png" alt="左：随着计算成本的增加，模型性能不断提高；注:Perplexity被广泛用于评价LLM的能力，Perplexity值越低表示模型性能越好，圆圈的大小表示用于训练模型的计算成本。右：GPT-4在多个专业考试中表现优于人类"></p><div class="note note-primary">            <p>我们需要科技突破来引导和控制比我们聪明得多的人工智能系统。为了<strong>在四年内</strong>解决这个问题，我们正在组建一个新的团队(超级联盟)。—— OpenAI</p><p>在<strong>不到三年</strong>的时间里，人工智能就能写出j.k.罗琳(《哈利波特》的作者)水平的小说，在物理学上有新的发现，在各个领域普遍超越人类的能力 —— 马斯克</p><p>我们不确定人工智能的未来会如何发展。然而，我们必须认真对待这样一种可能性，即在<strong>当前十年或下一个十年里</strong>，强大的通才人工智能系统将被开发出来，在许多关键领域超越人类的能力 —— 图灵奖得主Yoshua Bengio, Geoffrey Hinton, Andrew Yao</p>          </div><h3 id="通用人工智能的定义"><a href="#通用人工智能的定义" class="headerlink" title="通用人工智能的定义"></a>通用人工智能的定义</h3><ul><li><strong>通用人工智能（AGI）</strong>一词最早出现在Mark gubroud 1997年一篇关于军事技术的文章中<ul><li>我所说的高级通用人工智能，指的是<strong>在复杂性和速度上与人类大脑相媲美或超过人类大脑</strong>的人工智能系统，它们可以用一般知识获取、操纵和推理，基本上可以在任何需要人类智能的工业或军事行动阶段使用。</li></ul></li><li>随着技术的进步，AGI的定义已经被扩大，不再对特定的实现机制施加要求<ul><li>OpenAI：我们的使命是确保通用人工智能，<strong>比人类更聪明的人工智能系统</strong>，造福全人类。</li></ul></li></ul><p><img src="/img/ai/openbmb/lecture1/9.png" alt="谷歌DeepMind试图将AGI分为不同的级别"></p><div class="note note-danger">            <p>能力方面和自动化方面</p>          </div><h3 id="从专用智能到通用智能"><a href="#从专用智能到通用智能" class="headerlink" title="从专用智能到通用智能"></a>从专用智能到通用智能</h3><p>从专用人工智能到通用人工智能的演变以三个关键转换为标志：</p><ul><li>各种领域的统一架构：从特定于领域的架构到统一的<strong>Transformer</strong>架构的转换</li></ul><p><img src="/img/ai/openbmb/lecture1/10.png" alt="多种领域网络架构统一为 Transformer 架构"></p><ul><li>各种任务的统一模型：从特定于任务的小模型到统一的大模型的转换</li></ul><p><img src="/img/ai/openbmb/lecture1/11.png" alt="专用智能时代：为不同的任务训练特定任务的小模型"></p><div class="note note-danger">            <p>每个模型只能干一个任务，翻译，数学计算和诗歌生成</p>          </div><p><img src="/img/ai/openbmb/lecture1/12.png" alt="通用智能时代：统一大模型解决多任务"></p><ul><li>各种模态的统一模型：从不同模态数据到统一的token序列的转换，这些token序列被输入到统一的大模型中</li></ul><p><img src="/img/ai/openbmb/lecture1/13.png" alt="序列化token"></p><h3 id="大语言模型"><a href="#大语言模型" class="headerlink" title="大语言模型"></a>大语言模型</h3><ul><li>什么是大语言模型</li><li>LLM 如何学习知识</li><li>LLM 实现人工通用智能的关键</li><li>LLM 的潜力和挑战</li></ul><p><img src="/img/ai/openbmb/lecture1/14.png" alt="LLM"></p><h4 id="下一个token预测"><a href="#下一个token预测" class="headerlink" title="下一个token预测"></a>下一个token预测</h4><ul><li>几乎所有用自然语言表达的任务都可以统一为一个概念：下一个 Token 预测，在给定任何上下文的情况下，任务是生成下一个 Token</li><li>一次生成一个 Token 的过程也称为<strong>自回归生成</strong></li></ul><div class="note note-danger">            <p>根据已经生成的内容继续生成下一个词</p>          </div><p><img src="/img/ai/openbmb/lecture1/15.png" alt="Autoregressive Generation 自回归生成"></p><p><strong>Next Token Prediction</strong> 适用于各种任务，例如问答和机器翻译</p><p><img src="/img/ai/openbmb/lecture1/16.png" alt="应用"></p><h4 id="训练"><a href="#训练" class="headerlink" title="训练"></a>训练</h4><p>大型语言模型的训练过程：学习将训练语料中的 token 逐个输出</p><p><img src="/img/ai/openbmb/lecture1/17.png" alt="Train"></p><div class="note note-danger">            <p>输入 Tinghua University is a，预测不是标准答案 public，则更新权重，继续 university，预测不是则更新权重</p>          </div><h4 id="推理"><a href="#推理" class="headerlink" title="推理"></a>推理</h4><ul><li>LLM 输出<strong>所有 token 上的概率分布</strong>，输出 token 是从该分布中采样的</li><li>该模型可以使用不同的采样从相同的上下文中生成不同的响应</li></ul><p><img src="/img/ai/openbmb/lecture1/18.png" alt="Inference"></p><h4 id="总结"><a href="#总结" class="headerlink" title="总结"></a>总结</h4><p>什么是大型语言模型？</p><ul><li>大型语言模型充当 <strong>Next Token Prediction</strong> 模型，根据前面的上下文不断生成下一个 Token</li><li>大型语言模型的训练过程涉及逐个 Token 输出训练语料库</li><li>大型语言模型的输出是概率分布，每次从中采样下一个 Token</li></ul><h3 id="大语言模型训练方法"><a href="#大语言模型训练方法" class="headerlink" title="大语言模型训练方法"></a>大语言模型训练方法</h3><p><img src="/img/ai/openbmb/lecture1/19.png" alt="自监督预训练，标注微调，从人类反馈中学习"></p><h4 id="自监督预训练"><a href="#自监督预训练" class="headerlink" title="自监督预训练"></a>自监督预训练</h4><ul><li>第一阶段：自监督预训练，此阶段<strong>利用未标记的数据</strong>，要求模型预测下一个 Token 并根据正确答案（即文本本身）调整模型<ul><li>LLM 从庞大的语料库中进行 <strong>Next Token Prediction</strong> 训练，学习语言中嵌入的丰富世界知识</li></ul></li><li>第一阶段的结果：可以为任何给定上下文生成流畅的后续文本的模型<ul><li>此阶段的模型不知道如何应用从预训练中学到的知识，仅能够继续给定的输入</li></ul></li></ul><div class="note note-danger">            <p>这时候的模型知会续写，不知道怎么应用知识来满足人类的需求</p>          </div><p><img src="/img/ai/openbmb/lecture1/20.png" alt="用于模型训练的数据规模不断增长"></p><h4 id="标注微调"><a href="#标注微调" class="headerlink" title="标注微调"></a>标注微调</h4><ul><li>第二阶段：标注微调 (Supervised Fine-Tuning，SFT)，此阶段涉及使用人类标记的响应来训练模型</li><li>此阶段的目标是使模型具备理解用户意图的能力，从而将模型转变为有效的 AI 助手</li><li>为 SFT 收集大规模人类注释的聊天数据</li></ul><p><img src="/img/ai/openbmb/lecture1/21.png" alt="该模型模仿人类注释的回答，学习理解用户意图，并学习拒绝回答“不适当”的问题"></p><ul><li>SFT 使 LLM 能够学习如何应用从预训练中获得的知识来回答用户的问题</li><li>挑战：<strong>每个问题都有多个正确答案</strong>。限制模型只能学习一个答案可能会降低其应用知识的“灵活性”</li></ul><div class="note note-danger">            <p>人类给出大量的对话数据，告知模型应该怎么回答，包括正面的和负面的回答。但对话数据的回答相对单一，会限制灵活性</p>          </div><p><img src="/img/ai/openbmb/lecture1/22.png" alt="SFT 要求模型逐个 Token 学习标记的响应，这可能会误导模型"></p><h4 id="从人类反馈中学习"><a href="#从人类反馈中学习" class="headerlink" title="从人类反馈中学习"></a>从人类反馈中学习</h4><div class="note note-danger">            <p><strong>RLHF, Re-Learning From Human Feedback</strong><br>不再规定怎么输出，根据评分来评判输出的正面和负面，给出人类对模型输出的偏向，更好地照顾模型输出的灵活性</p>          </div><p>第三阶段：从人工反馈中学习，不再向模型提供逐字参考答案，而是仅提供模型输出的质量反馈（评分）。然后对模型进行训练以提高其响应的分数</p><p><img src="/img/ai/openbmb/lecture1/23.png" alt="从人类反馈中学习"></p><h3 id="大语言模型成功的关键"><a href="#大语言模型成功的关键" class="headerlink" title="大语言模型成功的关键"></a>大语言模型成功的关键</h3><p>通过 LLM 实现通用人工智能的关键：<strong>大规模数据 + 大规模参数</strong>，获取通用知识需要大量数据，而存储知识则需要大量参数</p><ul><li><strong>大规模数据</strong>：对海量数据集进行预训练使 LLM 能够学习语言中蕴含的世界知识</li><li><strong>大规模参数</strong>：参数规模的增长使得模型能够存储更多的知识，并表现出“涌现能力”<ul><li><strong>涌现能力（Emergent abilities）</strong>：当参数规模超过一定阈值时，LLM 会表现出新的能力，有效解决小模型难以应对的挑战性任务</li><li><strong>LLM 的涌现能力</strong>：情境（上下文）学习、指令遵循、思路链（In-context learning, instruction following, chain-of-thought）</li></ul></li></ul><div class="note note-danger">            <p>涌现，是爆发的，是突然出现的</p>          </div><div class="note note-primary">            <p>很好地预测下一个 token 意味着你了解导致创建该 token 的根本现实……人们有思想、有感觉，有想法，他们以特定的方式做事。所有这些都可以从下一个 token 预测中推断出来。 —— Ilya Sutskever OpenAI 前首席科学家</p>          </div><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture1/24.png" alt="LLM 的训练数据和参数规模呈指数级增长"></div><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture1/25.png" alt="LLM 学习的各类知识"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture1/26.png" alt="现实世界系统中的“涌现”"></div><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture1/27.png" alt="随着 LLM 参数规模的增加，性能飞跃"></div></div></div><h4 id="情境（上下文）学习"><a href="#情境（上下文）学习" class="headerlink" title="情境（上下文）学习"></a>情境（上下文）学习</h4><p><img src="/img/ai/openbmb/lecture1/28.png" alt="LLM 只需几个例子就能学习复杂的任务。左：我们定义一个新的数学运算符@：𝑎@𝑏 = (𝑎 + 𝑏)^2。我们只向GPT-4提供了几个示例，并要求GPT-4计算“4@5”；右：GPT-3 从有限数量的示例中学习时的准确率"></p><h4 id="遵循指令"><a href="#遵循指令" class="headerlink" title="遵循指令"></a>遵循指令</h4><p>这涉及理解用户指令并准确满足用户请求。即使任务以前没有出现在训练数据中，模型也能够理解和执行所需的指令</p><p><img src="/img/ai/openbmb/lecture1/29.png" alt="Instruction following"></p><h4 id="思维链"><a href="#思维链" class="headerlink" title="思维链"></a>思维链</h4><p>LLM 可以将复杂任务分解为多个子任务，逐步思考和推理每个步骤，以完成最终的复杂任务</p><p><img src="/img/ai/openbmb/lecture1/30.png" alt="Chain-of-Thought"></p><h3 id="潜力和挑战"><a href="#潜力和挑战" class="headerlink" title="潜力和挑战"></a>潜力和挑战</h3><p>语言是人类知识的载体，LLM 在语言理解和生成方面的出色表现可以大大加速人类社会知识的生产和获取。</p><div class="note note-primary">            <p>将 GPT3 的惊人表现推断到未来，生命、宇宙和一切的答案不过是 4.398 万亿个参数。 —— 杰弗里 · 辛顿，图灵奖获得者</p><p>ChatGPT 与个人电脑、互联网一样重要。 —— 比尔 · 盖茨，微软联合创始人</p>          </div><p><img src="/img/ai/openbmb/lecture1/31.png" alt="人工智能协助创作文本和图像"><br><img src="/img/ai/openbmb/lecture1/32.png" alt="人工智能助力科学研究"><br><img src="/img/ai/openbmb/lecture1/33.png" alt="AI协助信息收集和汇总"></p><ul><li><strong>信息污染</strong>：LLM 不可避免地会遇到<strong>幻觉问题</strong>，即他们生成的内容<strong>包含虚假信息</strong>。此外，当受到负面提示时，LLM 还会产生有害或有偏见的信息<ul><li><strong>谣言传播</strong>：2023年2月16日下午，杭州某小区业主在群里讨论ChatGPT，其中一位业主开玩笑地建议尝试用它写一篇关于杭州取消交通限行的新闻报道，这位业主随即用ChatGPT直播了写作过程，并将报道发布在群里。部分业主当真，截图转发，导致错误信息传播。</li></ul></li><li><strong>社会分工的变化</strong>：从长远来看，LLM 预计将导致高重复性和低创造力的工作减少或被取代。<ul><li>OpenAI 的研究显示，大约 80% 的美国劳动力的至少 10% 的工作任务可能会受到 LLM 引入的影响，而大约 19% 的劳动者的至少 50% 的工作任务可能会受到影响。</li></ul></li><li><strong>道德和法律问题</strong>：LLM 生成内容的使用涉及复杂的道德和法律挑战，例如<strong>知识产权、隐私和学术诚信</strong><ul><li>首例涉及人工智能生成图像的版权案件：2023年2月24日，李先生利用开源软件Stable Diffusion生成了一张图片。两天后，他在社交媒体上分享了这张图片，并配文“春天来了，温柔”。后来，李先生发现刘女士在3月2日发表在百家号上的文章《三月桃花盛开的爱情》中使用了他的图片。法院判决刘女士侵犯了李先生对图片的署名权和网络传播权。判决要求刘女士公开道歉并向李先生赔偿500元经济赔偿金</li></ul></li></ul><div class="note note-danger">            <p>垃圾数据进入互联网，在被大模型训练时学习，导致污染</p>          </div><h2 id="未来"><a href="#未来" class="headerlink" title="未来"></a>未来</h2><p><img src="/img/ai/openbmb/lecture1/39.png" alt="OpenBMB团队的2.4B大模型 miniCPM 可以与GPT3媲美"><br><img src="/img/ai/openbmb/lecture1/40.png" alt="GPT可以部署于端侧"></p><div class="note note-danger">            <ul><li>参考摩尔定律，芯片面积不断减小，在未来，模型不会永远的大下去，<strong>在有限的参数内塞下更多的知识（知识密度），是未来竞争的焦点之一</strong>。</li><li>端侧的设备的算力在未来可以充分利用，支撑起 LLM 的运行。</li></ul>          </div><p><img src="/img/ai/openbmb/lecture1/34.png" alt="大型语言模型的未来方向"></p><h3 id="人工智能科学"><a href="#人工智能科学" class="headerlink" title="人工智能科学"></a>人工智能科学</h3><ul><li>追求架构、算法和数据的迭代进步</li><li>专注于提高 LLM 的“知识密度”——用更少的参数存储更多的知识。</li></ul><p><img src="/img/ai/openbmb/lecture1/35.png" alt="Science in Artificial Intelligence"></p><div class="note note-danger">            <p>模型风洞：在训练前预测模型</p>          </div><h3 id="智能计算系统"><a href="#智能计算系统" class="headerlink" title="智能计算系统"></a>智能计算系统</h3><p>LLM将人类知识的管理转变为基于界面的过程，与<strong>芯片、操作系统、数据库、编程和网络通信</strong>等计算组件深度融合，增强计算系统的智能化.<br><img src="/img/ai/openbmb/lecture1/36.png" alt="Intelligent Computing System"></p><h3 id="广泛应用于各个领域"><a href="#广泛应用于各个领域" class="headerlink" title="广泛应用于各个领域"></a>广泛应用于各个领域</h3><ul><li><strong>长序列处理</strong>：LLM 需要与人类进行长时间的互动和协作，成为现实世界生产的重要组成部分</li><li><strong>专业能力提升</strong>：LLM 需要提升自己的专业能力，才能应用于潜在收益更高的场景，超越人类的能力</li><li><strong>应对失败风险</strong>： LLM 应有效应对并适应不同的环境，确保在高风险情况下可靠地使用</li></ul><p><img src="/img/ai/openbmb/lecture1/37.png" alt="Widespread Applications across Various Domains"></p><h3 id="总结-1"><a href="#总结-1" class="headerlink" title="总结"></a>总结</h3><ul><li>符号智能（1950-1980） 人类标注的规则与知识</li><li>专用智能 （1990-2018） 监督数据 特定任务模型</li><li><strong>通用智能 1.0（现在）</strong><ul><li>LLM 利用<strong>大量计算资源</strong>，采用<strong>自监督训练</strong>从大量未标记数据中学习知识。这种方法实现了“<strong>统一模型解决多项任务</strong>”，引发了人工智能通用智能 2.0 的早期迹象（早期原型）</li></ul></li><li>通用智能 2.0（早期原型）人工智能科学智能计算系统</li><li>通用智能 3.0（早期原型）广泛应用于各个领域</li></ul><p><img src="/img/ai/openbmb/lecture1/38.png" alt="LLM 发展历史"></p><h1 id="2-神经网络基础知识"><a href="#2-神经网络基础知识" class="headerlink" title="2 神经网络基础知识"></a>2 神经网络基础知识</h1><ul><li>简单神经网络</li><li>如何训练神经网络</li><li>循环神经网络和卷积神经网络</li><li>Seq2Seq 和 Transformers</li></ul><h2 id="简单神经网络"><a href="#简单神经网络" class="headerlink" title="简单神经网络"></a>简单神经网络</h2><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture2/0.png" alt="单个神经元"></div><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture2/1.png" alt="单层神经网络"></div><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture2/2.png" alt="多层神经网络"></div></div></div><h3 id="神经元"><a href="#神经元" class="headerlink" title="神经元"></a>神经元</h3><p>神经元是一个计算单元，具有 𝑛 维输入𝒙、一维偏置𝑏、𝑛 维权重𝒘和<strong>激活函数</strong>𝑓(𝑧)，其中𝒘、𝑏 是该神经元的参数。</p><p>$$<br>\bbox[,5px,border:2px solid red]<br>{<br>  \begin{equation}\begin{split}<br>  ℎ_{𝒘, 𝑏}(𝒙)&amp;&#x3D;𝑓(𝒘^{T}𝒙+𝑏)\\<br>  \\<br>  𝑓(𝑧)&amp;&#x3D;\frac{1}{1+𝑒^{-𝑧}}<br>  \end{split}\end{equation}<br>}<br>$$</p><div class="note note-danger">            <p>激活函数就是开和关，模仿人脑中激活研究。</p>          </div><h3 id="神经网络"><a href="#神经网络" class="headerlink" title="神经网络"></a>神经网络</h3><p>单层神经网络是由许多简单的神经元连接在一起构成的。</p><p>$$<br>\begin{equation}\begin{split}<br>𝑎_{1}&#x3D;𝑓(𝑊_{11}𝑥_{1}+𝑊_{12}𝑥_{2}+𝑊_{13}𝑥_{3}+𝑏_{1})\\<br>\\<br>𝑎_{2}&#x3D;𝑓(𝑊_{21}𝑥_{1}+𝑊_{22}𝑥_{2}+𝑊_{23}𝑥_{3}+𝑏_{2})\\<br>\\<br>𝑎_{3}&#x3D;𝑓(𝑊_{31}𝑥_{1}+𝑊_{32}𝑥_{2}+𝑊_{33}𝑥_{3}+𝑏_{3})\\<br>\end{split}\end{equation}<br>$$</p><p>以矩阵形式：</p><p>$$<br>𝒂&#x3D;𝑓(𝑾𝒙+𝒃)<br>$$</p><h3 id="多层神经网络"><a href="#多层神经网络" class="headerlink" title="多层神经网络"></a>多层神经网络</h3><p>多层神经网络由多层神经网络堆叠而成，<strong>中间输出称为隐藏状态</strong>。</p><div class="note note-danger">            <p>输入输出是有明确意义的，中间层则为黑盒。</p>          </div><p>前馈计算(Feedforward Computation)：</p><p>$$<br>\begin{equation}\begin{split}<br>𝒉_{1}&amp;&#x3D;𝑓(𝑊_{1}𝑥+𝑏_{1})\\<br>\\<br>𝒉_{2}&amp;&#x3D;𝑓(𝑊_{2}𝒉_{1}+𝑏_{2})\\<br>\\<br>𝒉_{3}&amp;&#x3D;𝑓(𝑊_{3}𝒉_{2}+𝑏_{3})\\<br>\end{split}\end{equation}<br>$$</p><div class="note note-primary">            <p>为何采用多层：多层神经网络可以通过分层表示来表示更复杂的特征。</p>          </div><h3 id="为什么需要激活函数"><a href="#为什么需要激活函数" class="headerlink" title="为什么需要激活函数"></a>为什么需要激活函数</h3><p>如果没有激活函数（非线性），深度神经网络就只能进行线性变换，多层级结构可以编译成单一的线性变换。</p><div class="note note-danger">            <p>计算退化为线性变换</p>          </div><div class="note note-primary">            <p>由于具有非线性，多层神经网络可以用更多层来逼近更复杂的函数。</p>          </div><p>$$<br>𝒉&#x3D;𝑊_{2}(𝑊_{1}𝑥+𝑏_{1})+𝑏_{2}&#x3D;(𝑊_{2}𝑊_{1})𝑥+(𝑊_{2}𝑏_{1}+𝑏_{2})<br>$$</p><h3 id="典型的激活函数"><a href="#典型的激活函数" class="headerlink" title="典型的激活函数"></a>典型的激活函数</h3><p>Sigmoid 函数：</p><p>$$<br>𝑓(𝑧)&#x3D;\frac{1}{1+𝑒^{-𝑧}}<br>$$</p><p>Tanh 函数：</p><p>$$<br>𝑓(𝑧)&#x3D;tanh(𝑧)&#x3D;\frac{𝑒^{𝑧}-𝑒^{-𝑧}}{𝑒^{𝑧}+𝑒^{-𝑧}}<br>$$</p><p>ReLU 函数：</p><p>$$<br>\bbox[,5px,border:2px solid red]<br>{𝑓(𝑧)&#x3D; max(𝑧, 0)}<br>$$</p><div class="note note-danger">            <p>ReLU 现在在大语言模型应用广泛</p>          </div><div class="note note-danger">            <p>计算机视觉模型中间层包含了图像的边缘信息等，是模型自己“学习”出来的。</p>          </div><h2 id="如何训练神经网络"><a href="#如何训练神经网络" class="headerlink" title="如何训练神经网络"></a>如何训练神经网络</h2><h3 id="训练目标"><a href="#训练目标" class="headerlink" title="训练目标"></a>训练目标</h3><div class="note note-danger">            <p>训练的本质是“拟合”，找到最优的参数，找到最符合期望的输出。</p>          </div><p>给定 𝑁 个训练示例 ${\{(𝒙_{i}, 𝒚_{i})\}}$ ，其中 𝒙 和 𝒚 是 <strong>golden input and output</strong>。我们想要训练一个神经网络 $𝐹_{𝜽}(⋅)$，它将 𝒙 作为输入并预测 𝒚。合理的训练目标是</p><p>$$<br>\mathop{min}\limits_{𝜽}𝐽({𝜽})&#x3D;\mathop{min}\limits_{𝜽}\frac{1}{N}\sum_{i&#x3D;1}^{N}l(𝒚_{i}-F_{𝜽}(𝒙_{i}))<br>$$</p><p>其中 𝜽 是神经网络 $𝐹_{𝜽}(⋅)$ 的参数。$l(𝒚_{i}-F_{𝜽}(𝒙_{i}))$ 是<strong>损失函数（Loss Function）</strong>，用于衡量神经网络输出与黄金输出之间的差异。</p><div class="note note-danger">            <p>有很多种损失函数的选择。</p>          </div><h3 id="随机梯度下降"><a href="#随机梯度下降" class="headerlink" title="随机梯度下降"></a>随机梯度下降</h3><p><strong>函数沿梯度方向下降速度最快</strong>: $𝜽^{new}&#x3D;𝜽^{old}−𝛼∇_𝜽J(𝜽)$。</p><div class="note note-primary">            <p>整个过程就像爬山一样：找到最陡峭的方向，然后迈出一步，找到下一个最陡峭的方向。</p>          </div><div class="note note-danger">            <p>可能会收敛到局部最优解。当随着维度和参数的增加，现在可以找到优秀解。<br><strong>学习率</strong>表示每次训练迭代的“步进”，越小越慢，过大则不能拟合</p>          </div><p><img src="/img/ai/openbmb/lecture2/gradient.png" alt="Stochastic Gradient Descent"></p><h3 id="梯度和反向传播"><a href="#梯度和反向传播" class="headerlink" title="梯度和反向传播"></a>梯度和反向传播</h3><p>给定一个具有一个输出和 𝑁 个输入的函数：</p><p>$$F(x) &#x3D; F(x_1,x_2…x_N)$$</p><p>其梯度是一个偏导数向量：</p><p>$$\frac{𝜕F}{𝜕x}&#x3D;[\frac{𝜕F}{𝜕x_1},\frac{𝜕F}{𝜕x_2}…\frac{𝜕F}{𝜕x_N}]$$</p><p><strong>反向传播是基于链式法则计算梯度的过程</strong>，现有的深度学习框架（TensorFlow、PyTorch 等）经常使用这种算法。</p><div class="note note-danger">            <p>神经网络中每一步都需要可导的，因此<strong>阶跃激活函数</strong>比较麻烦。激活函数需要平滑</p>          </div><p><img src="/img/ai/openbmb/lecture2/backpropagation1.png" alt="Backpropagation"></p><p>将神经网络方程表示为计算图，源节点表示输入，内部节点表示操作，边传递各种操作的结果。</p><p><img src="/img/ai/openbmb/lecture2/backpropagation2.png" alt="计算图"></p><p>可以通过沿着计算图的路径以相反的方向传递来获得梯度。</p><p><img src="/img/ai/openbmb/lecture2/backpropagation3.png" alt="反向传播"></p><div class="note note-danger">            <p>梯度下降效率比较低，现在有只寻找方向的收敛方法，以提高训练效率。</p>          </div><h2 id="循环神经网络"><a href="#循环神经网络" class="headerlink" title="循环神经网络"></a>循环神经网络</h2><div class="note note-primary">            <p><strong>RNN: Recurrent Neural Networks 循环神经网络</strong></p>          </div><div class="note note-danger">            <p>需要解决的问题：将离散的语言转为数值计算。语言的信息密度大，所以先诞生的是大语言模型，逐步发展为多模态大模型</p>          </div><h3 id="语言模型"><a href="#语言模型" class="headerlink" title="语言模型"></a>语言模型</h3><p>语言建模是预测即将出现的单词的任务。即将出现的单词 $𝑤_{n}$ 的条件概率由 $𝑃(𝑤_{n}|𝑤_{1},𝑤_{2},…,𝑤_{n-1})$ 计算</p><p><img src="/img/ai/openbmb/lecture2/language_model.png" alt="预测下一个单词"></p><p>假设：即将出现的单词的概率仅由其前面的所有单词决定，例如：</p><p>$$<br>\begin{equation}\begin{split}<br>𝑃(𝑁𝑒𝑣𝑒𝑟,𝑡𝑜𝑜,𝑙𝑎𝑡𝑒,𝑡𝑜,𝑙𝑒𝑎𝑟𝑛)&#x3D;&amp;𝑃(𝑁𝑒𝑣𝑒𝑟)×\\&amp;𝑃(𝑡𝑜𝑜|𝑁𝑒𝑣𝑒𝑟)×\\&amp;𝑃(𝑙𝑎𝑡𝑒|𝑁𝑒𝑣𝑒𝑟,𝑡𝑜𝑜)×\\&amp;𝑃(𝑡𝑜|𝑁𝑒𝑣𝑒𝑟,𝑡𝑜𝑜,𝑙𝑎𝑡𝑒)×\\&amp;𝑃(𝑙𝑒𝑎𝑟𝑛|𝑁𝑒𝑣𝑒𝑟,𝑡𝑜𝑜,𝑙𝑎𝑡𝑒,𝑡𝑜)\\<br>\\<br>𝑃(𝑙𝑒𝑎𝑟𝑛|𝑁𝑒𝑣𝑒𝑟,𝑡𝑜𝑜,𝑙𝑎𝑡𝑒,𝑡𝑜)&#x3D;&amp;\frac{𝑃(𝑁𝑒𝑣𝑒𝑟,𝑡𝑜𝑜,𝑙𝑎𝑡𝑒,𝑡𝑜,𝑙𝑒𝑎𝑟𝑛)}{𝑃(𝑁𝑒𝑣𝑒𝑟,𝑡𝑜𝑜,𝑙𝑎𝑡𝑒,𝑡𝑜)}\\<br>\\<br>P(w_{1},w_{2},…,w_{n})&#x3D;&amp;\prod_{i}P(w_{i}|w_{1},w_{2},\dots,w_{i-1})<br>\end{split}\end{equation}<br>$$</p><ul><li><strong>RNN 的关键概念</strong>：处理序列数据时的<strong>顺序记忆</strong></li></ul><div class="note note-primary">            <p>人脑顺序说26个字母，简单；倒序说26个字母，困难</p>          </div><div class="note note-danger">            <p>语言模式是包含序列化的，不是随机概率分布</p>          </div><ul><li><strong>RNN 的核心思想</strong>：一种使其能够识别序列模式的机制。</li></ul><p><img src="/img/ai/openbmb/lecture2/rnn1.png" alt="RNN 以递归方式更新序列记忆，以对序列数据进行建模"></p><div class="note note-danger">            <p>输入层按时间（序列）输入数据，中间层不断更新参数，实现对序列的建模。神经元包括输入向量 $ x_{i} $，乘以可以学习的权重 $W_{x}$ 加上上一步计算的结果 $h_{i-1}$，和偏置，再进行激活。最后计算出输出 $y_{i}$。</p>          </div><p><img src="/img/ai/openbmb/lecture2/rnn2.png" alt="tanh"></p><p>典型的RNN扩展：<strong>RNN、LSTM、GRU</strong>。</p><div class="note note-danger">            <p>RNN需要较大的内存，以储存之前的序列记忆，从而有更加精准的输出。扩展围绕在RNN其中加入一些开关。目前这些模型已经逐步被淘汰。因为反向传播太慢，所以RNN训练很慢。</p>          </div><p><img src="/img/ai/openbmb/lecture2/rnn3.png" alt="RNN extensions"></p><h3 id="用于语言建模的循环神经网络"><a href="#用于语言建模的循环神经网络" class="headerlink" title="用于语言建模的循环神经网络"></a>用于语言建模的循环神经网络</h3><p><img src="/img/ai/openbmb/lecture2/rnn4.png" alt="用于语言建模的循环神经网络"></p><div class="note note-primary">            <p><strong>RNN 神经元</strong>如何工作？RNN 神经元采用当前 RNN 状态和词向量，并生成对迄今为止的句子进行编码的后续 RNN 状态。学习到的权重表示如何结合<strong>过去的信息</strong> $𝒉_{t-1}$ 和<strong>当前的信息</strong> $𝒙_{t}$。</p>          </div><p>$$<br>𝒉_{t}&#x3D;tanh(𝑾_{𝒙}𝒙_{t}+𝑾_{h}𝒉_{t-1}+𝒃_{1})<br>$$</p><div class="note note-primary">            <p>输出功能如何运作？$𝒚_{4}$ 是根据 RNN 记忆和变换 $(𝑼,𝒃_{2})$ 构建的词汇的概率分布。<strong>softmax</strong> 函数将<strong>分数</strong>转换为<strong>概率分布</strong>。</p>          </div><div class="note note-danger">            <p>𝑼 也是可学习的权重。实际的输出结果不是 one-hot 的，因为有很多种可能性。</p>          </div><h2 id="卷积神经网络"><a href="#卷积神经网络" class="headerlink" title="卷积神经网络"></a>卷积神经网络</h2><div class="note note-danger">            <p>由于内存的限制，语言模型不能全序列去计算当下的下一个输出，所以 RNN ”退化“ 为一个处理局部状态的神经网络。当序列数量 n 足够大时，仍然是全序列语言模型。</p>          </div><div class="note note-primary">            <p><strong>CNN: Convolutional Neural Networks 卷积神经网络</strong></p><p>CNNs are good at extracting <strong>local and position-invariant patterns</strong>, by computing the representations for all possible <strong>N-gram phrases</strong> in a sentence.</p><p>Sentence: The plane is taking off.<br>Possible n-gram phrases:</p><ul><li>Bigram: The plane, plane is, is taking, taking off</li><li>Trigram: The plane is, plane is taking, is taking off</li><li>N-gram: …</li></ul>          </div><div class="note note-danger">            <p>将序列拆分出不同长度的窗格，以关注局部的序列状态。由于 RNN 反向传播路径太长，局部的 CNN 计算可以加快训练速度。</p>          </div><p><img src="/img/ai/openbmb/lecture2/cnn1.png" alt="Convolutional Neural Networks"></p><ul><li>输入层：通过词嵌入将单词转换为输入表示 $𝐱∈R^{m×d}$，其中 <strong>𝑚</strong> 是句子的长度，<strong>𝑑</strong> 是词嵌入的维数。</li><li>卷积层：通过滑动卷积滤波器从输入表示中提取特征表示<ul><li>输入表示<br>$$𝐱∈R^{m×d}$$</li><li>$(j+1)-gram$ 表示，$𝐱_{i},𝐱_{i+1},…,𝐱_{i+j}$ 的连接<br>$$𝐱_{i:i+j}∈R^{(j+1)d}$$</li><li>卷积滤波器，b 是偏差项（h 是窗口大小）<br>$$𝐰∈R^{h×d}$$</li><li>卷积特征表示<br>$$𝐟∈R^{n-h+1}$$</li></ul></li></ul><p><img src="/img/ai/openbmb/lecture2/cnn2.png" alt="Convolution Layer"></p><h3 id="对比"><a href="#对比" class="headerlink" title="对比"></a>对比</h3><p>用于 NLP 的神经网络模型对比：</p><ul><li>CNNs<ul><li>优点：提取局部和位置不变特征</li><li>参数：少量参数</li><li>并行化：句内并行化效果更好</li></ul></li><li>RNNs<ul><li>优点：建模长区间上下文依赖性</li><li>参数：更多参数（需要更多内存）</li><li>并行化：句子内无法并行化</li></ul></li></ul><h2 id="seq2seq-和-transformer"><a href="#seq2seq-和-transformer" class="headerlink" title="seq2seq 和 transformer"></a>seq2seq 和 transformer</h2><div class="note note-danger">            <p>Transformer 一开始是 Google 为了解决机器翻译的问题，训练速度和性能都比 RNN 好。机器翻译任务更关注长序列。</p>          </div><h3 id="机器翻译中的-seq2seq"><a href="#机器翻译中的-seq2seq" class="headerlink" title="机器翻译中的 seq2seq"></a>机器翻译中的 seq2seq</h3><p>机器翻译（Machine Translation，MT）：将文本从源语言翻译成目标语言的任务。回想一下序列到序列模型，它使用两个 RNN：</p><ul><li>Encoder RNN：生成源句子的表示</li><li>Decoder RNN：基于编码生成目标句子的语言模型</li></ul><p><img src="/img/ai/openbmb/lecture2/seq2seq.png" alt="Seq2Seq in MT"></p><h3 id="transformer"><a href="#transformer" class="headerlink" title="transformer"></a>transformer</h3><div class="note note-danger">            <p>Transformer 替换了 RNN 处理序列的机制。使用 attention 的方法。RNN 处理变长序列，可以看到之前的所有输入，缺点是因为串行处理，导致计算很慢，而且 RNN 的记忆序列长度是固定的（由隐藏状态参数数量决定）。</p><p>Attention 对于一个向量，映射到三个矩阵运算，Query，Key，Value，$ QK^T$ 内积计算距离，乘以缩放系数 $\frac{1}{\sqrt{d_k}}$，避免计算值过大，再通过 $softmax()$ 计算概率分布，再乘以 $V$ 得到最后的序列。</p><p>Attention 的优势：</p><ul><li>矩阵计算轻量化且固定，反向传播快</li><li>可以处理足够大的输入</li><li>不像 RNN 一样固定的序列记忆数量<ul><li>RNN 的序列记忆数量取决于隐藏状态参数数量大小</li><li>Transformer 在计算时，会“看到”前面计算的所有隐藏状态参数，输入越长，则记忆力越好，保证信息不会丢失</li></ul></li><li>Transformer 在剔除了RNN的序列处理逻辑后，加入了 feedforward 等结构，叠加形成了多层模型</li></ul>          </div><p>$$ \bbox[,5px,border:2px solid red]<br>{<br>  Attention(Q,K,V)&#x3D;softmax(\frac{1}{\sqrt{d_k}}QK^T)V<br>}<br>$$</p><p><img src="/img/ai/openbmb/lecture2/attention.png" alt="Transformer"></p><p><img src="/img/ai/openbmb/lecture2/transformer.png" alt="（左）缩放版的点积attention（右）Multi-Head Attention，由多个并行运行的attention层组成"></p><h3 id="decoder-only-和-encoder-decoder"><a href="#decoder-only-和-encoder-decoder" class="headerlink" title="decoder-only 和 encoder-decoder"></a>decoder-only 和 encoder-decoder</h3><p><img src="/img/ai/openbmb/lecture2/decenc.png" alt="仅解码或编解码"></p><div class="note note-danger">            <p>左图：目前主流是 Decoder-only，使得所有任务都变成生成任务<br>右图：</p><ul><li>深色的线表示 Attention 的概率大</li><li>Attention 机制看到的是一个 token 的上下文联系，不仅仅是某个 token。</li></ul>          </div><h1 id="3-大语言模型基础知识"><a href="#3-大语言模型基础知识" class="headerlink" title="3 大语言模型基础知识"></a>3 大语言模型基础知识</h1><ul><li>迁移学习</li><li>自监督学习、预训练</li><li>语言建模预训练</li><li>预训练模型和大语言模型</li></ul><h2 id="迁移学习"><a href="#迁移学习" class="headerlink" title="迁移学习"></a>迁移学习</h2><p>深度学习是各类自然语言处理任务的主流框架，但它仍然面临着一些挑战：<strong>缺乏大规模监督数据、模型深度有限、泛化性能差</strong>。</p><div class="note note-danger">            <ul><li>带有人工标注的数据，为有监督数据，作为训练集，然后用测试数据作为输入，完成特定的输出任务。</li><li>有监督数据集成本高，模型上限低。</li><li>在输入数据集以外的数据，能否正常处理，表现了模型的泛化能力。即举一反三的能力。</li><li>预训练使模型具有通用能力，再“迁移”到具体任务上，可迁移到任务一般具备相似性。</li></ul>          </div><p><img src="/img/ai/openbmb/lecture3/1.png" alt="特定任务的监督数据"></p><div class="note note-primary">            <p>PTMs (<strong>Pre-Trained Models 预训练模型</strong>) are proposed, which are pre-trained on large-scale unlabeled data, and then be finetuned on downstream tasks, showing strong performance on various downstream tasks.</p>          </div><p><img src="/img/ai/openbmb/lecture3/2.png" alt="large-scale unlabeled data"></p><p><strong>预训练-微调范式（Pretraining-Finetuning paradigm）</strong>是<strong>迁移学习（Transfer Learning）</strong>的一种形式，之前学到的能力可以迁移到新任务中。</p><p><img src="/img/ai/openbmb/lecture3/3.png" alt="迁移学习（Transfer Learning）"></p><p>迁移学习：知识获取 &#x3D;&gt; 知识迁移，包括<strong>基于特征的迁移和基于参数的迁移</strong>。</p><p><img src="/img/ai/openbmb/lecture3/4.png" alt="基于特征的迁移和基于参数的迁移"></p><p>计算机视觉任务中的早期迁移学习工作：</p><ul><li>在人工标记的 ImageNet 上对模型进行预训练</li><li>然后在下游任务上对模型进行微调</li><li>基于 CNN（例如 <a href="https://github.com/huaweicloud/ModelArts-Lab/wiki/ResNet%E6%A8%A1%E5%9E%8B%E8%A7%A3%E6%9E%90">残差神经网络 ResNet</a>）构建模型</li></ul><p><img src="/img/ai/openbmb/lecture3/5.png" alt="VGG"></p><p>是否可以使用未标记数据预训练模型？</p><ul><li><strong>自监督学习</strong>：从未标记数据中挖掘内部信息来训练模型</li><li><strong>对比学习</strong>：最大化正例和反例之间的距离</li></ul><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture3/6.png" alt="利用卷积神经网络进行判别式无监督特征学习"></div><div class="group-image-wrap"><img src="/img/ai/openbmb/lecture3/7.png" alt="无监督视觉表征学习的动量对比，利用动量对比学习改进基线"></div></div></div><h2 id="语言建模的预训练"><a href="#语言建模的预训练" class="headerlink" title="语言建模的预训练"></a>语言建模的预训练</h2><p>如何衡量文本的概率？</p><p>$$<br>Pr(I like deep learning) &gt; Pr(I hate deep learning)<br>$$</p><h3 id="word2vec"><a href="#word2vec" class="headerlink" title="word2vec"></a>word2vec</h3><p>Word2vec 使用浅层神经网络将单词与分布式表示关联起来。它可以捕捉许多语言规律，例如：</p><p><img src="/img/ai/openbmb/lecture3/8.png" alt="Efficient Estimation of Word Representations in Vector Space"></p><p>Word2vec 可以利用两种架构来生成单词的分布式表示，</p><ul><li>连续词袋 (CBOW)</li><li>连续 Skip-Gram<br><img src="/img/ai/openbmb/lecture3/9.png" alt="向量空间中词语表征的有效估计"></li></ul><p>Word2Vec 的挑战</p><ul><li>歧义：<ul><li>我去银行（bank）存钱。</li><li>我去岸边（bank）钓鱼。</li></ul></li><li>反义词：<ul><li>我喜欢这部电影，这部电影太糟糕了。</li><li>我不喜欢这部电影，这部电影太好了。</li></ul></li></ul><h3 id="上下文相关的词语表示"><a href="#上下文相关的词语表示" class="headerlink" title="上下文相关的词语表示"></a>上下文相关的词语表示</h3><p>在<strong>海量文本数据</strong>上对 RNN 进行预训练。RNN 模型模拟自然语言概率。此功能可以很好地迁移到下游自然语言处理任务。</p><p><img src="/img/ai/openbmb/lecture3/10.png" alt="下游自然语言处理"></p><p>上下文相关的词语表示:</p><p><img src="/img/ai/openbmb/lecture3/11.png" alt="Context-sensitive word representations"></p><h2 id="预训练模型和大语言模型"><a href="#预训练模型和大语言模型" class="headerlink" title="预训练模型和大语言模型"></a>预训练模型和大语言模型</h2><p>2018年，以 ELMo、BERT 为代表的预训练模型给NLP领域带来了一场革命。基于预训练模型的工作在几乎所有的 NLP 任务上都取得了巨大的突破，各类 benchmark 的结果也得到了显著的提升。</p><p><img src="/img/ai/openbmb/lecture3/12.png" alt="预训练模型"></p><h3 id="预训练模型"><a href="#预训练模型" class="headerlink" title="预训练模型"></a>预训练模型</h3><p>GLUE 上的预训练模型的结果超越了人类的水平，体现了它们的语言理解能力。</p><p><img src="/img/ai/openbmb/lecture3/13.png" alt="GLUE Benchmark"></p><h3 id="大语言模型-1"><a href="#大语言模型-1" class="headerlink" title="大语言模型"></a>大语言模型</h3><p>过去两年，预训练模型的规模每年增长约10倍，数据量也随之增长，计算成本也越来越昂贵。<br><img src="/img/ai/openbmb/lecture3/14.png" alt="大语言模型"></p><p>一个非常有代表性的模型是拥有1700亿（170B）个参数的GPT-3。</p><p><img src="/img/ai/openbmb/lecture3/15.png" alt="GPT3"></p><p>GPT-3具有一定的知识，可以进行一定的逻辑推理。</p><p><img src="/img/ai/openbmb/lecture3/16.png" alt="GPT3 问答"></p><p>此外，GPT-3 具有强大的零次&#x2F;小样本学习能力，可以执行许多任务。</p><p><img src="/img/ai/openbmb/lecture3/17.png" alt="GPT3 的学习"></p><h3 id="语言模型的特性和功能"><a href="#语言模型的特性和功能" class="headerlink" title="语言模型的特性和功能"></a>语言模型的特性和功能</h3><p>大型语言模型使用下一个 token 预测任务来对大数据进行建模。学习大数据需要大量参数，<strong>训练大模型需要大量计算能力。更多的 FLOP 带来更多的功能，智能逐渐出现。</strong></p><p><img src="/img/ai/openbmb/lecture3/18.png" alt="将大数据转换成统一序列化格式的过程；更多的 FLOP 带来更多的功能"></p><h1 id="4-大语言模型的训练方法"><a href="#4-大语言模型的训练方法" class="headerlink" title="4 大语言模型的训练方法"></a>4 大语言模型的训练方法</h1><p><img src="/img/ai/openbmb/lecture4/1.png" alt="如何训练这些模型"></p><ul><li>Pre-training 预训练<ul><li>Language Modeling 语言建模</li><li>Development of Pre-trained Language Models 预训练语言模型的开发</li></ul></li><li>Post-training 后训练<ul><li>Conventional Fine-Tuning 常规微调</li><li>Advanced Adaptation 高级自适应</li><li>Alignment &amp; SuperAlignment 对齐和超对齐</li></ul></li></ul><h2 id="大模型的普及"><a href="#大模型的普及" class="headerlink" title="大模型的普及"></a>大模型的普及</h2><ul><li>一切都可以 <strong>tokenized</strong> —— 文本、代码、图像、DNA……</li><li>每个 Token 都可以被学习（和推广）</li></ul><p><img src="/img/ai/openbmb/lecture4/2.png" alt="tokenize"></p><h3 id="tokenization"><a href="#tokenization" class="headerlink" title="tokenization"></a>tokenization</h3><p>标记化将文本（或其他信息）分解为子单词（标记）</p><ul><li>有多种方法来标记文本</li><li>标记可以通过嵌入（Embedding）进一步表示</li></ul><p><img src="/img/ai/openbmb/lecture4/3.png" alt="单词化"></p><p><img src="/img/ai/openbmb/lecture4/4.png" alt="BPE标记化训练过程"></p><h3 id="过去的预训练嵌入"><a href="#过去的预训练嵌入" class="headerlink" title="过去的预训练嵌入"></a>过去的预训练嵌入</h3><ul><li>词嵌入以上下文无关的方式应用</li><li>训练神经语言模型，根据句子中的前几个单词来预测下一个单词，并将其内部表示用作词向量</li></ul><p><img src="/img/ai/openbmb/lecture4/5.png" alt="如何表示一个单词的不同含义？"></p><div class="note note-primary">            <p>ELMo：情境化预训练从这里开始</p><ul><li>架构：堆叠式 Bi-LSTM，基于 1B Word Benchmark。</li><li>将每层的隐藏状态组合在一起作为上下文词嵌入。</li><li>语境化：每个单词的表示取决于其使用的整个上下文。</li><li>深度：单词表示结合了深度预训练神经网络的所有层</li></ul><p><img src="/img/ai/openbmb/lecture4/6.png" alt="ELMo：深度上下文词嵌入"></p>          </div><h2 id="transformer-1"><a href="#transformer-1" class="headerlink" title="transformer"></a>transformer</h2><p><img src="/img/ai/openbmb/lecture4/7.png" alt="Encoder Decoder"></p><p><img src="/img/ai/openbmb/lecture4/8.png" alt="BERT &amp; GPT"></p><h3 id="gpt"><a href="#gpt" class="headerlink" title="gpt"></a>gpt</h3><ul><li>受到 Transformer 在不同 NLP 任务中成功的启发，GPT 是<strong>第一个基于 Transformer 预训练 PLM 的工作</strong></li><li>Transformer + 从左到右的 LM；对下游任务进行了微调。</li></ul><p><img src="/img/ai/openbmb/lecture4/9.png" alt="GPT"></p><ul><li>训练 Transformer 是高效的：我们实际上可以在一次前向传递中计算出序列中所有标记的语言建模概率。</li><li>注意掩码可控制哪些上下文标记在注意力计算中可见。</li></ul><p><img src="/img/ai/openbmb/lecture4/10.png" alt="Training"></p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><ul><li><a href="https://cloud.tencent.com/developer/article/2330592">GPT太「奢侈」，平替大汇总来了，再也不用担心部署大难题</a></li><li><a href="https://ar5iv.labs.arxiv.org/html/2308.14149">Examining User-Friendly and Open-Sourced Large GPT Models: A Survey on Language, Multimodal, and Scientific GPT Models</a></li><li><a href="https://blog.csdn.net/u010945683/article/details/46757757">MathJax基本的使用方式</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>ChatTTS</title>
    <link href="/2024/08/07/AI/TTS/"/>
    <url>/2024/08/07/AI/TTS/</url>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/2noise/ChatTTS">ChatTTS</a> 是一个用于对话场景的文本转语音的强大工具</p><span id="more"></span><ul><li><a href="https://chattts.com/zh">ChatTTS 主页</a></li><li><a href="https://blog.csdn.net/weixin_43935971/article/details/139877978">ChatTTS增强版V3【已开源】，长文本修复，中英混读，导入音色，批量SRT、TXT</a><ul><li><a href="https://github.com/CCmahua/ChatTTS-Enhanced">ChatTTS-Enhanced</a></li><li><a href="https://github.com/lenML/ChatTTS-Forge">ChatTTS-Forge</a></li><li><a href="https://github.com/6drf21e/ChatTTS_colab">离线整合包 ChatTTS_colab</a></li></ul></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:2noise/ChatTTS.git<br><span class="hljs-built_in">cd</span> ChatTTS<br><br><span class="hljs-comment"># 使用 https://www.tech-odyssey.cn/2024/06/24/AI/Computing-Startup/ 已经创建好的 conda-gpu 环境</span><br>pip install -r requirements.txt -i https://pypi.tuna.tsinghua.edu.cn/simple<br><br><span class="hljs-comment"># 以下是为适配 GPU，可以快速生成</span><br><span class="hljs-comment"># 注意：安装编译十分缓慢</span><br>pip install git+https://github.com/NVIDIA/TransformerEngine.git@stable -i https://pypi.tuna.tsinghua.edu.cn/simple<br>pip install flash-attn --no-build-isolation -i https://pypi.tuna.tsinghua.edu.cn/simple<br><br><span class="hljs-comment"># 需要手动一一下载模型文件: https://huggingface.co/2Noise/ChatTTS</span><br><span class="hljs-comment"># 启动一个 WebUI</span><br>python examples/web/webui.py<br></code></pre></td></tr></table></figure><p>运行示意图：</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/ai/tts/1.png" alt="UI"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/ai/tts/2.png" alt="Backend"></div></div></div><p>示例结果：</p><!-- 参考 https://dplayer.diygod.dev/zh/ --><div id="dplayer0" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer0"),"theme":"#FADFA3","loop":true,"lang":"zh-cn","screenshot":true,"hotkey":true,"preload":"auto","volume":0.9,"mutex":true,"video":{"url":"/img/ai/tts/audio.mp3","pic":"/img/ai/tts/index.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><h1 id="Demo"><a href="#Demo" class="headerlink" title="Demo"></a>Demo</h1><p>一个基础的测试：</p><figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> ChatTTS<br><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">import</span> torchaudio<br><br>chat = ChatTTS.Chat()<br>chat.load(<span class="hljs-built_in">compile</span>=<span class="hljs-literal">False</span>) <span class="hljs-comment"># Set to True for better performance</span><br><br>texts = [<span class="hljs-string">&quot;你好，欢迎来到上海&quot;</span>, <span class="hljs-string">&quot;你好，我是你的私人助理&quot;</span>]<br><br>wavs = chat.infer(texts)<br><br><span class="hljs-keyword">for</span> i <span class="hljs-keyword">in</span> <span class="hljs-built_in">range</span>(<span class="hljs-built_in">len</span>(wavs)):<br>    torchaudio.save(<span class="hljs-string">f&quot;basic_output<span class="hljs-subst">&#123;i&#125;</span>.wav&quot;</span>, torch.from_numpy(wavs[i]).unsqueeze(<span class="hljs-number">0</span>), <span class="hljs-number">24000</span>)<br></code></pre></td></tr></table></figure><p>在 WSL 中，我们需要播放这个.wav，使用 VLC 来简单打开并播放它。参考 <a href="https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/gui-apps">在适用于 Linux 的 Windows 子系统上运行 Linux GUI 应用</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Ref: https://learn.microsoft.com/zh-cn/windows/wsl/tutorials/gui-apps</span><br><span class="hljs-built_in">sudo</span> apt install vlc -y<br>cvlc basic_output0.wav <span class="hljs-comment"># will not create a window.</span><br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>TTS</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>LLM 算法分析</title>
    <link href="/2024/08/07/AI/gpt/"/>
    <url>/2024/08/07/AI/gpt/</url>
    
    <content type="html"><![CDATA[<p>一文了解 GPT 推理原理。</p><span id="more"></span><h2 id="AI演化趋势"><a href="#AI演化趋势" class="headerlink" title="AI演化趋势"></a>AI演化趋势</h2><p>AI模型规模越来越庞大，越来越简洁，人工参与度要求越来越低，和硬件发展相匹配。</p><ul><li>2000年前百家齐放，主要环境PC机：<ul><li>专家系统、贝叶斯网络、<a href="https://charlesliuyx.github.io/2017/09/19/%E6%94%AF%E6%8C%81%E5%90%91%E9%87%8F%E6%9C%BASVM%E5%AD%A6%E4%B9%A0%E7%AC%94%E8%AE%B0/">支持向量机</a>、<a href="https://blog.csdn.net/weixin_46323666/article/details/125843236">决策树</a>、神经网络、…</li><li>IBM深蓝(国际象棋), Doctor Watson</li></ul></li></ul><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/gpt/expert.png" alt="专家系统"></div><div class="group-image-wrap"><img src="/img/gpt/tree.png" alt="决策树"></div><div class="group-image-wrap"><img src="/img/gpt/svm.png" alt="向量机"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/gpt/deepblue.jpg" alt="更深的蓝"></div></div></div><ul><li>2000s深度学习兴起，和GPU适配<ul><li>1940s早期神经网络，1980s <a href="https://yann.lecun.com/exdb/lenet/index.html">CNN</a>提出，1990s RNN&amp;<a href="https://developer.aliyun.com/article/1112196">LSTM</a>，复杂多变的网络结构和算子<ul><li><a href="https://blog.csdn.net/hduxiejun/article/details/53571768">Lenet论文学习笔记</a></li></ul></li><li>2006 NV CUDA框架， 2016 AlphaGo</li></ul></li></ul><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/gpt/cnn.png" alt="卷积神经网络"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/gpt/LSTM.png" alt="贝叶斯长期短期记忆模型（LSTM）"></div><div class="group-image-wrap"><img src="/img/gpt/alphago.jpg" alt="阿法狗"></div></div></div><ul><li>2020s大语言模型兴起, 得益于GPU与AI相互促进发展<ul><li>2017 <strong>Attention is all you need</strong></li><li>2018 GPT&#x2F;BERT</li><li>2022 chatGPT<ul><li><strong>矩阵乘，残差网络，LayerNormalization，Attention</strong></li><li><strong>Elementwise 非线性激活函数</strong></li><li><strong>基于 Transformer 结构</strong></li></ul></li></ul></li></ul><p><img src="/img/gpt/llmApp.png" alt="LLM 应用"></p><h2 id="神经网络简介"><a href="#神经网络简介" class="headerlink" title="神经网络简介"></a>神经网络简介</h2><p><img src="/img/gpt/nn.png" alt="神经网络"></p><h2 id="残差神经网络"><a href="#残差神经网络" class="headerlink" title="残差神经网络"></a>残差神经网络</h2><p>解决退化问题</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/gpt/degradation-problem.png" alt="Degradation Problem"></div><div class="group-image-wrap"><img src="/img/gpt/resnet.png" alt="多层残差神经网络"></div></div></div><p>计算残差:</p><p><img src="/img/gpt/res.png" alt="算子"></p><h2 id="编码器与解码器"><a href="#编码器与解码器" class="headerlink" title="编码器与解码器"></a>编码器与解码器</h2><p>Seq2Seq : RNN, LSTM, Transformer</p><ul><li><a href="https://ir.vignan.ac.in/id/eprint/623/1/19.ANAND%20REAL%20TIMESPEECH%20TRANSLATION%20USING%20RNN.pdf">REAL TIMESPEECH TRANSLATION USING RECURRENT NEURAL NETWORKS</a></li></ul><p><img src="/img/gpt/encdec.gif" alt="Encode &amp; Decoder"></p><h2 id="LLM-分类"><a href="#LLM-分类" class="headerlink" title="LLM 分类"></a>LLM 分类</h2><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/gpt/attention.png" alt="Attention 架构"></div><div class="group-image-wrap"><img src="/img/gpt/class.jpg" alt="分类"></div></div></div><h2 id="Encoder-Decoder功能对比"><a href="#Encoder-Decoder功能对比" class="headerlink" title="Encoder &amp; Decoder功能对比"></a>Encoder &amp; Decoder功能对比</h2><ul><li>Masked Language Model （BERT Training）</li><li>Next Token Generation （GPT）：我爱北京天安，计算出下一个字 “门”</li></ul><p><img src="/img/gpt/bert.png" alt="bert"></p><h2 id="Attention-介绍"><a href="#Attention-介绍" class="headerlink" title="Attention 介绍"></a>Attention 介绍</h2><p>Attention is all you need!</p><p><img src="/img/gpt/bertVSgpt.png" alt="Bert VS GPT"></p><p>$$<br>Attention&#x3D;Softmax(QK^𝑇)𝑉<br>$$</p><p><img src="/img/gpt/qkv1.png" alt="Attention"></p><p>归一化，权重系数，突出主要因子</p><p>$$<br>Softmax([𝑣1,𝑣2,𝑣3,…,𝑣𝑛])&#x3D; \frac{[𝑒^{𝑣1}, 𝑒^{𝑣2}, 𝑒^{𝑣3}, …, 𝑒^{𝑣3}]}{𝑒^{𝑣1} + 𝑒^{𝑣2} + 𝑒^{𝑣3} + … + 𝑒^{𝑣𝑛}}<br>$$</p><p>例如：</p><p>$$<br>Softmax([1,−∞,0,2,5])&#x3D;[0.01704,0,0.00627,0.04632,0.93037]<br>$$</p><p><strong>Decode-only: 每个 Token 都只依赖历史信息而不依赖未来信息。</strong>可以通过使用 <code>KV-cache</code> 极大降低generation过程计算量 – Memory Bound</p><p>更多：</p><ul><li><a href="https://cloud.tencent.com/developer/article/1609905">一文讲透预训练模型的改进训练算法 ，轻松达到State of the Art</a></li><li><a href="https://blog.csdn.net/weixin_44799217/article/details/115374101">BERT模型的详细介绍</a></li><li><a href="https://www.cvmart.net/community/detail/5137?hmsr=joyk.com&utm_source=joyk.com&utm_medium=referral">transformer 中: self-attention 部分是否需要进行 mask？</a></li><li><a href="https://pythonziliao.com/post/758.html">学习笔记：基于Transformer的时间序列预测模型</a></li><li><a href="https://qiankunli.github.io/2023/09/04/llm_source.html"><strong>Transformers源码学习</strong></a></li><li><a href="https://duanmofan.com/archives/self-attention2transformer">从self-attention到transformer的超详细的算法解析和主流论文研究分享</a></li><li><a href="https://juejin.cn/post/6982152969969991711">This post is all you need（①多头注意力机制原理）</a></li></ul><h2 id="非线性激活函数"><a href="#非线性激活函数" class="headerlink" title="非线性激活函数"></a>非线性激活函数</h2><p><img src="/img/gpt/%E9%9D%9E%E7%BA%BF%E6%80%A7%E5%8F%98%E6%8D%A2.png" alt="非线性变换"></p><p>目标，通过非线性变换把的分界线拉直；更高的维度提供了更多的弯曲变换机会。</p><p><img src="/img/gpt/%E7%BB%B4%E5%BA%A6.png" alt="GPT3 先将输入升维度再降维度"></p><p>Transformer中 Feedforwad 部件，Elementwise 激活函数（Tensor中每个元素独立进行相同的非线性运算）</p><ul><li>GPT3使用 <a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html#relu">ReLU</a> 算子</li><li>Llama2 使用<a href="https://zhuanlan.zhihu.com/p/650237644">SwiGLU</a>算子，带有参数</li></ul><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/gpt/relu.png" alt="ReLU"></div><div class="group-image-wrap"><img src="/img/gpt/swiglu.png" alt="SwiGLU"></div></div></div>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
      <tag>GPT</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Analysis Llama.cpp</title>
    <link href="/2024/08/04/AI/llama-cpp/"/>
    <url>/2024/08/04/AI/llama-cpp/</url>
    
    <content type="html"><![CDATA[<p>This blog is about the code structure analysis of <code>llama.cpp</code> project.</p><span id="more"></span><h2 id="Compilation"><a href="#Compilation" class="headerlink" title="Compilation"></a>Compilation</h2><p>This project supports <code>Makefile</code> and <code>CMakeLists.txt</code>, while I don’t understand <code>Makefile</code> well, I’ll use the latter one to help understand the compilation of <code>Make</code>.</p><p>The most important example given by the LLM deployment framework is <code>llama-cli</code>. <strong>The usage of <code>llama-cli</code> can be found in <a href="https://github.com/ggerganov/llama.cpp/tree/master/examples/main">https://github.com/ggerganov/llama.cpp/tree/master/examples/main</a></strong>.</p><p>It’s CMake configuration shows in <code>examples/main/CMakeLists.txt</code>:</p><figure class="highlight cmake"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs cmake"><span class="hljs-keyword">set</span>(<span class="hljs-keyword">TARGET</span> llama-cli)<br><span class="hljs-keyword">add_executable</span>(<span class="hljs-variable">$&#123;TARGET&#125;</span> main.cpp)<br><span class="hljs-keyword">install</span>(TARGETS <span class="hljs-variable">$&#123;TARGET&#125;</span> RUNTIME)<br><span class="hljs-keyword">target_link_libraries</span>(<span class="hljs-variable">$&#123;TARGET&#125;</span> PRIVATE common llama <span class="hljs-variable">$&#123;CMAKE_THREAD_LIBS_INIT&#125;</span>)<br><span class="hljs-keyword">target_compile_features</span>(<span class="hljs-variable">$&#123;TARGET&#125;</span> PRIVATE cxx_std_11)<br></code></pre></td></tr></table></figure><p>The source file to compile <code>llama-cli</code> is <code>examples/main/main.cpp</code>. It shows the execution file depends on <code>common</code> and <code>llama</code> libraries.</p><p>We could easily found the <code>llama</code> library in <code>src/CMakeLists.txt</code>, it is built by the most important backend source file <code>src/llama.cpp</code>, and the public header file <code>include/llama.h</code>. I may analyze the how the backend works later, while in this blog, I mainly focus the logic of <code>llama-cli</code> execution, and then I want to modify it. The library <code>common</code> is in the folder <code>common</code>, from the CMake code we can know it contains basic functions of the project.</p><h2 id="main-cpp"><a href="#main-cpp" class="headerlink" title="main.cpp"></a>main.cpp</h2><p>Let’s dive into the <code>main.cpp</code> to find how it woks.</p><p>In the <a href="https://www.tech-odyssey.cn/2024/07/23/AI/Local-LLAMA-Deployment/">chat_llama3.sh</a>:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">FIRST_INSTRUCTION=<span class="hljs-variable">$2</span><br>SYSTEM_PROMPT=<span class="hljs-string">&quot;You are a helpful assistant.&quot;</span><br><br>./llama-cli -m <span class="hljs-variable">$1</span> --color -i \<br>-c 0 -t 6 --temp 0.2 --repeat_penalty 1.1 -ngl 40 \<br>-r <span class="hljs-string">&#x27;&lt;|eot_id|&gt;&#x27;</span> \<br>--in-prefix <span class="hljs-string">&#x27;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n&#x27;</span> \<br>--in-suffix <span class="hljs-string">&#x27;&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&#x27;</span> \<br>-p <span class="hljs-string">&quot;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\n\n<span class="hljs-variable">$SYSTEM_PROMPT</span>\n\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n<span class="hljs-variable">$FIRST_INSTRUCTION</span>\n\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&quot;</span><br></code></pre></td></tr></table></figure><h3 id="Debug-main-cpp"><a href="#Debug-main-cpp" class="headerlink" title="Debug main.cpp"></a>Debug main.cpp</h3><p>Firstly, we need to compile in Debug mode. We can see <code>-g</code> in the <code>CXXFLAGS</code>.</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">make clean<br>make GGML_CUDA=1 LLAMA_DEBUG=1 -j32<br></code></pre></td></tr></table></figure><p>Then, create a <code>launch.json</code> to use VSCode to debug with UI:</p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-5b75660a" role="button" aria-expanded="false" aria-controls="collapse-5b75660a">        <div class="fold-arrow">▶</div>launch.json      </div>      <div class="fold-collapse collapse" id="collapse-5b75660a">        <div class="fold-content">          <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;version&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;0.2.0&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;configurations&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>        <span class="hljs-punctuation">&#123;</span><br>            <span class="hljs-attr">&quot;name&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;gdb&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;type&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;cppdbg&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;request&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;launch&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;program&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;workspaceFolder&#125;/llama-cli&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;args&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>                <span class="hljs-string">&quot;-m&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;/home/sjl/work/llama.cpp/model/lllama-3-chinese-8b-instruct-v3-ggml-model-q8_0.gguf&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;--color&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;-i&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;-c&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;0&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;-t&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;6&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;--temp&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;0.2&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;--repeat_penalty&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;1.1&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;-ngl&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;999&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;-r&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;&#x27;&lt;|eot_id|&gt;&#x27;&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;--in-prefix&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;&#x27;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n&#x27;&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;--in-suffix&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;&#x27;&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n&#x27;&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;-p&quot;</span><span class="hljs-punctuation">,</span><br>                <span class="hljs-string">&quot;&#x27;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\\n\\nYou are a helpful assistant.\\n\\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\\n\\n介绍一下北京\\n\\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\\n\\n&#x27;&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;stopAtEntry&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;cwd&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;$&#123;fileDirname&#125;&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;environment&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;externalConsole&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>            <span class="hljs-attr">&quot;MIMode&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;gdb&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-punctuation">&#125;</span><br>    <span class="hljs-punctuation">]</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>        </div>      </div>    </div><div id="dplayer3" class="dplayer hexo-tag-dplayer-mark" style="margin-bottom: 20px;"></div><script>(function(){var player = new DPlayer({"container":document.getElementById("dplayer3"),"theme":"#FADFA3","loop":true,"lang":"zh-cn","screenshot":true,"hotkey":true,"preload":"auto","volume":0.9,"mutex":true,"video":{"url":"/img/ai/debug.MOV","pic":"/img/ai/dplay_index.png"}});window.dplayers||(window.dplayers=[]);window.dplayers.push(player);})()</script><h2 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h2><ul><li><a href="https://mp.weixin.qq.com/s/SsPyZy1poOTuuoDWOoJctg">lama.cpp 源码解析</a><ul><li><a href="https://www.bilibili.com/video/BV1Ez4y1w7fc/">llama.cpp 源码解析– CUDA版本流程与逐算子详解</a></li></ul></li><li><a href="https://blog.yanghong.dev/llama-cpp-practice/">Llama.cpp 上手实战指南</a></li><li><a href="https://zhuanlan.zhihu.com/p/670515231">笔记：Llama.cpp 代码浅析（一）：并行机制与KVCache</a></li><li><a href="https://blog.csdn.net/qq_29788741/article/details/132352856">llama.cpp</a></li><li><a href="https://www.53ai.com/news/qianyanjishu/976.html">基于llama.cpp的量化部署实战</a></li><li><a href="https://hub.baai.ac.cn/view/28608">LLaMa.cpp深度解析</a></li><li><a href="https://cloud.tencent.com/developer/article/2325942">研究完llama.cpp，我发现手机跑大模型竟这么简单</a></li></ul>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
      <tag>LLAMA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Llama Local Deployment</title>
    <link href="/2024/07/23/AI/Local-LLAMA-Deployment/"/>
    <url>/2024/07/23/AI/Local-LLAMA-Deployment/</url>
    
    <content type="html"><![CDATA[<p>Chinese-LLaMA-Alpaca 是基于 Meta 发布的可商用大模型 Llama 开发，llama.cpp 是一个 C++ 语言部署 Llama 的框架。</p><span id="more"></span><ul><li><a href="https://github.com/ggerganov/llama.cpp">llama.cpp</a></li></ul><h1 id="llama-2"><a href="#llama-2" class="headerlink" title="llama 2"></a>llama 2</h1><ul><li><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-2">Chinese-LLaMA-Alpaca-2</a></li></ul><h2 id="部署"><a href="#部署" class="headerlink" title="部署"></a>部署</h2><ul><li><a href="https://huggingface.co/hfl/chinese-alpaca-2-7b-64k-gguf/tree/main">长上下文版模型 Chinese-Alpaca-2-7B-64K</a></li><li><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-2/wiki/llamacpp_zh">llama.cpp部署教程</a></li></ul><p>注：FP16版本较慢，可以下<code>q8_0</code>或<code>Q6_K</code>，非常接近F16模型的效果。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> https://github.com/ggerganov/llama.cpp<br><span class="hljs-built_in">cd</span> llama.cpp<br><br>make GGML_CUDA=1<br>./chat.sh model/chinese-alpaca-2-7b-64k-ggml-model-f16.gguf <span class="hljs-string">&#x27;介绍一下北京&#x27;</span><br></code></pre></td></tr></table></figure><ul><li><code>chat.sh</code> 内容：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><br><span class="hljs-comment"># temporary script to chat with Chinese Alpaca-2 model</span><br><span class="hljs-comment"># usage: ./chat.sh alpaca2-ggml-model-path your-first-instruction</span><br><br>SYSTEM=<span class="hljs-string">&#x27;You are a helpful assistant. 你是一个乐于助人的助手。&#x27;</span><br>FIRST_INSTRUCTION=<span class="hljs-variable">$2</span><br><br><span class="hljs-comment"># 注，新版 llama.cpp 拆分了编译的 main 可执行文件</span><br>./llama-cli -m <span class="hljs-variable">$1</span> \<br>--color -i -c 4096 -t 8 --temp 0.5 --top_k 40 --top_p 0.9 --repeat_penalty 1.1 \<br>--in-prefix-bos -ngl 40 --in-prefix <span class="hljs-string">&#x27; [INST] &#x27;</span> --in-suffix <span class="hljs-string">&#x27; [/INST]&#x27;</span> -p \<br><span class="hljs-string">&quot;[INST] &lt;&lt;SYS&gt;&gt;</span><br><span class="hljs-string"><span class="hljs-variable">$SYSTEM</span></span><br><span class="hljs-string">&lt;&lt;/SYS&gt;&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string"><span class="hljs-variable">$FIRST_INSTRUCTION</span> [/INST]&quot;</span><br></code></pre></td></tr></table></figure><div class="note note-primary">            <p>GPU版本需要用<code>-ngl 40</code>参数指定（必须编译CUDA版本）。</p>          </div><p><img src="/img/ai/llama/llama_gpu.png" alt="LLAMA"></p><h2 id="server-设置"><a href="#server-设置" class="headerlink" title="server 设置"></a>server 设置</h2><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./llama-server -m model/chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf -c 4096 -ngl 40<br></code></pre></td></tr></table></figure><p>创建一个client脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># server_curl_example.sh</span><br><br>SYSTEM_PROMPT=<span class="hljs-string">&#x27;You are a helpful assistant. 你是一个乐于助人的助手。&#x27;</span><br><span class="hljs-comment"># SYSTEM_PROMPT=&#x27;You are a helpful assistant. 你是一个乐于助人的助手。请你提供专业、有逻辑、内 容真实、有价值的详细回复。&#x27; # Try this one, if you prefer longer response.</span><br>INSTRUCTION=<span class="hljs-variable">$1</span><br>ALL_PROMPT=<span class="hljs-string">&quot;[INST] &lt;&lt;SYS&gt;&gt;\n<span class="hljs-variable">$SYSTEM_PROMPT</span>\n&lt;&lt;/SYS&gt;&gt;\n\n<span class="hljs-variable">$INSTRUCTION</span> [/INST]&quot;</span><br>CURL_DATA=<span class="hljs-string">&quot;&#123;\&quot;prompt\&quot;: \&quot;<span class="hljs-variable">$ALL_PROMPT</span>\&quot;,\&quot;n_predict\&quot;: 128&#125;&quot;</span><br><br>curl --request POST \<br>    --url http://localhost:8080/completion \<br>    --header <span class="hljs-string">&quot;Content-Type: application/json&quot;</span> \<br>    --data <span class="hljs-string">&quot;<span class="hljs-variable">$CURL_DATA</span>&quot;</span><br><br><span class="hljs-built_in">echo</span><br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./server_curl_example.sh <span class="hljs-string">&#x27;请列举5条文明乘车的建议&#x27;</span><br></code></pre></td></tr></table></figure><p><img src="/img/ai/llama/llama_server.png" alt="LLAMA Server"></p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-5b5bd572" role="button" aria-expanded="false" aria-controls="collapse-5b5bd572">        <div class="fold-arrow">▶</div>运行后返回一个json条目      </div>      <div class="fold-collapse collapse" id="collapse-5b5bd572">        <div class="fold-content">          <figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs json"><span class="hljs-punctuation">&#123;</span><br>    <span class="hljs-attr">&quot;content&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot; 1. 保持秩序：尽量保持车内安静，尊重他人的权益。不要大声喧哗、大声打电话或使用电子设备，以 免干扰他人的休息和学习。\n\n2. 不吸烟：在乘车过程中，不吸烟或使用电子烟，以保持车内空气质量，并尊重他人的健康。\n\n3. 注意个人卫生：尽量避免在车内进食、嚼口香糖、吐痰等，保持车内的卫生和清洁。同时，保持个人卫生，如洗手、洗脸等，以减少细菌和病毒传播的风险。\n\n4. 遵守乘车规则：遵守乘车&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;id_slot&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;stop&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model/chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;tokens_predicted&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">128</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;tokens_evaluated&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">43</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;generation_settings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;n_ctx&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4096</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;n_predict&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">-1</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;model&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;model/chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;seed&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">4294967295</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;temperature&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.800000011920929</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;dynatemp_range&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;dynatemp_exponent&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;top_k&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">40</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;top_p&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.949999988079071</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;min_p&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.05000000074505806</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;tfs_z&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;typical_p&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;repeat_last_n&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">64</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;repeat_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">1.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;presence_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;frequency_penalty&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;penalty_prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;use_penalty_prompt_tokens&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;mirostat&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;mirostat_tau&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">5.0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;mirostat_eta&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0.10000000149011612</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;penalize_nl&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;stop&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;n_keep&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;n_discard&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;ignore_eos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;stream&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;logit_bias&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;n_probs&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;min_keep&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">0</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;grammar&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;samplers&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">[</span><br>            <span class="hljs-string">&quot;top_k&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-string">&quot;tfs_z&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-string">&quot;typical_p&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-string">&quot;top_p&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-string">&quot;min_p&quot;</span><span class="hljs-punctuation">,</span><br>            <span class="hljs-string">&quot;temperature&quot;</span><br>        <span class="hljs-punctuation">]</span><br>    <span class="hljs-punctuation">&#125;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;prompt&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;[INST] &lt;&lt;SYS&gt;&gt;\nYou are a helpful assistant. 你是一个乐于助人的助手。\n&lt;&lt;/SYS&gt;&gt;\n\n请列举5条文明乘车的建议 [/INST]&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;truncated&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;stopped_eos&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;stopped_word&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">false</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;stopped_limit&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-literal"><span class="hljs-keyword">true</span></span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;stopping_word&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-string">&quot;&quot;</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;tokens_cached&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">170</span><span class="hljs-punctuation">,</span><br>    <span class="hljs-attr">&quot;timings&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-punctuation">&#123;</span><br>        <span class="hljs-attr">&quot;prompt_n&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">43</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;prompt_ms&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">244.353</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;prompt_per_token_ms&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">5.6826279069767445</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;prompt_per_second&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">175.97492152746233</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;predicted_n&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">128</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;predicted_ms&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">2295.145</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;predicted_per_token_ms&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">17.9308203125</span><span class="hljs-punctuation">,</span><br>        <span class="hljs-attr">&quot;predicted_per_second&quot;</span><span class="hljs-punctuation">:</span> <span class="hljs-number">55.7698968910461</span><br>    <span class="hljs-punctuation">&#125;</span><br><span class="hljs-punctuation">&#125;</span><br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="Jetson-Orin-Nano"><a href="#Jetson-Orin-Nano" class="headerlink" title="Jetson Orin Nano"></a>Jetson Orin Nano</h2><ul><li><a href="https://developer.nvidia.com/cuda-gpus">Your GPU Compute Capability</a></li><li><a href="https://huggingface.co/hfl/chinese-alpaca-2-1.3b-gguf">chinese-alpaca-2-1.3b-gguf</a> 下载 <code>q_2k</code> 版本，其他未测试</li></ul><p>因为cuda版本低，编译llama.cpp前需要指定计算能力:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">export</span> CUDA_DOCKER_ARCH=compute_87<br>make GGML_CUDA=1 -j 4<br></code></pre></td></tr></table></figure><p>其他配置同上</p><p><img src="/img/ai/llama/llama_jetson.png" alt="Jetson 运行 Llama"></p><div class="note note-primary">            <p>第一次执行导入模型会很慢，之后会变快很多。图右边为<code>jtop</code>指令显示GPU占用情况。</p>          </div><p>测试长上下文 <code>7B q_2k</code>: <a href="https://huggingface.co/hfl/chinese-alpaca-2-7b-64k-gguf/tree/main">chinese-alpaca-2-7b-64k-gguf</a>, 显著提高了显存占用率。</p><p><img src="/img/ai/llama/llama_jetson2.png" alt="Jetson 运行 Llama 7B"></p><h2 id="Jetson-WebUI"><a href="#Jetson-WebUI" class="headerlink" title="Jetson + WebUI"></a>Jetson + WebUI</h2><p>参考：</p><ul><li><a href="https://www.jetson-ai-lab.com/tutorial_ollama.html">https://www.jetson-ai-lab.com/tutorial_ollama.html</a></li><li><a href="https://github.com/open-webui/open-webui">https://github.com/open-webui/open-webui</a></li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 创建 ollama server</span><br>jetson-containers run --name ollama $(autotag ollama)<br>docker run -it --<span class="hljs-built_in">rm</span> --network=host --add-host=host.docker.internal:host-gateway ghcr.io/open-webui/open-webui:main<br></code></pre></td></tr></table></figure><p>打开<code>http://JETSON_IP:8080</code>：</p><p><img src="/img/ai/llama/llama_webui.png" alt="Jetson 运行 Ollama，并运行 WebUI"></p><h2 id="ollama-部署"><a href="#ollama-部署" class="headerlink" title="ollama 部署"></a>ollama 部署</h2><ul><li><a href="https://blog.csdn.net/nlpstarter/article/details/138910697">ollama部署体验Chinese-LLaMA-Alpaca-3大模型项目</a></li><li><a href="https://ollama.com/download">ollama下载地址</a></li><li><a href="https://github.com/ollama/ollama?tab=readme-ov-file">ollama仓库</a></li></ul><p>首次运行<code>ollama run llama3</code>，会联网加载模型：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ ollama run llama3<br>pulling manifest<br>pulling 6a0746a1ec1a... 100% ▕███████████████████████████████████████▏  4.7 GB<br>pulling 4fa551d4f938... 100% ▕███████████████████████████████████████▏  12 KB<br>pulling 8ab4849b038c... 100% ▕███████████████████████████████████████▏  254 B<br>pulling 577073ffcc6c... 100% ▕███████████████████████████████████████▏  110 B<br>pulling 3f8eb4da87fa... 100% ▕███████████████████████████████████████▏  485 B<br>verifying sha256 digest<br>writing manifest<br>removing any unused layers<br>success<br></code></pre></td></tr></table></figure><p><img src="/img/ai/llama/ollama.png" alt="Ollama"></p><p>实测是自动运行了GPU加速的。</p><p>体验本地中文LLama2大模型，参考<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/ollama_zh">使用Ollama进行聊天</a>，Modelfile如下：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">FROM D:\work\LLAMA-Chinese-Model\chinese-alpaca-2-7b-64k-ggml-model-q8_0.gguf<br>TEMPLATE <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;&#123;&#123; if .System &#125;&#125;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;&#123; .System &#125;&#125;&lt;|eot_id|&gt;&#123;&#123; end &#125;&#125;&#123;&#123; if .Prompt &#125;&#125;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;&#123; .Prompt &#125;&#125;&lt;|eot_id|&gt;&#123;&#123; end &#125;&#125;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;&#123; .Response &#125;&#125;&lt;|eot_id|&gt;&quot;</span><span class="hljs-string">&quot;&quot;</span><br>SYSTEM <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;You are a helpful assistant. 你是一个乐于助人的助手。请你提供专业、有逻辑、内 容真实、有价值的详细回复。&quot;</span><span class="hljs-string">&quot;&quot;</span><br>PARAMETER temperature 0.2<br>PARAMETER num_keep 24<br>PARAMETER stop &lt;|start_header_id|&gt;<br>PARAMETER stop &lt;|end_header_id|&gt;<br>PARAMETER stop &lt;|eot_id|&gt;<br></code></pre></td></tr></table></figure><p><img src="/img/ai/llama/ollama_zh.png" alt="Ollama"></p><h2 id="模型下载"><a href="#模型下载" class="headerlink" title="模型下载"></a>模型下载</h2><h3 id="模型选择指引"><a href="#模型选择指引" class="headerlink" title="模型选择指引"></a>模型选择指引</h3><p>以下是中文LLaMA-2和Alpaca-2模型的对比以及建议使用场景。<strong>如需聊天交互，请选择Alpaca而不是LLaMA。<sup id="fnref:1" class="footnote-ref"><a href="#fn:1" rel="footnote"><span class="hint--top hint--rounded" aria-label="不建议单独使用1.3B模型，而是通过投机采样搭配更大的模型（7B、13B）使用。">[1]</span></a></sup></strong></p><table><thead><tr><th align="left">对比项</th><th align="center">中文LLaMA-2</th><th align="center">中文Alpaca-2</th></tr></thead><tbody><tr><td align="left">模型类型</td><td align="center"><strong>基座模型</strong></td><td align="center"><strong>指令&#x2F;Chat模型（类ChatGPT）</strong></td></tr><tr><td align="left">已开源大小</td><td align="center">1.3B、7B、13B</td><td align="center">1.3B、7B、13B</td></tr><tr><td align="left">训练类型</td><td align="center">Causal-LM (CLM)</td><td align="center">指令精调</td></tr><tr><td align="left">训练方式</td><td align="center">7B、13B：LoRA + 全量emb&#x2F;lm-head; 1.3B：全量</td><td align="center">7B、13B：LoRA + 全量emb&#x2F;lm-head; 1.3B：全量</td></tr><tr><td align="left">基于什么模型训练</td><td align="center"><a href="https://github.com/facebookresearch/llama">原版Llama-2</a>（非chat版）</td><td align="center">中文LLaMA-2</td></tr><tr><td align="left">训练语料</td><td align="center">无标注通用语料（120G纯文本）</td><td align="center">有标注指令数据（500万条）</td></tr><tr><td align="left">词表大小<sup id="fnref:2" class="footnote-ref"><a href="#fn:2" rel="footnote"><span class="hint--top hint--rounded" aria-label="本项目一代模型和二代模型的词表不同，请勿混用。二代LLaMA和Alpaca的词表相同。">[2]</span></a></sup></td><td align="center">55,296</td><td align="center">55,296</td></tr><tr><td align="left">上下文长度<sup id="fnref:3" class="footnote-ref"><a href="#fn:3" rel="footnote"><span class="hint--top hint--rounded" aria-label="括号内表示基于NTK上下文扩展支持的最大长度。">[3]</span></a></sup></td><td align="center">标准版：4K（12K-18K）; 长上下文版（PI）：16K（24K-32K）; 长上下文版（YaRN）：64K</td><td align="center">标准版：4K（12K-18K）; 长上下文版（PI）：16K（24K-32K）; 长上下文版（YaRN）：64K</td></tr><tr><td align="left">输入模板</td><td align="center">不需要</td><td align="center">需要套用特定模板<sup id="fnref:4" class="footnote-ref"><a href="#fn:4" rel="footnote"><span class="hint--top hint--rounded" aria-label="Alpaca-2采用了Llama-2-chat系列模板（格式相同，提示语不同），而不是一代Alpaca的模板，请勿混用。">[4]</span></a></sup>，类似Llama-2-Chat</td></tr><tr><td align="left">适用场景</td><td align="center">文本续写：给定上文，让模型生成下文</td><td align="center">指令理解：问答、写作、聊天、交互等</td></tr><tr><td align="left">不适用场景</td><td align="center">指令理解 、多轮聊天等</td><td align="center">文本无限制自由生成</td></tr><tr><td align="left">偏好对齐</td><td align="center">无</td><td align="center">RLHF版本（1.3B、7B）</td></tr></tbody></table><h3 id="完整模型下载"><a href="#完整模型下载" class="headerlink" title="完整模型下载"></a>完整模型下载</h3><p>以下是完整版模型，直接下载即可使用，无需其他合并步骤。推荐网络带宽充足的用户。</p><table><thead><tr><th align="left">模型名称</th><th align="center">类型</th><th align="center">大小</th><th align="center">下载地址</th><th align="center">GGUF</th></tr></thead><tbody><tr><td align="left">Chinese-LLaMA-2-13B</td><td align="center">基座模型</td><td align="center">24.7 GB</td><td align="center"><a href="https://pan.baidu.com/s/1T3RqEUSmyg6ZuBwMhwSmoQ?pwd=e9qy">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1YNa5qJ0x59OEOI7tNODxea-1YvMPoH05?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-llama-2-13b">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-13b">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-llama-2-13b-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-LLaMA-2-7B</td><td align="center">基座模型</td><td align="center">12.9 GB</td><td align="center"><a href="https://pan.baidu.com/s/1E5NI3nlQpx1j8z3eIzbIlg?pwd=n8k3">[Baidu]</a> <a href="https://drive.google.com/drive/folders/18pp4I-mvQxRA7b8vF9gP-2cH_ocnXVKh?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-llama-2-7b">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-7b">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-llama-2-7b-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-LLaMA-2-1.3B</td><td align="center">基座模型</td><td align="center">2.4 GB</td><td align="center"><a href="https://pan.baidu.com/s/1hEuOCllnJJ5NMEZJf8OkRw?pwd=nwjg">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1Sd3PA_gs6JctXtBg5HwmHXh9GX93riMP?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-llama-2-1.3b">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-1.3b">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-llama-2-1.3b-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-Alpaca-2-13B</td><td align="center">指令模型</td><td align="center">24.7 GB</td><td align="center"><a href="https://pan.baidu.com/s/1MT_Zlap1OtdYMgoBNTS3dg?pwd=9xja">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1MTsKlzR61xmbTR4hBWzQas_MOpUZsogN?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-alpaca-2-13b">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-13b">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-alpaca-2-13b-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-Alpaca-2-7B</td><td align="center">指令模型</td><td align="center">12.9 GB</td><td align="center"><a href="https://pan.baidu.com/s/1wxx-CdgbMupXVRBcaN4Slw?pwd=kpn9">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1JsJDVs7tE2y31PBNleBlDPsB7S0ZrY8d?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-alpaca-2-7b">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-7b">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-alpaca-2-7b-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-Alpaca-2-1.3B</td><td align="center">指令模型</td><td align="center">2.4 GB</td><td align="center"><a href="https://pan.baidu.com/s/1PD7Ng-ltOIdUGHNorveptA?pwd=ar1p">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1h6qOy-Unvqs1_CJ8uPp0eKC61Gbbn8n7?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-alpaca-2-1.3b">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-1.3b">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-alpaca-2-1.3b-gguf">[🤗HF]</a></td></tr></tbody></table><h3 id="长上下文版模型"><a href="#长上下文版模型" class="headerlink" title="长上下文版模型"></a>长上下文版模型</h3><p>以下是长上下文版模型，<strong>推荐以长文本为主的下游任务使用</strong>，否则建议使用上述标准版。</p><table><thead><tr><th align="left">模型名称</th><th align="center">类型</th><th align="center">大小</th><th align="center">下载地址</th><th align="center">GGUF</th></tr></thead><tbody><tr><td align="left">Chinese-LLaMA-2-7B-64K 🆕</td><td align="center">基座模型</td><td align="center">12.9 GB</td><td align="center"><a href="https://pan.baidu.com/s/1ShDQ2FG2QUJrvfnxCn4hwQ?pwd=xe5k">[Baidu]</a> <a href="https://drive.google.com/drive/folders/17l9xJx55L2YNpqt7NiLVQzOZ6fV4rzJ-?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-llama-2-7b-64k">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-7b-64k">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-llama-2-7b-64k-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-Alpaca-2-7B-64K 🆕</td><td align="center">指令模型</td><td align="center">12.9 GB</td><td align="center"><a href="https://pan.baidu.com/s/1KBAr9PCGvX2oQkYfCuLEjw?pwd=sgp6">[Baidu]</a> <a href="https://drive.google.com/drive/folders/13G_d5xcDnhtaMOaulj1BFiZbVoVwJ-Cu?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-alpaca-2-7b-64k">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-7b-64k">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-alpaca-2-7b-64k-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-LLaMA-2-13B-16K</td><td align="center">基座模型</td><td align="center">24.7 GB</td><td align="center"><a href="https://pan.baidu.com/s/1XWrh3Ru9x4UI4-XmocVT2w?pwd=f7ik">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1nii6lF0DgB1u81CnsE4cCK2jD5oq_OW-?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-llama-2-13b-16k">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-13b-16k">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-llama-2-13b-16k-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-LLaMA-2-7B-16K</td><td align="center">基座模型</td><td align="center">12.9 GB</td><td align="center"><a href="https://pan.baidu.com/s/1ZH7T7KU_up61ugarSIXw2g?pwd=pquq">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1Zc6jI5bl3myQbQsY79dWJJ8mP_fyf3iF?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-llama-2-7b-16k">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-llama-2-7b-16k">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-llama-2-7b-16k-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-Alpaca-2-13B-16K</td><td align="center">指令模型</td><td align="center">24.7 GB</td><td align="center"><a href="https://pan.baidu.com/s/1gIzRM1eg-Xx1xV-3nXW27A?pwd=qi7c">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1mOkYQCvEqtGoZ9DaIpYFweSkSia2Q0vl?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-alpaca-2-13b-16k">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-13b-16k">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-alpaca-2-13b-16k-gguf">[🤗HF]</a></td></tr><tr><td align="left">Chinese-Alpaca-2-7B-16K</td><td align="center">指令模型</td><td align="center">12.9 GB</td><td align="center"><a href="https://pan.baidu.com/s/1Qk3U1LyvMb1RSr5AbiatPw?pwd=bfis">[Baidu]</a> <a href="https://drive.google.com/drive/folders/1KBRSd2xAhiVQmamfA5wpm5ovYFRKuMdr?usp=share_link">[Google]</a> <a href="https://huggingface.co/hfl/chinese-alpaca-2-7b-16k">[🤗HF]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/chinese-alpaca-2-7b-16k">[🤖ModelScope]</a></td><td align="center"><a href="https://huggingface.co/hfl/chinese-alpaca-2-7b-16k-gguf">[🤗HF]</a></td></tr></tbody></table><h1 id="llama-3"><a href="#llama-3" class="headerlink" title="llama 3"></a>llama 3</h1><ul><li><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3">Chinese-LLaMA-Alpaca-3</a></li><li><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3-gguf/tree/main">llama-3-chinese-8b-instruct-v3-gguf</a></li></ul><h2 id="模型下载-1"><a href="#模型下载-1" class="headerlink" title="模型下载"></a>模型下载</h2><table><thead><tr><th align="left">模型名称</th><th align="center">完整版</th><th align="center">LoRA版</th><th align="center">GGUF版</th></tr></thead><tbody><tr><td align="left"><strong>Llama-3-Chinese-8B-Instruct-v3</strong>(指令模型)</td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v3">[🤖ModelScope]</a><a href="https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v3">[🟣wisemodel]</a></td><td align="center">N&#x2F;A</td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3-gguf">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v3-gguf">[🤖ModelScope]</a></td></tr><tr><td align="left"><strong>Llama-3-Chinese-8B-Instruct-v2</strong>(指令模型)</td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2">[🤖ModelScope]</a><a href="https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2">[🟣wisemodel]</a></td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2-lora">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-lora">[🤖ModelScope]</a><a href="https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-lora">[🟣wisemodel]</a></td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v2-gguf">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-v2-gguf">[🤖ModelScope]</a></td></tr><tr><td align="left"><strong>Llama-3-Chinese-8B-Instruct</strong>(指令模型)</td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct">[🤖ModelScope]</a><a href="https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct">[🟣wisemodel]</a></td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-lora">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-lora">[🤖ModelScope]</a><a href="https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-lora">[🟣wisemodel]</a></td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-gguf">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-instruct-gguf">[🤖ModelScope]</a></td></tr><tr><td align="left"><strong>Llama-3-Chinese-8B</strong>(基座模型)</td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b">[🤖ModelScope]</a><a href="https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b">[🟣wisemodel]</a></td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-lora">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-lora">[🤖ModelScope]</a><a href="https://wisemodel.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-lora">[🟣wisemodel]</a></td><td align="center"><a href="https://huggingface.co/hfl/llama-3-chinese-8b-gguf">[🤗Hugging Face]</a> <a href="https://modelscope.cn/models/ChineseAlpacaGroup/llama-3-chinese-8b-gguf">[🤖ModelScope]</a></td></tr></tbody></table><h2 id="部署-1"><a href="#部署-1" class="headerlink" title="部署"></a>部署</h2><ul><li><a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/llamacpp_zh">llama.cpp 部署</a></li><li><code>chat_llama3.sh</code>:</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs bash">FIRST_INSTRUCTION=<span class="hljs-variable">$2</span><br>SYSTEM_PROMPT=<span class="hljs-string">&quot;You are a helpful assistant.&quot;</span><br><br>./llama-cli -m <span class="hljs-variable">$1</span> --color -i \<br>-c 0 -t 6 --temp 0.2 --repeat_penalty 1.1 -ngl 40 \<br>-r <span class="hljs-string">&#x27;&lt;|eot_id|&gt;&#x27;</span> \<br>--in-prefix <span class="hljs-string">&#x27;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n&#x27;</span> \<br>--in-suffix <span class="hljs-string">&#x27;&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&#x27;</span> \<br>-p <span class="hljs-string">&quot;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;\n\n<span class="hljs-variable">$SYSTEM_PROMPT</span>\n\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;\n\n<span class="hljs-variable">$FIRST_INSTRUCTION</span>\n\n&lt;|eot_id|&gt;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;\n\n&quot;</span><br></code></pre></td></tr></table></figure><ul><li>运行：</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">./chat_llama3.sh model/llama-3-chinese-8b-instruct-v3-ggml-model-q8_0.gguf 介绍一下北京<br></code></pre></td></tr></table></figure><h2 id="ollama-部署-1"><a href="#ollama-部署-1" class="headerlink" title="ollama 部署"></a>ollama 部署</h2><ul><li><code>Modelfile_llama3</code>:</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs bash">FROM D:\work\LLAMA-Chinese-Model\llama-3-chinese-8b-instruct-v3-ggml-model-q8_0.gguf<br>TEMPLATE <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;&#123;&#123; if .System &#125;&#125;&lt;|start_header_id|&gt;system&lt;|end_header_id|&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;&#123; .System &#125;&#125;&lt;|eot_id|&gt;&#123;&#123; end &#125;&#125;&#123;&#123; if .Prompt &#125;&#125;&lt;|start_header_id|&gt;user&lt;|end_header_id|&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;&#123; .Prompt &#125;&#125;&lt;|eot_id|&gt;&#123;&#123; end &#125;&#125;&lt;|start_header_id|&gt;assistant&lt;|end_header_id|&gt;</span><br><span class="hljs-string"></span><br><span class="hljs-string">&#123;&#123; .Response &#125;&#125;&lt;|eot_id|&gt;&quot;</span><span class="hljs-string">&quot;&quot;</span><br>SYSTEM <span class="hljs-string">&quot;&quot;</span><span class="hljs-string">&quot;You are a helpful assistant. 你是一个乐于助人的助手。&quot;</span><span class="hljs-string">&quot;&quot;</span><br>PARAMETER temperature 0.2<br>PARAMETER num_keep 24<br>PARAMETER stop &lt;|start_header_id|&gt;<br>PARAMETER stop &lt;|end_header_id|&gt;<br>PARAMETER stop &lt;|eot_id|&gt;<br></code></pre></td></tr></table></figure><ul><li>运行</li></ul><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">ollama create llama3-zh-inst -f Modelfile_llama3<br>ollama run llama3-zh-inst<br></code></pre></td></tr></table></figure><h1 id="指令微调"><a href="#指令微调" class="headerlink" title="指令微调"></a>指令微调</h1><ul><li>模型下载：<a href="https://huggingface.co/hfl/llama-3-chinese-8b-instruct-v3/tree/main">llama-3-chinese-8b-instruct-v3</a></li><li>数据：<a href="https://huggingface.co/datasets/hfl/ruozhiba_gpt4/tree/main">ruozhiba_gpt4</a></li><li>训练参考：<a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/sft_scripts_zh">指令精调脚本</a></li></ul><p>训练示意图：</p><p><img src="/img/ai/llama/llama_train_inst.png" alt="Llama train"></p><p>报错：显存不足</p><ul><li><a href="https://blog.csdn.net/Coldlebron/article/details/127575370">CUDA报错:Out of Memory</a></li></ul><p>在<a href="https://www.modelscope.cn/my/mynotebook/preset">魔塔社区</a>使用GPU实例：</p><p><img src="/img/ai/llama/modelscope.png" alt="选择 24GB 实例"></p><p>训练脚本：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-meta">#!/bin/bash</span><br><span class="hljs-comment">## 运行脚本前请仔细阅读wiki(https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/sft_scripts_zh)</span><br><span class="hljs-comment">## Read the wiki(https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/sft_scripts_en) carefully before running the script</span><br>lr=1e-4<br>lora_rank=64<br>lora_alpha=128<br>lora_trainable=<span class="hljs-string">&quot;q_proj,v_proj,k_proj,o_proj,gate_proj,down_proj,up_proj&quot;</span><br><span class="hljs-comment"># modules_to_save=&quot;embed_tokens,lm_head&quot;</span><br>modules_to_save=<span class="hljs-string">&quot;None&quot;</span><br>lora_dropout=0.05<br><br>pretrained_model=/root/llama-3-chinese-8b-instruct-v3<br>tokenizer_name_or_path=<span class="hljs-variable">$&#123;pretrained_model&#125;</span><br>dataset_dir=/root/ruozhi<br>per_device_train_batch_size=1<br>per_device_eval_batch_size=1<br>gradient_accumulation_steps=8<br>max_seq_length=512<br>output_dir=output_dir<br>validation_file=/root/ruozhi/ruozhiba_qa2449_gpt4t.json<br><br>torchrun --nnodes 1 --nproc_per_node 1 run_clm_sft_with_peft.py \<br>    --model_name_or_path <span class="hljs-variable">$&#123;pretrained_model&#125;</span> \<br>    --tokenizer_name_or_path <span class="hljs-variable">$&#123;tokenizer_name_or_path&#125;</span> \<br>    --dataset_dir <span class="hljs-variable">$&#123;dataset_dir&#125;</span> \<br>    --per_device_train_batch_size <span class="hljs-variable">$&#123;per_device_train_batch_size&#125;</span> \<br>    --per_device_eval_batch_size <span class="hljs-variable">$&#123;per_device_eval_batch_size&#125;</span> \<br>    --do_train \<br>    --low_cpu_mem_usage \<br>    --do_eval \<br>    --seed <span class="hljs-variable">$RANDOM</span> \<br>    --bf16 \<br>    --num_train_epochs 3 \<br>    --lr_scheduler_type cosine \<br>    --learning_rate <span class="hljs-variable">$&#123;lr&#125;</span> \<br>    --warmup_ratio 0.03 \<br>    --logging_strategy steps \<br>    --logging_steps 10 \<br>    --save_strategy steps \<br>    --save_total_limit 3 \<br>    --evaluation_strategy steps \<br>    --eval_steps 100 \<br>    --save_steps 200 \<br>    --gradient_accumulation_steps <span class="hljs-variable">$&#123;gradient_accumulation_steps&#125;</span> \<br>    --preprocessing_num_workers 8 \<br>    --max_seq_length <span class="hljs-variable">$&#123;max_seq_length&#125;</span> \<br>    --output_dir <span class="hljs-variable">$&#123;output_dir&#125;</span> \<br>    --overwrite_output_dir \<br>    --ddp_timeout 30000 \<br>    --logging_first_step True \<br>    --lora_rank <span class="hljs-variable">$&#123;lora_rank&#125;</span> \<br>    --lora_alpha <span class="hljs-variable">$&#123;lora_alpha&#125;</span> \<br>    --trainable <span class="hljs-variable">$&#123;lora_trainable&#125;</span> \<br>    --lora_dropout <span class="hljs-variable">$&#123;lora_dropout&#125;</span> \<br>    --modules_to_save <span class="hljs-variable">$&#123;modules_to_save&#125;</span> \<br>    --torch_dtype bfloat16 \<br>    --validation_file <span class="hljs-variable">$&#123;validation_file&#125;</span> \<br>    --load_in_kbits 4 \<br>    --ddp_find_unused_parameters False<br></code></pre></td></tr></table></figure><p>其中一些参数的含义不言自明。部分参数的解释如下：</p><ul><li>–dataset_dir: 指令精调数据的目录，包含一个或多个以json结尾的Stanford Alpaca格式的指令精调数据文件</li><li>–validation_file: 用作验证集的单个指令精调文件，以json结尾，同样遵循Stanford Alpaca格式</li><li>–use_flash_attention_2: 启用FlashAttention-2加速训练</li><li>–load_in_kbits: 可选择参数为16&#x2F;8&#x2F;4，即使用fp16或8bit&#x2F;4bit量化进行模型训练，默认fp16训练。</li><li>–modules_to_save：需要额外训练的模块，注意这部分是全量精调；资源受限的情况下请设置为None（效果也会受到一些影响）</li></ul><p>训练过程：</p><p><img src="/img/ai/llama/SFT.png" alt="SFT"></p><p>实测，int4，缺省<code>modules_to_save</code> 要 20GB，难怪我的小卡爆显存。</p><p>魔塔社区可以关闭网页，下次进来还是当前窗口。注意，单次实例只有10h，不会保存任何文件。</p><p>训练完成：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs txt">***** eval metrics *****<br>  epoch                   =     2.9988<br>  eval_loss               =     0.4938<br>  eval_runtime            = 0:13:21.30<br>  eval_samples            =       2449<br>  eval_samples_per_second =      3.056<br>  eval_steps_per_second   =      3.056<br>  perplexity              =     1.6385<br></code></pre></td></tr></table></figure><p>在最后一次checkpoint文件夹里：</p><figure class="highlight txt"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs txt">.<br>├── README.md<br>├── adapter_config.json<br>├── adapter_model.safetensors<br>├── optimizer.pt<br>├── rng_state.pth<br>├── scheduler.pt<br>├── special_tokens_map.json<br>├── tokenizer.json<br>├── tokenizer_config.json<br>├── trainer_state.json<br>└── training_args.bin<br></code></pre></td></tr></table></figure><p>TODO: 参考 <a href="https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/llamacpp_zh">https://github.com/ymcui/Chinese-LLaMA-Alpaca-3/wiki/llamacpp_zh</a> 量化模型，尝试调用。</p><h1 id="参考"><a href="#参考" class="headerlink" title="参考"></a>参考</h1><section class="footnotes"><div class="footnote-list"><ol><li><span id="fn:1" class="footnote-text"><span>不建议单独使用1.3B模型，而是通过投机采样搭配更大的模型（7B、13B）使用。<a href="#fnref:1" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:2" class="footnote-text"><span>本项目一代模型和二代模型的词表不同，请勿混用。二代LLaMA和Alpaca的词表相同。<a href="#fnref:2" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:3" class="footnote-text"><span>括号内表示基于NTK上下文扩展支持的最大长度。<a href="#fnref:3" rev="footnote" class="footnote-backref"> ↩</a></span></span></li><li><span id="fn:4" class="footnote-text"><span>Alpaca-2采用了Llama-2-chat系列模板（格式相同，提示语不同），而不是一代Alpaca的模板，请勿混用。<a href="#fnref:4" rev="footnote" class="footnote-backref"> ↩</a></span></span></li></ol></div></section>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
      <tag>LLAMA</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Stable Diffusion 安裝配置</title>
    <link href="/2024/07/23/AI/Stable-Diffusion/"/>
    <url>/2024/07/23/AI/Stable-Diffusion/</url>
    
    <content type="html"><![CDATA[<p><a href="https://github.com/Stability-AI/stablediffusion">Stable Diffusion</a><br><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui">Stable Diffusion WebUI</a></p><span id="more"></span><h2 id="Installation-on-Windows-10-11"><a href="#Installation-on-Windows-10-11" class="headerlink" title="Installation on Windows 10&#x2F;11"></a>Installation on Windows 10&#x2F;11</h2><ol><li>Download sd.webui.zip from <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/releases">releases</a> and extract its contents.</li><li>Run webui.bat.</li></ol><p>需要安装python3.10</p><p>For more details see <a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/wiki/Install-and-Run-on-NVidia-GPUs">Install-and-Run-on-NVidia-GPUs</a></p><h2 id="Model-Download"><a href="#Model-Download" class="headerlink" title="Model Download"></a>Model Download</h2><p>要下载的是：<code>v1-5-pruned-emaonly.safetensors</code>，国内可能下载不下来，可以到<a href="https://huggingface.co/models?sort=trending&search=pruned-emaonly">huggingface</a>下载。</p><p>其他模型：<a href="https://huggingface.co/stabilityai/stable-diffusion-3-medium/tree/main">medium model</a></p><h2 id="插件"><a href="#插件" class="headerlink" title="插件"></a>插件</h2><p>将<a href="https://github.com/dtlnor/stable-diffusion-webui-localization-zh_CN">简体中文翻译扩展</a>一个个安装后，得到下面的界面：</p><p><img src="/img/stable/lobe.png" alt="Lobe主题的界面"></p><blockquote><p>注：有时候无法从github拉取插件，或者搜索安装，考虑手动安装。</p></blockquote><p>已安装插件一览：</p><p><img src="/img/stable/lobe2.png" alt="插件一览"></p><h2 id="issues"><a href="#issues" class="headerlink" title="issues"></a>issues</h2><p>xformer问题：<a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui/discussions/5303">No module ‘xformers’. Proceeding without it. #5303</a></p><p>修改<code>webui-user.bat</code>：</p><figure class="highlight bat"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bat"><span class="hljs-built_in">set</span> COMMANDLINE_ARGS= --xformers --opt-sdp-no-mem-attention --enable-insecure-extension-access<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>LLM</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>机密计算: HCC 驱动代码</title>
    <link href="/2024/07/02/Nvidia-HCC-Driver-Code/"/>
    <url>/2024/07/02/Nvidia-HCC-Driver-Code/</url>
    
    <content type="html"><![CDATA[<p>Hopper GPU驱动代码 CC 部分分析。</p><span id="more"></span><h1 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h1><p>535.43.02</p><ul><li>新增了Hopper CC，主架构为H100</li><li>新增mbedtls和spdm库</li><li>SEC2（Security Engine 2） 是一种集成在GPU或其他硬件中的安全模块，专门用于处理加密、解密和认证等安全操作。它通常用于确保数据在传输和存储过程中的机密性和完整性。</li><li>CSL（Crypto Security Layer）</li></ul><h1 id="文件"><a href="#文件" class="headerlink" title="文件"></a>文件</h1><ul><li>src&#x2F;nvidia&#x2F;src&#x2F;kernel&#x2F;gpu&#x2F;conf_compute&#x2F;conf_*</li><li>src&#x2F;nvidia&#x2F;src&#x2F;kernel&#x2F;gpu&#x2F;conf_compute&#x2F;arch&#x2F;hopper&#x2F;conf_*</li><li>src&#x2F;nvidia&#x2F;inc&#x2F;kernel&#x2F;gpu&#x2F;spdm&#x2F;</li><li>src&#x2F;nvidia&#x2F;generated&#x2F;g_conf_compute_*</li><li>src&#x2F;nvidia&#x2F;src&#x2F;libraries&#x2F;libspdm&#x2F;</li><li>src&#x2F;nvidia&#x2F;src&#x2F;libraries&#x2F;libspdm&#x2F;2.3.1&#x2F;include&#x2F;hal&#x2F;library&#x2F;cryptlib&#x2F;</li></ul><h1 id="顶层架构图"><a href="#顶层架构图" class="headerlink" title="顶层架构图"></a>顶层架构图</h1><p><img src="/img/HCC/code/init.png" alt="GPU 初始化"></p><p><img src="/img/HCC/code/block_copy_push.png" alt="Block Copy Push"></p><p><img src="/img/HCC/code/tools_access_va_block.png" alt="Tools Access VA Block"></p><h1 id="nv-uvm-interface-h"><a href="#nv-uvm-interface-h" class="headerlink" title="nv_uvm_interface.h"></a>nv_uvm_interface.h</h1>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-d06d829c" role="button" aria-expanded="false" aria-controls="collapse-d06d829c">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Init Context 为给定的安全通道分配并初始化 CSL 上下文      </div>      <div class="fold-collapse collapse" id="collapse-d06d829c">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslInitContext</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                       uvmGpuChannelHandle channel)</span>;<br></code></pre></td></tr></table></figure><p>为给定的安全通道分配并初始化 CSL 上下文。上下文的生命周期与其配对的安全通道的生命周期相同。</p><ul><li>参数：<ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>channel[IN]</strong> - 安全通道句柄。</li></ul></li><li>错误代码：<ul><li><strong>NV_ERR_INVALID_STATE</strong> - 系统未在机密计算模式下运行。</li><li><strong>NV_ERR_INVALID_CHANNEL</strong> - 关联通道不是安全通道。</li><li><strong>NV_ERR_IN_USE</strong> - 上下文已初始化。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-744eb808" role="button" aria-expanded="false" aria-controls="collapse-744eb808">        <div class="fold-arrow">▶</div>NV UVM Interface Deinit Csl Context 安全地取消初始化并清除上下文的内容      </div>      <div class="fold-collapse collapse" id="collapse-744eb808">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">nvUvmInterfaceDeinitCslContext</span><span class="hljs-params">(UvmCslContext *uvmCslContext)</span>;<br></code></pre></td></tr></table></figure><p>安全地取消初始化并清除上下文的内容。如果上下文已取消初始化，则函数立即返回。</p><ul><li>参数：<ul><li><strong>uvmCslContext[IN]</strong> - CSL 上下文。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-9d8895e3" role="button" aria-expanded="false" aria-controls="collapse-9d8895e3">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Acquire Encryption IV 返回一个 IV      </div>      <div class="fold-collapse collapse" id="collapse-9d8895e3">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslAcquireEncryptionIv</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                               UvmCslIv *encryptIv)</span>;<br></code></pre></td></tr></table></figure><p>返回一个 IV，稍后可在 <strong>nvUvmInterfaceCslEncrypt</strong> 方法中使用。IV 包含一个“freshness bit”，其值由此方法设置，随后由 <strong>nvUvmInterfaceCslEncrypt</strong> 弄脏，以防止 IV 的非恶意重用。</p><ul><li>参数：<ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>encryptIv[OUT]</strong> - 设备加密成功之前存储的参数。它用作 <strong>nvUvmInterfaceCslEncrypt</strong> 的输入。</li></ul></li><li>错误代码：<ul><li><strong>NV_ERR_INSUFFICIENT_RESOURCES</strong> - 新的 IV 会导致计数器溢出。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-f6c4df22" role="button" aria-expanded="false" aria-controls="collapse-f6c4df22">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Log Device Encryption 记录并检查有关设备加密的信息      </div>      <div class="fold-collapse collapse" id="collapse-f6c4df22">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslLogDeviceEncryption</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                               UvmCslIv *decryptIv)</span>;<br></code></pre></td></tr></table></figure><p>记录并检查有关设备加密的信息。</p><ul><li><p>参数：</p><ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>decryptIv[OUT]</strong> - 设备加密成功之前存储的参数。它用作 nvUvmInterfaceCslDecrypt 的输入。</li></ul></li><li><p>错误代码：</p><ul><li><strong>NV_ERR_INSUFFICIENT_RESOURCES</strong> - 设备加密会导致计数器溢出。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-4481de76" role="button" aria-expanded="false" aria-controls="collapse-4481de76">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Rotate IV 旋转给定通道和方向的 IV      </div>      <div class="fold-collapse collapse" id="collapse-4481de76">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslRotateIv</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                    UvmCslDirection direction)</span>;<br></code></pre></td></tr></table></figure><p>旋转给定通道和方向的 IV。此函数将在 CPU 和 GPU 上旋转 IV。应首先解密已由 GPU 加密的未完成消息，然后调用方向等于 <strong>UVM_CSL_DIR_GPU_TO_CPU</strong> 的此函数。同样，应首先解密已由 CPU 加密的未完成消息，然后调用方向等于 <strong>UVM_CSL_DIR_CPU_TO_GPU</strong> 的此函数。对于给定方向，在调用此函数之前通道必须处于空闲状态。无论 IV 的消息计数器的值如何，都可以调用此函数。</p><ul><li>参数：<ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>direction[IN]</strong> - 任一<ul><li><strong>UVM_CSL_DIR_CPU_TO_GPU</strong></li><li><strong>UVM_CSL_DIR_GPU_TO_CPU</strong></li></ul></li></ul></li><li>错误代码：<ul><li><strong>NV_ERR_INSUFFICIENT_RESOURCES</strong> - 旋转操作会导致计数器溢出。</li><li><strong>NV_ERR_INVALID_ARGUMENT</strong> - 方向值无效。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-6ccf396e" role="button" aria-expanded="false" aria-controls="collapse-6ccf396e">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Encrypt 加密数据并生成身份验证标签      </div>      <div class="fold-collapse collapse" id="collapse-6ccf396e">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslEncrypt</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                   NvU32 bufferSize,</span><br><span class="hljs-params">                                   NvU8 <span class="hljs-type">const</span> *inputBuffer,</span><br><span class="hljs-params">                                   UvmCslIv *encryptIv,</span><br><span class="hljs-params">                                   NvU8 *outputBuffer,</span><br><span class="hljs-params">                                   NvU8 *authTagBuffer)</span>;<br></code></pre></td></tr></table></figure><p>加密数据并生成身份验证标签。身份验证、输入和输出缓冲区不得重叠。如果重叠，则调用此函数会产生未定义的行为。当输入和输出缓冲区按 16 字节对齐时，性能通常会最大化。这是 AES 块的自然对齐。encryptIV 可以从 <strong>nvUvmInterfaceCslAcquireEncryptionIv</strong> 获得。但是，它是可选的。如果它为 NULL，则将使用行中的下一个 IV。</p><ul><li>参数：<ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>bufferSize[IN]</strong> - 输入和输出缓冲区的大小（以字节为单位）。值的范围可以从 1 字节到 (2^32) - 1 字节。</li><li><strong>inputBuffer[IN]</strong> - 明文输入缓冲区的地址。</li><li><strong>encryptIv[IN&#x2F;OUT]</strong> - 用于加密的 IV。可以为 NULL。</li><li><strong>outputBuffer[OUT]</strong> - 密文输出缓冲区的地址。</li><li><strong>authTagBuffer[OUT]</strong> - 身份验证标签缓冲区的地址。其大小为 <strong>UVM_CSL_CRYPT_AUTH_TAG_SIZE_BYTES</strong></li></ul></li><li>错误代码：<ul><li><strong>NV_ERR_INVALID_ARGUMENT</strong><ul><li>数据大小为 0 字节。</li><li>encryptIv 已被使用。</li></ul></li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-20e00cd9" role="button" aria-expanded="false" aria-controls="collapse-20e00cd9">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Decrypt 验证身份验证标签并解密数据      </div>      <div class="fold-collapse collapse" id="collapse-20e00cd9">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslDecrypt</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                   NvU32 bufferSize,</span><br><span class="hljs-params">                                   NvU8 <span class="hljs-type">const</span> *inputBuffer,</span><br><span class="hljs-params">                                   UvmCslIv <span class="hljs-type">const</span> *decryptIv,</span><br><span class="hljs-params">                                   NvU8 *outputBuffer,</span><br><span class="hljs-params">                                   NvU8 <span class="hljs-type">const</span> *authTagBuffer)</span>;<br></code></pre></td></tr></table></figure><p>验证身份验证标签并解密数据。身份验证、输入和输出缓冲区不得重叠。如果重叠，则调用此函数会产生未定义的行为。当输入和输出缓冲区按 16 字节对齐时，性能通常会最大化。这是 AES 块的自然对齐。</p><ul><li>参数：<ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>bufferSize[IN]</strong> - 输入和输出缓冲区的大小（以字节为单位）。值的范围可以从 1 字节到 (2^32) - 1 字节。</li><li><strong>decryptIv[IN]</strong> - <strong>nvUvmInterfaceCslLogDeviceEncryption</strong> 给出的参数。</li><li><strong>inputBuffer[IN]</strong> - 密文输入缓冲区的地址。</li><li><strong>outputBuffer[OUT]</strong> - 明文输出缓冲区的地址。</li><li><strong>authTagBuffer[IN]</strong> - 身份验证标签缓冲区的地址。其大小为 UVM_CSL_CRYPT_AUTH_TAG_SIZE_BYTES。</li></ul></li><li>错误代码：<ul><li><strong>NV_ERR_INSUFFICIENT_RESOURCES</strong> - 解密操作会导致计数器溢出。</li><li><strong>NV_ERR_INVALID_ARGUMENT</strong> - 数据大小为 0 字节。</li><li><strong>NV_ERR_INVALID_DATA</strong> - 身份验证标签验证失败。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-c603e4b4" role="button" aria-expanded="false" aria-controls="collapse-c603e4b4">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Sign 为安全工作启动生成身份验证标签      </div>      <div class="fold-collapse collapse" id="collapse-c603e4b4">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslSign</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                NvU32 bufferSize,</span><br><span class="hljs-params">                                NvU8 <span class="hljs-type">const</span> *inputBuffer,</span><br><span class="hljs-params">                                NvU8 *authTagBuffer)</span>;<br></code></pre></td></tr></table></figure><p>为安全工作启动生成身份验证标签。身份验证和输入缓冲区不得重叠。如果重叠，则调用此函数会产生未定义的行为。</p><ul><li><p>参数：</p><ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>bufferSize[IN]</strong> - 输入缓冲区的大小（以字节为单位）。值的范围可以从 1 字节到 (2^32) - 1 字节。</li><li><strong>inputBuffer[IN]</strong> - 明文输入缓冲区的地址。</li><li><strong>authTagBuffer[OUT]</strong> - 身份验证标签缓冲区的地址。其大小为 UVM_CSL_SIGN_AUTH_TAG_SIZE_BYTES。</li></ul></li><li><p>错误代码：</p><ul><li><strong>NV_ERR_INSUFFICIENT_RESOURCES</strong> - 签名操作会导致计数器溢出。</li><li><strong>NV_ERR_INVALID_ARGUMENT</strong> - 数据大小为 0 字节。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-f2b99e34" role="button" aria-expanded="false" aria-controls="collapse-f2b99e34">        <div class="fold-arrow">▶</div>NV UVM Interface Csl Query Message Pool 返回在消息计数器溢出之前可以加密的消息数量      </div>      <div class="fold-collapse collapse" id="collapse-f2b99e34">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">nvUvmInterfaceCslQueryMessagePool</span><span class="hljs-params">(UvmCslContext *uvmCslContext,</span><br><span class="hljs-params">                                            UvmCslDirection direction,</span><br><span class="hljs-params">                                            NvU64 *messageNum)</span>;<br></code></pre></td></tr></table></figure><p>返回在消息计数器溢出之前可以加密的消息数量。</p><ul><li>参数：<ul><li><strong>uvmCslContext[IN&#x2F;OUT]</strong> - CSL 上下文。</li><li><strong>direction[IN]</strong> - <strong>UVM_CSL_DIR_CPU_TO_GPU</strong> 或 <strong>UVM_CSL_DIR_GPU_TO_CPU</strong></li><li><strong>messageNum[OUT]</strong> - 溢出前剩余的消息数量。</li></ul></li><li>错误代码：<ul><li><strong>NV_ERR_INVALID_ARGUMENT</strong> - direction 参数的值非法。</li></ul></li></ul>        </div>      </div>    </div><h1 id="uvm-conf-computing-h"><a href="#uvm-conf-computing-h" class="headerlink" title="uvm_conf_computing.h"></a>uvm_conf_computing.h</h1>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-a8163d0f" role="button" aria-expanded="false" aria-controls="collapse-a8163d0f">        <div class="fold-arrow">▶</div>宏定义等      </div>      <div class="fold-collapse collapse" id="collapse-a8163d0f">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-meta">#<span class="hljs-keyword">define</span> UVM_CONF_COMPUTING_AUTH_TAG_SIZE (UVM_CSL_CRYPT_AUTH_TAG_SIZE_BYTES)</span><br><br><span class="hljs-comment">// 硬件要求认证标签指针必须 16 字节对齐。</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UVM_CONF_COMPUTING_AUTH_TAG_ALIGNMENT 16</span><br><br><span class="hljs-comment">// HW 要求 IV 指针为 16 字节对齐。使用 sizeof(UvmCslIv) 来引用 IV 大小。</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UVM_CONF_COMPUTING_IV_ALIGNMENT 16</span><br><br><span class="hljs-comment">// SEC2 解密操作缓冲区需要 16 字节对齐。如果缓冲区位于单个 32B 段中，则 CE 加密/解密可以</span><br><span class="hljs-comment">// 不对齐。否则，它们需要 32B 对齐。</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UVM_CONF_COMPUTING_BUF_ALIGNMENT 32</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UVM_CONF_COMPUTING_DMA_BUFFER_SIZE UVM_VA_BLOCK_SIZE</span><br><br><span class="hljs-comment">// SEC2 最多支持 64 个方法流条目进行签名。每个条目由方法地址和方法数据组成，因此最大缓冲区</span><br><span class="hljs-comment">// 大小为：UVM_METHOD_SIZE * 2 * 64 = 512。但是 UVM 不会使用这么多条目，在最坏的情况下，</span><br><span class="hljs-comment">// 我们会推送一个 semaphore_releases 或一个解密。SEC2 semaphore_release 使用 6 个</span><br><span class="hljs-comment">// 1U 条目，而 SEC2 解密使用 10 个 1U 条目。对于 10 个条目，UVM_METHOD_SIZE * 2 * 10 = 80。</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> UVM_CONF_COMPUTING_SIGN_BUF_MAX_SIZE 80</span><br><br><span class="hljs-comment">// 所有 GPU 都从其父 GPU 获得机密计算状态。根据当前政策，所有父 GPU 都具有相同的机密计算状态。</span><br>NV_STATUS <span class="hljs-title function_">uvm_conf_computing_init_parent_gpu</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_parent_gpu_t</span> *parent)</span>;<br><span class="hljs-type">bool</span> <span class="hljs-title function_">uvm_conf_computing_mode_enabled_parent</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_parent_gpu_t</span> *parent)</span>;<br><span class="hljs-type">bool</span> <span class="hljs-title function_">uvm_conf_computing_mode_enabled</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_gpu_t</span> *gpu)</span>;<br><span class="hljs-type">bool</span> <span class="hljs-title function_">uvm_conf_computing_mode_is_hcc</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_gpu_t</span> *gpu)</span>;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-9a1c5b83" role="button" aria-expanded="false" aria-controls="collapse-9a1c5b83">        <div class="fold-arrow">▶</div>uvm_conf_computing_dma_buffer_pool_t      </div>      <div class="fold-collapse collapse" id="collapse-9a1c5b83">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-comment">// 空闲 DMA 缓冲区列表（uvm_conf_computing_dma_buffer_t）。空闲的 DMA 缓冲区可以随</span><br>    <span class="hljs-comment">// 时获取，但其中的跟踪器可能仍有待处理的工作。</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">list_head</span> <span class="hljs-title">free_dma_buffers</span>;</span><br><br>    <span class="hljs-comment">// 用于在池满时增大 pool</span><br>    <span class="hljs-type">size_t</span> num_dma_buffers;<br><br>    <span class="hljs-comment">// 保护 dma_buffer_pool 的锁</span><br>    <span class="hljs-type">uvm_mutex_t</span> lock;<br>&#125; <span class="hljs-type">uvm_conf_computing_dma_buffer_pool_t</span>;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-d02d7b34" role="button" aria-expanded="false" aria-controls="collapse-d02d7b34">        <div class="fold-arrow">▶</div>uvm_conf_computing_dma_buffer_t      </div>      <div class="fold-collapse collapse" id="collapse-d02d7b34">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-comment">// 支持 DMA 分配</span><br>    <span class="hljs-type">uvm_mem_t</span> *alloc;<br><br>    <span class="hljs-comment">// 由池管理代码内部使用，以跟踪空闲缓冲区的状态。</span><br>    <span class="hljs-type">uvm_tracker_t</span> tracker;<br><br>    <span class="hljs-comment">// 当 DMA 缓冲区用作 GPU 加密的目标时，SEC2 会在此处写入身份验证标签。稍后，当缓冲区</span><br>    <span class="hljs-comment">// 在 CPU 上解密时，身份验证标签将再次用于（读取）CSL 以验证真实性。分配缓冲区中每个</span><br>    <span class="hljs-comment">// PAGE_SIZE 页的分配足够大，可以容纳一个身份验证标签。</span><br>    <span class="hljs-type">uvm_mem_t</span> *auth_tag;<br><br>    <span class="hljs-comment">// CSL 支持无序解密，解密 IV 的使用方式与身份验证标签类似。分配缓冲区中每个 PAGE_SIZE</span><br>    <span class="hljs-comment">// 页的分配足够大，可以容纳一个 IV。解密 IV 和身份验证标签之间的粒度必须匹配。</span><br>    UvmCslIv decrypt_iv[(UVM_CONF_COMPUTING_DMA_BUFFER_SIZE / PAGE_SIZE)];<br><br>    <span class="hljs-comment">// 后备分配中的加密页面的 mask</span><br>    <span class="hljs-type">uvm_page_mask_t</span> encrypted_page_mask;<br><br>    <span class="hljs-comment">// 参见 uvm_conf_computing_dma_pool 列表</span><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">list_head</span> <span class="hljs-title">node</span>;</span><br>&#125; <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span>;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-39f682c6" role="button" aria-expanded="false" aria-controls="collapse-39f682c6">        <div class="fold-arrow">▶</div>uvm_conf_computing_dma_buffer_alloc 从给定的 DMA 分配池中检索 DMA 缓冲区      </div>      <div class="fold-collapse collapse" id="collapse-39f682c6">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">uvm_conf_computing_dma_buffer_alloc</span><span class="hljs-params">(<span class="hljs-type">uvm_conf_computing_dma_buffer_pool_t</span> *dma_buffer_pool,</span><br><span class="hljs-params">                                              <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> **out_dma_buffer,</span><br><span class="hljs-params">                                              <span class="hljs-type">uvm_tracker_t</span> *out_tracker)</span>;<br></code></pre></td></tr></table></figure><p>从给定的 DMA 分配池中检索 DMA 缓冲区。</p><ul><li><strong>NV_OK</strong> 阶段缓冲区已成功检索</li><li><strong>NV_ERR_NO_MEMORY</strong> 没有可供抓取的空闲 DMA 缓冲区，扩展内存池以获取新缓冲区失败。</li></ul><p><strong>out_dma_buffer</strong> 仅在返回 NV_OK 时才有效。调用者负责在完成此缓冲区上的操作后调用 <strong>uvm_conf_computing_dma_buffer_free</strong>。当 <strong>out_tracker</strong> 传递给函数时，缓冲区的依赖项将添加到跟踪器。调用者保证所有待处理的跟踪器条目都来自与池所有者相同的 GPU。在能够使用 DMA 缓冲区之前，调用者负责获取或等待 <strong>out_tracker</strong>。如果 <strong>out_tracker</strong> 为 NULL，则等待发生在分配本身中。</p><p><strong>成功后，encrypted_pa​​ge_mask</strong> 将作为分配的一部分被清除。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-b9950d2b" role="button" aria-expanded="false" aria-controls="collapse-b9950d2b">        <div class="fold-arrow">▶</div>uvm_conf_computing_dma_buffer_free 将 DMA 缓冲区释放到 DMA 分配池      </div>      <div class="fold-collapse collapse" id="collapse-b9950d2b">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_conf_computing_dma_buffer_free</span><span class="hljs-params">(<span class="hljs-type">uvm_conf_computing_dma_buffer_pool_t</span> *dma_buffer_pool,</span><br><span class="hljs-params">                                        <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> *dma_buffer,</span><br><span class="hljs-params">                                        <span class="hljs-type">uvm_tracker_t</span> *tracker)</span>;<br></code></pre></td></tr></table></figure><p>将 DMA 缓冲区释放到 DMA 分配池。在 GPU 取消初始化之前，必须释放所有 DMA 缓冲区。跟踪器是可选的，NULL 跟踪器表示尚未为缓冲区推送任何新操作。非 NULL 跟踪器表示调用者推送的缓冲区上任何其他待处理操作，这些操作需要在释放或重新使用缓冲区之前进行同步。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-02d317b4" role="button" aria-expanded="false" aria-controls="collapse-02d317b4">        <div class="fold-arrow">▶</div>uvm_conf_computing_dma_buffer_pool_sync 同步 GPU 的 DMA 池中的所有条目中的跟踪器      </div>      <div class="fold-collapse collapse" id="collapse-02d317b4">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_conf_computing_dma_buffer_pool_sync</span><span class="hljs-params">(<span class="hljs-type">uvm_conf_computing_dma_buffer_pool_t</span> *dma_buffer_pool)</span>;<br></code></pre></td></tr></table></figure><p>同步 GPU 的 DMA 池中的所有条目中的跟踪器</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-9efd27d7" role="button" aria-expanded="false" aria-controls="collapse-9efd27d7">        <div class="fold-arrow">▶</div>uvm_conf_computing_gpu_init 初始化和取消初始化给定 GPU 的机密计算数据结构      </div>      <div class="fold-collapse collapse" id="collapse-9efd27d7">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">uvm_conf_computing_gpu_init</span><span class="hljs-params">(<span class="hljs-type">uvm_gpu_t</span> *gpu)</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_conf_computing_gpu_deinit</span><span class="hljs-params">(<span class="hljs-type">uvm_gpu_t</span> *gpu)</span>;<br></code></pre></td></tr></table></figure><p>初始化和取消初始化给定 GPU 的机密计算数据结构。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-50e381c7" role="button" aria-expanded="false" aria-controls="collapse-50e381c7">        <div class="fold-arrow">▶</div>uvm_conf_computing_log_gpu_encryption 记录来自 GPU 的加密信息并返回 IV      </div>      <div class="fold-collapse collapse" id="collapse-50e381c7">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_conf_computing_log_gpu_encryption</span><span class="hljs-params">(<span class="hljs-type">uvm_channel_t</span> *channel, UvmCslIv *iv)</span>;<br></code></pre></td></tr></table></figure><p>记录来自 GPU 的加密信息并返回 IV。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-987976c4" role="button" aria-expanded="false" aria-controls="collapse-987976c4">        <div class="fold-arrow">▶</div>uvm_conf_computing_acquire_encryption_iv 获取下一个 CPU 加密 IV 并返回      </div>      <div class="fold-collapse collapse" id="collapse-987976c4">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_conf_computing_acquire_encryption_iv</span><span class="hljs-params">(<span class="hljs-type">uvm_channel_t</span> *channel, UvmCslIv *iv)</span>;<br></code></pre></td></tr></table></figure><p>获取下一个 CPU 加密 IV 并返回。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-76e09153" role="button" aria-expanded="false" aria-controls="collapse-76e09153">        <div class="fold-arrow">▶</div>uvm_conf_computing_cpu_encrypt CPU 端加密辅助程序      </div>      <div class="fold-collapse collapse" id="collapse-76e09153">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs c"><br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_conf_computing_cpu_encrypt</span><span class="hljs-params">(<span class="hljs-type">uvm_channel_t</span> *channel,</span><br><span class="hljs-params">                                    <span class="hljs-type">void</span> *dst_cipher,</span><br><span class="hljs-params">                                    <span class="hljs-type">const</span> <span class="hljs-type">void</span> *src_plain,</span><br><span class="hljs-params">                                    UvmCslIv *encrypt_iv,</span><br><span class="hljs-params">                                    <span class="hljs-type">size_t</span> size,</span><br><span class="hljs-params">                                    <span class="hljs-type">void</span> *auth_tag_buffer)</span><br>&#123;<br>    NV_STATUS status;<br><br>    UVM_ASSERT(size);<br><br>    uvm_mutex_lock(&amp;channel-&gt;csl.ctx_lock);<br>    status = nvUvmInterfaceCslEncrypt(&amp;channel-&gt;csl.ctx,<br>                                      size,<br>                                      (NvU8 <span class="hljs-type">const</span> *) src_plain,<br>                                      encrypt_iv,<br>                                      (NvU8 *) dst_cipher,<br>                                      (NvU8 *) auth_tag_buffer);<br>    uvm_mutex_unlock(&amp;channel-&gt;csl.ctx_lock);<br><br>    <span class="hljs-comment">// nvUvmInterfaceCslEncrypt fails when a 64-bit encryption counter</span><br>    <span class="hljs-comment">// overflows. This is not supposed to happen on CC.</span><br>    UVM_ASSERT(status == NV_OK);<br>&#125;<br></code></pre></td></tr></table></figure><p>CPU 端加密辅助程序，具有显式 IV，可从 <strong>uvm_conf_computing_acquire_encryption_iv</strong> 获取。如果没有显式 IV，该函数将按顺序使用下一个 IV。加密 <strong>src_plain</strong> 中的数据并将密文写入 <strong>dst_cipher</strong>。<strong>src_plain</strong> 和 <strong>dst_cipher</strong> 不能重叠。此操作后，IV 无效，无法再次使用。</p>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-89f0fe48" role="button" aria-expanded="false" aria-controls="collapse-89f0fe48">        <div class="fold-arrow">▶</div>uvm_conf_computing_cpu_decrypt CPU 端解密辅助程序      </div>      <div class="fold-collapse collapse" id="collapse-89f0fe48">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs c">NV_STATUS <span class="hljs-title function_">uvm_conf_computing_cpu_decrypt</span><span class="hljs-params">(<span class="hljs-type">uvm_channel_t</span> *channel,</span><br><span class="hljs-params">                                         <span class="hljs-type">void</span> *dst_plain,</span><br><span class="hljs-params">                                         <span class="hljs-type">const</span> <span class="hljs-type">void</span> *src_cipher,</span><br><span class="hljs-params">                                         <span class="hljs-type">const</span> UvmCslIv *src_iv,</span><br><span class="hljs-params">                                         <span class="hljs-type">size_t</span> size,</span><br><span class="hljs-params">                                         <span class="hljs-type">const</span> <span class="hljs-type">void</span> *auth_tag_buffer)</span><br>&#123;<br>    NV_STATUS status;<br><br>    uvm_mutex_lock(&amp;channel-&gt;csl.ctx_lock);<br>    status = nvUvmInterfaceCslDecrypt(&amp;channel-&gt;csl.ctx,<br>                                      size,<br>                                      (<span class="hljs-type">const</span> NvU8 *) src_cipher,<br>                                      src_iv,<br>                                      (NvU8 *) dst_plain,<br>                                      (<span class="hljs-type">const</span> NvU8 *) auth_tag_buffer);<br>    uvm_mutex_unlock(&amp;channel-&gt;csl.ctx_lock);<br><br>    <span class="hljs-keyword">return</span> status;<br>&#125;<br><br></code></pre></td></tr></table></figure><p>CPU 端解密辅助程序。从 <strong>src_cipher</strong> 解密数据并将纯文本写入 <strong>dst_plain</strong>。<strong>src_cipher</strong> 和 <strong>dst_plain</strong> 不能重叠。从 <strong>uvm_conf_computing_log_gpu_encryption()</strong> 获得的 IV 需要传递给 <strong>src_iv</strong></p>        </div>      </div>    </div><h1 id="uvm-hal-h"><a href="#uvm-hal-h" class="headerlink" title="uvm_hal.h"></a>uvm_hal.h</h1>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-b829a153" role="button" aria-expanded="false" aria-controls="collapse-b829a153">        <div class="fold-arrow">▶</div>指针指向的函数      </div>      <div class="fold-collapse collapse" id="collapse-b829a153">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_maxwell_sec2_init_noop</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push)</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_hopper_sec2_init</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push)</span>;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_maxwell_ce_encrypt_unsupported</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                                            <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                                            <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                                            NvU32 size,</span><br><span class="hljs-params">                                            <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_maxwell_ce_decrypt_unsupported</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                                            <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                                            <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                                            NvU32 size,</span><br><span class="hljs-params">                                            <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_hopper_ce_encrypt</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                               NvU32 size,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_hopper_ce_decrypt</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                               NvU32 size,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span>;<br><br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_maxwell_sec2_decrypt_unsupported</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                                              NvU64 dst_va,</span><br><span class="hljs-params">                                              NvU64 src_va,</span><br><span class="hljs-params">                                              NvU32 size,</span><br><span class="hljs-params">                                              NvU64 auth_tag_va)</span>;<br><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_hopper_sec2_decrypt</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push, NvU64 dst_va, NvU64 src_va, NvU32 size, NvU64 auth_tag_va)</span>;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-832292e7" role="button" aria-expanded="false" aria-controls="collapse-832292e7">        <div class="fold-arrow">▶</div>函数指针 uvm_hal_ce_encrypt_t，将源缓冲区的内容加密到目标缓冲区中，直到指定的大小      </div>      <div class="fold-collapse collapse" id="collapse-832292e7">        <div class="fold-content">          <p>将源缓冲区的内容加密到目标缓冲区中，直到指定的大小。加密内容的认证标签（auth_tag）将写入auth_tag，以便稍后通过解密操作进行验证。目标地址和认证标签地址的寻址模式应匹配。如果寻址模式为物理模式，则地址范围也应匹配。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-title function_">void</span> <span class="hljs-params">(*<span class="hljs-type">uvm_hal_ce_encrypt_t</span>)</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                                     <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                                     <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                                     NvU32 size,</span><br><span class="hljs-params">                                     <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span>;<br></code></pre></td></tr></table></figure><p>copy engine 表使用了该函数指针：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 用于复制引擎函数的表。</span><br><span class="hljs-comment">// 每个条目通过 &#x27;class&#x27; 字段与一个复制引擎类关联。</span><br><span class="hljs-comment">// 通过设置 &#x27;parent_class&#x27; 字段，如果在模块加载时调用 uvm_hal_init_table() 时某些字段为空，</span><br><span class="hljs-comment">// 该类将继承父类的函数。父类必须出现在数组中子类之前。</span><br><span class="hljs-type">static</span> <span class="hljs-type">uvm_hal_class_ops_t</span> ce_table[] =<br>&#123;<br>    &#123;<br>        .id = MAXWELL_DMA_COPY_A,<br>        .u.ce_ops = &#123;<br>            <span class="hljs-comment">// ...</span><br>            .encrypt = uvm_hal_maxwell_ce_encrypt_unsupported,<br>            .decrypt = uvm_hal_maxwell_ce_decrypt_unsupported,<br>        &#125;<br>    &#125;,<br>    <span class="hljs-comment">// ...</span><br>    &#123;<br>        .id = HOPPER_DMA_COPY_A,<br>        .parent_id = AMPERE_DMA_COPY_B,<br>        .u.ce_ops = &#123;<br>            <span class="hljs-comment">// ...</span><br>            .memcopy_copy_type = uvm_hal_hopper_ce_memcopy_copy_type,<br>            <span class="hljs-comment">// ...</span><br>            .encrypt = uvm_hal_hopper_ce_encrypt,<br>            .decrypt = uvm_hal_hopper_ce_decrypt,<br>        &#125;,<br>    &#125;,<br>&#125;;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-comment">// id is either a hardware class or GPU architecture</span><br>    NvU32 id;<br>    NvU32 parent_id;<br>    <span class="hljs-class"><span class="hljs-keyword">union</span></span><br><span class="hljs-class">    &#123;</span><br>        <span class="hljs-comment">// host_ops: id is a hardware class</span><br>        <span class="hljs-type">uvm_host_hal_t</span> host_ops;<br><br>        <span class="hljs-comment">// ce_ops: id is a hardware class</span><br>        <span class="hljs-type">uvm_ce_hal_t</span> ce_ops;<br><br>        <span class="hljs-comment">// arch_ops: id is an architecture</span><br>        <span class="hljs-type">uvm_arch_hal_t</span> arch_ops;<br><br>        <span class="hljs-comment">// fault_buffer_ops: id is an architecture</span><br>        <span class="hljs-type">uvm_fault_buffer_hal_t</span> fault_buffer_ops;<br><br>        <span class="hljs-comment">// access_counter_buffer_ops: id is an architecture</span><br>        <span class="hljs-type">uvm_access_counter_buffer_hal_t</span> access_counter_buffer_ops;<br><br>        <span class="hljs-comment">// sec2_ops: id is an architecture</span><br>        <span class="hljs-type">uvm_sec2_hal_t</span> sec2_ops;<br>    &#125; u;<br>&#125; <span class="hljs-type">uvm_hal_class_ops_t</span>;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uvm_ce_hal_struct</span> <span class="hljs-title">uvm_ce_hal_t</span>;</span><br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uvm_ce_hal_struct</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-comment">// ...</span><br>    <span class="hljs-type">uvm_hal_ce_memcopy_type_t</span> memcopy_copy_type;<br>    <span class="hljs-comment">// ...</span><br>    <span class="hljs-type">uvm_hal_ce_encrypt_t</span> encrypt;<br>    <span class="hljs-type">uvm_hal_ce_decrypt_t</span> decrypt;<br>&#125;;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uvm_sec2_hal_struct</span> <span class="hljs-title">uvm_sec2_hal_t</span>;</span><br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uvm_sec2_hal_struct</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-type">uvm_hal_init_t</span> init;<br>    <span class="hljs-type">uvm_hal_sec2_decrypt_t</span> decrypt;<br>    <span class="hljs-type">uvm_hal_semaphore_release_t</span> semaphore_release;<br>    <span class="hljs-type">uvm_hal_semaphore_timestamp_t</span> semaphore_timestamp;<br>&#125;;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-64d2c9e3" role="button" aria-expanded="false" aria-controls="collapse-64d2c9e3">        <div class="fold-arrow">▶</div>uvm_hal_hopper_ce_encrypt 用于在指定的GPU上执行加密操作      </div>      <div class="fold-collapse collapse" id="collapse-64d2c9e3">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_hopper_ce_encrypt</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                               NvU32 size,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span><br></code></pre></td></tr></table></figure><p>用于在指定的GPU上执行加密操作。它将源地址的数据加密后存储到目标地址，并生成一个认证标签。</p><ul><li>参数<ul><li><strong>push</strong>：指向用于推送命令的结构体。</li><li><strong>dst</strong>：目标地址，解密后的数据将存储在此地址。</li><li><strong>src</strong>：源地址，包含需要加密的数据。</li><li><strong>size</strong>：加密数据的大小，必须大于0且为4字节的倍数。</li><li><strong>auth_tag</strong>：认证标签的地址，用于验证源数据的完整性。</li></ul></li><li>执行流程：<ul><li><strong>获取GPU和参数验证</strong><ul><li><strong>获取GPU</strong>：从 <code>push</code> 结构体中获取GPU指针。</li><li><strong>参数验证</strong>：<ul><li>确保GPU处于特定计算模式（例如HCC模式）。</li><li>确保 <code>push</code> 是虚拟的或通道是安全的。</li><li>确保认证标签地址是对齐的。</li><li>如果源地址不是虚拟地址，确保其光圈类型是 <code>UVM_APERTURE_VID</code>。</li></ul></li></ul></li><li><strong>目的地址和认证标签验证</strong><ul><li>确保目标地址和认证标签的地址模式一致（都是虚拟或都是物理地址）。</li><li>如果目标地址不是虚拟地址，确保其光圈类型和认证标签的光圈类型都是 <code>UVM_APERTURE_SYS</code>。</li></ul></li><li><strong>设置加密模式</strong>：通过 <code>NV_PUSH_1U</code> 设置安全复制模式为加密</li><li><strong>设置认证标签和IV地址</strong><ul><li>计算并设置认证标签的高32位和低32位地址。</li><li>计算初始化向量（IV）的地址。</li><li>计算并设置IV的高32位和低32位地址。</li><li>使用 <code>NV_PUSH_4U</code> 将这些地址推送到硬件寄存器。</li></ul></li><li><strong>执行加密操作</strong>：调用 <code>encrypt_or_decrypt</code> 函数执行实际的加密操作，将源地址的数据加密后存储到目标地址</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-b9ab48e6" role="button" aria-expanded="false" aria-controls="collapse-b9ab48e6">        <div class="fold-arrow">▶</div>函数指针 uvm_hal_ce_decrypt_t，将源缓冲区的内容解密到目标缓冲区中，直到指定的大小      </div>      <div class="fold-collapse collapse" id="collapse-b9ab48e6">        <div class="fold-content">          <p>将源缓冲区的内容解密到目标缓冲区中，直到指定的大小。该方法还通过计算加密缓冲区的认证标签并将其与作为参数提供的标签进行比较，以验证其完整性。源地址和认证标签地址的寻址模式应匹配。如果寻址模式为物理模式，则地址范围也应匹配。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-title function_">void</span> <span class="hljs-params">(*<span class="hljs-type">uvm_hal_ce_decrypt_t</span>)</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                                     <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                                     <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                                     NvU32 size,</span><br><span class="hljs-params">                                     <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span>;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-7f63652d" role="button" aria-expanded="false" aria-controls="collapse-7f63652d">        <div class="fold-arrow">▶</div>uvm_hal_hopper_ce_decrypt 用于在指定的GPU上执行解密操作      </div>      <div class="fold-collapse collapse" id="collapse-7f63652d">        <div class="fold-content">          <p>用于在指定的GPU上执行解密操作。它将源地址的数据解密后存储到目标地址，并验证源数据的完整性。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">void</span> <span class="hljs-title function_">uvm_hal_hopper_ce_decrypt</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> dst,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> src,</span><br><span class="hljs-params">                               NvU32 size,</span><br><span class="hljs-params">                               <span class="hljs-type">uvm_gpu_address_t</span> auth_tag)</span><br></code></pre></td></tr></table></figure><ul><li>参数<ul><li><strong>push</strong>：指向用于推送命令的结构体。</li><li><strong>dst</strong>：目标地址，解密后的数据将存储在此地址。</li><li><strong>src</strong>：源地址，包含需要解密的数据。</li><li><strong>size</strong>：解密数据的大小，必须大于0且为4字节的倍数。</li><li><strong>auth_tag</strong>：认证标签的地址，用于验证源数据的完整性。</li></ul></li><li>执行流程：<ul><li>获取GPU和参数验证<ul><li><strong>获取GPU</strong>：从 <code>push</code> 结构体中获取GPU指针。</li><li><strong>参数验证</strong>：<ul><li>确保GPU处于特定计算模式（例如HCC模式）。</li><li>确保 <code>push</code> 没有通道或者通道是安全的。</li><li>确保认证标签地址是对齐的。</li></ul></li></ul></li><li>源地址和认证标签验证<ul><li>确保源地址和认证标签的地址模式一致（都是虚拟或都是物理地址）。</li><li>如果源地址不是虚拟地址，确保其光圈类型和认证标签的光圈类型都是 <code>UVM_APERTURE_SYS</code>。</li></ul></li><li>目的地址验证：如果目标地址不是虚拟地址，确保其光圈类型是 <code>UVM_APERTURE_VID</code>。</li><li>设置解密模式：通过 <code>NV_PUSH_1U</code> 设置安全复制模式为解密。</li><li>设置认证标签地址<ul><li>计算并设置认证标签的高32位和低32位地址。</li><li>使用 <code>NV_PUSH_2U</code> 将这些地址推送到硬件寄存器。</li></ul></li><li>执行解密操作：调用 <code>encrypt_or_decrypt</code> 函数执行实际的解密操作，将源地址的数据解密后存储到目标地址。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-50e550f4" role="button" aria-expanded="false" aria-controls="collapse-50e550f4">        <div class="fold-arrow">▶</div>函数指针 uvm_hal_sec2_decrypt_t      </div>      <div class="fold-collapse collapse" id="collapse-50e550f4">        <div class="fold-content">          <p>源地址和目标地址必须是16字节对齐的。注意，最佳性能是在256字节对齐时实现的。解密大小必须大于0，并且是4字节的倍数。认证标签地址也必须是16字节对齐的。认证标签缓冲区大小在uvm_conf_computing.h中定义为UVM_CONF_COMPUTING_AUTH_TAG_SIZE字节。将src缓冲区解密到给定大小的dst缓冲区中。该方法还通过计算src缓冲区的认证标签并与提供的标签进行比较来验证其完整性。注意：SEC2不支持加密。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-keyword">typedef</span> <span class="hljs-title function_">void</span> <span class="hljs-params">(*<span class="hljs-type">uvm_hal_sec2_decrypt_t</span>)</span><span class="hljs-params">(<span class="hljs-type">uvm_push_t</span> *push, NvU64 dst_va, NvU64 src_va, NvU32 size, NvU64 auth_tag_va)</span>;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h1 id="nvrm-registry-h"><a href="#nvrm-registry-h" class="headerlink" title="nvrm_registry.h"></a>nvrm_registry.h</h1>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-e033605d" role="button" aria-expanded="false" aria-controls="collapse-e033605d">        <div class="fold-arrow">▶</div>宏定义等      </div>      <div class="fold-collapse collapse" id="collapse-e033605d">        <div class="fold-content">          <figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 添加条件以从 Orin 构建中排除这些宏，因为 CONFIDENTIAL_COMPUTE 是一个保护字。当从 Orin 构建中修剪 nvRmReg.h 文件时，可以删除 #if。</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 启用禁用机密计算并控制其各种操作模式</span><br><span class="hljs-comment">// 0 - 功能禁用</span><br><span class="hljs-comment">// 1 - 功能启用</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE                              <span class="hljs-string">&quot;RmConfidentialCompute&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_ENABLED                      0:0</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_ENABLED_NO                   0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_ENABLED_YES                  0x00000001</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_DEV_MODE_ENABLED             1:1</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_DEV_MODE_ENABLED_NO          0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_DEV_MODE_ENABLED_YES         0x00000001</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_GPUS_READY_CHECK             2:2</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_GPUS_READY_CHECK_DISABLED    0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONFIDENTIAL_COMPUTE_GPUS_READY_CHECK_ENABLED     0x00000001</span><br><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONF_COMPUTE_EARLY_INIT                            <span class="hljs-string">&quot;RmConfComputeEarlyInit&quot;</span></span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONF_COMPUTE_EARLY_INIT_DISABLED                   0x00000000</span><br><span class="hljs-meta">#<span class="hljs-keyword">define</span> NV_REG_STR_RM_CONF_COMPUTE_EARLY_INIT_ENABLED                    0x00000001</span><br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h1 id="uvm-va-block-c"><a href="#uvm-va-block-c" class="headerlink" title="uvm_va_block.c"></a>uvm_va_block.c</h1>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-30f54d6f" role="button" aria-expanded="false" aria-controls="collapse-30f54d6f">        <div class="fold-arrow">▶</div>encrypted_memcopy_gpu_to_cpu 在 GPU 和 CPU 之间进行同步加密复制的操作      </div>      <div class="fold-collapse collapse" id="collapse-30f54d6f">        <div class="fold-content">          <p>实现了在 GPU 和 CPU 之间进行同步加密复制的操作。它通过 GPU 端的加密（<strong>使用Copy Engine</strong>）和 CPU 端的解密，将 GPU 上的数据传输到 CPU，最终在目标 CPU 缓冲区中得到解密后的明文数据。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 启动 GPU 和 CPU 之间的同步加密复制操作。</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 该复制操作包括 GPU 端加密（依赖于Copy Engine）和 CPU 端解密步骤，</span><br><span class="hljs-comment">// 使得目标 CPU 缓冲区（由 dst_plain 指向）将包含未加密的（明文）内容。</span><br><span class="hljs-comment">// 目标缓冲区可以在受保护或未受保护的系统内存中，而源缓冲区必须在受保护的显存中。</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 允许的最大复制大小是 UVM_CONF_COMPUTING_DMA_BUFFER_SIZE。</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 如果输入追踪器不为 NULL，则由负责加密复制的推送命令内部获取。</span><br>__attribute__ ((format(<span class="hljs-built_in">printf</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>)))<br><span class="hljs-type">static</span> NV_STATUS <span class="hljs-title function_">encrypted_memcopy_gpu_to_cpu</span><span class="hljs-params">(<span class="hljs-type">uvm_gpu_t</span> *gpu,</span><br><span class="hljs-params">                                              <span class="hljs-type">void</span> *dst_plain,</span><br><span class="hljs-params">                                              <span class="hljs-type">uvm_gpu_address_t</span> src_gpu_address,</span><br><span class="hljs-params">                                              <span class="hljs-type">size_t</span> size,</span><br><span class="hljs-params">                                              <span class="hljs-type">uvm_tracker_t</span> *tracker,</span><br><span class="hljs-params">                                              <span class="hljs-type">const</span> <span class="hljs-type">char</span> *format,</span><br><span class="hljs-params">                                              ...)</span><br>&#123;<br>    NV_STATUS status;<br>    UvmCslIv decrypt_iv;<br>    <span class="hljs-type">uvm_push_t</span> push;<br>    <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> *dma_buffer;<br>    <span class="hljs-type">uvm_gpu_address_t</span> dst_gpu_address, auth_tag_gpu_address;<br>    <span class="hljs-type">void</span> *src_cipher, *auth_tag;<br>    va_list args;<br><br>    UVM_ASSERT(uvm_conf_computing_mode_enabled(gpu));<br>    UVM_ASSERT(size &lt;= UVM_CONF_COMPUTING_DMA_BUFFER_SIZE);<br><br>    status = uvm_conf_computing_dma_buffer_alloc(&amp;gpu-&gt;conf_computing.dma_buffer_pool, &amp;dma_buffer, <span class="hljs-literal">NULL</span>);<br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">return</span> status;<br><br>    va_start(args, format);<br>    status = uvm_push_begin_acquire(gpu-&gt;channel_manager, UVM_CHANNEL_TYPE_GPU_TO_CPU, tracker, &amp;push, format, args);<br>    va_end(args);<br><br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">goto</span> out;<br><br>    uvm_conf_computing_log_gpu_encryption(push.channel, &amp;decrypt_iv);<br><br>    dst_gpu_address = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;alloc, gpu);<br>    auth_tag_gpu_address = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;auth_tag, gpu);<br>    gpu-&gt;parent-&gt;ce_hal-&gt;encrypt(&amp;push, dst_gpu_address, src_gpu_address, size, auth_tag_gpu_address);<br><br>    status = uvm_push_end_and_wait(&amp;push);<br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">goto</span> out;<br><br>    src_cipher = uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;alloc);<br>    auth_tag = uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;auth_tag);<br>    status = uvm_conf_computing_cpu_decrypt(push.channel, dst_plain, src_cipher, &amp;decrypt_iv, size, auth_tag);<br><br> out:<br>    uvm_conf_computing_dma_buffer_free(&amp;gpu-&gt;conf_computing.dma_buffer_pool, dma_buffer, <span class="hljs-literal">NULL</span>);<br>    <span class="hljs-keyword">return</span> status;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>参数<ul><li><strong>gpu</strong>：指向 GPU 结构体的指针。</li><li><strong>dst_plain</strong>：目标 CPU 缓冲区的指针，用于存储解密后的明文数据。</li><li><strong>src_gpu_address</strong>：源 GPU 地址，包含需要加密的数据。</li><li><strong>size</strong>：需要复制的数据大小。</li><li><strong>tracker</strong>：用于跟踪操作的追踪器，可以为 NULL。</li><li><strong>format</strong>：格式化字符串，用于日志记录。</li><li><strong>...</strong>：可变参数列表，与格式化字符串对应。</li></ul></li><li>返回值<ul><li><strong>NV_STATUS</strong>：表示操作的状态，可能的值包括 <code>NV_OK</code>（成功）或其他错误代码。</li></ul></li><li>流程<ul><li>初始化变量和检查条件<ul><li><strong>初始化状态变量和加密相关变量</strong>。</li><li><strong>检查 GPU 是否启用了机密计算模式</strong>。</li><li><strong>确保要复制的数据大小不超过最大限制</strong> <code>UVM_CONF_COMPUTING_DMA_BUFFER_SIZE</code>。</li></ul></li><li>分配 DMA 缓冲区<ul><li><strong>从 GPU 的 DMA 缓冲池中分配一个 DMA 缓冲区</strong>。</li><li><strong>如果分配失败，返回错误状态</strong>。</li></ul></li><li>开始推送命令并记录日志<ul><li><strong>使用可变参数列表初始化推送命令</strong>。</li><li><strong>如果推送命令初始化失败，跳转到错误处理部分</strong>。</li><li><strong>记录 GPU 加密操作的日志</strong>。</li></ul></li><li>设置地址并执行加密<ul><li><strong>设置目标 GPU 地址和认证标签地址</strong>。</li><li><strong>使用复制引擎在 GPU 上执行加密操作</strong>。</li><li><strong>等待推送命令完成</strong>。</li><li><strong>如果等待失败，跳转到错误处理部分</strong>。</li></ul></li><li>获取加密数据并在 CPU 上解密<ul><li><strong>获取加密数据和认证标签的 CPU 地址</strong>。</li><li><strong>在 CPU 上执行解密操作</strong>。</li><li><strong>如果解密失败，跳转到错误处理部分</strong>。</li></ul></li><li>错误处理和释放资源<ul><li><strong>释放分配的 DMA 缓冲区</strong>。</li><li><strong>返回操作状态</strong>。</li></ul></li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-d64150a0" role="button" aria-expanded="false" aria-controls="collapse-d64150a0">        <div class="fold-arrow">▶</div>encrypted_memcopy_cpu_to_gpu 在 CPU 和 GPU 之间进行同步加密复制的操作      </div>      <div class="fold-collapse collapse" id="collapse-d64150a0">        <div class="fold-content">          <p>实现了在 CPU 和 GPU 之间进行同步加密复制的操作。它通过 CPU 端的加密和 GPU 端的解密，将 CPU 上的明文数据传输到 GPU，最终在目标 GPU 缓冲区中得到解密后的密文数据。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 启动 CPU 和 GPU 之间的同步加密复制操作。</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 源 CPU 缓冲区（由 src_plain 指向）包含未加密的明文内容；</span><br><span class="hljs-comment">// 该函数在内部执行 CPU 端加密步骤，然后启动 GPU 端 CE 解密。</span><br><span class="hljs-comment">// 源缓冲区可以在受保护或未受保护的系统内存中，而目标缓冲区必须在受保护的显存中。</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 允许的最大复制大小是 UVM_CONF_COMPUTING_DMA_BUFFER_SIZE。</span><br><span class="hljs-comment">//</span><br><span class="hljs-comment">// 如果输入追踪器不为 NULL，则由负责加密复制的推送命令内部获取。</span><br>__attribute__ ((format(<span class="hljs-built_in">printf</span>, <span class="hljs-number">6</span>, <span class="hljs-number">7</span>)))<br><span class="hljs-type">static</span> NV_STATUS <span class="hljs-title function_">encrypted_memcopy_cpu_to_gpu</span><span class="hljs-params">(<span class="hljs-type">uvm_gpu_t</span> *gpu,</span><br><span class="hljs-params">                                              <span class="hljs-type">uvm_gpu_address_t</span> dst_gpu_address,</span><br><span class="hljs-params">                                              <span class="hljs-type">void</span> *src_plain,</span><br><span class="hljs-params">                                              <span class="hljs-type">size_t</span> size,</span><br><span class="hljs-params">                                              <span class="hljs-type">uvm_tracker_t</span> *tracker,</span><br><span class="hljs-params">                                              <span class="hljs-type">const</span> <span class="hljs-type">char</span> *format,</span><br><span class="hljs-params">                                              ...)</span><br>&#123;<br>    NV_STATUS status;<br>    <span class="hljs-type">uvm_push_t</span> push;<br>    <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> *dma_buffer;<br>    <span class="hljs-type">uvm_gpu_address_t</span> src_gpu_address, auth_tag_gpu_address;<br>    <span class="hljs-type">void</span> *dst_cipher, *auth_tag;<br>    va_list args;<br><br>    <span class="hljs-comment">// 确认 GPU 启用了机密计算模式</span><br>    UVM_ASSERT(uvm_conf_computing_mode_enabled(gpu));<br>    <span class="hljs-comment">// 确认数据大小不超过最大限制</span><br>    UVM_ASSERT(size &lt;= UVM_CONF_COMPUTING_DMA_BUFFER_SIZE);<br><br>    <span class="hljs-comment">// 分配 DMA 缓冲区</span><br>    status = uvm_conf_computing_dma_buffer_alloc(&amp;gpu-&gt;conf_computing.dma_buffer_pool, &amp;dma_buffer, <span class="hljs-literal">NULL</span>);<br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">return</span> status;<br><br>    <span class="hljs-comment">// 初始化推送命令</span><br>    va_start(args, format);<br>    status = uvm_push_begin_acquire(gpu-&gt;channel_manager, UVM_CHANNEL_TYPE_CPU_TO_GPU, tracker, &amp;push, format, args);<br>    va_end(args);<br><br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">goto</span> out;<br><br>    <span class="hljs-comment">// 获取加密数据和认证标签的 CPU 地址</span><br>    dst_cipher = uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;alloc);<br>    auth_tag = uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;auth_tag);<br>    <span class="hljs-comment">// 在 CPU 上执行加密操作</span><br>    uvm_conf_computing_cpu_encrypt(push.channel, dst_cipher, src_plain, <span class="hljs-literal">NULL</span>, size, auth_tag);<br><br>    <span class="hljs-comment">// 设置源 GPU 地址和认证标签地址</span><br>    src_gpu_address = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;alloc, gpu);<br>    auth_tag_gpu_address = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;auth_tag, gpu);<br>    <span class="hljs-comment">// 在 GPU 上执行解密操作</span><br>    gpu-&gt;parent-&gt;ce_hal-&gt;decrypt(&amp;push, dst_gpu_address, src_gpu_address, size, auth_tag_gpu_address);<br><br>    <span class="hljs-comment">// 等待推送命令完成</span><br>    status = uvm_push_end_and_wait(&amp;push);<br><br>out:<br>    <span class="hljs-comment">// 释放 DMA 缓冲区</span><br>    uvm_conf_computing_dma_buffer_free(&amp;gpu-&gt;conf_computing.dma_buffer_pool, dma_buffer, <span class="hljs-literal">NULL</span>);<br>    <span class="hljs-keyword">return</span> status;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>参数<ul><li><strong>gpu</strong>：指向 GPU 结构体的指针。</li><li><strong>dst_gpu_address</strong>：目标 GPU 地址，存储解密后的密文数据。</li><li><strong>src_plain</strong>：源 CPU 缓冲区的指针，包含未加密的明文数据。</li><li><strong>size</strong>：需要复制的数据大小。</li><li><strong>tracker</strong>：用于跟踪操作的追踪器，可以为 NULL。</li><li><strong>format</strong>：格式化字符串，用于日志记录。</li><li><strong>...</strong>：可变参数列表，与格式化字符串对应。</li></ul></li><li>返回值<ul><li><strong>NV_STATUS</strong>：表示操作的状态，可能的值包括 <code>NV_OK</code>（成功）或其他错误代码。</li></ul></li><li>流程<ul><li>初始化变量和检查条件<ul><li><strong>初始化状态变量和加密相关变量</strong>。</li><li><strong>检查 GPU 是否启用了机密计算模式</strong>。</li><li><strong>确保要复制的数据大小不超过最大限制</strong> <code>UVM_CONF_COMPUTING_DMA_BUFFER_SIZE</code>。</li></ul></li><li>分配 DMA 缓冲区<ul><li><strong>从 GPU 的 DMA 缓冲池中分配一个 DMA 缓冲区</strong>。</li><li><strong>如果分配失败，返回错误状态</strong>。</li></ul></li><li>开始推送命令并记录日志<ul><li><strong>使用可变参数列表初始化推送命令</strong>。</li><li><strong>如果推送命令初始化失败，跳转到错误处理部分</strong>。</li></ul></li><li>CPU 端加密操作<ul><li><strong>获取加密数据和认证标签的 CPU 地址</strong>。</li><li><strong>在 CPU 上执行加密操作</strong>。</li></ul></li><li>设置地址并执行解密<ul><li><strong>设置源 GPU 地址和认证标签地址</strong>。</li><li><strong>使用复制引擎在 GPU 上执行解密操作</strong>。</li><li><strong>等待推送命令完成</strong>。</li></ul></li><li>错误处理和释放资源<ul><li><strong>释放分配的 DMA 缓冲区</strong>。</li><li><strong>返回操作状态</strong>。</li></ul></li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-0fbfa9de" role="button" aria-expanded="false" aria-controls="collapse-0fbfa9de">        <div class="fold-arrow">▶</div>uvm_conf_computing_mode_enabled 查询 HCC 状态      </div>      <div class="fold-collapse collapse" id="collapse-0fbfa9de">        <div class="fold-content">          <p>查询 HCC 状态。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">bool</span> <span class="hljs-title function_">uvm_conf_computing_mode_enabled_parent</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_parent_gpu_t</span> *parent)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> uvm_conf_computing_get_mode(parent) != UVM_GPU_CONF_COMPUTE_MODE_NONE;<br>&#125;<br><br><span class="hljs-type">bool</span> <span class="hljs-title function_">uvm_conf_computing_mode_enabled</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_gpu_t</span> *gpu)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> uvm_conf_computing_mode_enabled_parent(gpu-&gt;parent);<br>&#125;<br><br><span class="hljs-type">bool</span> <span class="hljs-title function_">uvm_conf_computing_mode_is_hcc</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_gpu_t</span> *gpu)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> uvm_conf_computing_get_mode(gpu-&gt;parent) == UVM_GPU_CONF_COMPUTE_MODE_HCC;<br>&#125;<br><br><span class="hljs-type">static</span> UvmGpuConfComputeMode <span class="hljs-title function_">uvm_conf_computing_get_mode</span><span class="hljs-params">(<span class="hljs-type">const</span> <span class="hljs-type">uvm_parent_gpu_t</span> *parent)</span><br>&#123;<br>    <span class="hljs-keyword">return</span> parent-&gt;rm_info.gpuConfComputeCaps.mode;<br>&#125;WS<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">enum</span></span><br><span class="hljs-class">&#123;</span><br>    UVM_GPU_CONF_COMPUTE_MODE_NONE,<br>    UVM_GPU_CONF_COMPUTE_MODE_APM,<br>    UVM_GPU_CONF_COMPUTE_MODE_HCC,<br>    UVM_GPU_CONF_COMPUTE_MODE_COUNT<br>&#125; UvmGpuConfComputeMode;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">UvmGpuInfo_tag</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-comment">// ...</span><br><br>    <span class="hljs-comment">// Confidential Compute capabilities of this GPU</span><br>    UvmGpuConfComputeCaps gpuConfComputeCaps;<br><br>    <span class="hljs-comment">// ...</span><br>&#125; UvmGpuInfo;<br><br>nvGpuOpsGetGpuInfo()<br>--&gt; status = nvGpuOpsQueryGpuConfidentialComputeCaps(clientHandle, &amp;pGpuInfo-&gt;gpuConfComputeCaps);<br><br><span class="hljs-type">static</span> NV_STATUS<br><span class="hljs-title function_">nvGpuOpsQueryGpuConfidentialComputeCaps</span><span class="hljs-params">(NvHandle hClient,</span><br><span class="hljs-params">                                        UvmGpuConfComputeCaps *pGpuConfComputeCaps)</span><br>&#123;<br>    NV_CONFIDENTIAL_COMPUTE_ALLOC_PARAMS confComputeAllocParams = &#123;<span class="hljs-number">0</span>&#125;;<br>    NV_CONF_COMPUTE_CTRL_CMD_SYSTEM_GET_CAPABILITIES_PARAMS confComputeParams = &#123;<span class="hljs-number">0</span>&#125;;<br>    RM_API *pRmApi = rmapiGetInterface(RMAPI_EXTERNAL_KERNEL);<br>    NvHandle hConfCompute = <span class="hljs-number">0</span>;<br>    NV_STATUS status = NV_OK;<br><br>    <span class="hljs-comment">// ...</span><br><br>    <span class="hljs-keyword">if</span> (confComputeParams.ccFeature == NV_CONF_COMPUTE_SYSTEM_FEATURE_APM_ENABLED)<br>    &#123;<br>        pGpuConfComputeCaps-&gt;mode = UVM_GPU_CONF_COMPUTE_MODE_APM;<br>    &#125;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (confComputeParams.ccFeature == NV_CONF_COMPUTE_SYSTEM_FEATURE_HCC_ENABLED)<br>    &#123;<br>        pGpuConfComputeCaps-&gt;mode = UVM_GPU_CONF_COMPUTE_MODE_HCC;<br>    &#125;<br><br>cleanup:<br>    pRmApi-&gt;Free(pRmApi, hClient, hConfCompute);<br>    <span class="hljs-keyword">return</span> status;<br>&#125;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-87d70493" role="button" aria-expanded="false" aria-controls="collapse-87d70493">        <div class="fold-arrow">▶</div>conf_computing_dma_buffer_pool_init      </div>      <div class="fold-collapse collapse" id="collapse-87d70493">        <div class="fold-content">          <p>分配并映射新的 DMA 阶段缓冲区到 CPU 和 GPU（VA）</p><p>主体调用了 <code>dma_buffer_create()</code>：</p><p>用于分配并映射新的DMA缓冲区到CPU和GPU的虚拟地址空间。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> NV_STATUS <span class="hljs-title function_">dma_buffer_create</span><span class="hljs-params">(<span class="hljs-type">uvm_conf_computing_dma_buffer_pool_t</span> *dma_buffer_pool,</span><br><span class="hljs-params">                                   <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> **dma_buffer_out)</span><br></code></pre></td></tr></table></figure><ul><li><strong>参数</strong>：<ul><li><code>dma_buffer_pool</code>：指向DMA缓冲区池的指针，用于管理DMA缓冲区的分配。</li><li><code>dma_buffer_out</code>：指向指针的指针，用于输出分配的DMA缓冲区。</li></ul></li><li><strong>返回值</strong>：<ul><li><code>NV_STATUS</code>：表示操作的状态，可以是成功（<code>NV_OK</code>）或失败（如<code>NV_ERR_NO_MEMORY</code>）。</li></ul></li><li>流程<ul><li>变量定义和初始化</li><li>分配并初始化DMA缓冲区结构</li><li>获取DMA缓冲区所有者并初始化相关结构</li><li>分配和映射DMA缓冲区到CPU内核空间</li><li>将分配的内存映射到GPU内核空间</li><li>分配和映射认证标签内存到CPU内核空间</li><li>将认证标签内存映射到GPU内核空间</li><li>成功分配并返回</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-15f185ba" role="button" aria-expanded="false" aria-controls="collapse-15f185ba">        <div class="fold-arrow">▶</div>dummy_iv_mem_init 为指定的GPU分配和映射用于存储初始化向量（IV）的内存      </div>      <div class="fold-collapse collapse" id="collapse-15f185ba">        <div class="fold-content">          <p>为指定的GPU分配和映射用于存储初始化向量（IV）的内存。如果GPU处于特定的计算模式（例如HCC模式），则执行这些操作。</p><ul><li>参数 <strong>gpu</strong>：指向表示GPU的结构体的指针。</li><li>返回值 <strong>NV_STATUS</strong>：表示操作的状态，可以是<code>NV_OK</code>（成功）或其他错误代码。</li><li>流程<ul><li>检查GPU计算模式：检查GPU是否处于特定的计算模式（例如HCC模式）。如果不处于该模式，则不需要进行任何初始化，直接返回成功状态<code>NV_OK</code>。</li><li>分配系统内存用于初始化向量（IV）<ul><li>调用 <code>uvm_mem_alloc_sysmem_dma</code> 函数分配系统内存，并将其映射为DMA内存。</li><li>分配的内存大小为 <code>sizeof(UvmCslIv)</code>，存储在 <code>gpu-&gt;conf_computing.iv_mem</code> 中。</li><li>如果分配失败，返回相应的错误状态 <code>status</code>。</li></ul></li><li>将分配的内存映射到GPU内核空间<ul><li>调用 <code>uvm_mem_map_gpu_kernel</code> 函数将分配的内存映射到GPU内核空间。</li><li>如果映射失败，跳转到错误处理部分 <code>error</code>。</li></ul></li><li>成功返回：如果所有操作都成功，返回 <code>NV_OK</code>，表示初始化成功。</li><li>错误处理部分<ul><li>如果在内存分配或映射过程中发生错误，跳转到 <code>error</code> 标签。</li><li>调用 <code>dummy_iv_mem_deinit</code> 函数进行清理，释放已经分配的资源。</li><li>返回错误状态 <code>status</code>。</li></ul></li></ul></li></ul><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-type">static</span> NV_STATUS <span class="hljs-title function_">dummy_iv_mem_init</span><span class="hljs-params">(<span class="hljs-type">uvm_gpu_t</span> *gpu)</span><br>&#123;<br>    NV_STATUS status;<br><br>    <span class="hljs-keyword">if</span> (!uvm_conf_computing_mode_is_hcc(gpu))<br>        <span class="hljs-keyword">return</span> NV_OK;<br><br>    status = uvm_mem_alloc_sysmem_dma(<span class="hljs-keyword">sizeof</span>(UvmCslIv), gpu, <span class="hljs-literal">NULL</span>, &amp;gpu-&gt;conf_computing.iv_mem);<br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">return</span> status;<br><br>    status = uvm_mem_map_gpu_kernel(gpu-&gt;conf_computing.iv_mem, gpu);<br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">goto</span> error;<br><br>    <span class="hljs-keyword">return</span> NV_OK;<br><br>error:<br>    dummy_iv_mem_deinit(gpu);<br>    <span class="hljs-keyword">return</span> status;<br>&#125;<br><br><span class="hljs-keyword">typedef</span> <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uvm_gpu_struct</span> <span class="hljs-title">uvm_gpu_t</span>;</span><br><br><span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">uvm_gpu_struct</span></span><br><span class="hljs-class">&#123;</span><br>    <span class="hljs-type">uvm_parent_gpu_t</span> *parent;<br>    <span class="hljs-comment">// ...</span><br><br>    <span class="hljs-class"><span class="hljs-keyword">struct</span></span><br><span class="hljs-class">    &#123;</span><br>        <span class="hljs-type">uvm_conf_computing_dma_buffer_pool_t</span> dma_buffer_pool;<br><br>        <span class="hljs-comment">// 在CE加密过程中用于存储IV内容的临时内存。这个内存位置只有在CE通道之后才可用，</span><br>        <span class="hljs-comment">// 因为我们使用它们来写入分配所需的PTE（页表项）。当需要物理地址来访问IV缓冲区时使用这个位置。</span><br>        <span class="hljs-comment">// 参考函数：uvm_hal_hopper_ce_encrypt()。</span><br>        <span class="hljs-type">uvm_mem_t</span> *iv_mem;<br><br>        <span class="hljs-comment">// 在CE加密过程中用于存储IV内容的临时内存。由于`iv_mem`的限制，并且需要在通道初始化时使用此类缓冲区，</span><br>        <span class="hljs-comment">// 我们使用RM分配。当需要虚拟地址来访问IV缓冲区时使用这个位置。</span><br>        <span class="hljs-comment">// 参考函数：uvm_hal_hopper_ce_encrypt()。</span><br>        <span class="hljs-type">uvm_rm_mem_t</span> *iv_rm_mem;<br>    &#125; conf_computing;<br><br>    <span class="hljs-comment">// ...</span><br>&#125;;<br></code></pre></td></tr></table></figure>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-aae03ce4" role="button" aria-expanded="false" aria-controls="collapse-aae03ce4">        <div class="fold-arrow">▶</div>conf_computing_block_copy_push_cpu_to_gpu CPU 端页面加密和 GPU 端解密操作      </div>      <div class="fold-collapse collapse" id="collapse-aae03ce4">        <div class="fold-content">          <p>间接调用了 <code>uvm_hal_hopper_ce_decrypt</code></p><p>实现了在启用机密计算功能时，CPU 端页面加密和 GPU 端解密操作。它使用推送命令（push）在 GPU 上执行这些操作，并且 GPU 操作会遵守调用者先前在推送命令中设置的内存屏障（membar）。以下是对这段代码的详细分析：</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 当启用机密计算功能时，该函数执行 CPU 端页面加密和 GPU 端解密到 CPR。</span><br><span class="hljs-comment">// GPU 操作遵守调用者在推送命令中先前设置的内存屏障。</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">conf_computing_block_copy_push_cpu_to_gpu</span><span class="hljs-params">(<span class="hljs-type">uvm_va_block_t</span> *block,</span><br><span class="hljs-params">                                                      <span class="hljs-type">block_copy_state_t</span> *copy_state,</span><br><span class="hljs-params">                                                      <span class="hljs-type">uvm_va_block_region_t</span> region,</span><br><span class="hljs-params">                                                      <span class="hljs-type">uvm_push_t</span> *push)</span><br>&#123;<br>    <span class="hljs-type">uvm_push_flag_t</span> membar_flag = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">uvm_gpu_t</span> *gpu = uvm_push_get_gpu(push);<br>    <span class="hljs-type">uvm_page_index_t</span> page_index = region.first;<br>    <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> *dma_buffer = copy_state-&gt;dma_buffer;<br>    <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">page</span> *<span class="hljs-title">src_page</span> =</span> uvm_cpu_chunk_get_cpu_page(block, page_index);<br>    <span class="hljs-type">uvm_gpu_address_t</span> staging_buffer = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;alloc, gpu);<br>    <span class="hljs-type">uvm_gpu_address_t</span> auth_tag_buffer = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;auth_tag, gpu);<br>    <span class="hljs-type">char</span> *cpu_auth_tag_buffer = (<span class="hljs-type">char</span> *)uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;auth_tag) +<br>                                        (page_index * UVM_CONF_COMPUTING_AUTH_TAG_SIZE);<br>    <span class="hljs-type">uvm_gpu_address_t</span> dst_address = block_copy_get_address(block, &amp;copy_state-&gt;dst, page_index, gpu);<br>    <span class="hljs-type">char</span> *cpu_va_staging_buffer = (<span class="hljs-type">char</span> *)uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;alloc) + (page_index * PAGE_SIZE);<br><br>    UVM_ASSERT(UVM_ID_IS_CPU(copy_state-&gt;src.id));<br>    UVM_ASSERT(UVM_ID_IS_GPU(copy_state-&gt;dst.id));<br><br>    UVM_ASSERT(uvm_conf_computing_mode_enabled(gpu));<br><br>    <span class="hljs-comment">// 参见 block_copy_begin_push 中的注释。</span><br>    UVM_ASSERT(uvm_tracker_is_completed(&amp;block-&gt;tracker));<br><br>    staging_buffer.address += page_index * PAGE_SIZE;<br>    auth_tag_buffer.address += page_index * UVM_CONF_COMPUTING_AUTH_TAG_SIZE;<br><br>    <span class="hljs-keyword">if</span> (uvm_push_get_and_reset_flag(push, UVM_PUSH_FLAG_NEXT_MEMBAR_NONE))<br>        membar_flag = UVM_PUSH_FLAG_NEXT_MEMBAR_NONE;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (uvm_push_get_and_reset_flag(push, UVM_PUSH_FLAG_NEXT_MEMBAR_GPU))<br>        membar_flag = UVM_PUSH_FLAG_NEXT_MEMBAR_GPU;<br><br>    <span class="hljs-comment">// kmap() 只保证 PAGE_SIZE 的连续性，所有加密和解密必须在 PAGE_SIZE 的基础上进行。</span><br>    for_each_va_block_page_in_region(page_index, region) &#123;<br>        <span class="hljs-type">void</span> *src_cpu_virt_addr;<br><br>        <span class="hljs-comment">// 调用者保证区域内的所有页面都是连续的，</span><br>        <span class="hljs-comment">// 这意味着它们被保证是同一个复合页面的一部分。</span><br>        UVM_ASSERT(src_page == uvm_cpu_chunk_get_cpu_page(block, page_index));<br><br>        src_cpu_virt_addr = kmap(src_page);<br>        uvm_conf_computing_cpu_encrypt(push-&gt;channel,<br>                                       cpu_va_staging_buffer,<br>                                       src_cpu_virt_addr,<br>                                       <span class="hljs-literal">NULL</span>,<br>                                       PAGE_SIZE,<br>                                       cpu_auth_tag_buffer);<br>        kunmap(src_page);<br><br>        <span class="hljs-comment">// 第一个 LCE 操作应该是非流水线的，以保证顺序，因为我们不知道上次非流水线复制的时间。</span><br>        <span class="hljs-comment">// 最后一个应用最初为推送计划的 membar（如果有的话）</span><br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> 3857691: 继承策略而不是强制第一次调用非流水线。</span><br>        <span class="hljs-keyword">if</span> (page_index &gt; region.first)<br>            uvm_push_set_flag(push, UVM_PUSH_FLAG_CE_NEXT_PIPELINED);<br><br>        <span class="hljs-keyword">if</span> (page_index &lt; (region.outer - <span class="hljs-number">1</span>))<br>            uvm_push_set_flag(push, UVM_PUSH_FLAG_NEXT_MEMBAR_NONE);<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (membar_flag)<br>            uvm_push_set_flag(push, membar_flag);<br><br>        gpu-&gt;parent-&gt;ce_hal-&gt;decrypt(push, dst_address, staging_buffer, PAGE_SIZE, auth_tag_buffer);<br><br>        src_page++;<br>        dst_address.address += PAGE_SIZE;<br>        cpu_va_staging_buffer += PAGE_SIZE;<br>        staging_buffer.address += PAGE_SIZE;<br>        cpu_auth_tag_buffer += UVM_CONF_COMPUTING_AUTH_TAG_SIZE;<br>        auth_tag_buffer.address += UVM_CONF_COMPUTING_AUTH_TAG_SIZE;<br>    &#125;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>参数<ul><li><strong>block</strong>：表示虚拟地址块的结构体指针。</li><li><strong>copy_state</strong>：表示块复制状态的结构体指针。</li><li><strong>region</strong>：表示虚拟地址块区域的结构体。</li><li><strong>push</strong>：用于推送命令的结构体指针。</li></ul></li><li>流程<ul><li>初始化变量<ul><li><strong>初始化 GPU 和 DMA 缓冲区相关的变量</strong>。</li><li><strong>获取源页面、目标地址和认证标签的相关信息</strong>。</li></ul></li><li>参数和状态验证<ul><li><strong>验证源和目标是否为 CPU 和 GPU</strong>。</li><li><strong>确保 GPU 启用了机密计算模式</strong>。</li><li><strong>确保块追踪器已经完成</strong>。</li></ul></li><li>调整缓冲区地址：<strong>根据页面索引调整 staging_buffer 和 auth_tag_buffer 的地址</strong>。</li><li>内存屏障标志设置：<strong>根据推送命令设置内存屏障标志</strong>。</li><li>循环处理每个页面<ul><li><strong>循环处理区域内的每个页面</strong>。</li><li><strong>对每个页面进行 kmap 和 kunmap 操作</strong>。</li><li><strong>执行 CPU 端加密，并使用 GPU 端解密</strong>。</li></ul></li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-0efd135b" role="button" aria-expanded="false" aria-controls="collapse-0efd135b">        <div class="fold-arrow">▶</div>conf_computing_block_copy_push_gpu_to_cpu GPU 端页面加密和 CPU 端解密操作      </div>      <div class="fold-collapse collapse" id="collapse-0efd135b">        <div class="fold-content">          <p>调用了decrypt，间接调用了 <code>uvm_hal_hopper_ce_encrypt</code></p><p>实现了在启用机密计算功能时，GPU 端页面加密和 CPU 端解密操作。它使用推送命令（push）在 GPU 上执行这些操作，并且 GPU 操作会遵守调用者先前在推送命令中设置的内存屏障（membar）。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 当启用机密计算功能时，该函数执行 GPU 端页面加密。GPU 操作遵守调用者在推送命令中先前设置的内存屏障。</span><br><span class="hljs-type">static</span> <span class="hljs-type">void</span> <span class="hljs-title function_">conf_computing_block_copy_push_gpu_to_cpu</span><span class="hljs-params">(<span class="hljs-type">uvm_va_block_t</span> *block,</span><br><span class="hljs-params">                                                      <span class="hljs-type">block_copy_state_t</span> *copy_state,</span><br><span class="hljs-params">                                                      <span class="hljs-type">uvm_va_block_region_t</span> region,</span><br><span class="hljs-params">                                                      <span class="hljs-type">uvm_push_t</span> *push)</span><br>&#123;<br>    <span class="hljs-type">uvm_push_flag_t</span> membar_flag = <span class="hljs-number">0</span>;<br>    <span class="hljs-type">uvm_gpu_t</span> *gpu = uvm_push_get_gpu(push);<br>    <span class="hljs-type">uvm_page_index_t</span> page_index = region.first;<br>    <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> *dma_buffer = copy_state-&gt;dma_buffer;<br>    <span class="hljs-type">uvm_gpu_address_t</span> staging_buffer = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;alloc, gpu);<br>    <span class="hljs-type">uvm_gpu_address_t</span> auth_tag_buffer = uvm_mem_gpu_address_virtual_kernel(dma_buffer-&gt;auth_tag, gpu);<br>    <span class="hljs-type">uvm_gpu_address_t</span> src_address = block_copy_get_address(block, &amp;copy_state-&gt;src, page_index, gpu);<br><br>    UVM_ASSERT(UVM_ID_IS_GPU(copy_state-&gt;src.id));<br>    UVM_ASSERT(UVM_ID_IS_CPU(copy_state-&gt;dst.id));<br><br>    UVM_ASSERT(uvm_conf_computing_mode_enabled(gpu));<br><br>    staging_buffer.address += page_index * PAGE_SIZE;<br>    auth_tag_buffer.address += page_index * UVM_CONF_COMPUTING_AUTH_TAG_SIZE;<br><br>    <span class="hljs-keyword">if</span> (uvm_push_get_and_reset_flag(push, UVM_PUSH_FLAG_NEXT_MEMBAR_NONE))<br>        membar_flag = UVM_PUSH_FLAG_NEXT_MEMBAR_NONE;<br>    <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (uvm_push_get_and_reset_flag(push, UVM_PUSH_FLAG_NEXT_MEMBAR_GPU))<br>        membar_flag = UVM_PUSH_FLAG_NEXT_MEMBAR_GPU;<br><br>    <span class="hljs-comment">// 由于我们使用 kmap() 映射用于 CPU 端加密操作的页面，它只保证 PAGE_SIZE 的连续性，</span><br>    <span class="hljs-comment">// 所有加密和解密操作必须在 PAGE_SIZE 基础上进行。</span><br>    for_each_va_block_page_in_region(page_index, region) &#123;<br>        uvm_conf_computing_log_gpu_encryption(push-&gt;channel, &amp;dma_buffer-&gt;decrypt_iv[page_index]);<br><br>        <span class="hljs-comment">// 第一个 LCE 操作应该是非流水线的，以保证顺序，因为我们不知道上次非流水线复制的时间。</span><br>        <span class="hljs-comment">// 最后一个应用最初为推送计划的 membar（如果有的话）</span><br>        <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> 3857691: 继承策略而不是强制第一次调用非流水线。</span><br>        <span class="hljs-keyword">if</span> (page_index &gt; region.first)<br>            uvm_push_set_flag(push, UVM_PUSH_FLAG_CE_NEXT_PIPELINED);<br><br>        <span class="hljs-keyword">if</span> (page_index &lt; (region.outer - <span class="hljs-number">1</span>))<br>            uvm_push_set_flag(push, UVM_PUSH_FLAG_NEXT_MEMBAR_NONE);<br>        <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (membar_flag)<br>            uvm_push_set_flag(push, membar_flag);<br><br>        gpu-&gt;parent-&gt;ce_hal-&gt;encrypt(push, staging_buffer, src_address, PAGE_SIZE, auth_tag_buffer);<br><br>        src_address.address += PAGE_SIZE;<br>        staging_buffer.address += PAGE_SIZE;<br>        auth_tag_buffer.address += UVM_CONF_COMPUTING_AUTH_TAG_SIZE;<br>    &#125;<br><br>    uvm_page_mask_region_fill(&amp;dma_buffer-&gt;encrypted_page_mask, region);<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>参数<ul><li><strong>block</strong>：表示虚拟地址块的结构体指针。</li><li><strong>copy_state</strong>：表示块复制状态的结构体指针。</li><li><strong>region</strong>：表示虚拟地址块区域的结构体。</li><li><strong>push</strong>：用于推送命令的结构体指针。</li></ul></li><li>流程<ul><li>初始化变量<ul><li><strong>初始化 GPU 和 DMA 缓冲区相关的变量</strong>。</li><li><strong>获取源地址和认证标签的相关信息</strong>。</li></ul></li><li>参数和状态验证<ul><li><strong>验证源和目标是否为 GPU 和 CPU</strong>。</li><li><strong>确保 GPU 启用了机密计算模式</strong>。</li></ul></li><li>调整缓冲区地址：<strong>根据页面索引调整 staging_buffer 和 auth_tag_buffer 的地址</strong>。</li><li>内存屏障标志设置：<strong>根据推送命令设置内存屏障标志</strong>。</li><li>循环处理每个页面<ul><li><strong>循环处理区域内的每个页面</strong>。</li><li><strong>记录 GPU 加密操作</strong>。</li><li><strong>执行 GPU 端加密操作，并根据页面索引调整地址和认证标签地址</strong>。</li></ul></li><li>填充已加密页面掩码：<strong>更新 DMA 缓冲区中的已加密页面掩码</strong>。</li></ul></li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-985bda36" role="button" aria-expanded="false" aria-controls="collapse-985bda36">        <div class="fold-arrow">▶</div>conf_computing_copy_pages_finish 完成机密计算中的页面复制操作      </div>      <div class="fold-collapse collapse" id="collapse-985bda36">        <div class="fold-content">          <p>负责完成机密计算中的页面复制操作。它在推送命令完成后，处理从GPU到CPU的页面数据传输，并在CPU端解密这些数据。</p><figure class="highlight c"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br></pre></td><td class="code"><pre><code class="hljs c"><span class="hljs-comment">// 当启用机密计算功能时，该函数完成 GPU 到 CPU 的页面复制操作。</span><br><span class="hljs-comment">// GPU 操作遵守调用者在推送命令中先前设置的内存屏障。</span><br><span class="hljs-type">static</span> NV_STATUS <span class="hljs-title function_">conf_computing_copy_pages_finish</span><span class="hljs-params">(<span class="hljs-type">uvm_va_block_t</span> *block,</span><br><span class="hljs-params">                                                  <span class="hljs-type">block_copy_state_t</span> *copy_state,</span><br><span class="hljs-params">                                                  <span class="hljs-type">uvm_push_t</span> *push)</span><br>&#123;<br>    NV_STATUS status;<br>    <span class="hljs-type">uvm_page_index_t</span> page_index;<br>    <span class="hljs-type">uvm_conf_computing_dma_buffer_t</span> *dma_buffer = copy_state-&gt;dma_buffer;<br>    <span class="hljs-type">uvm_page_mask_t</span> *encrypted_page_mask = &amp;dma_buffer-&gt;encrypted_page_mask;<br>    <span class="hljs-type">void</span> *auth_tag_buffer_base = uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;auth_tag);<br>    <span class="hljs-type">void</span> *staging_buffer_base = uvm_mem_get_cpu_addr_kernel(dma_buffer-&gt;alloc);<br><br>    UVM_ASSERT(uvm_channel_is_secure(push-&gt;channel));<br><br>    <span class="hljs-keyword">if</span> (UVM_ID_IS_GPU(copy_state-&gt;dst.id))<br>        <span class="hljs-keyword">return</span> NV_OK;<br><br>    UVM_ASSERT(UVM_ID_IS_GPU(copy_state-&gt;src.id));<br><br>    status = uvm_push_wait(push);<br>    <span class="hljs-keyword">if</span> (status != NV_OK)<br>        <span class="hljs-keyword">return</span> status;<br><br>    <span class="hljs-comment">// kmap() 只保证 PAGE_SIZE 的连续性，所有加密和解密操作必须在 PAGE_SIZE 的基础上进行。</span><br>    for_each_va_block_page_in_mask(page_index, encrypted_page_mask, block) &#123;<br>        <span class="hljs-class"><span class="hljs-keyword">struct</span> <span class="hljs-title">page</span> *<span class="hljs-title">dst_page</span> =</span> uvm_cpu_chunk_get_cpu_page(block, page_index);<br>        <span class="hljs-type">void</span> *staging_buffer = (<span class="hljs-type">char</span> *)staging_buffer_base + (page_index * PAGE_SIZE);<br>        <span class="hljs-type">void</span> *auth_tag_buffer = (<span class="hljs-type">char</span> *)auth_tag_buffer_base + (page_index * UVM_CONF_COMPUTING_AUTH_TAG_SIZE);<br>        <span class="hljs-type">void</span> *cpu_page_address = kmap(dst_page);<br><br>        status = uvm_conf_computing_cpu_decrypt(push-&gt;channel,<br>                                                cpu_page_address,<br>                                                staging_buffer,<br>                                                &amp;dma_buffer-&gt;decrypt_iv[page_index],<br>                                                PAGE_SIZE,<br>                                                auth_tag_buffer);<br>        kunmap(dst_page);<br>        <span class="hljs-keyword">if</span> (status != NV_OK) &#123;<br>            <span class="hljs-comment">// <span class="hljs-doctag">TODO:</span> Bug 3814087: [UVM][HCC] 处理 CSL 认证标签验证失败和其他失败情况。</span><br>            <span class="hljs-comment">// uvm_conf_computing_cpu_decrypt() 可能因为认证标签验证失败而失败。</span><br>            <span class="hljs-comment">// 如果发生这种情况，认为是严重故障，无法恢复。</span><br>            uvm_global_set_fatal_error(status);<br>            <span class="hljs-keyword">return</span> status;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-keyword">return</span> NV_OK;<br>&#125;<br></code></pre></td></tr></table></figure><ul><li>参数<ul><li><strong>block</strong>：表示虚拟地址块的结构体指针。</li><li><strong>copy_state</strong>：表示块复制状态的结构体指针。</li><li><strong>push</strong>：用于推送命令的结构体指针。</li></ul></li><li>返回值<ul><li><strong>NV_STATUS</strong>：表示操作的状态，可能的值包括 <code>NV_OK</code>（成功）或其他错误代码。</li></ul></li><li>流程<ul><li>初始化变量<ul><li><strong>初始化DMA缓冲区和相关内存地址</strong>。</li><li><strong>获取加密页面掩码、认证标签缓冲区基地址和暂存缓冲区基地址</strong>。</li></ul></li><li>参数和状态验证<ul><li><strong>确保推送命令的通道是安全的</strong>。</li><li><strong>如果目标是GPU，直接返回成功状态</strong>。</li><li><strong>确保源是GPU</strong>。</li></ul></li><li>等待推送命令完成<ul><li><strong>等待推送命令完成</strong>。</li><li><strong>如果等待失败，返回错误状态</strong>。</li></ul></li><li>处理每个页面<ul><li><strong>遍历加密页面掩码中的每个页面</strong>。</li><li><strong>获取目标页面和相关缓冲区地址</strong>。</li><li><strong>将页面映射到CPU地址空间</strong>。</li><li><strong>调用 <code>uvm_conf_computing_cpu_decrypt</code> 函数在CPU端解密页面数据</strong>。</li><li><strong>解除页面映射</strong>。</li><li><strong>如果解密失败，记录严重错误并返回错误状态</strong>。</li></ul></li></ul></li></ul>        </div>      </div>    </div>]]></content>
    
    
    <categories>
      
      <category>Security</category>
      
    </categories>
    
    
    <tags>
      
      <tag>TEE</tag>
      
      <tag>Confidential Compute</tag>
      
      <tag>GPU</tag>
      
      <tag>Security</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>GPU Computing Startup</title>
    <link href="/2024/06/24/AI/Computing-Startup/"/>
    <url>/2024/06/24/AI/Computing-Startup/</url>
    
    <content type="html"><![CDATA[<p>GPU, Compute and AI.</p><span id="more"></span><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li><li><a href="#%E8%B5%84%E6%96%99%E6%B1%87%E6%80%BB">资料汇总</a></li><li><a href="#github-%E8%B5%84%E6%BA%90%E6%B1%87%E6%80%BB">github 资源汇总</a></li><li><a href="#%E8%AE%BA%E6%96%87">论文</a></li><li><a href="#datawhale">datawhale</a></li><li><a href="#%E6%9D%8E%E6%B2%90">李沐</a></li><li><a href="#pytorch-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86">pytorch 知识点整理</a></li><li><a href="#%E5%AE%89%E8%A3%85-pytorch-cpu-%E7%89%88%E6%9C%AC">安装 pytorch cpu 版本</a></li><li><a href="#%E5%AE%89%E8%A3%85-pytorch-cuda-%E7%89%88%E6%9C%AC">安装 pytorch cuda 版本</a></li><li><a href="#pytorch-book-vscode-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">pytorch book vscode 环境配置</a></li><li><a href="#%E7%A4%BA%E4%BE%8B">示例</a><ul><li><a href="#%E7%BA%BF%E6%80%A7%E5%9B%9E%E5%BD%92">线性回归</a></li><li><a href="#fashion-mnist-%E6%89%8B%E5%86%99%E6%95%B0%E5%AD%97%E5%88%86%E7%B1%BB">fashion mnist 手写数字分类</a></li><li><a href="#cifar-10">cifar 10</a></li></ul></li></ul><h2 id="资料汇总"><a href="#资料汇总" class="headerlink" title="资料汇总"></a>资料汇总</h2><table><thead><tr><th>链接</th><th>说明</th></tr></thead><tbody><tr><td><a href="https://github.com/chenyuntc/pytorch-book"><strong>《深度学习框架PyTorch：入门与实战》代码</strong></a></td><td>这个适合开始阶段，参考<a href="#pytorch-%E7%9F%A5%E8%AF%86%E7%82%B9%E6%95%B4%E7%90%86">pytorch 知识点整理</a>。此书配套1.6版本的pytorch，参考<a href="#%E5%AE%89%E8%A3%85-pytorch-cpu-%E7%89%88%E6%9C%AC">安装 pytorch cpu 版本</a>和<a href="#pytorch-book-vscode-%E7%8E%AF%E5%A2%83%E9%85%8D%E7%BD%AE">pytorch book vscode 环境配置</a></td></tr><tr><td><a href="https://pytorch.org/tutorials/beginner/basics/intro.html">Pytorch 官方文档</a></td><td>最新的是2.3版本，和下面教程搭配着看</td></tr><tr><td><a href="https://github.com/pytorch/tutorials">Pytorch 官方文档教程仓库</a></td><td>PyTorch tutorials。有点占地方，里面和文档内容对应，有直接可运行的脚本</td></tr><tr><td><a href="https://pytorch.org/get-started/locally/">Pytorch 安装指引</a></td><td>安装CPU&#x2F;CUDA版本</td></tr><tr><td><a href="https://github.com/apachecn/pytorch-doc-zh">Pytorch 官方文档翻译版</a></td><td>Pytorch 中文文档，缺点，广告太多</td></tr><tr><td><a href="https://github.com/pytorch/examples">Pytorch Examples</a></td><td>围绕 pytorch 的视觉、文本、强化学习等方面的一组示例。</td></tr><tr><td><a href="https://github.com/pytorch/pytorch">Pytorch 源码仓库</a></td><td>具有强大 GPU 加速的 Python 张量和动态神经网络。</td></tr></tbody></table><table><thead><tr><th align="center">Cuda</th><th align="center">Jetson 嵌入式AI</th><th align="center">GPU driver</th></tr></thead><tbody><tr><td align="center"><a href="https://docs.nvidia.com/cuda/">CUDA 官方文档</a><br/><a href="https://docs.nvidia.com/cuda/cuda-runtime-api/index.html">CUDA Runtime API</a><br/><a href="https://github.com/NVIDIA/cuda-samples"><strong>Samples for CUDA Developers</strong></a></td><td align="center"><a href="https://www.nvidia.com/en-us/autonomous-machines/embedded-systems/jetson-orin/"><strong>Jetson Orin</strong></a><br/><a href="https://www.jetson-ai-lab.com/tutorial-intro.html"><strong>NVIDIA Jetson AI Lab</strong></a><br/><a href="https://developer.nvidia.com/embedded/community/jetson-projects"><strong>NVIDIA Jetson-projects</strong></a><br/><a href="https://www.yahboom.com/study/Jetson-Orin-NANO"><strong>Yahboom官方教程 提取码lguu</strong></a><br/><a href="https://developer.nvidia.com/blog/develop-ai-powered-robots-smart-vision-systems-and-more-with-nvidia-jetson-orin-nano-developer-kit">Jetson Orin Nano Developer Kit Now Available</a></td><td align="center"><a href="https://github.com/NVIDIA/open-gpu-kernel-modules"><strong>NVIDIA GPU Kernel Modules</strong></a><br/><a href="https://github.com/torvalds/linux/tree/master/drivers/gpu/drm/amd/amdgpu">AMD KMD Driver in Linux</a></td></tr></tbody></table>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-a44f8816" role="button" aria-expanded="false" aria-controls="collapse-a44f8816">        <div class="fold-arrow">▶</div>PyTorch文档      </div>      <div class="fold-collapse collapse" id="collapse-a44f8816">        <div class="fold-content">          <iframe src="https://pytorch.org/tutorials/beginner/basics/intro.html" width="100%" height="800" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-4348e078" role="button" aria-expanded="false" aria-controls="collapse-4348e078">        <div class="fold-arrow">▶</div>CUDA文档      </div>      <div class="fold-collapse collapse" id="collapse-4348e078">        <div class="fold-content">          <iframe src="https://docs.nvidia.com/cuda/" width="100%" height="800" name="topFrame" scrolling="yes"  noresize="noresize" frameborder="0" id="topFrame"></iframe>        </div>      </div>    </div><h2 id="github-资源汇总"><a href="#github-资源汇总" class="headerlink" title="github 资源汇总"></a>github 资源汇总</h2><table><thead><tr><th align="center">仓库</th><th>说明</th></tr></thead><tbody><tr><td align="center"><strong>1. AI&#x2F;AGI&#x2F;AIoT</strong></td><td></td></tr><tr><td align="center"><a href="https://github.com/huggingface/transformers"><strong>HuggingFace&#x2F;Transformers<br/>★★★★★</strong></a></td><td>著名论文<a href="https://arxiv.org/abs/1706.03762">Attention Is All You Need</a> 提出的 Transformers  提供数千个预训练模型，用于执行不同模态（例如文本、视觉和音频）的任务。这些模型可应用于：<br/>1. 📝 文本，用于 100 多种语言的文本分类、信息提取、问答、摘要、翻译和文本生成等任务。<br/>2. 🖼️ 图像，用于图像分类、对象检测和分割等任务。<br/>3. 🗣️ 音频，用于语音识别和音频分类等任务。<br/>Transformers 模型还可以执行多种模态组合的任务，例如表格问答、光学字符识别、从扫描文档中提取信息、视频分类和视觉问答。</td></tr><tr><td align="center"><a href="https://github.com/karpathy/llm.c"><strong>Karpathy&#x2F;llm.c<br/>★★★★★</strong></a></td><td>简单、纯 C&#x2F;CUDA 的 LLM，无需 245MB 的 PyTorch 或 107MB 的 cPython。当前重点是预训练，特别是重现 GPT-2 和 GPT-3 迷你剧，以及 train_gpt2.py 中的并行 PyTorch 参考实现。测试见：<a href="http://tech-odyssey.cn/2024/04/28/llm.c/">llm.c</a></td></tr><tr><td align="center"><a href="https://github.com/google-research/vision_transformer"><strong>Google&#x2F;Vision Transformer<br/>★★★★★</strong></a></td><td>在这个存储库中，我们发布了论文中的模型<br/><br/>1. 一张图片胜过 16x16 个单词：用于大规模图像识别的 Transformers<br/>2. MLP-Mixer：用于视觉的全 MLP 架构<br/>3. 如何训练你的 ViT？视觉 Transformers 中的数据、增强和正则化<br/>4. 当视觉 Transformers 在没有预训练或强大的数据增强的情况下胜过 ResNets 时<br/>5. LiT：使用锁定图像文本调整的零样本传输<br/>6. 替代间隙最小化改进了清晰度感知训练<br/><br/>这些模型在 ImageNet 和 ImageNet-21k 数据集上进行了预训练。我们在 JAX&#x2F;Flax 中提供了用于微调已发布模型的代码。<br/></td></tr><tr><td align="center"><a href="https://github.com/open-webui/open-webui"><strong>Open WebUI (Formerly Ollama WebUI)<br/>★★★★★</strong></a></td><td>Open WebUI 是一个可扩展、功能丰富且用户友好的自托管 WebUI，旨在完全离线操作。它支持各种LLM运行程序，包括 Ollama 和 OpenAI 兼容的 API。有关更多信息，请务必查看我们的Open WebUI 文档。</td></tr><tr><td align="center"><a href="https://github.com/ultralytics/yolov5"><strong>Ultralytics&#x2F;Yolov5<br/>★★★★★</strong></a></td><td>YOLOv5🚀是世界上最受欢迎的视觉 AI，代表了 Ultralytics 对未来视觉 AI 方法的开源研究，融合了数千小时研发过程中获得的经验教训和最佳实践。</td></tr><tr><td align="center"><a href="https://github.com/dusty-nv/jetson-inference"><strong>Dusty-nv&#x2F;Jetson Inference<br/>★★★★★</strong></a></td><td>该项目使用 TensorRT 在 C++ 或 Python 的 GPU 上运行优化网络，并使用 PyTorch 训练模型。支持的 DNN 视觉基元包括用于图像分类的 imageNet、用于对象检测的 detectNet、用于语义分割的 segNet、用于姿势估计的 poseNet 和用于动作识别的 actionNet。提供了从实时摄像头源进行流式传输、使用 WebRTC 制作 Web 应用程序以及对 ROS&#x2F;ROS2 的支持的示例。</td></tr><tr><td align="center"><a href="https://github.com/AUTOMATIC1111/stable-diffusion-webui"><strong>Stable Diffusion WebUI<br/>★★★★★</strong></a></td><td>使用 Gradio 库实现的Stable Diffusion的 Web 界面。 <a href="https://github.com/dtlnor/stable-diffusion-webui-localization-zh_CN">简体中文翻译扩展</a></td></tr><tr><td align="center"><a href="https://github.com/Zhouyi-AIPU/Model_zoo"><strong>Zhouyi-AIPU&#x2F;Model Zoo<br/>★★★</strong></a></td><td>各种Embedded model汇总</td></tr><tr><td align="center"><a href="https://github.com/huggingface/pytorch-image-models">HuggingFace&#x2F;Pytorch image models<br/>★</a></td><td>最大的 PyTorch 图像 encoders &#x2F; backbone 集合。包括训练、评估、推理、导出脚本和预训练权重 - ResNet、ResNeXT、EfficientNet、NFNet、Vision Transformer (ViT)、MobileNetV4、MobileNet-V3 &amp; V2、RegNet、DPN、CSPNet、Swin Transformer、MaxViT、CoAtNet、ConvNeXt 等</td></tr><tr><td align="center"><a href="https://github.com/huggingface/datasets">HuggingFace&#x2F;Datasets<br/>★</a></td><td>Datasets 是一个轻量级库，提供两个主要功能：适用于许多公共数据集的单行数据加载器；高效的数据预处理。</td></tr><tr><td align="center"><a href="https://github.com/huggingface/accelerate">HuggingFace&#x2F;Accelerate<br/>★</a></td><td>Accelerate 是为那些喜欢编写 PyTorch 模型训练循环但不愿意编写和维护使用多 GPU&#x2F;TPU&#x2F;fp16 所需的样板代码的 PyTorch 用户创建的。</td></tr><tr><td align="center"><a href="https://github.com/Stability-AI/generative-models">Stability-AI&#x2F;Generative Models<br/>★</a></td><td>Generative Models by Stability AI</td></tr><tr><td align="center"><a href="https://github.com/Stability-AI/stablediffusion">Stability-AI&#x2F;Stable Diffusion<br/>★</a></td><td>此存储库包含从头开始训练的 Stable Diffusion 模型，并将使用新的检查点不断更新。</td></tr><tr><td align="center"><a href="https://github.com/tensorflow/tensorflow">TensorFlow<br/>★</a></td><td>An Open Source Machine Learning Framework for Everyone</td></tr><tr><td align="center"><a href="https://github.com/tensorflow/models">TensorFlow Models<br/>★</a></td><td>Models and examples built with TensorFlow</td></tr><tr><td align="center"><a href="https://github.com/ultralytics/ultralytics">Ultralytics&#x2F;ultralytics<br/>★</a></td><td>Ultralytics YOLOv8 是一款尖端的、最先进的 (SOTA) 模型，它以之前 YOLO 版本的成功为基础，并引入了新功能和改进，以进一步提高性能和灵活性。YOLOv8 旨在快速、准确且易于使用，使其成为各种对象检测和跟踪、实例分割、图像分类和姿势估计任务的绝佳选择。</td></tr><tr><td align="center"><a href="https://github.com/karpathy/llama2.c">Karpathy&#x2F;llama2.c<br/>★</a></td><td>在 PyTorch 中训练 Llama 2 LLM 架构，然后使用一个简单的 700 行 C 文件 (run.c) 进行推理。</td></tr><tr><td align="center"><a href="https://github.com/Morizeyao/GPT2-Chinese">GPT2-Chinese<br/>★</a></td><td>中文的GPT2训练代码，使用BERT的Tokenizer或Sentencepiece的BPE model</td></tr><tr><td align="center"><a href="https://github.com/openai/openai-cookbook">openai-cookbook<br/>★★</a></td><td>使用 OpenAI API 完成常见任务的示例代码和指南。</td></tr><tr><td align="center"><a href="https://github.com/onnx/onnx">ONNX<br/>★★★</a></td><td>开放神经网络交换(ONNX)是一个开放的生态系统，使人工智能开发人员能够随着项目的发展选择合适的工具。ONNX为人工智能模型提供了一种开源格式，包括深度学习和传统ML，它定义了一个可扩展的计算图模型，以及内置运算符和标准数据类型的定义。目前我们专注于推理(评分)所需的功能。</td></tr><tr><td align="center"><a href="https://github.com/microsoft/onnxruntime">Microsoft&#x2F;ONNX Runtime<br/>★</a></td><td>ONNX Runtime 是一个跨平台推理和训练机器学习加速器。</td></tr><tr><td align="center"><a href="https://github.com/onnx/onnx-tensorrt">onnx-tensorrt<br/>★★</a></td><td>解析 ONNX 模型以便使用 <a href="https://developer.nvidia.com/tensorrt">TensorRT</a> 执行。 NVIDIA® TensorRT™ 是一个用于高性能深度学习推理的 API 生态系统。TensorRT 包括推理运行时和模型优化，可为生产应用程序提供低延迟和高吞吐量。TensorRT 生态系统包括 TensorRT、TensorRT-LLM、TensorRT 模型优化器和 TensorRT Cloud。</td></tr><tr><td align="center"><a href="https://github.com/daquexian/onnx-simplifier">onnx-simplifier<br/>★</a></td><td>ONNX 很棒，但有时太复杂。</td></tr><tr><td align="center"><a href="https://github.com/onnx/tensorflow-onnx">tensorflow-onnx<br/>★</a></td><td>tf2onnx 通过命令行或 python api 将 TensorFlow（tf-1.x 或 tf-2.x）、keras、tensorflow.js 和 tflite 模型转换为 ONNX。</td></tr><tr><td align="center"><strong>2. GPU&#x2F;CUDA&#x2F;Rocm</strong></td><td></td></tr><tr><td align="center"><a href="https://github.com/DefTruth/CUDA-Learn-Notes"><strong>CUDA-Learn-Notes<br/>★★★★★</strong></a></td><td>CUDA-Learn-Notes: CUDA 笔记、大模型手撕CUDA、C++笔记</td></tr><tr><td align="center"><a href="https://github.com/HeKun-NVIDIA/CUDA-Programming-Guide-in-Chinese"><strong>CUDA-Programming-Guide-in-Chinese<br/>★</strong></a></td><td>本项目为 CUDA C Programming Guide 的中文翻译版。</td></tr><tr><td align="center"><a href="https://github.com/godweiyang/NN-CUDA-Example">NN-CUDA-Example<br/>★</a></td><td>调用自定义 CUDA 运算符的神经网络工具包（PyTorch、TensorFlow 等）的几个简单示例。</td></tr><tr><td align="center"><a href="https://github.com/NVIDIA/nvtrust">NVTrust<br/>★</a></td><td>nvTrust 是一个存储库，其中包含在受信任的环境（例如机密计算）中使用 NVIDIA 解决方案时利用的许多实用程序和工具、开源代码和 SDK。</td></tr><tr><td align="center"><a href="https://github.com/protectai/llm-guard">LLM Guard</a></td><td>LLM 交互的安全工具包</td></tr><tr><td align="center"><a href="https://github.com/ROCm/ROCT-Thunk-Interface">ROCm&#x2F;ROCT-Thunk-Interface<br/>★</a></td><td>此存储库包含用于与 (AMD)ROCk 驱动程序交互的用户模式 ​​API 接口。</td></tr><tr><td align="center"><strong>3. 免费资源</strong></td><td></td></tr><tr><td align="center"><a href="https://github.com/GrowingGit/GitHub-Chinese-Top-Charts"><strong>GitHub中文开源仓库排行榜<br/>★★★★★</strong></a></td><td>GitHub中文排行榜，帮助你发现优秀中文项目，可以无语言障碍地、更高效地吸收优秀经验成果</td></tr><tr><td align="center"><a href="https://github.com/EbookFoundation/free-programming-books"><strong>free-programming-books<br/>★★★★★</strong></a></td><td>多种语言的免费学习资源列表</td></tr><tr><td align="center"><a href="https://github.com/datawhalechina"><strong>Datawhale<br/>★★★★★</strong></a></td><td>Datawhale 是一个专注于数据科学与 AI 领域的开源组织，汇集了众多领域院校和知名企业的优秀学习者，聚合了一群有开源精神和探索精神的团队成员。</td></tr><tr><td align="center"><a href="https://github.com/OpenBMB"><strong>OpenBMB<br/>★★★★★</strong></a></td><td>OpenBMB (Open Lab for Big Model Base), founded by ModelBest Inc (面壁智能) &amp; TsinghuaNLP, aims to build foundation models and systems towards AGI.</td></tr><tr><td align="center"><a href="https://github.com/forthespada/CS-Books">CS EBook<br/>★★★</a></td><td>超过1000本的计算机经典书籍分享，解压密码：a123654</td></tr><tr><td align="center"><a href="https://github.com/lining808/CS-Ebook">CS EBook<br/>★★★</a></td><td>本储存库是一些高质量的计算机科学与技术书籍推荐书单，需要学习的可以按照此书单进行学习进阶，包含了计算机大多数软件相关方向。而且敢承诺一直更新。</td></tr><tr><td align="center"><a href="https://github.com/zhoucz97/myLearning">zhoucz97&#x2F;myLearning</a></td><td>记录个人的学习历程。包括但不限于算法、机器学习、论文写作等。</td></tr><tr><td align="center"><a href="https://github.com/datawhalechina/leedl-tutorial">李宏毅深度学习教程LeeDL-Tutorial（苹果书）</a></td><td>本教程主要内容源于《机器学习》（2021年春），并在其基础上进行了一定的原创。比如，为了尽可能地降低阅读门槛，笔者对这门公开课的精华内容进行选取并优化，对所涉及的公式都给出详细的推导过程，对较难理解的知识点进行了重点讲解和强化，以方便读者较为轻松地入门。此外，为了丰富内容，笔者在教程中选取了《机器学习》（2017年春） 的部分内容，并补充了不少除这门公开课之外的深度学习相关知识。</td></tr></tbody></table><h2 id="论文"><a href="#论文" class="headerlink" title="论文"></a>论文</h2><p><a href="https://www.yiyibooks.cn/yiyibooks/Attention_Is_All_You_Need/index.html">Attention is All Your Need 中英对照</a></p><h2 id="datawhale"><a href="#datawhale" class="headerlink" title="datawhale"></a>datawhale</h2><p><img src="/img/ai/datawhale/index.png" alt="Datawhale"></p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-28bd864b" role="button" aria-expanded="false" aria-controls="collapse-28bd864b">        <div class="fold-arrow">▶</div>学习资源      </div>      <div class="fold-collapse collapse" id="collapse-28bd864b">        <div class="fold-content">          <p>Datawhale 是一个专注于数据科学与 AI 领域的开源组织，汇集了众多领域院校和知名企业的优秀学习者，聚合了一群有开源精神和探索精神的团队成员。</p><p>Datawhale 以“ for the learner，和学习者一起成长”为愿景，鼓励真实地展现自我、开放包容、互信互助、敢于试错和勇于担当。同时 Datawhale 用开源的理念去探索开源内容、开源学习和开源方案，赋能人才培养，助力人才成长，建立起人与人，人与知识，人与企业和人与未来的联结。</p><p>官网：<a href="https://linklearner.com/">https://linklearner.com/</a><br>课程：<a href="https://linklearner.com/learn">https://linklearner.com/learn</a><br>Github：<a href="https://github.com/datawhalechina">https://github.com/datawhalechina</a></p><p>课程：</p><ul><li><a href="https://linklearner.com/learn/summary/18">基于transformers的自然语言处理(NLP)入门</a></li><li><a href="https://linklearner.com/learn/summary/19">动手学大模型应用开发</a></li><li><a href="https://linklearner.com/learn/summary/20">面向开发者的 LLM 入门课程</a></li></ul><p>LLM 相关仓库：</p><ul><li><a href="https://github.com/datawhalechina/so-large-lm">大模型基础: 一文了解大模型基础知识</a></li><li><a href="https://github.com/datawhalechina/llm-cookbook">面向开发者的大模型手册 - LLM Cookbook</a></li><li><a href="https://github.com/datawhalechina/learn-nlp-with-transformers">基于transformers的自然语言处理(NLP)入门</a></li><li><a href="https://github.com/datawhalechina/llms-from-scratch-cn">动手学LLM, 从0逐步构建GLM4\Llama3\RWKV6， 深入理解大模型原理</a></li><li><a href="https://github.com/datawhalechina/self-llm">《开源大模型食用指南》基于Linux环境快速部署开源大模型，更适合中国宝宝的部署教程</a></li><li><a href="https://github.com/datawhalechina/llm-universe">面向小白开发者的大模型应用开发教程</a></li></ul><p>补充：</p><ul><li><a href="https://github.com/datawhalechina/thorough-pytorch">深入浅出PyTorch</a></li><li><a href="https://github.com/datawhalechina/leedl-tutorial">李宏毅深度学习教程LeeDL-Tutorial（苹果书）</a></li><li><a href="https://github.com/datawhalechina/easy-rl">蘑菇书EasyRL 李宏毅老师的《深度强化学习》</a></li><li><a href="https://github.com/datawhalechina/pumpkin-book">南瓜书PumpkinBook</a></li></ul>        </div>      </div>    </div><h2 id="李沐"><a href="#李沐" class="headerlink" title="李沐"></a>李沐</h2><ul><li><a href="https://zh.d2l.ai/index.html"><strong>动手学深度学习 在线书籍第二版</strong></a></li><li><a href="https://space.bilibili.com/1567748478/channel/seriesdetail?sid=358497"><strong>动手学深度学习 PyTorch版 视频</strong></a></li><li><a href="https://courses.d2l.ai/zh-v2/">动手学深度学习 课程大纲</a></li><li><a href="https://github.com/d2l-ai/d2l-zh">动手学深度学习 Github 代码</a></li><li><a href="https://space.bilibili.com/1567748478/channel/collectiondetail?sid=28144">斯坦福2021秋季·实用机器学习【中文】</a><ul><li><a href="https://c.d2l.ai/stanford-cs329p/">课程 Slides</a></li></ul></li><li><a href="https://github.com/mli/paper-reading">深度学习论文精读</a></li></ul><h2 id="pytorch-知识点整理"><a href="#pytorch-知识点整理" class="headerlink" title="pytorch 知识点整理"></a>pytorch 知识点整理</h2><p>《深度学习框架 PyTorch: 入门与实战》</p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-13aa53af" role="button" aria-expanded="false" aria-controls="collapse-13aa53af">        <div class="fold-arrow">▶</div>Chapter 2, 简单介绍 tensor 和构建 cifar-10 训练模型      </div>      <div class="fold-collapse collapse" id="collapse-13aa53af">        <div class="fold-content">          <ul><li>安装Pytorch</li><li>基本操作，如cat等</li><li>准备一个cifar-10模型，并训练推理</li></ul>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-898f91ec" role="button" aria-expanded="false" aria-controls="collapse-898f91ec">        <div class="fold-arrow">▶</div>Chapter 3, 介绍 tensor      </div>      <div class="fold-collapse collapse" id="collapse-898f91ec">        <div class="fold-content">          <table><thead><tr><th>概要</th><th>内容</th></tr></thead><tbody><tr><td>基本操作</td><td>Tensor(*sizes), tensor(data)<br/>ones&#x2F;zeros&#x2F;eye(*sizes)<br/>arrange(start, end, step), linspace(start, end, steps)<br/>rand &#x2F; randn(*sizes)<br/>new_* &#x2F; *_like()</td></tr><tr><td>命名张量</td><td>names, refine_names, rename, align_to</td></tr><tr><td>类型</td><td>set_default_tensor_type, type(new_type) &#x3D;&#x3D; .float(), .long(), .half(), to(device)</td></tr><tr><td>索引</td><td>index_select(input, dim, index)<br/>masked_select(input, mask)<br/>gather(input, dim, index)<br/>input.scatter_(dim, index)放回<br/>non_zero(input)非零下标</td></tr><tr><td>元素操作</td><td>abs&#x2F;sqrt&#x2F;div&#x2F;exp&#x2F;fmod&#x2F;log&#x2F;pow, cos&#x2F;sin&#x2F;asin&#x2F;atan2&#x2F;cosh, ceil&#x2F;round&#x2F;floor&#x2F;trunc, clamp(input,min,max), sigmod&#x2F;tanh, cumsum&#x2F;cumprod</td></tr><tr><td>归并操作</td><td>mean&#x2F;sum&#x2F;median&#x2F;mode, norm&#x2F;dist, std&#x2F;var, keepdim&#x3D;True<br/>保留维度, 在哪个维度操作, 哪个维度变成1，或者消失</td></tr><tr><td>比较</td><td>gt&#x2F;lt&#x2F;ge&#x2F;le&#x2F;eq&#x2F;ne, topk, sort, max&#x2F;min</td></tr><tr><td>线性代数</td><td>trace, diag, triu&#x2F;tril, mm&#x2F;bmm, addmm&#x2F;addbmm&#x2F;addmv, t, dot&#x2F;cross, inverse, svd</td></tr><tr><td>Numpy</td><td>from_numpy，共享内存<br/>torch.tensor()只进行数据拷贝, 不会共享内存<br/>torch.Tensor()在类型不一致时是复制而非共享内存</td></tr><tr><td>Tensor基本结构</td><td>storage()查看是否共享, contiguous()变成连续</td></tr><tr><td>Tensor改变形状</td><td>查看信息, size() &#x3D; shape, dim() &#x3D; len(tensor.shape), numel &lt;&#x3D;&gt; numpy.size<br/>改变维度, reshape(), view(), view_as()<br/>增加减少维度, squeeze()压缩, unsqueeze()新建维度, flatten(start_dim, end_dim)<br/>转置, transpose()仅限二维, t(), T, permute()</td></tr><tr><td>线性回归实例</td><td>手动计算求导函数</td></tr><tr><td>autograd</td><td>requires_grad&#x3D;True, retain_graph&#x3D;None, is_leaf, backward()</td></tr><tr><td>用autograd实现线性回归</td><td>自动backward, 梯度下降</td></tr></tbody></table>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-fafb6dcd" role="button" aria-expanded="false" aria-controls="collapse-fafb6dcd">        <div class="fold-arrow">▶</div>Chapter 4, 神经网络工具箱nn      </div>      <div class="fold-collapse collapse" id="collapse-fafb6dcd">        <div class="fold-content">          <p>torch.nn是专门为深度学习而设计的模块。torch.nn的核心数据结构是<code>Module</code>，它是一个抽象的概念，既可以表示神经网络中的某个层（layer），也可以表示一个包含很多层的神经网络。在实际使用中，最常见的做法是继承<code>nn.Module</code>，从而编写自己的网络&#x2F;层。多层感知机的网络结构如图所示，它由两个全连接层组成，采用$sigmoid$函数作为激活函数（图中没有画出）。</p><p><img src="/img/ai/multi_perceptron.png" alt="神经网络"></p><p>PyTorch内部实现了神经网络中绝大多数的layer，这些layer都继承于<code>nn.Module</code>，封装了可学习参数<code>parameter</code>，并实现了<code>forward</code>函数。同时，大部分layer都专门针对GPU运算进行了CuDNN优化，其速度和性能都十分优异。关注每一层的信息有：</p><ol><li>构造函数的参数，如nn.Linear(in_features, out_features, bias)，需关注这三个参数的作用；</li><li>属性、可学习参数和子module。如nn.Linear中有<code>weight</code>和<code>bias</code>两个可学习参数，不包含子module；</li><li>输入输出的形状，如nn.linear的输入形状是(N, input_features)，输出为(N，output_features)，其中N是batch_size。</li></ol><p>图像nn包括，卷积层（Conv）、池化层（Pool），池化方式又分为平均池化（AvgPool）、最大值池化（MaxPool）、自适应池化（AdaptiveAvgPool）等。而卷积层除了常用的前向卷积之外，还有逆卷积（TransposeConv）。卷积神经网络的本质就是卷积层、池化层、激活层以及其他层的叠加。池化层可以看作是一种特殊的卷积层，其主要用于下采样，增加池化层可以在保留主要特征的同时降低参数量，从而一定程度上防止了过拟合。池化层没有可学习参数，它的weight是固定的。在<code>torch.nn</code>工具箱中封装好了各种池化层，常见的有最大池化（MaxPool）和平均池化（AvgPool)。</p>        </div>      </div>    </div><h2 id="安装-pytorch-cpu-版本"><a href="#安装-pytorch-cpu-版本" class="headerlink" title="安装 pytorch cpu 版本"></a>安装 pytorch cpu 版本</h2><p><a href="https://pytorch.org/get-started/previous-versions/">https://pytorch.org/get-started/previous-versions/</a></p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-24a91446" role="button" aria-expanded="false" aria-controls="collapse-24a91446">        <div class="fold-arrow">▶</div>点击此处查看步骤      </div>      <div class="fold-collapse collapse" id="collapse-24a91446">        <div class="fold-content">          <p><img src="/img/ai/Pytorch.png" alt="Pytorch"></p><p><strong>安装 Anaconda. 下载地址:</strong> <a href="https://www.anaconda.com/download">https://www.anaconda.com/download</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># For example, Ubuntu</span><br>$ wget https://repo.anaconda.com/archive/Anaconda3-2024.02-1-Linux-x86_64.sh<br>$ <span class="hljs-built_in">chmod</span> +x Anaconda3-2024.02-1-Linux-x86_64.sh<br>$ ./Anaconda3-2024.02-1-Linux-x86_64.sh<br>$ <span class="hljs-built_in">echo</span> <span class="hljs-string">&quot;export PATH=\&quot;/root/anaconda3/bin\&quot;:\$PATH&quot;</span> &gt;&gt; ~/.bashrc   <span class="hljs-comment"># Check the path</span><br>$ <span class="hljs-built_in">source</span> ~/.bashrc<br><br><span class="hljs-comment"># Check if it is installed successfully:</span><br>$ conda --version<br>conda 24.1.2<br></code></pre></td></tr></table></figure><p><strong>换源</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Reference https://blog.csdn.net/adreammaker/article/details/123396951</span><br>$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/<br>$ conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/<br>$ conda config --<span class="hljs-built_in">set</span> show_channel_urls <span class="hljs-built_in">yes</span><br></code></pre></td></tr></table></figure><p><strong>创建Pytorch虚拟环境</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda create -n torch-1.6  python=3.6.13<br></code></pre></td></tr></table></figure><details><summary>创建过程的log</summary><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ conda create -n torch-1.6  python=3.6.13<br>Channels:<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free<br> - defaults<br>Platform: linux-64<br>Collecting package metadata (repodata.json): <span class="hljs-keyword">done</span><br>Solving environment: <span class="hljs-keyword">done</span><br><br><span class="hljs-comment">## Package Plan ##</span><br><br>  environment location: /home/&lt;user&gt;/anaconda3/envs/torch-1.6<br><br>  added / updated specs:<br>    - python=3.6.13<br><br><br>The following packages will be downloaded:<br><br>    package                    |            build<br>    ---------------------------|-----------------<br>    certifi-2021.5.30          |   py36h06a4308_0         139 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libffi-3.3                 |       he6710b0_2          50 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    openssl-1.1.1w             |       h7f8727e_0         3.7 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    pip-21.2.2                 |   py36h06a4308_0         1.8 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    python-3.6.13              |       h12debd9_1        32.5 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    setuptools-58.0.4          |   py36h06a4308_0         788 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    wheel-0.37.1               |     pyhd3eb1b0_0          33 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    ------------------------------------------------------------<br>                                           Total:        39.0 MB<br><br>The following NEW packages will be INSTALLED:<br><br>  _libgcc_mutex      anaconda/pkgs/main/linux-64::_libgcc_mutex-0.1-main<br>  _openmp_mutex      anaconda/pkgs/main/linux-64::_openmp_mutex-5.1-1_gnu<br>  ca-certificates    anaconda/pkgs/main/linux-64::ca-certificates-2024.3.11-h06a4308_0<br>  certifi            anaconda/pkgs/main/linux-64::certifi-2021.5.30-py36h06a4308_0<br>  ld_impl_linux-64   anaconda/pkgs/main/linux-64::ld_impl_linux-64-2.38-h1181459_1<br>  libffi             anaconda/pkgs/main/linux-64::libffi-3.3-he6710b0_2<br>  libgcc-ng          anaconda/pkgs/main/linux-64::libgcc-ng-11.2.0-h1234567_1<br>  libgomp            anaconda/pkgs/main/linux-64::libgomp-11.2.0-h1234567_1<br>  libstdcxx-ng       anaconda/pkgs/main/linux-64::libstdcxx-ng-11.2.0-h1234567_1<br>  ncurses            anaconda/pkgs/main/linux-64::ncurses-6.4-h6a678d5_0<br>  openssl            anaconda/pkgs/main/linux-64::openssl-1.1.1w-h7f8727e_0<br>  pip                anaconda/pkgs/main/linux-64::pip-21.2.2-py36h06a4308_0<br>  python             anaconda/pkgs/main/linux-64::python-3.6.13-h12debd9_1<br>  readline           anaconda/pkgs/main/linux-64::readline-8.2-h5eee18b_0<br>  setuptools         anaconda/pkgs/main/linux-64::setuptools-58.0.4-py36h06a4308_0<br>  sqlite             anaconda/pkgs/main/linux-64::sqlite-3.45.3-h5eee18b_0<br>  tk                 anaconda/pkgs/main/linux-64::tk-8.6.14-h39e8969_0<br>  wheel              anaconda/pkgs/main/noarch::wheel-0.37.1-pyhd3eb1b0_0<br>  xz                 anaconda/pkgs/main/linux-64::xz-5.4.6-h5eee18b_1<br>  zlib               anaconda/pkgs/main/linux-64::zlib-1.2.13-h5eee18b_1<br><br><br>Proceed ([y]/n)? y<br><br><br>Downloading and Extracting Packages:<br><br>Preparing transaction: <span class="hljs-keyword">done</span><br>Verifying transaction: <span class="hljs-keyword">done</span><br>Executing transaction: <span class="hljs-keyword">done</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># To activate this environment, use</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#     $ conda activate torch-1.6</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment"># To deactivate an active environment, use</span><br><span class="hljs-comment">#</span><br><span class="hljs-comment">#     $ conda deactivate</span><br></code></pre></td></tr></table></figure></details><p><strong>激活环境</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda activate torch-1.6<br></code></pre></td></tr></table></figure><p><strong>安装Pytorch 1.6</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">conda install pytorch==1.6.0 torchvision==0.7.0 -c pytorch<br></code></pre></td></tr></table></figure><details><summary>安装的log</summary><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br></pre></td><td class="code"><pre><code class="hljs bash">$ conda install pytorch==1.6.0 torchvision==0.7.0 -c pytorch<br>Channels:<br> - pytorch<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br> - https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free<br> - defaults<br>Platform: linux-64<br>Collecting package metadata (repodata.json): <span class="hljs-keyword">done</span><br>Solving environment: <span class="hljs-keyword">done</span><br><br><span class="hljs-comment">## Package Plan ##</span><br><br>  environment location: /home/&lt;user&gt;/anaconda3/envs/torch-1.6<br><br>  added / updated specs:<br>    - pytorch==1.6.0<br>    - torchvision==0.7.0<br><br><br>The following packages will be downloaded:<br><br>    package                    |            build<br>    ---------------------------|-----------------<br>    cudatoolkit-10.2.89        |       hfd86e86_1       365.1 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    giflib-5.2.1               |       h5eee18b_3          80 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    intel-openmp-2022.1.0      |    h9e868ea_3769         4.5 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libgfortran-ng-7.5.0       |      ha8ba4b0_17          22 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libgfortran4-7.5.0         |      ha8ba4b0_17         995 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libwebp-1.2.4              |       h11a3e52_1          86 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    libwebp-base-1.2.4         |       h5eee18b_1         376 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    mkl-2022.1.0               |     hc2b9512_224       129.7 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    ninja-1.10.2               |       h06a4308_5           8 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    ninja-base-1.10.2          |       hd09550d_5         109 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    numpy-1.14.2               |   py36hdbf6ddf_0         3.2 MB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    olefile-0.46               |     pyhd3eb1b0_0          34 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    pillow-8.3.1               |   py36h5aabda8_0         638 KB  https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main<br>    pytorch-1.6.0              |py3.6_cuda10.2.89_cudnn7.6.5_0       537.3 MB  pytorch<br>    torchvision-0.7.0          |       py36_cu102        11.0 MB  pytorch<br>    ------------------------------------------------------------<br>                                           Total:        1.03 GB<br><br>The following NEW packages will be INSTALLED:<br><br>  blas               anaconda/pkgs/main/linux-64::blas-1.0-mkl<br>  cudatoolkit        anaconda/pkgs/main/linux-64::cudatoolkit-10.2.89-hfd86e86_1<br>  freetype           anaconda/pkgs/main/linux-64::freetype-2.12.1-h4a9f257_0<br>  giflib             anaconda/pkgs/main/linux-64::giflib-5.2.1-h5eee18b_3<br>  intel-openmp       anaconda/pkgs/main/linux-64::intel-openmp-2022.1.0-h9e868ea_3769<br>  jpeg               anaconda/pkgs/main/linux-64::jpeg-9e-h5eee18b_1<br>  lcms2              anaconda/pkgs/main/linux-64::lcms2-2.12-h3be6417_0<br>  lerc               anaconda/pkgs/main/linux-64::lerc-3.0-h295c915_0<br>  libdeflate         anaconda/pkgs/main/linux-64::libdeflate-1.17-h5eee18b_1<br>  libgfortran-ng     anaconda/pkgs/main/linux-64::libgfortran-ng-7.5.0-ha8ba4b0_17<br>  libgfortran4       anaconda/pkgs/main/linux-64::libgfortran4-7.5.0-ha8ba4b0_17<br>  libpng             anaconda/pkgs/main/linux-64::libpng-1.6.39-h5eee18b_0<br>  libtiff            anaconda/pkgs/main/linux-64::libtiff-4.5.1-h6a678d5_0<br>  libwebp            anaconda/pkgs/main/linux-64::libwebp-1.2.4-h11a3e52_1<br>  libwebp-base       anaconda/pkgs/main/linux-64::libwebp-base-1.2.4-h5eee18b_1<br>  lz4-c              anaconda/pkgs/main/linux-64::lz4-c-1.9.4-h6a678d5_1<br>  mkl                anaconda/pkgs/main/linux-64::mkl-2022.1.0-hc2b9512_224<br>  ninja              anaconda/pkgs/main/linux-64::ninja-1.10.2-h06a4308_5<br>  ninja-base         anaconda/pkgs/main/linux-64::ninja-base-1.10.2-hd09550d_5<br>  numpy              anaconda/pkgs/main/linux-64::numpy-1.14.2-py36hdbf6ddf_0<br>  olefile            anaconda/pkgs/main/noarch::olefile-0.46-pyhd3eb1b0_0<br>  pillow             anaconda/pkgs/main/linux-64::pillow-8.3.1-py36h5aabda8_0<br>  pytorch            pytorch/linux-64::pytorch-1.6.0-py3.6_cuda10.2.89_cudnn7.6.5_0<br>  torchvision        pytorch/linux-64::torchvision-0.7.0-py36_cu102<br>  zstd               anaconda/pkgs/main/linux-64::zstd-1.5.5-hc292b87_2<br><br><br>Proceed ([y]/n)? y<br><br><br>Downloading and Extracting Packages:<br><br>Preparing transaction: <span class="hljs-keyword">done</span><br>Verifying transaction: <span class="hljs-keyword">done</span><br>Executing transaction: <span class="hljs-keyword">done</span><br></code></pre></td></tr></table></figure></details><p><strong>Conda删除环境</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 退出当前环境</span><br>$ conda deactivate<br><br><span class="hljs-comment"># 列出当前env</span><br>$ conda <span class="hljs-built_in">env</span> list<br><span class="hljs-comment"># conda environments:</span><br><span class="hljs-comment">#</span><br>base                     /home/&lt;user&gt;/anaconda3<br>torch-1.6             *  /home/&lt;user&gt;/anaconda3/envs/torch-1.6<br><br><span class="hljs-comment"># 删除</span><br>$ conda <span class="hljs-built_in">env</span> remove -p /home/&lt;user&gt;/anaconda3/envs/torch-1.6<br></code></pre></td></tr></table></figure><p><strong>不用Anaconda，使用python虚拟env</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install python3-venv<br>python3.6 -m venv myenv<br><span class="hljs-built_in">source</span> myenv/bin/activate<br><br>pip install torch==1.6.0+cpu torchvision==0.7.0+cpu -f https://download.pytorch.org/whl/torch_stable.html<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="安装-pytorch-cuda-版本"><a href="#安装-pytorch-cuda-版本" class="headerlink" title="安装 pytorch cuda 版本"></a>安装 pytorch cuda 版本</h2><p>在RTX4070S windows中配置WSL相关的AI环境，包括CUDA，PyTorch，Cudnn等</p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-4b838b6a" role="button" aria-expanded="false" aria-controls="collapse-4b838b6a">        <div class="fold-arrow">▶</div>步骤      </div>      <div class="fold-collapse collapse" id="collapse-4b838b6a">        <div class="fold-content">          <p><strong>安装WSL&#x2F;Docker&#x2F;Nvidia：</strong><br><a href="https://blog.csdn.net/ndscvipuser/article/details/136610169">Windows 下让 Docker Desktop 关联上 NVidia GPU</a><br><a href="https://blog.csdn.net/dghcs18/article/details/134244426">如何查看wsl是wsl1还是wsl2</a><br><a href="https://docs.nvidia.com/datacenter/cloud-native/container-toolkit/latest/install-guide.html">Nvidia WSL官方指引</a><br><a href="https://blog.csdn.net/weixin_55274216/article/details/137630257">linux上cuda相关包与opencv及相关模块安装（wsl+ubuntu22.04）</a></p><blockquote><p>注意：WSL不需要装cuda驱动，丢在win host安装，比如Geforce等驱动软件，安装完成后运行<code>nvidia-smi</code></p></blockquote><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># Powershell中测试</span><br>docker run --<span class="hljs-built_in">rm</span> --runtime=nvidia --gpus all ubuntu nvidia-smi<br></code></pre></td></tr></table></figure><p>Docker Desktop中的设置：</p><p><img src="/img/ai/docker_set1.png" alt="1"><br><img src="/img/ai/docker_set2.png" alt="2"></p><p>测试结果：</p><p><img src="/img/ai/docker.png" alt="3"></p><p>WSL中测试：</p><p><img src="/img/ai/wsl.png" alt="4"></p><p>安装<a href="https://developer.nvidia.cn/cuda-downloads">cuda toolkit</a></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://developer.download.nvidia.com/compute/cuda/repos/wsl-ubuntu/x86_64/cuda-wsl-ubuntu.pin<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">mv</span> cuda-wsl-ubuntu.pin /etc/apt/preferences.d/cuda-repository-pin-600<br>wget https://developer.download.nvidia.com/compute/cuda/12.4.1/local_installers/cuda-repo-wsl-ubuntu-12-4-local_12.4.1-1_amd64.deb<br><span class="hljs-built_in">sudo</span> dpkg -i cuda-repo-wsl-ubuntu-12-4-local_12.4.1-1_amd64.deb<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">cp</span> /var/cuda-repo-wsl-ubuntu-12-4-<span class="hljs-built_in">local</span>/cuda-*-keyring.gpg /usr/share/keyrings/<br><span class="hljs-built_in">sudo</span> apt-get update<br><span class="hljs-built_in">sudo</span> apt-get -y install cuda-toolkit-12-4<br><br><span class="hljs-comment"># ~/.bashrc</span><br><span class="hljs-built_in">export</span> LD_LIBRARY_PATH=/usr/local/cuda/lib64<br><span class="hljs-built_in">export</span> PATH=<span class="hljs-variable">$PATH</span>:/usr/local/cuda/bin<br><br>nvcc -V<br>nvcc: NVIDIA (R) Cuda compiler driver<br>Copyright (c) 2005-2024 NVIDIA Corporation<br>Built on Thu_Mar_28_02:18:24_PDT_2024<br>Cuda compilation tools, release 12.4, V12.4.131<br>Build cuda_12.4.r12.4/compiler.34097967_0<br></code></pre></td></tr></table></figure><p><strong>安装Conda</strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment">#创建环境</span><br>conda init<br>conda create -n torch-gpu  python=3.9<br>conda activate torch-gpu<br><br><span class="hljs-comment">#换源，参考https://blog.csdn.net/watermelon1123/article/details/88122020</span><br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/free/<br>conda config --add channels https://mirrors.tuna.tsinghua.edu.cn/anaconda/pkgs/main/<br>conda config --<span class="hljs-built_in">set</span> show_channel_urls <span class="hljs-built_in">yes</span><br><br><span class="hljs-comment">#安装torch，命令在 https://pytorch.org/ 寻找</span><br>conda install pytorch torchvision torchaudio pytorch-cuda=12.1 -c pytorch-nightly -c nvidia<br><br><span class="hljs-comment"># ~/.bashrc</span><br>conda activate torch-gpu<br></code></pre></td></tr></table></figure><p><strong>安装cuDNN：<a href="https://developer.nvidia.com/cudnn-downloads">https://developer.nvidia.com/cudnn-downloads</a></strong></p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">wget https://developer.download.nvidia.com/compute/cudnn/9.2.0/local_installers/cudnn-local-repo-ubuntu2004-9.2.0_1.0-1_amd64.deb<br><span class="hljs-built_in">sudo</span> dpkg -i cudnn-local-repo-ubuntu2004-9.2.0_1.0-1_amd64.deb<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">cp</span> /var/cudnn-local-repo-ubuntu2004-9.2.0/cudnn-*-keyring.gpg /usr/share/keyrings/<br><span class="hljs-built_in">sudo</span> apt-get update<br><span class="hljs-built_in">sudo</span> apt-get -y install cudnn-cuda-12<br><br><span class="hljs-comment"># 查看版本</span><br><span class="hljs-built_in">cat</span> /usr/include/cudnn_version.h | grep CUDNN_MAJOR -A 2<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h2 id="pytorch-book-vscode-环境配置"><a href="#pytorch-book-vscode-环境配置" class="headerlink" title="pytorch book vscode 环境配置"></a>pytorch book vscode 环境配置</h2>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-cb5c858a" role="button" aria-expanded="false" aria-controls="collapse-cb5c858a">        <div class="fold-arrow">▶</div>步骤      </div>      <div class="fold-collapse collapse" id="collapse-cb5c858a">        <div class="fold-content">          <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">git <span class="hljs-built_in">clone</span> git@github.com:chenyuntc/pytorch-book.git<br></code></pre></td></tr></table></figure><p>VScode安装插件</p><p><img src="/img/ai/torch-book-extension.png"></p><p>此时打开任意一个note可以看到代码变成可以执行的框了：</p><p><img src="/img/ai/vscode-load-python-1.png"></p><p>但是会显示torch未导入，点击左侧的执行三角形按钮，会提示选择安装必要的插件，安装完成后再次点击，会提示选择python版本</p><p><img src="/img/ai/vscode-load-python-11.png"></p><p>选择python环境，找到conda路径下的python解释器</p><p><img src="/img/ai/vscode-load-python-111.png"></p><p>再次点击左侧运行，弹出要安装pykernel包，点击安装完成后，可以在右上角看到环境和python版本，也可以点击此处继续更换环境。</p>        </div>      </div>    </div><h2 id="示例"><a href="#示例" class="headerlink" title="示例"></a>示例</h2><h3 id="线性回归"><a href="#线性回归" class="headerlink" title="线性回归"></a>线性回归</h3><p>梯度下降算法和auto grad自动求解梯度函数，参考 <a href="https://github.com/chenyuntc/pytorch-book"><strong>《深度学习框架PyTorch：入门与实战》代码</strong></a> 小试牛刀: 用autograd实现线性回归。</p><h3 id="fashion-mnist-手写数字分类"><a href="#fashion-mnist-手写数字分类" class="headerlink" title="fashion mnist 手写数字分类"></a>fashion mnist 手写数字分类</h3><p>参考Pytorch教程: <a href="https://pytorch.org/tutorials/beginner/basics/quickstart_tutorial.html">Quick Start</a></p>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-bca7c96c" role="button" aria-expanded="false" aria-controls="collapse-bca7c96c">        <div class="fold-arrow">▶</div>训练步骤      </div>      <div class="fold-collapse collapse" id="collapse-bca7c96c">        <div class="fold-content">          <ol><li>下载数据集</li><li>数据预处理等<a href="https://pytorch.org/tutorials/beginner/basics/data_tutorial.html">Data Tutorial</a></li><li>定义model，类型、层、前向函数和损失计算函数，并传递至device，如CPU或者CUDA，<a href="https://pytorch.org/tutorials/beginner/basics/buildmodel_tutorial.html">Build Model</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Sequential.html">Sequential</a>，构建连续的层<a href="https://blog.csdn.net/dss_dssssd/article/details/82980222">pytorch系列 nn.Sequential讲解</a></li><li>一些层级的简单介绍，<a href="https://yey.world/2020/12/16/Pytorch-13/">nn 网络层：池化层、线性层和激活函数层</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.ReLU.html">ReLU</a></li><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.Linear.html">Linear</a></li></ol></li></ol></li><li>优化损失计算，<a href="https://pytorch.org/tutorials/beginner/basics/optimization_tutorial.html">Optimization Tutorials</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.nn.CrossEntropyLoss.html">交叉熵损失Cross Entropy Loss</a>，参考<a href="https://blog.csdn.net/chao_shine/article/details/89925762">交叉熵损失函数原理及Pytorch代码简介</a></li><li><a href="https://zhuanlan.zhihu.com/p/78622301">Pytorch中常用的四种优化器SGD、Momentum、RMSProp、Adam</a><ol><li><a href="https://pytorch.org/docs/stable/generated/torch.optim.SGD.html">SGD</a></li></ol></li></ol></li><li>训练，导入数据，计算损失，调用前向函数</li><li>测试，对测试集预测，计算预测结果争取率</li><li>保存模型，<a href="https://pytorch.org/tutorials/beginner/basics/saveloadrun_tutorial.html">Save &amp; Load &amp; Run</a></li></ol>        </div>      </div>    </div>    <div class="fold">      <div class="fold-title fold-default collapsed" data-toggle="collapse" href="#collapse-2063547c" role="button" aria-expanded="false" aria-controls="collapse-2063547c">        <div class="fold-arrow">▶</div>测试模型      </div>      <div class="fold-collapse collapse" id="collapse-2063547c">        <div class="fold-content">          <figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br></pre></td><td class="code"><pre><code class="hljs python"><span class="hljs-keyword">import</span> torch<br><span class="hljs-keyword">from</span> torch <span class="hljs-keyword">import</span> nn<br><span class="hljs-keyword">from</span> torchvision <span class="hljs-keyword">import</span> datasets<br><span class="hljs-keyword">from</span> torchvision.transforms <span class="hljs-keyword">import</span> ToTensor<br><br>test_data = datasets.FashionMNIST(<br>    root=<span class="hljs-string">&quot;data&quot;</span>,<br>    train=<span class="hljs-literal">False</span>,<br>    download=<span class="hljs-literal">True</span>,<br>    transform=ToTensor(),<br>)<br><br>device = (<br>    <span class="hljs-string">&quot;cuda&quot;</span><br>    <span class="hljs-keyword">if</span> torch.cuda.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;mps&quot;</span><br>    <span class="hljs-keyword">if</span> torch.backends.mps.is_available()<br>    <span class="hljs-keyword">else</span> <span class="hljs-string">&quot;cpu&quot;</span><br>)<br><span class="hljs-built_in">print</span>(<span class="hljs-string">f&quot;Using <span class="hljs-subst">&#123;device&#125;</span> device&quot;</span>)<br><br><br><span class="hljs-keyword">class</span> <span class="hljs-title class_">NeuralNetwork</span>(nn.Module):<br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">__init__</span>(<span class="hljs-params">self</span>):<br>        <span class="hljs-built_in">super</span>().__init__()<br>        <span class="hljs-variable language_">self</span>.flatten = nn.Flatten()<br>        <span class="hljs-variable language_">self</span>.linear_relu_stack = nn.Sequential(<br>            nn.Linear(<span class="hljs-number">28</span>*<span class="hljs-number">28</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">512</span>),<br>            nn.ReLU(),<br>            nn.Linear(<span class="hljs-number">512</span>, <span class="hljs-number">10</span>)<br>        )<br><br>    <span class="hljs-keyword">def</span> <span class="hljs-title function_">forward</span>(<span class="hljs-params">self, x</span>):<br>        x = <span class="hljs-variable language_">self</span>.flatten(x)<br>        logits = <span class="hljs-variable language_">self</span>.linear_relu_stack(x)<br>        <span class="hljs-keyword">return</span> logits<br><br>model = NeuralNetwork().to(device)<br>model.load_state_dict(torch.load(<span class="hljs-string">&quot;model.pth&quot;</span>))<br><br><br>classes = [<br>    <span class="hljs-string">&quot;T-shirt/top&quot;</span>,<br>    <span class="hljs-string">&quot;Trouser&quot;</span>,<br>    <span class="hljs-string">&quot;Pullover&quot;</span>,<br>    <span class="hljs-string">&quot;Dress&quot;</span>,<br>    <span class="hljs-string">&quot;Coat&quot;</span>,<br>    <span class="hljs-string">&quot;Sandal&quot;</span>,<br>    <span class="hljs-string">&quot;Shirt&quot;</span>,<br>    <span class="hljs-string">&quot;Sneaker&quot;</span>,<br>    <span class="hljs-string">&quot;Bag&quot;</span>,<br>    <span class="hljs-string">&quot;Ankle boot&quot;</span>,<br>]<br><br>model.<span class="hljs-built_in">eval</span>()<br><br>x, y = test_data[<span class="hljs-number">1</span>][<span class="hljs-number">0</span>], test_data[<span class="hljs-number">1</span>][<span class="hljs-number">1</span>]<br><span class="hljs-keyword">with</span> torch.no_grad():<br>    x = x.to(device)<br>    pred = model(x)<br>    predicted, actual = classes[pred[<span class="hljs-number">0</span>].argmax(<span class="hljs-number">0</span>)], classes[y]<br>    <span class="hljs-built_in">print</span>(<span class="hljs-string">f&#x27;Predicted: &quot;<span class="hljs-subst">&#123;predicted&#125;</span>&quot;, Actual: &quot;<span class="hljs-subst">&#123;actual&#125;</span>&quot;&#x27;</span>)<br></code></pre></td></tr></table></figure>        </div>      </div>    </div><h3 id="cifar-10"><a href="#cifar-10" class="headerlink" title="cifar 10"></a>cifar 10</h3><p>参考 <a href="https://github.com/chenyuntc/pytorch-book"><strong>《深度学习框架PyTorch：入门与实战》代码</strong></a> 2.2.4 小试牛刀：CIFAR-10分类。</p>]]></content>
    
    
    <categories>
      
      <category>AI</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
      <tag>Algorithm</tag>
      
      <tag>CUDA</tag>
      
      <tag>Pytorch</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>装机记录</title>
    <link href="/2024/06/20/DIY-PC/"/>
    <url>/2024/06/20/DIY-PC/</url>
    
    <content type="html"><![CDATA[<p>MATX 和 ITX 装机</p><span id="more"></span><h1 id="ITX-白"><a href="#ITX-白" class="headerlink" title="ITX 白"></a>ITX 白</h1><p>娱乐大师170w分，双烤CPU 80度（积木风扇买反了），GPU 72度。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/itx2.jpg" alt="理线"></div><div class="group-image-wrap"><img src="/img/pc/itx3.jpg" alt="点亮"></div><div class="group-image-wrap"><img src="/img/pc/itx1.jpg" alt="成品"></div></div></div><h2 id="清单"><a href="#清单" class="headerlink" title="清单"></a>清单</h2><table><thead><tr><th align="center"><span style="display:inline-block;width:100px">模块</span></th><th align="center"><span style="display:inline-block;width:600px">型号</span></th><th align="center"><span style="display:inline-block;width:100px">价格</span></th></tr></thead><tbody><tr><td align="center">CPU</td><td align="center">Intel i5-12600KF</td><td align="center">￥1199</td></tr><tr><td align="center">GPU</td><td align="center">微星万图师 GeForce RTX 4060 2X OC 小白龙</td><td align="center">￥2220</td></tr><tr><td align="center">固态</td><td align="center">长城 1 TB SSD M.2接口（NVMe协议）</td><td align="center">￥467</td></tr><tr><td align="center">内存</td><td align="center">光威 D5 6400 32 GB</td><td align="center">￥ 695</td></tr><tr><td align="center">主板</td><td align="center">七彩虹 B760i WIFI D5</td><td align="center">￥996</td></tr><tr><td align="center">散热</td><td align="center">利民 SI 100 白色 ARGB</td><td align="center">￥198</td></tr><tr><td align="center">电源</td><td align="center">神雕十三道金牌 SFX650 白</td><td align="center">￥487</td></tr><tr><td align="center">风扇</td><td align="center">利民 TL-C12CW 白 x 1 + TL-B8W 白 x 2</td><td align="center">￥141</td></tr><tr><td align="center">机箱</td><td align="center">Rider R2 白 五代</td><td align="center">￥545</td></tr><tr><td align="center">定制线</td><td align="center">Rider R2 定制线 白，UmCat 极致猫</td><td align="center">￥120</td></tr><tr><td align="center">积木风扇</td><td align="center">联力积木风扇 TL LCD 四代 120 正叶</td><td align="center">￥368</td></tr><tr><td align="center">风扇控制器</td><td align="center">联力积木风扇 TL LCD 四代</td><td align="center">￥293</td></tr></tbody></table><p>注：</p><ul><li>积木风扇一定要买正叶</li><li>下压散热器 SI 100 不兼容积木风扇，如需积木风扇，需买 ID-Cooling IS-67XT，才能安装积木风扇</li><li>下压散热器的开口朝上（铜管在机箱下方），散热鳍片缝隙水平</li><li>尽量买低一些的内存条，太高会妨碍散热器，我是暴力怼上去的</li><li>尽量买薄一些的 8cm 风扇，以及 12 cm 风扇，推荐不差钱买猫扇</li><li>风扇控制器尽量买白色，目前白色黑色均缺货严重</li><li>机箱白色缺货严重</li></ul><h1 id="MATX-黑"><a href="#MATX-黑" class="headerlink" title="MATX 黑"></a>MATX 黑</h1><p>娱乐大师 230w 分。</p><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/all.jpg" alt="点亮"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/zhijia.jpg" alt="支架"></div><div class="group-image-wrap"><img src="/img/pc/light.jpg" alt="内存灯"></div></div></div><h2 id="清单-1"><a href="#清单-1" class="headerlink" title="清单"></a>清单</h2><table><thead><tr><th align="center"><span style="display:inline-block;width:100px">模块</span></th><th align="center"><span style="display:inline-block;width:600px">型号</span></th><th align="center"><span style="display:inline-block;width:100px">价格</span></th></tr></thead><tbody><tr><td align="center">CPU</td><td align="center">Intel i5-13600KF</td><td align="center">￥1799</td></tr><tr><td align="center">GPU</td><td align="center">（丐卡）微星万图师 GeForce RTX 4070S 12 GB Ventus 3X OC</td><td align="center">￥4874</td></tr><tr><td align="center">固态</td><td align="center">宏碁 2TB + 1TB GM7000系列 SSD M.2接口（NVMe协议）</td><td align="center">￥1421</td></tr><tr><td align="center">内存</td><td align="center">宏碁 32G（16GB x 2） DDR5 6800</td><td align="center">￥ 795</td></tr><tr><td align="center">主板</td><td align="center">华硕 TUF GAMING  B760M-PLUS WIFI II</td><td align="center">￥1243</td></tr><tr><td align="center">散热</td><td align="center">ID-COOLING SE-207-XT 黑</td><td align="center">￥183</td></tr><tr><td align="center">电源</td><td align="center">神雕十三道金牌 SFX750（ATX 3.0 16pin）</td><td align="center">￥497</td></tr><tr><td align="center">风扇</td><td align="center">利民 TL-C12C x 5</td><td align="center">￥75</td></tr><tr><td align="center">机箱</td><td align="center">机械大师 C28 脉冲 MATX</td><td align="center">￥693</td></tr><tr><td align="center">定制线</td><td align="center">机械大师 C 系列，定制显卡线 12vhpwr + 4 Pin（16pin）</td><td align="center">￥185</td></tr><tr><td align="center">显示器</td><td align="center">EHOMEWEI 2K144Hz</td><td align="center">￥1096</td></tr><tr><td align="center">鼠标</td><td align="center">罗技 G102</td><td align="center">￥108</td></tr><tr><td align="center">U 盘</td><td align="center">爱国者 16 GB</td><td align="center">￥19</td></tr></tbody></table><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/total.jpg" alt="全家福"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/mem.jpg" alt="内存条"></div><div class="group-image-wrap"><img src="/img/pc/ssd.jpg" alt="固态"></div><div class="group-image-wrap"><img src="/img/pc/board.jpg" alt="板U"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/gpu.jpg" alt="丐卡"></div></div></div><h2 id="过程"><a href="#过程" class="headerlink" title="过程"></a>过程</h2><ul><li>拆机箱</li><li>主板安装CPU、散热器（背夹，支架，风扇）</li><li>主板安装内存、固态（安装散热马甲）</li><li>主板插线，电源线、风扇线</li><li>安装主板至机箱，插上开关接线和Type-C线</li><li>安装风扇，理线</li><li>安装电源，接线，理线</li><li>安装显卡，插上电源线，理线</li><li>点亮</li><li>安装系统、驱动</li><li>跑分</li><li>安装机箱</li></ul><blockquote><p>点亮可以在机箱装主板之前验证，只要相信自己，一步到位也可以</p></blockquote><div class="group-image-container"><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/pwr.jpg" alt="开关线"></div></div><div class="group-image-row"><div class="group-image-wrap"><img src="/img/pc/fans.jpg" alt="风扇理线"></div><div class="group-image-wrap"><img src="/img/pc/lines.jpg" alt="理线"></div></div><div class="group-image-row"></div></div><h2 id="插曲"><a href="#插曲" class="headerlink" title="插曲"></a>插曲</h2><ul><li>开机没进bios，主板亮黄灯，因为内存条没插紧</li><li>没有wifi驱动，连有线来下载驱动</li><li>win官网制作的U盘也要激活系统</li></ul>]]></content>
    
    
    <categories>
      
      <category>GPU</category>
      
    </categories>
    
    
    <tags>
      
      <tag>GPU</tag>
      
      <tag>AI</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>Leetcode主要算法汇总</title>
    <link href="/2024/01/19/Leetcode-2024/"/>
    <url>/2024/01/19/Leetcode-2024/</url>
    
    <content type="html"><![CDATA[<p>Leetcode题解汇总。统计到<code>NO.500</code>。</p><span id="more"></span><h2 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h2><ul><li><a href="#%E7%9B%AE%E5%BD%95">目录</a></li><li><a href="#%E9%93%BE%E8%A1%A8">链表</a><ul><li><a href="#19-%E5%88%A0%E9%99%A4%E9%93%BE%E8%A1%A8%E7%9A%84%E5%80%92%E6%95%B0%E7%AC%ACn%E4%B8%AA%E7%BB%93%E7%82%B9">19. 删除链表的倒数第N个结点</a></li><li><a href="#21-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E9%93%BE%E8%A1%A8">21. 合并两个有序链表</a></li><li><a href="#23-%E5%90%88%E5%B9%B6-k-%E4%B8%AA%E5%8D%87%E5%BA%8F%E9%93%BE%E8%A1%A8">23. 合并 K 个升序链表</a></li><li><a href="#24-%E4%B8%A4%E4%B8%A4%E4%BA%A4%E6%8D%A2%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E8%8A%82%E7%82%B9">24. 两两交换链表中的节点</a></li><li><a href="#25-k-%E4%B8%AA%E4%B8%80%E7%BB%84%E7%BF%BB%E8%BD%AC%E9%93%BE%E8%A1%A8">25. K 个一组翻转链表</a></li><li><a href="#61-%E6%97%8B%E8%BD%AC%E9%93%BE%E8%A1%A8">61. 旋转链表</a></li><li><a href="#82-%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0-ii">82. 删除排序链表中的重复元素 II</a></li><li><a href="#83-%E5%88%A0%E9%99%A4%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E5%85%83%E7%B4%A0">83. 删除排序链表中的重复元素</a></li><li><a href="#86-%E5%88%86%E9%9A%94%E9%93%BE%E8%A1%A8">86. 分隔链表</a></li><li><a href="#92-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8-ii">92. 反转链表 II</a></li><li><a href="#141-%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8">141. 环形链表</a></li><li><a href="#142-%E7%8E%AF%E5%BD%A2%E9%93%BE%E8%A1%A8-ii">142. 环形链表 II</a></li><li><a href="#148-%E6%8E%92%E5%BA%8F%E9%93%BE%E8%A1%A8">148. 排序链表</a></li><li><a href="#206-%E5%8F%8D%E8%BD%AC%E9%93%BE%E8%A1%A8">206. 反转链表</a></li><li><a href="#328-%E5%A5%87%E5%81%B6%E9%93%BE%E8%A1%A8">328. 奇偶链表</a></li></ul></li><li><a href="#dfs">DFS</a><ul><li><a href="#22-%E6%8B%AC%E5%8F%B7%E7%94%9F%E6%88%90">22. 括号生成</a></li><li><a href="#39-%E7%BB%84%E5%90%88%E6%80%BB%E5%92%8C">39. 组合总和</a></li><li><a href="#40-%E7%BB%84%E5%90%88%E6%80%BB%E5%92%8C-ii">40. 组合总和 II</a></li><li><a href="#46-%E5%85%A8%E6%8E%92%E5%88%97">46. 全排列</a></li><li><a href="#77-%E7%BB%84%E5%90%88">77. 组合</a></li><li><a href="#78-%E5%AD%90%E9%9B%86">78. 子集</a></li><li><a href="#130-%E8%A2%AB%E5%9B%B4%E7%BB%95%E7%9A%84%E5%8C%BA%E5%9F%9F">130. 被围绕的区域</a></li><li><a href="#200-%E5%B2%9B%E5%B1%BF%E6%95%B0%E9%87%8F">200. 岛屿数量</a></li><li><a href="#207-%E8%AF%BE%E7%A8%8B%E8%A1%A8">207. 课程表</a></li><li><a href="#210-%E8%AF%BE%E7%A8%8B%E8%A1%A8-ii">210. 课程表 II</a></li></ul></li><li><a href="#%E5%8A%A8%E6%80%81%E8%A7%84%E5%88%92">动态规划</a><ul><li><a href="#5-%E6%9C%80%E9%95%BF%E5%9B%9E%E6%96%87%E5%AD%90%E4%B8%B2">5. 最长回文子串</a></li><li><a href="#32-%E6%9C%80%E9%95%BF%E6%9C%89%E6%95%88%E6%8B%AC%E5%8F%B7">32. 最长有效括号</a></li><li><a href="#45-%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F-ii">45. 跳跃游戏 II</a></li><li><a href="#53-%E6%9C%80%E5%A4%A7%E5%AD%90%E6%95%B0%E7%BB%84%E5%92%8C">53. 最大子数组和</a></li><li><a href="#55-%E8%B7%B3%E8%B7%83%E6%B8%B8%E6%88%8F">55. 跳跃游戏</a></li><li><a href="#62-%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84">62. 不同路径</a></li><li><a href="#63-%E4%B8%8D%E5%90%8C%E8%B7%AF%E5%BE%84-ii">63. 不同路径 II</a></li><li><a href="#64-%E6%9C%80%E5%B0%8F%E8%B7%AF%E5%BE%84%E5%92%8C">64. 最小路径和</a></li><li><a href="#72-%E7%BC%96%E8%BE%91%E8%B7%9D%E7%A6%BB">72. 编辑距离</a></li><li><a href="#79-%E5%8D%95%E8%AF%8D%E6%90%9C%E7%B4%A2">79. 单词搜索</a></li><li><a href="#97-%E4%BA%A4%E9%94%99%E5%AD%97%E7%AC%A6%E4%B8%B2">97. 交错字符串</a></li><li><a href="#122-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-ii">122. 买卖股票的最佳时机 II</a></li><li><a href="#123-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-iii">123. 买卖股票的最佳时机 III</a></li><li><a href="#188-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-iv">188. 买卖股票的最佳时机 IV</a></li><li><a href="#309-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA%E5%90%AB%E5%86%B7%E5%86%BB%E6%9C%9F">309. 买卖股票的最佳时机含冷冻期</a></li><li><a href="#714-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA%E5%90%AB%E6%89%8B%E7%BB%AD%E8%B4%B9">714. 买卖股票的最佳时机含手续费</a></li><li><a href="#198-%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D">198. 打家劫舍</a></li><li><a href="#213-%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D-ii">213. 打家劫舍 II</a></li><li><a href="#221-%E6%9C%80%E5%A4%A7%E6%AD%A3%E6%96%B9%E5%BD%A2">221. 最大正方形</a></li><li><a href="#279-%E5%AE%8C%E5%85%A8%E5%B9%B3%E6%96%B9%E6%95%B0">279. 完全平方数</a></li><li><a href="#300-%E6%9C%80%E9%95%BF%E9%80%92%E5%A2%9E%E5%AD%90%E5%BA%8F%E5%88%97">300. 最长递增子序列</a></li></ul></li><li><a href="#%E4%BA%8C%E5%8F%89%E6%A0%91">二叉树</a><ul><li><a href="#144-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%89%8D%E5%BA%8F%E9%81%8D%E5%8E%86">144. 二叉树的前序遍历</a></li><li><a href="#94-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86">94. 二叉树的中序遍历</a></li><li><a href="#145-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86">145. 二叉树的后序遍历</a></li><li><a href="#95-%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91-ii">95. 不同的二叉搜索树 II</a></li><li><a href="#96-%E4%B8%8D%E5%90%8C%E7%9A%84%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91">96. 不同的二叉搜索树</a></li><li><a href="#98-%E9%AA%8C%E8%AF%81%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91">98. 验证二叉搜索树</a></li><li><a href="#99-%E6%81%A2%E5%A4%8D%E4%BA%8C%E5%8F%89%E6%90%9C%E7%B4%A2%E6%A0%91">99. 恢复二叉搜索树</a></li><li><a href="#100-%E7%9B%B8%E5%90%8C%E7%9A%84%E6%A0%91">100. 相同的树</a></li><li><a href="#101-%E5%AF%B9%E7%A7%B0%E4%BA%8C%E5%8F%89%E6%A0%91">101. 对称二叉树</a></li><li><a href="#102-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86">102. 二叉树的层序遍历</a></li><li><a href="#104-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%A4%A7%E6%B7%B1%E5%BA%A6">104. 二叉树的最大深度</a></li><li><a href="#105-%E4%BB%8E%E5%89%8D%E5%BA%8F%E4%B8%8E%E4%B8%AD%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91">105. 从前序与中序遍历序列构造二叉树</a></li><li><a href="#106-%E4%BB%8E%E4%B8%AD%E5%BA%8F%E4%B8%8E%E5%90%8E%E5%BA%8F%E9%81%8D%E5%8E%86%E5%BA%8F%E5%88%97%E6%9E%84%E9%80%A0%E4%BA%8C%E5%8F%89%E6%A0%91">106. 从中序与后序遍历序列构造二叉树</a></li><li><a href="#107-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E5%B1%82%E5%BA%8F%E9%81%8D%E5%8E%86-ii">107. 二叉树的层序遍历 II</a></li><li><a href="#110-%E5%B9%B3%E8%A1%A1%E4%BA%8C%E5%8F%89%E6%A0%91">110. 平衡二叉树</a></li><li><a href="#111-%E4%BA%8C%E5%8F%89%E6%A0%91%E7%9A%84%E6%9C%80%E5%B0%8F%E6%B7%B1%E5%BA%A6">111. 二叉树的最小深度</a></li><li><a href="#112-%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C">112. 路径总和</a></li><li><a href="#113-%E8%B7%AF%E5%BE%84%E6%80%BB%E5%92%8C-ii">113. 路径总和 II</a></li><li><a href="#114-%E4%BA%8C%E5%8F%89%E6%A0%91%E5%B1%95%E5%BC%80%E4%B8%BA%E9%93%BE%E8%A1%A8">114. 二叉树展开为链表</a></li><li><a href="#124-%E4%BA%8C%E5%8F%89%E6%A0%91%E4%B8%AD%E7%9A%84%E6%9C%80%E5%A4%A7%E8%B7%AF%E5%BE%84%E5%92%8C">124. 二叉树中的最大路径和</a></li><li><a href="#337-%E6%89%93%E5%AE%B6%E5%8A%AB%E8%88%8D-iii">337. 打家劫舍 III</a></li></ul></li><li><a href="#%E5%AD%97%E7%AC%A6%E4%B8%B2">字符串</a><ul><li><a href="#28-%E6%89%BE%E5%87%BA%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%AC%AC%E4%B8%80%E4%B8%AA%E5%8C%B9%E9%85%8D%E9%A1%B9%E7%9A%84%E4%B8%8B%E6%A0%87kmp">28. 找出字符串中第一个匹配项的下标（KMP）</a></li><li><a href="#43-%E5%AD%97%E7%AC%A6%E4%B8%B2%E7%9B%B8%E4%B9%98">43. 字符串相乘</a></li><li><a href="#58-%E6%9C%80%E5%90%8E%E4%B8%80%E4%B8%AA%E5%8D%95%E8%AF%8D%E7%9A%84%E9%95%BF%E5%BA%A6">58. 最后一个单词的长度</a></li><li><a href="#71-%E7%AE%80%E5%8C%96%E8%B7%AF%E5%BE%84">71. 简化路径</a></li><li><a href="#93-%E5%A4%8D%E5%8E%9F-ip-%E5%9C%B0%E5%9D%80">93. 复原 IP 地址</a></li></ul></li><li><a href="#%E6%95%B0%E5%AD%A6">数学</a><ul><li><a href="#50-powx-n">50. Pow(x, n)</a></li><li><a href="#136-%E5%8F%AA%E5%87%BA%E7%8E%B0%E4%B8%80%E6%AC%A1%E7%9A%84%E6%95%B0%E5%AD%97">136. 只出现一次的数字</a></li><li><a href="#172-%E9%98%B6%E4%B9%98%E5%90%8E%E7%9A%84%E9%9B%B6">172. 阶乘后的零</a></li><li><a href="#365-%E6%B0%B4%E5%A3%B6%E9%97%AE%E9%A2%98">365. 水壶问题</a></li><li><a href="#461-%E6%B1%89%E6%98%8E%E8%B7%9D%E7%A6%BB">461. 汉明距离</a></li></ul></li><li><a href="#%E6%95%B0%E7%BB%84">数组</a><ul><li><a href="#48-%E6%97%8B%E8%BD%AC%E5%9B%BE%E5%83%8F">48. 旋转图像</a></li><li><a href="#54-%E8%9E%BA%E6%97%8B%E7%9F%A9%E9%98%B5">54. 螺旋矩阵</a></li><li><a href="#56-%E5%90%88%E5%B9%B6%E5%8C%BA%E9%97%B4">56. 合并区间</a></li><li><a href="#66-%E5%8A%A0%E4%B8%80">66. 加一</a></li><li><a href="#85-%E6%9C%80%E5%A4%A7%E7%9F%A9%E5%BD%A2">85. 最大矩形</a></li><li><a href="#209-%E9%95%BF%E5%BA%A6%E6%9C%80%E5%B0%8F%E7%9A%84%E5%AD%90%E6%95%B0%E7%BB%84">209. 长度最小的子数组</a></li></ul></li><li><a href="#%E6%A0%88">栈</a><ul><li><a href="#20-%E6%9C%89%E6%95%88%E7%9A%84%E6%8B%AC%E5%8F%B7">20. 有效的括号</a></li><li><a href="#232-%E7%94%A8%E6%A0%88%E5%AE%9E%E7%8E%B0%E9%98%9F%E5%88%97">232. 用栈实现队列</a></li></ul></li><li><a href="#%E5%8F%8C%E6%8C%87%E9%92%88">双指针</a><ul><li><a href="#11-%E7%9B%9B%E6%9C%80%E5%A4%9A%E6%B0%B4%E7%9A%84%E5%AE%B9%E5%99%A8">11. 盛最多水的容器</a></li><li><a href="#26-%E5%88%A0%E9%99%A4%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9">26. 删除有序数组中的重复项</a></li><li><a href="#27-%E7%A7%BB%E9%99%A4%E5%85%83%E7%B4%A0">27. 移除元素</a></li><li><a href="#31-%E4%B8%8B%E4%B8%80%E4%B8%AA%E6%8E%92%E5%88%97">31. 下一个排列</a></li><li><a href="#42-%E6%8E%A5%E9%9B%A8%E6%B0%B4">42. 接雨水</a></li><li><a href="#75-%E9%A2%9C%E8%89%B2%E5%88%86%E7%B1%BB">75. 颜色分类</a></li><li><a href="#80-%E5%88%A0%E9%99%A4%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84%E4%B8%AD%E7%9A%84%E9%87%8D%E5%A4%8D%E9%A1%B9-ii">80. 删除有序数组中的重复项 II</a></li><li><a href="#88-%E5%90%88%E5%B9%B6%E4%B8%A4%E4%B8%AA%E6%9C%89%E5%BA%8F%E6%95%B0%E7%BB%84">88. 合并两个有序数组</a></li><li><a href="#283-%E7%A7%BB%E5%8A%A8%E9%9B%B6">283. 移动零</a></li><li><a href="#345-%E5%8F%8D%E8%BD%AC%E5%AD%97%E7%AC%A6%E4%B8%B2%E4%B8%AD%E7%9A%84%E5%85%83%E9%9F%B3%E5%AD%97%E6%AF%8D">345. 反转字符串中的元音字母</a></li><li><a href="#455-%E5%88%86%E5%8F%91%E9%A5%BC%E5%B9%B2">455. 分发饼干</a></li></ul></li><li><a href="#%E5%93%88%E5%B8%8C%E8%A1%A8">哈希表</a><ul><li><a href="#1-%E4%B8%A4%E6%95%B0%E4%B9%8B%E5%92%8C">1. 两数之和</a></li><li><a href="#3-%E6%97%A0%E9%87%8D%E5%A4%8D%E5%AD%97%E7%AC%A6%E7%9A%84%E6%9C%80%E9%95%BF%E5%AD%90%E4%B8%B2">3. 无重复字符的最长子串</a></li><li><a href="#76-%E6%9C%80%E5%B0%8F%E8%A6%86%E7%9B%96%E5%AD%90%E4%B8%B2">76. 最小覆盖子串</a></li><li><a href="#128-%E6%9C%80%E9%95%BF%E8%BF%9E%E7%BB%AD%E5%BA%8F%E5%88%97">128. 最长连续序列</a></li><li><a href="#202-%E5%BF%AB%E4%B9%90%E6%95%B0">202. 快乐数</a></li></ul></li><li><a href="#%E4%BA%8C%E5%88%86">二分</a><ul><li><a href="#74-%E6%90%9C%E7%B4%A2%E4%BA%8C%E7%BB%B4%E7%9F%A9%E9%98%B5">74. 搜索二维矩阵</a></li><li><a href="#162-%E5%AF%BB%E6%89%BE%E5%B3%B0%E5%80%BC">162. 寻找峰值</a></li></ul></li><li><a href="#%E8%B4%AA%E5%BF%83">贪心</a><ul><li><a href="#122-%E4%B9%B0%E5%8D%96%E8%82%A1%E7%A5%A8%E7%9A%84%E6%9C%80%E4%BD%B3%E6%97%B6%E6%9C%BA-ii-1">122. 买卖股票的最佳时机 II</a></li></ul></li></ul><h2 id="链表"><a href="#链表" class="headerlink" title="链表"></a>链表</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">// Definition for singly-linked list.</span><br><span class="hljs-keyword">struct</span> <span class="hljs-title class_">ListNode</span> &#123;<br>    <span class="hljs-type">int</span> val;<br>    ListNode *next;<br>    <span class="hljs-built_in">ListNode</span>() : <span class="hljs-built_in">val</span>(<span class="hljs-number">0</span>), <span class="hljs-built_in">next</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>    <span class="hljs-built_in">ListNode</span>(<span class="hljs-type">int</span> x) : <span class="hljs-built_in">val</span>(x), <span class="hljs-built_in">next</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>    <span class="hljs-built_in">ListNode</span>(<span class="hljs-type">int</span> x, ListNode *next) : <span class="hljs-built_in">val</span>(x), <span class="hljs-built_in">next</span>(next) &#123;&#125;<br> &#125;;<br></code></pre></td></tr></table></figure><h3 id="19-删除链表的倒数第N个结点"><a href="#19-删除链表的倒数第N个结点" class="headerlink" title="19. 删除链表的倒数第N个结点"></a>19. 删除链表的倒数第N个结点</h3><p>给你一个链表，删除链表的倒数第<code>n</code>个结点，并且返回链表的头结点。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">removeNthFromEnd</span><span class="hljs-params">(ListNode* head, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>        ListNode* dummy = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">0</span>, head);<br>        ListNode* first = head;<br>        ListNode* second = dummy;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>            first = first-&gt;next;<br>        &#125;<br>        <span class="hljs-keyword">while</span> (first) &#123;<br>            first = first-&gt;next;<br>            second = second-&gt;next;<br>        &#125;<br>        second-&gt;next = second-&gt;next-&gt;next;<br>        ListNode* ans = dummy-&gt;next;<br>        <span class="hljs-keyword">delete</span> dummy;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="21-合并两个有序链表"><a href="#21-合并两个有序链表" class="headerlink" title="21. 合并两个有序链表"></a>21. 合并两个有序链表</h3><p>将两个升序链表合并为一个新的<strong>升序</strong>链表并返回。新链表是通过拼接给定的两个链表的所有节点组成的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">mergeTwoLists</span><span class="hljs-params">(ListNode* list1, ListNode* list2)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(!list1)&#123;<br>            <span class="hljs-keyword">return</span> list2;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(!list2)&#123;<br>            <span class="hljs-keyword">return</span> list1;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(list1-&gt;val &lt; list2-&gt;val)&#123;<br>            list1-&gt;next = <span class="hljs-built_in">mergeTwoLists</span>(list1-&gt;next, list2);<br>            <span class="hljs-keyword">return</span> list1;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            list2-&gt;next = <span class="hljs-built_in">mergeTwoLists</span>(list2-&gt;next, list1);<br>            <span class="hljs-keyword">return</span> list2;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="23-合并-K-个升序链表"><a href="#23-合并-K-个升序链表" class="headerlink" title="23. 合并 K 个升序链表"></a>23. 合并 K 个升序链表</h3><p>给你一个链表数组，每个链表都已经按升序排列。请你将所有链表合并到一个升序链表中，返回合并后的链表。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">mergeTwoLists</span><span class="hljs-params">(ListNode* list1, ListNode* list2)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(!list1)&#123;<br>            <span class="hljs-keyword">return</span> list2;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(!list2)&#123;<br>            <span class="hljs-keyword">return</span> list1;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(list1-&gt;val &lt; list2-&gt;val)&#123;<br>            list1-&gt;next = <span class="hljs-built_in">mergeTwoLists</span>(list1-&gt;next, list2);<br>            <span class="hljs-keyword">return</span> list1;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            list2-&gt;next = <span class="hljs-built_in">mergeTwoLists</span>(list2-&gt;next, list1);<br>            <span class="hljs-keyword">return</span> list2;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-function">ListNode* <span class="hljs-title">mergeKLists</span><span class="hljs-params">(vector&lt;ListNode*&gt;&amp; lists)</span> </span>&#123;<br>        ListNode* ret = <span class="hljs-literal">nullptr</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; lists.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            ret = <span class="hljs-built_in">mergeTwoLists</span>(ret, lists[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="24-两两交换链表中的节点"><a href="#24-两两交换链表中的节点" class="headerlink" title="24. 两两交换链表中的节点"></a>24. 两两交换链表中的节点</h3><p>给你一个链表，两两交换其中相邻的节点，并返回交换后链表的头节点。你必须在不修改节点内部的值的情况下完成本题（即，只能进行节点交换）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">swapPairs</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">nullptr</span> || head-&gt;next == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> head;<br>        &#125;<br><br>        ListNode* tmp = head-&gt;next;<br>        head-&gt;next = <span class="hljs-built_in">swapPairs</span>(tmp-&gt;next);<br>        tmp-&gt;next = head;<br>        <span class="hljs-keyword">return</span> tmp;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="25-K-个一组翻转链表"><a href="#25-K-个一组翻转链表" class="headerlink" title="25. K 个一组翻转链表"></a>25. K 个一组翻转链表</h3><p>给你链表的头节点<code>head</code>，每<code>k</code>个节点一组进行翻转，请你返回修改后的链表。<br><code>k</code>是一个正整数，它的值小于或等于链表的长度。如果节点总数不是<code>k</code>的整数倍，那么请将最后剩余的节点保持原有顺序。</p><p><strong>你不能只是单纯的改变节点内部的值，而是需要实际进行节点交换。</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">reverseList</span><span class="hljs-params">(ListNode *head)</span></span>&#123;<br>        ListNode* pre;<br>        ListNode* tmp;<br>        ListNode* cur = head;<br>        <span class="hljs-keyword">while</span>(cur)&#123;<br>            tmp = cur-&gt;next;<br>            cur-&gt;next = pre;<br>            pre = cur;<br>            cur = tmp;<br>        &#125;<br>        <span class="hljs-keyword">return</span> pre;<br>    &#125;<br><br>    <span class="hljs-function">ListNode* <span class="hljs-title">reverseKGroup</span><span class="hljs-params">(ListNode* head, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-comment">// 构造头节点</span><br>        ListNode* dummy = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">-1</span>);<br>        dummy-&gt;next = head;<br><br>        ListNode* end = dummy;<br>        ListNode* pre = dummy;<br><br>        <span class="hljs-type">int</span> cnt = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span>(end &amp;&amp; end-&gt;next)&#123;<br>            <span class="hljs-comment">// end是每k个的最后一个，从每一段的前一个开始向后，即idx[0] - 1</span><br>            <span class="hljs-comment">// pre是每k个的第一个的前一个，更新后就是上一个end</span><br>            end = end-&gt;next;<br>            cnt += <span class="hljs-number">1</span>;<br><br>            <span class="hljs-keyword">if</span> (cnt == k)&#123;<br>                cnt = <span class="hljs-number">0</span>;<br><br>                <span class="hljs-comment">// next保存下一段的开头</span><br>                ListNode *next = end-&gt;next;<br>                <span class="hljs-comment">// 这一段的开头是start</span><br>                ListNode* start = pre-&gt;next;<br>                <span class="hljs-comment">// 这一段的结尾截断</span><br>                end-&gt;next = <span class="hljs-literal">nullptr</span>;<br><br>                <span class="hljs-comment">// 反转后，start变为了最后一个</span><br>                pre-&gt;next = <span class="hljs-built_in">reverseList</span>(start);<br>                start-&gt;next = next;<br><br>                <span class="hljs-comment">// 更新pre，指向当前反转段的段尾</span><br>                pre = start;<br>                <span class="hljs-comment">// 重新开始end</span><br>                end = pre;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> dummy-&gt;next;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="61-旋转链表"><a href="#61-旋转链表" class="headerlink" title="61. 旋转链表"></a>61. 旋转链表</h3><p>给你一个链表的头节点<code>head</code>，旋转链表，将链表每个节点向右移动<code>k</code>个位置。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：<span class="hljs-built_in">head</span> = [1,2,3,4,5], k = 2<br>输出：[4,5,1,2,3]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">rotateRight</span><span class="hljs-params">(ListNode* head, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (k == <span class="hljs-number">0</span> || head == <span class="hljs-literal">nullptr</span> || head-&gt;next == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> head;<br>        &#125;<br>        <span class="hljs-type">int</span> n = <span class="hljs-number">1</span>;<br>        ListNode* iter = head;<br>        <span class="hljs-keyword">while</span> (iter-&gt;next != <span class="hljs-literal">nullptr</span>) &#123;<br>            iter = iter-&gt;next;<br>            n++;<br>        &#125;<br>        <span class="hljs-type">int</span> add = n - k % n;<br>        <span class="hljs-keyword">if</span> (add == n) &#123;<br>            <span class="hljs-keyword">return</span> head;<br>        &#125;<br>        iter-&gt;next = head;<br>        <span class="hljs-keyword">while</span> (add--) &#123;<br>            iter = iter-&gt;next;<br>        &#125;<br>        ListNode* ret = iter-&gt;next;<br>        iter-&gt;next = <span class="hljs-literal">nullptr</span>;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="82-删除排序链表中的重复元素-II"><a href="#82-删除排序链表中的重复元素-II" class="headerlink" title="82. 删除排序链表中的重复元素 II"></a>82. 删除排序链表中的重复元素 II</h3><p>给定一个已排序的链表的头<code>head</code>， 删除原始链表中所有重复数字的节点，只留下不同的数字。返回已排序的链表。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：<span class="hljs-built_in">head</span> = [1,2,3,3,4,4,5]<br>输出：[1,2,5]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">deleteDuplicates</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (!head) &#123;<br>            <span class="hljs-keyword">return</span> head;<br>        &#125;<br>        <br>        ListNode* dummy = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">0</span>, head);<br><br>        ListNode* cur = dummy;<br>        <span class="hljs-keyword">while</span> (cur-&gt;next &amp;&amp; cur-&gt;next-&gt;next) &#123;<br>            <span class="hljs-keyword">if</span> (cur-&gt;next-&gt;val == cur-&gt;next-&gt;next-&gt;val) &#123;<br>                <span class="hljs-type">int</span> x = cur-&gt;next-&gt;val;<br>                <span class="hljs-keyword">while</span> (cur-&gt;next &amp;&amp; cur-&gt;next-&gt;val == x) &#123;<br>                    cur-&gt;next = cur-&gt;next-&gt;next;<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">else</span> &#123;<br>                cur = cur-&gt;next;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> dummy-&gt;next;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="83-删除排序链表中的重复元素"><a href="#83-删除排序链表中的重复元素" class="headerlink" title="83. 删除排序链表中的重复元素"></a>83. 删除排序链表中的重复元素</h3><p>给定一个已排序的链表的头<code>head</code>， 删除所有重复的元素，使每个元素只出现一次 。返回已排序的链表。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：<span class="hljs-built_in">head</span> = [1,1,2]<br>输出：[1,2]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">deleteDuplicates</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;<br>        ListNode* cur = head;<br>        <span class="hljs-keyword">while</span>(cur)&#123;<br>            <span class="hljs-keyword">while</span> (cur-&gt;next &amp;&amp; cur-&gt;val == cur-&gt;next-&gt;val)&#123;<br>                cur-&gt;next = cur-&gt;next-&gt;next;<br>            &#125;<br><br>            cur = cur-&gt;next;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> head;<br><br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="86-分隔链表"><a href="#86-分隔链表" class="headerlink" title="86. 分隔链表"></a>86. 分隔链表</h3><p>给你一个链表的头节点<code>head</code>和一个特定值<code>x</code>，请你对链表进行分隔，使得所有<strong>小于</strong><code>x</code> 的节点都出现在<strong>大于或等于</strong><code>x</code>的节点之前。你应当<strong>保留</strong>两个分区中每个节点的初始相对位置。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：<span class="hljs-built_in">head</span> = [1,4,3,2,5,2], x = 3<br>输出：[1,2,2,4,3,5]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">partition</span><span class="hljs-params">(ListNode* head, <span class="hljs-type">int</span> x)</span> </span>&#123;<br>        ListNode *smlDummy = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">0</span>), *bigDummy = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">0</span>);<br>        ListNode *sml = smlDummy, *big = bigDummy;<br>        <span class="hljs-keyword">while</span> (head != <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">if</span> (head-&gt;val &lt; x) &#123;<br>                sml-&gt;next = head;<br>                sml = sml-&gt;next;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                big-&gt;next = head;<br>                big = big-&gt;next;<br>            &#125;<br>            head = head-&gt;next;<br>        &#125;<br>        sml-&gt;next = bigDummy-&gt;next;<br>        big-&gt;next = <span class="hljs-literal">nullptr</span>;<br>        <span class="hljs-keyword">return</span> smlDummy-&gt;next;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="92-反转链表-II"><a href="#92-反转链表-II" class="headerlink" title="92. 反转链表 II"></a>92. 反转链表 II</h3><p>给你单链表的头指针<code>head</code>和两个整数<code>left</code>和<code>right</code>，其中<code>left &lt;= right</code>。请你反转从位置<code>left</code>到位置<code>right</code>的链表节点，返回反转后的链表。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：<span class="hljs-built_in">head</span> = [1,2,3,4,5], left = 2, right = 4<br>输出：[1,4,3,2,5]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode *<span class="hljs-title">reverseBetween</span><span class="hljs-params">(ListNode *head, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right)</span> </span>&#123;<br>        <span class="hljs-comment">// 设置 dummyNode 是这一类问题的一般做法</span><br>        ListNode *dummyNode = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">-1</span>);<br>        dummyNode-&gt;next = head;<br>        ListNode *pre = dummyNode;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; left - <span class="hljs-number">1</span>; i++) &#123;<br>            pre = pre-&gt;next;<br>        &#125;<br>        ListNode *cur = pre-&gt;next;<br>        ListNode *next;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; right - left; i++) &#123;<br>            next = cur-&gt;next;<br>            cur-&gt;next = next-&gt;next;<br>            next-&gt;next = pre-&gt;next;<br>            pre-&gt;next = next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dummyNode-&gt;next;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="141-环形链表"><a href="#141-环形链表" class="headerlink" title="141. 环形链表"></a>141. 环形链表</h3><p>给你一个链表的头节点<code>head</code>，判断链表中是否有环。如果链表中有某个节点，可以通过连续跟踪<code>next</code>指针再次到达，则链表中存在环。为了表示给定链表中的环，评测系统内部使用整数<code>pos</code>来表示链表尾连接到链表中的位置（索引从<code>0</code>开始）。注意：<code>pos</code>不作为参数进行传递 。仅仅是为了标识链表的实际情况。如果链表中存在环，则返回<code>true</code>。否则，返回<code>false</code>。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">hasCycle</span><span class="hljs-params">(ListNode *head)</span> </span>&#123;<br>        ListNode* fast = head;<br>        ListNode* slow = head;<br>        <span class="hljs-keyword">while</span>(fast &amp;&amp; fast-&gt;next)&#123;<br>            fast = fast-&gt;next-&gt;next;<br>            slow = slow-&gt;next;<br>            <span class="hljs-keyword">if</span>(fast == slow)&#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="142-环形链表-II"><a href="#142-环形链表-II" class="headerlink" title="142. 环形链表 II"></a>142. 环形链表 II</h3><p>给定一个链表的头节点<code>head</code>，返回链表开始入环的第一个节点。 如果链表无环，则返回<code>null</code>。如果链表中有某个节点，可以通过连续跟踪<code>next</code>指针再次到达，则链表中存在环。为了表示给定链表中的环，评测系统内部使用整数<code>pos</code>来表示链表尾连接到链表中的位置（索引从<code>0</code>开始）。如果<code>pos</code>是<code>-1</code>，则在该链表中没有环。注意：<code>pos</code>不作为参数进行传递，仅仅是为了标识链表的实际情况。<strong>不允许修改链表。</strong></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode *<span class="hljs-title">detectCycle</span><span class="hljs-params">(ListNode *head)</span> </span>&#123;<br>        ListNode* fast = head;<br>        ListNode* slow = head;<br>        <span class="hljs-keyword">while</span> (<span class="hljs-literal">true</span>) &#123;<br>            <span class="hljs-keyword">if</span> (fast == <span class="hljs-literal">nullptr</span> || fast-&gt;next == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>            fast = fast-&gt;next-&gt;next;<br>            slow = slow-&gt;next;<br>            <span class="hljs-keyword">if</span> (fast == slow) <span class="hljs-keyword">break</span>;<br>        &#125;<br>        fast = head;<br>        <span class="hljs-keyword">while</span> (slow != fast) &#123;<br>            slow = slow-&gt;next;<br>            fast = fast-&gt;next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> fast;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="148-排序链表"><a href="#148-排序链表" class="headerlink" title="148. 排序链表"></a>148. 排序链表</h3><p>给你链表的头结点<code>head</code>，请将其按<strong>升序</strong>排列并返回排序后的链表。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">sortList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">sortList</span>(head, <span class="hljs-literal">nullptr</span>);<br>    &#125;<br><br>    <span class="hljs-function">ListNode* <span class="hljs-title">sortList</span><span class="hljs-params">(ListNode* head, ListNode* tail)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> head;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (head-&gt;next == tail) &#123;<br>            head-&gt;next = <span class="hljs-literal">nullptr</span>;<br>            <span class="hljs-keyword">return</span> head;<br>        &#125;<br>        ListNode* slow = head, *fast = head;<br>        <span class="hljs-keyword">while</span> (fast != tail) &#123;<br>            slow = slow-&gt;next;<br>            fast = fast-&gt;next;<br>            <span class="hljs-keyword">if</span> (fast != tail) &#123;<br>                fast = fast-&gt;next;<br>            &#125;<br>        &#125;<br>        ListNode* mid = slow;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">merge</span>(<span class="hljs-built_in">sortList</span>(head, mid), <span class="hljs-built_in">sortList</span>(mid, tail));<br>    &#125;<br><br>    <span class="hljs-function">ListNode* <span class="hljs-title">merge</span><span class="hljs-params">(ListNode* head1, ListNode* head2)</span> </span>&#123;<br>        ListNode* dummyHead = <span class="hljs-keyword">new</span> <span class="hljs-built_in">ListNode</span>(<span class="hljs-number">0</span>);<br>        ListNode* temp = dummyHead, *temp1 = head1, *temp2 = head2;<br>        <span class="hljs-keyword">while</span> (temp1 != <span class="hljs-literal">nullptr</span> &amp;&amp; temp2 != <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">if</span> (temp1-&gt;val &lt;= temp2-&gt;val) &#123;<br>                temp-&gt;next = temp1;<br>                temp1 = temp1-&gt;next;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                temp-&gt;next = temp2;<br>                temp2 = temp2-&gt;next;<br>            &#125;<br>            temp = temp-&gt;next;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (temp1 != <span class="hljs-literal">nullptr</span>) &#123;<br>            temp-&gt;next = temp1;<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (temp2 != <span class="hljs-literal">nullptr</span>) &#123;<br>            temp-&gt;next = temp2;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dummyHead-&gt;next;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="206-反转链表"><a href="#206-反转链表" class="headerlink" title="206. 反转链表"></a>206. 反转链表</h3><p>给你单链表的头节点<code>head</code>，请你反转链表，并返回反转后的链表。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">reverseList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;<br>        ListNode* prev = <span class="hljs-literal">nullptr</span>;<br>        ListNode* curr = head;<br>        <span class="hljs-keyword">while</span> (curr) &#123;<br>            ListNode* next = curr-&gt;next;<br>            curr-&gt;next = prev;<br>            prev = curr;<br>            curr = next;<br>        &#125;<br>        <span class="hljs-keyword">return</span> prev;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="328-奇偶链表"><a href="#328-奇偶链表" class="headerlink" title="328. 奇偶链表"></a>328. 奇偶链表</h3><p>给定单链表的头节点 <code>head</code>，将所有索引为奇数的节点和索引为偶数的节点分别组合在一起，然后返回重新排序的列表。第一个节点的索引被认为是<strong>奇数</strong>， 第二个节点的索引为<strong>偶数</strong>，以此类推。</p><p>请注意，偶数组和奇数组内部的相对顺序应该与输入时保持一致。你必须在<code>O(1)</code>的额外空间复杂度和<code>O(n)</code>的时间复杂度下解决这个问题。</p><p>示例 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入: <span class="hljs-built_in">head</span> = [1,2,3,4,5]<br>输出: [1,3,5,2,4]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">ListNode* <span class="hljs-title">oddEvenList</span><span class="hljs-params">(ListNode* head)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (head == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> head;<br>        &#125;<br>        ListNode* evenHead = head-&gt;next;<br>        ListNode* odd = head;<br>        ListNode* even = evenHead;<br>        <span class="hljs-keyword">while</span> (even != <span class="hljs-literal">nullptr</span> &amp;&amp; even-&gt;next != <span class="hljs-literal">nullptr</span>) &#123;<br>            odd-&gt;next = even-&gt;next;<br>            odd = odd-&gt;next;<br>            even-&gt;next = odd-&gt;next;<br>            even = even-&gt;next;<br>        &#125;<br>        odd-&gt;next = evenHead;<br>        <span class="hljs-keyword">return</span> head;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="DFS"><a href="#DFS" class="headerlink" title="DFS"></a>DFS</h2><h3 id="22-括号生成"><a href="#22-括号生成" class="headerlink" title="22. 括号生成"></a>22. 括号生成</h3><p>数字<code>n</code>代表生成括号的对数，请你设计一个函数，用于能够生成所有可能的并且<strong>有效的</strong>括号组合。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;string&gt; res;<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-type">const</span> string&amp; str, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right)</span></span>&#123;<br>        <span class="hljs-keyword">if</span>(left &lt; <span class="hljs-number">0</span> || left &gt; right)&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(left == <span class="hljs-number">0</span> &amp;&amp; right == <span class="hljs-number">0</span>)&#123;<br>            res.<span class="hljs-built_in">push_back</span>(str);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-built_in">dfs</span>(str + <span class="hljs-string">&#x27;(&#x27;</span>, left - <span class="hljs-number">1</span>, right);<br>        <span class="hljs-built_in">dfs</span>(str + <span class="hljs-string">&#x27;)&#x27;</span>, left, right - <span class="hljs-number">1</span>);<br>    &#125;<br>    <span class="hljs-function">vector&lt;string&gt; <span class="hljs-title">generateParenthesis</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-built_in">dfs</span>(<span class="hljs-string">&quot;&quot;</span>, n, n);<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="39-组合总和"><a href="#39-组合总和" class="headerlink" title="39. 组合总和"></a>39. 组合总和</h3><p>给你一个<strong>无重复元素</strong>的整数数组<code>candidates</code>和一个目标整数 <code>target</code>，找出<code>candidates</code>中可以使数字和为目标数<code>target</code>的<strong>所有</strong>不同组合，并以列表形式返回。你可以按<strong>任意顺序</strong>返回这些组合。<code>candidates</code>中的<strong>同一个</strong>数字可以无限制重复被选取。如果至少一个数字的被选数量不同，则两种组合是不同的。对于给定的输入，保证和为<code>target</code>的不同组合数少于<code>150</code>个。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：candidates = [2,3,6,7], target = 7<br>输出：[[2,2,3],[7]]<br>解释：<br>2 和 3 可以形成一组候选，2 + 2 + 3 = 7。注意 2 可以使用多次。<br>7 也是一个候选， 7 = 7。<br>仅有这两种组合。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; candidates, <span class="hljs-type">int</span> target, vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; ans, vector&lt;<span class="hljs-type">int</span>&gt;&amp; combine, <span class="hljs-type">int</span> idx)</span></span>&#123;<br>        <span class="hljs-keyword">if</span>(idx == candidates.<span class="hljs-built_in">size</span>())&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>(target == <span class="hljs-number">0</span>)&#123;<br>            ans.<span class="hljs-built_in">push_back</span>(combine);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-built_in">dfs</span>(candidates, target, ans, combine, idx<span class="hljs-number">+1</span>);<br><br>        <span class="hljs-keyword">if</span>(target - candidates[idx] &gt;= <span class="hljs-number">0</span>)&#123;<br>            combine.<span class="hljs-built_in">push_back</span>(candidates[idx]);<br>            <span class="hljs-built_in">dfs</span>(candidates, target - candidates[idx], ans, combine, idx);<br>            combine.<span class="hljs-built_in">pop_back</span>();<br>        &#125;<br>    &#125;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">combinationSum</span>(vector&lt;<span class="hljs-type">int</span>&gt;&amp; candidates, <span class="hljs-type">int</span> target) &#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; ans;<br>        vector&lt;<span class="hljs-type">int</span>&gt; combine;<br>        <span class="hljs-built_in">dfs</span>(candidates, target, ans, combine, <span class="hljs-number">0</span>);<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="40-组合总和-II"><a href="#40-组合总和-II" class="headerlink" title="40. 组合总和 II"></a>40. 组合总和 II</h3><p>给定一个候选人编号的集合<code>candidates</code>和一个目标数<code>target</code>，找出<code>candidates</code>中所有可以使数字和为<code>target</code>的组合。<code>candidates</code>中的每个数字在每个组合中只能使用<strong>一次</strong>。<br>注意：解集不能包含重复的组合。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">示例 1:<br><br>输入: candidates = [10,1,2,7,6,1,5], target = 8,<br>输出:<br>[<br>    [1,1,6],<br>    [1,2,5],<br>    [1,7],<br>    [2,6]<br>]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    vector&lt;pair&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt;&gt; freq;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; ans;<br>    vector&lt;<span class="hljs-type">int</span>&gt; sequence;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-type">int</span> pos, <span class="hljs-type">int</span> rest)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (rest == <span class="hljs-number">0</span>) &#123;<br>            ans.<span class="hljs-built_in">push_back</span>(sequence);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (pos == freq.<span class="hljs-built_in">size</span>() || rest &lt; freq[pos].first) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br><br>        <span class="hljs-built_in">dfs</span>(pos + <span class="hljs-number">1</span>, rest);<br><br>        <span class="hljs-type">int</span> most = <span class="hljs-built_in">min</span>(rest / freq[pos].first, freq[pos].second);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= most; ++i) &#123;<br>            sequence.<span class="hljs-built_in">push_back</span>(freq[pos].first);<br>            <span class="hljs-built_in">dfs</span>(pos + <span class="hljs-number">1</span>, rest - i * freq[pos].first);<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= most; ++i) &#123;<br>            sequence.<span class="hljs-built_in">pop_back</span>();<br>        &#125;<br>    &#125;<br><br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">combinationSum2</span>(vector&lt;<span class="hljs-type">int</span>&gt;&amp; candidates, <span class="hljs-type">int</span> target) &#123;<br>        <span class="hljs-built_in">sort</span>(candidates.<span class="hljs-built_in">begin</span>(), candidates.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> num: candidates) &#123;<br>            <span class="hljs-keyword">if</span> (freq.<span class="hljs-built_in">empty</span>() || num != freq.<span class="hljs-built_in">back</span>().first) &#123;<br>                freq.<span class="hljs-built_in">emplace_back</span>(num, <span class="hljs-number">1</span>);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                ++freq.<span class="hljs-built_in">back</span>().second;<br>            &#125;<br>        &#125;<br>        <span class="hljs-built_in">dfs</span>(<span class="hljs-number">0</span>, target);<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br><br></code></pre></td></tr></table></figure><h3 id="46-全排列"><a href="#46-全排列" class="headerlink" title="46. 全排列"></a>46. 全排列</h3><p>给定一个不含重复数字的数组<code>nums</code>，返回其<strong>所有可能的全排列</strong>。你可以<strong>按任意顺序</strong>返回答案。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [1,2,3]<br>输出：[[1,2,3],[1,3,2],[2,1,3],[2,3,1],[3,1,2],[3,2,1]]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; res, vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> idx, <span class="hljs-type">int</span> len)</span></span>&#123;<br>        <span class="hljs-keyword">if</span> (idx == len)&#123;<br>            res.<span class="hljs-built_in">push_back</span>(nums);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = idx; i &lt; len; i++)&#123;<br>            <span class="hljs-built_in">swap</span>(nums[i], nums[idx]);<br>            <span class="hljs-built_in">dfs</span>(res, nums, idx + <span class="hljs-number">1</span>, len);<br>            <span class="hljs-built_in">swap</span>(nums[i], nums[idx]);<br>        &#125;<br>    &#125;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">permute</span>(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums) &#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; res;<br>        <span class="hljs-built_in">dfs</span>(res, nums, <span class="hljs-number">0</span>, <span class="hljs-built_in">int</span>(nums.<span class="hljs-built_in">size</span>()));<br><br>        <span class="hljs-keyword">return</span> res;<br><br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="77-组合"><a href="#77-组合" class="headerlink" title="77. 组合"></a>77. 组合</h3><p>给定两个整数<code>n</code>和<code>k</code>，返回范围<code>[1, n]</code>中所有可能的<code>k</code>个数的组合。你可以按<strong>任何顺序</strong>返回答案。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：n = 4, k = 2<br>输出：<br>[<br>  [2,4],<br>  [3,4],<br>  [2,3],<br>  [1,2],<br>  [1,3],<br>  [1,4],<br>]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;<span class="hljs-type">int</span>&gt; temp;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; ans;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-type">int</span> cur, <span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-comment">// 剪枝：temp 长度加上区间 [cur, n] 的长度小于 k，不可能构造出长度为 k 的 temp</span><br>        <span class="hljs-keyword">if</span> (temp.<span class="hljs-built_in">size</span>() + (n - cur + <span class="hljs-number">1</span>) &lt; k) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-comment">// 记录合法的答案</span><br>        <span class="hljs-keyword">if</span> (temp.<span class="hljs-built_in">size</span>() == k) &#123;<br>            ans.<span class="hljs-built_in">push_back</span>(temp);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-comment">// 考虑选择当前位置</span><br>        temp.<span class="hljs-built_in">push_back</span>(cur);<br>        <span class="hljs-built_in">dfs</span>(cur + <span class="hljs-number">1</span>, n, k);<br>        temp.<span class="hljs-built_in">pop_back</span>();<br>        <span class="hljs-comment">// 考虑不选择当前位置</span><br>        <span class="hljs-built_in">dfs</span>(cur + <span class="hljs-number">1</span>, n, k);<br>    &#125;<br><br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">combine</span>(<span class="hljs-type">int</span> n, <span class="hljs-type">int</span> k) &#123;<br>        <span class="hljs-built_in">dfs</span>(<span class="hljs-number">1</span>, n, k);<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="78-子集"><a href="#78-子集" class="headerlink" title="78. 子集"></a>78. 子集</h3><p>给你一个整数数组<code>nums</code>，数组中的元素<strong>互不相同</strong>。返回该数组所有可能的子集（幂集）。解集<strong>不能</strong>包含重复的子集。你可以按<strong>任意顺序</strong>返回解集。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [1,2,3]<br>输出：[[],[1],[2],[1,2],[3],[1,3],[2,3],[1,2,3]]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;<span class="hljs-type">int</span>&gt; t;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; ans;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-type">int</span> cur, vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (cur == nums.<span class="hljs-built_in">size</span>()) &#123;<br>            ans.<span class="hljs-built_in">push_back</span>(t);<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        t.<span class="hljs-built_in">push_back</span>(nums[cur]);<br>        <span class="hljs-built_in">dfs</span>(cur + <span class="hljs-number">1</span>, nums);<br>        t.<span class="hljs-built_in">pop_back</span>();<br>        <span class="hljs-built_in">dfs</span>(cur + <span class="hljs-number">1</span>, nums);<br>    &#125;<br><br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">subsets</span>(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums) &#123;<br>        <span class="hljs-built_in">dfs</span>(<span class="hljs-number">0</span>, nums);<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><p>位运算：</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;<span class="hljs-type">int</span>&gt; t;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; ans;<br><br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">subsets</span>(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums) &#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> mask = <span class="hljs-number">0</span>; mask &lt; (<span class="hljs-number">1</span> &lt;&lt; n); ++mask) &#123;<br>            t.<span class="hljs-built_in">clear</span>();<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>                <span class="hljs-keyword">if</span> (mask &amp; (<span class="hljs-number">1</span> &lt;&lt; i)) &#123;<br>                    t.<span class="hljs-built_in">push_back</span>(nums[i]);<br>                &#125;<br>            &#125;<br>            ans.<span class="hljs-built_in">push_back</span>(t);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="130-被围绕的区域"><a href="#130-被围绕的区域" class="headerlink" title="130. 被围绕的区域"></a>130. 被围绕的区域</h3><p>给你一个<code>m x n</code>的矩阵<code>board</code>，由若干字符<code>&#39;X&#39;</code>和<code>&#39;O&#39;</code>，找到所有被<code>&#39;X&#39;</code>围绕的区域，并将这些区域里所有的<code>&#39;O&#39;</code>用<code>&#39;X&#39;</code>填充。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：board = [[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>],[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;O&quot;</span>,<span class="hljs-string">&quot;O&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>],[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;O&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>],[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;O&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>]]<br>输出：[[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>],[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>],[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>],[<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;O&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>,<span class="hljs-string">&quot;X&quot;</span>]]<br>解释：被围绕的区间不会存在于边界上，换句话说，任何边界上的 <span class="hljs-string">&#x27;O&#x27;</span> 都不会被填充为 <span class="hljs-string">&#x27;X&#x27;</span>。 任何不在边界上，或不与边界上的 <span class="hljs-string">&#x27;O&#x27;</span> 相连的 <span class="hljs-string">&#x27;O&#x27;</span> 最终都会被填充为 <span class="hljs-string">&#x27;X&#x27;</span>。如果两个元素在水平或垂直方向相邻，则称它们是“相连”的。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-type">int</span> n, m;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; board, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (x &lt; <span class="hljs-number">0</span> || x &gt;= n || y &lt; <span class="hljs-number">0</span> || y &gt;= m || board[x][y] != <span class="hljs-string">&#x27;O&#x27;</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        board[x][y] = <span class="hljs-string">&#x27;A&#x27;</span>;<br>        <span class="hljs-built_in">dfs</span>(board, x + <span class="hljs-number">1</span>, y);<br>        <span class="hljs-built_in">dfs</span>(board, x - <span class="hljs-number">1</span>, y);<br>        <span class="hljs-built_in">dfs</span>(board, x, y + <span class="hljs-number">1</span>);<br>        <span class="hljs-built_in">dfs</span>(board, x, y - <span class="hljs-number">1</span>);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">solve</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; board)</span> </span>&#123;<br>        n = board.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        m = board[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-built_in">dfs</span>(board, i, <span class="hljs-number">0</span>);<br>            <span class="hljs-built_in">dfs</span>(board, i, m - <span class="hljs-number">1</span>);<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; m - <span class="hljs-number">1</span>; i++) &#123;<br>            <span class="hljs-built_in">dfs</span>(board, <span class="hljs-number">0</span>, i);<br>            <span class="hljs-built_in">dfs</span>(board, n - <span class="hljs-number">1</span>, i);<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; m; j++) &#123;<br>                <span class="hljs-keyword">if</span> (board[i][j] == <span class="hljs-string">&#x27;A&#x27;</span>) &#123;<br>                    board[i][j] = <span class="hljs-string">&#x27;O&#x27;</span>;<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (board[i][j] == <span class="hljs-string">&#x27;O&#x27;</span>) &#123;<br>                    board[i][j] = <span class="hljs-string">&#x27;X&#x27;</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="200-岛屿数量"><a href="#200-岛屿数量" class="headerlink" title="200. 岛屿数量"></a>200. 岛屿数量</h3><p>给你一个由<code>&#39;1&#39;</code>（陆地和<code>&#39;0&#39;</code>（水）组成的的二维网格，请你计算网格中岛屿的数量。岛屿总是被水包围，并且每座岛屿只能由水平方向和&#x2F;或竖直方向上相邻的陆地连接形成。此外，你可以假设该网格的四条边均被水包围。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：grid = [<br>  [<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>],<br>  [<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>],<br>  [<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>],<br>  [<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>]<br>]<br>输出：1<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; grid, <span class="hljs-type">int</span> r, <span class="hljs-type">int</span> c)</span> </span>&#123;<br>        <span class="hljs-type">int</span> nr = grid.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> nc = grid[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br><br>        grid[r][c] = <span class="hljs-string">&#x27;0&#x27;</span>;<br>        <span class="hljs-keyword">if</span> (r - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; grid[r<span class="hljs-number">-1</span>][c] == <span class="hljs-string">&#x27;1&#x27;</span>) <span class="hljs-built_in">dfs</span>(grid, r - <span class="hljs-number">1</span>, c);<br>        <span class="hljs-keyword">if</span> (r + <span class="hljs-number">1</span> &lt; nr &amp;&amp; grid[r<span class="hljs-number">+1</span>][c] == <span class="hljs-string">&#x27;1&#x27;</span>) <span class="hljs-built_in">dfs</span>(grid, r + <span class="hljs-number">1</span>, c);<br>        <span class="hljs-keyword">if</span> (c - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; grid[r][c<span class="hljs-number">-1</span>] == <span class="hljs-string">&#x27;1&#x27;</span>) <span class="hljs-built_in">dfs</span>(grid, r, c - <span class="hljs-number">1</span>);<br>        <span class="hljs-keyword">if</span> (c + <span class="hljs-number">1</span> &lt; nc &amp;&amp; grid[r][c<span class="hljs-number">+1</span>] == <span class="hljs-string">&#x27;1&#x27;</span>) <span class="hljs-built_in">dfs</span>(grid, r, c + <span class="hljs-number">1</span>);<br>    &#125;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">numIslands</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; grid)</span> </span>&#123;<br>        <span class="hljs-type">int</span> nr = grid.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span> (!nr) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> nc = grid[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br><br>        <span class="hljs-type">int</span> num_islands = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> r = <span class="hljs-number">0</span>; r &lt; nr; ++r) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> c = <span class="hljs-number">0</span>; c &lt; nc; ++c) &#123;<br>                <span class="hljs-keyword">if</span> (grid[r][c] == <span class="hljs-string">&#x27;1&#x27;</span>) &#123;<br>                    ++num_islands;<br>                    <span class="hljs-built_in">dfs</span>(grid, r, c);<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> num_islands;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="207-课程表"><a href="#207-课程表" class="headerlink" title="207. 课程表"></a>207. 课程表</h3><p>你这个学期必须选修<code>numCourses</code>门课程，记为<code>0</code>到<code>numCourses - 1</code>。在选修某些课程之前需要一些先修课程。先修课程按数组<code>prerequisites</code>给出，其中<code>prerequisites[i] = [ai, bi]</code>，表示如果要学习课程<code>ai</code>则<strong>必须</strong>先学习课程<code>bi</code>。</p><p>例如，先修课程对<code>[0, 1]</code>表示：想要学习课程<code>0</code>，你需要先完成课程<code>1</code>。<br>请你判断是否可能完成所有课程的学习？如果可以，返回<code>true</code>；否则，返回<code>false</code>。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：numCourses = 2, prerequisites = [[1,0]]<br>输出：<span class="hljs-literal">true</span><br>解释：总共有 2 门课程。学习课程 1 之前，你需要完成课程 0 。这是可能的。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; edges, vector&lt;<span class="hljs-type">int</span>&gt;&amp; visited, <span class="hljs-type">int</span> idx)</span></span>&#123;<br>        visited[idx] = <span class="hljs-number">1</span>;<br>        <span class="hljs-type">bool</span> valid;<br><br>        <span class="hljs-comment">// 遍历一个点的所有边</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; edges[idx].<span class="hljs-built_in">size</span>(); i++)&#123;<br>            <span class="hljs-keyword">if</span> (visited[edges[idx][i]] == <span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-comment">// 如果边的另一个端点没有访问，则继续</span><br>                valid = <span class="hljs-built_in">dfs</span>(edges, visited, edges[idx][i]);<br><br>                <span class="hljs-comment">// 向下递归后如果遇到环，则立即返回</span><br>                <span class="hljs-keyword">if</span>(valid == <span class="hljs-literal">false</span>)&#123;<br>                    <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>                &#125;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (visited[edges[idx][i]] == <span class="hljs-number">1</span>)&#123;<br>                <span class="hljs-comment">// 如果访问了，则说明有环</span><br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 标记这个点对应的所有边已结束，下次遇到这个点直接跳过</span><br>        visited[idx] = <span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">canFinish</span><span class="hljs-params">(<span class="hljs-type">int</span> numCourses, vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; prerequisites)</span> </span>&#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">edges</span>(numCourses);<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">visited</span><span class="hljs-params">(numCourses, <span class="hljs-number">0</span>)</span></span>;<br>        <span class="hljs-type">bool</span> valid = <span class="hljs-literal">true</span>;<br><br>        <span class="hljs-comment">// 生成边</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; prerequisites.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            edges[prerequisites[i][<span class="hljs-number">0</span>]].<span class="hljs-built_in">push_back</span>(prerequisites[i][<span class="hljs-number">1</span>]);<br>        &#125;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; numCourses; i++)&#123;<br>            <span class="hljs-keyword">if</span>(visited[i] == <span class="hljs-number">0</span>)&#123;<br>                valid = <span class="hljs-built_in">dfs</span>(edges, visited, i);<br>                <span class="hljs-keyword">if</span>(valid == <span class="hljs-literal">false</span>)&#123;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> valid;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="210-课程表-II"><a href="#210-课程表-II" class="headerlink" title="210. 课程表 II"></a>210. 课程表 II</h3><p>现在你总共有 numCourses 门课需要选，记为 0 到 numCourses - 1。给你一个数组 prerequisites ，其中 prerequisites[i] &#x3D; [ai, bi] ，表示在选修课程 ai 前 必须 先选修 bi 。</p><p>例如，想要学习课程 0 ，你需要先完成课程 1 ，我们用一个匹配来表示：[0,1] 。<br>返回你为了学完所有课程所安排的学习顺序。可能会有多个正确的顺序，你只要返回 任意一种 就可以了。如果不可能完成所有课程，返回 一个空数组 。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：numCourses = 2, prerequisites = [[1,0]]<br>输出：[0,1]<br>解释：总共有 2 门课程。要学习课程 1，你需要先完成课程 0。因此，正确的课程顺序为 [0,1] 。<br></code></pre></td></tr></table></figure><p>示例 2：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：numCourses = 4, prerequisites = [[1,0],[2,0],[3,1],[3,2]]<br>输出：[0,2,1,3]<br>解释：总共有 4 门课程。要学习课程 3，你应该先完成课程 1 和课程 2。并且课程 1 和课程 2 都应该排在课程 0 之后。<br>因此，一个正确的课程顺序是 [0,1,2,3] 。另一个正确的排序是 [0,2,1,3] 。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-comment">// 存储有向图</span><br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; edges;<br>    <span class="hljs-comment">// 标记每个节点的状态：0=未搜索，1=搜索中，2=已完成</span><br>    vector&lt;<span class="hljs-type">int</span>&gt; visited;<br>    <span class="hljs-comment">// 用数组来模拟栈，下标 0 为栈底，n-1 为栈顶</span><br>    vector&lt;<span class="hljs-type">int</span>&gt; result;<br>    <span class="hljs-comment">// 判断有向图中是否有环</span><br>    <span class="hljs-type">bool</span> valid = <span class="hljs-literal">true</span>;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(<span class="hljs-type">int</span> u)</span> </span>&#123;<br>        <span class="hljs-comment">// 将节点标记为「搜索中」</span><br>        visited[u] = <span class="hljs-number">1</span>;<br>        <span class="hljs-comment">// 搜索其相邻节点</span><br>        <span class="hljs-comment">// 只要发现有环，立刻停止搜索</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> v: edges[u]) &#123;<br>            <span class="hljs-comment">// 如果「未搜索」那么搜索相邻节点</span><br>            <span class="hljs-keyword">if</span> (visited[v] == <span class="hljs-number">0</span>) &#123;<br>                <span class="hljs-built_in">dfs</span>(v);<br>                <span class="hljs-keyword">if</span> (!valid) &#123;<br>                    <span class="hljs-keyword">return</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-comment">// 如果「搜索中」说明找到了环</span><br>            <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (visited[v] == <span class="hljs-number">1</span>) &#123;<br>                valid = <span class="hljs-literal">false</span>;<br>                <span class="hljs-keyword">return</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-comment">// 将节点标记为「已完成」</span><br>        visited[u] = <span class="hljs-number">2</span>;<br>        <span class="hljs-comment">// 将节点入栈</span><br>        result.<span class="hljs-built_in">push_back</span>(u);<br>    &#125;<br><br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">findOrder</span><span class="hljs-params">(<span class="hljs-type">int</span> numCourses, vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; prerequisites)</span> </span>&#123;<br>        edges.<span class="hljs-built_in">resize</span>(numCourses);<br>        visited.<span class="hljs-built_in">resize</span>(numCourses);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span>&amp; info: prerequisites) &#123;<br>            edges[info[<span class="hljs-number">1</span>]].<span class="hljs-built_in">push_back</span>(info[<span class="hljs-number">0</span>]);<br>        &#125;<br>        <span class="hljs-comment">// 每次挑选一个「未搜索」的节点，开始进行深度优先搜索</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; numCourses &amp;&amp; valid; ++i) &#123;<br>            <span class="hljs-keyword">if</span> (!visited[i]) &#123;<br>                <span class="hljs-built_in">dfs</span>(i);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (!valid) &#123;<br>            <span class="hljs-keyword">return</span> &#123;&#125;;<br>        &#125;<br>        <span class="hljs-comment">// 如果没有环，那么就有拓扑排序</span><br>        <span class="hljs-comment">// 注意下标 0 为栈底，因此需要将数组反序输出</span><br>        <span class="hljs-built_in">reverse</span>(result.<span class="hljs-built_in">begin</span>(), result.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-keyword">return</span> result;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="动态规划"><a href="#动态规划" class="headerlink" title="动态规划"></a>动态规划</h2><h3 id="5-最长回文子串"><a href="#5-最长回文子串" class="headerlink" title="5. 最长回文子串"></a>5. 最长回文子串</h3><p>给你一个字符串 s，找到 s 中最长的回文子串。 如果字符串的反序与原始字符串相同，则该字符串称为回文字符串。<br>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：s = <span class="hljs-string">&quot;babad&quot;</span><br>输出：<span class="hljs-string">&quot;bab&quot;</span><br>解释：<span class="hljs-string">&quot;aba&quot;</span> 同样是符合题意的答案。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">longestPalindrome</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span>(n &lt; <span class="hljs-number">2</span>)&#123;<br>            <span class="hljs-keyword">return</span> s;<br>        &#125;<br><br>        <span class="hljs-type">int</span> max_len = <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> idx = <span class="hljs-number">0</span>;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">dp</span>(n, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(n));<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>            dp[i][i] = <span class="hljs-number">1</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> L = <span class="hljs-number">2</span>; L &lt;=n; L++)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>                <span class="hljs-type">int</span> j = L + i <span class="hljs-number">-1</span>;<br>                <span class="hljs-keyword">if</span>(j &gt;= n)&#123;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br><br>                <span class="hljs-keyword">if</span>(s[i] != s[j])&#123;<br>                    dp[i][j] = <span class="hljs-number">0</span>;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-keyword">if</span> (j - i &lt; <span class="hljs-number">3</span>)&#123;<br>                        dp[i][j] = <span class="hljs-number">1</span>;<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        dp[i][j] = dp[i<span class="hljs-number">+1</span>][j<span class="hljs-number">-1</span>];<br>                    &#125;<br>                &#125;<br><br>                <span class="hljs-keyword">if</span>(dp[i][j] == <span class="hljs-number">1</span> &amp;&amp; L &gt; max_len)&#123;<br>                    max_len = L;<br>                    idx = i;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> s.<span class="hljs-built_in">substr</span>(idx, max_len);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="32-最长有效括号"><a href="#32-最长有效括号" class="headerlink" title="32. 最长有效括号"></a>32. 最长有效括号</h3><p>给你一个只包含 ‘(‘ 和 ‘)’ 的字符串，找出最长有效（格式正确且连续）括号子串的长度。<br>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：s = <span class="hljs-string">&quot;(()&quot;</span><br>输出：2<br>解释：最长有效括号子串是 <span class="hljs-string">&quot;()&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">longestValidParentheses</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-type">int</span> maxans = <span class="hljs-number">0</span>, n = s.<span class="hljs-built_in">length</span>();<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n, <span class="hljs-number">0</span>)</span></span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++) &#123;<br>            <span class="hljs-keyword">if</span> (s[i] == <span class="hljs-string">&#x27;)&#x27;</span>) &#123;<br>                <span class="hljs-keyword">if</span> (s[i - <span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;(&#x27;</span>) &#123;<br>                    dp[i] = (i &gt;= <span class="hljs-number">2</span> ? dp[i - <span class="hljs-number">2</span>] : <span class="hljs-number">0</span>) + <span class="hljs-number">2</span>;<br>                &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (i - dp[i - <span class="hljs-number">1</span>] &gt; <span class="hljs-number">0</span> &amp;&amp; s[i - dp[i - <span class="hljs-number">1</span>] - <span class="hljs-number">1</span>] == <span class="hljs-string">&#x27;(&#x27;</span>) &#123;<br>                    dp[i] = dp[i - <span class="hljs-number">1</span>] + ((i - dp[i - <span class="hljs-number">1</span>]) &gt;= <span class="hljs-number">2</span> ? dp[i - dp[i - <span class="hljs-number">1</span>] - <span class="hljs-number">2</span>] : <span class="hljs-number">0</span>) + <span class="hljs-number">2</span>;<br>                &#125;<br>                maxans = <span class="hljs-built_in">max</span>(maxans, dp[i]);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> maxans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="45-跳跃游戏-II"><a href="#45-跳跃游戏-II" class="headerlink" title="45. 跳跃游戏 II"></a>45. 跳跃游戏 II</h3><p>给定一个长度为 n 的 0 索引整数数组 nums。初始位置为 nums[0]。</p><p>每个元素 nums[i] 表示从索引 i 向前跳转的最大长度。换句话说，如果你在 nums[i] 处，你可以跳转到任意 nums[i + j] 处:</p><p>0 &lt;&#x3D; j &lt;&#x3D; nums[i]<br>i + j &lt; n<br>返回到达 nums[n - 1] 的最小跳跃次数。生成的测试用例可以到达 nums[n - 1]。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">jump</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br><br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n, INT_MAX)</span></span>;<br><br>        dp[<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= nums[i] &amp;&amp; i + j &lt; n; j++)&#123;<br>                dp[i + j] = <span class="hljs-built_in">min</span>(dp[i+j], dp[i] + <span class="hljs-number">1</span>);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n<span class="hljs-number">-1</span>];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="53-最大子数组和"><a href="#53-最大子数组和" class="headerlink" title="53. 最大子数组和"></a>53. 最大子数组和</h3><p>给你一个整数数组 nums ，请你找出一个具有最大和的连续子数组（子数组最少包含一个元素），返回其最大和。<br>子数组 是数组中的一个连续部分。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [-2,1,-3,4,-1,2,1,-5,4]<br>输出：6<br>解释：连续子数组 [4,-1,2,1] 的和最大，为 6。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxSubArray</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> ret;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n)</span></span>;<br><br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> nums[<span class="hljs-number">0</span>];<br>        &#125;<br><br>        dp[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        ret = dp[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++)&#123;<br>            dp[i] = <span class="hljs-built_in">max</span>(dp[i<span class="hljs-number">-1</span>] + nums[i], nums[i]);<br>            ret = <span class="hljs-built_in">max</span>(ret, dp[i]);<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="55-跳跃游戏"><a href="#55-跳跃游戏" class="headerlink" title="55. 跳跃游戏"></a>55. 跳跃游戏</h3><p>给你一个非负整数数组 nums ，你最初位于数组的 第一个下标。数组中的每个元素代表你在该位置可以跳跃的最大长度。<br>判断你是否能够到达最后一个下标，如果可以，返回 true ；否则，返回 false。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">canJump</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> max_jump = <span class="hljs-number">0</span>;<br><br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n - <span class="hljs-number">1</span>; i++)&#123;<br>            <span class="hljs-keyword">if</span> (i &lt;= max_jump)&#123;<br>                max_jump = <span class="hljs-built_in">max</span>(max_jump, i + nums[i]);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> max_jump &gt;= n<span class="hljs-number">-1</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="62-不同路径"><a href="#62-不同路径" class="headerlink" title="62. 不同路径"></a>62. 不同路径</h3><p>一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。<br>机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish” ）。<br>问总共有多少条不同的路径？</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">uniquePaths</span><span class="hljs-params">(<span class="hljs-type">int</span> m, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n)</span></span>;<br>        dp[<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; m; j ++)&#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n ; i++)&#123;<br>                <span class="hljs-keyword">if</span> (j == <span class="hljs-number">0</span> &amp;&amp; i &gt; <span class="hljs-number">0</span>)&#123;<br>                    dp[i] = <span class="hljs-number">1</span>;<br>                &#125;<br>                <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span> &amp;&amp; j &gt; <span class="hljs-number">1</span>)&#123;<br>                    dp[i] = <span class="hljs-number">1</span>;<br>                &#125;<br>                <span class="hljs-keyword">if</span>(i &gt; <span class="hljs-number">0</span> &amp;&amp; j &gt; <span class="hljs-number">0</span>)&#123;<br>                    dp[i] = dp[i] + dp[i<span class="hljs-number">-1</span>];<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n<span class="hljs-number">-1</span>];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="63-不同路径-II"><a href="#63-不同路径-II" class="headerlink" title="63. 不同路径 II"></a>63. 不同路径 II</h3><p>一个机器人位于一个 m x n 网格的左上角 （起始点在下图中标记为 “Start” ）。<br>机器人每次只能向下或者向右移动一步。机器人试图达到网格的右下角（在下图中标记为 “Finish”）。<br>现在考虑网格中有障碍物。那么从左上角到右下角将会有多少条不同的路径？<br>网格中的障碍物和空位置分别用 1 和 0 来表示。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">uniquePathsWithObstacles</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; obstacleGrid)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = obstacleGrid.<span class="hljs-built_in">size</span>(), m = obstacleGrid.<span class="hljs-built_in">at</span>(<span class="hljs-number">0</span>).<span class="hljs-built_in">size</span>();<br>        vector &lt;<span class="hljs-type">int</span>&gt; <span class="hljs-built_in">f</span>(m);<br><br>        f[<span class="hljs-number">0</span>] = (obstacleGrid[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] == <span class="hljs-number">0</span>);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; m; ++j) &#123;<br>                <span class="hljs-keyword">if</span> (obstacleGrid[i][j] == <span class="hljs-number">1</span>) &#123;<br>                    f[j] = <span class="hljs-number">0</span>;<br>                    <span class="hljs-keyword">continue</span>;<br>                &#125;<br>                <span class="hljs-keyword">if</span> (j - <span class="hljs-number">1</span> &gt;= <span class="hljs-number">0</span> &amp;&amp; obstacleGrid[i][j - <span class="hljs-number">1</span>] == <span class="hljs-number">0</span>) &#123;<br>                    f[j] += f[j - <span class="hljs-number">1</span>];<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> f.<span class="hljs-built_in">back</span>();<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="64-最小路径和"><a href="#64-最小路径和" class="headerlink" title="64. 最小路径和"></a>64. 最小路径和</h3><p>给定一个包含非负整数的 m x n 网格 grid ，请找出一条从左上角到右下角的路径，使得路径上的数字总和为最小。<br>说明：每次只能向下或者向右移动一步。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：grid = [[1,3,1],[1,5,1],[4,2,1]]<br>输出：7<br>解释：因为路径 1→3→1→1→1 的总和最小。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">minPathSum</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; grid)</span> </span>&#123;<br>        <span class="hljs-type">int</span> m = grid.<span class="hljs-built_in">size</span>(), n = grid[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n)</span></span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++)&#123;<br>                <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span>)&#123;<br>                    <span class="hljs-keyword">if</span>(j == <span class="hljs-number">0</span>)&#123;<br>                        dp[j] = grid[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>];<br>                    &#125; <span class="hljs-keyword">else</span>&#123;<br>                        dp[j] = dp[j<span class="hljs-number">-1</span>] + grid[i][j];<br>                    &#125;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-keyword">if</span> (j == <span class="hljs-number">0</span>)&#123;<br>                        dp[j] += grid[i][<span class="hljs-number">0</span>];<br>                    &#125; <span class="hljs-keyword">else</span> &#123;<br>                        dp[j] = <span class="hljs-built_in">min</span>(dp[j], dp[j<span class="hljs-number">-1</span>]) + grid[i][j];<br>                    &#125;<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n<span class="hljs-number">-1</span>];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="72-编辑距离"><a href="#72-编辑距离" class="headerlink" title="72. 编辑距离"></a>72. 编辑距离</h3><p>给你两个单词 word1 和 word2， 请返回将 word1 转换成 word2 所使用的最少操作数。</p><p>你可以对一个单词进行如下三种操作：</p><p>插入一个字符<br>删除一个字符<br>替换一个字符</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：word1 = <span class="hljs-string">&quot;horse&quot;</span>, word2 = <span class="hljs-string">&quot;ros&quot;</span><br>输出：3<br>解释：<br>horse -&gt; rorse (将 <span class="hljs-string">&#x27;h&#x27;</span> 替换为 <span class="hljs-string">&#x27;r&#x27;</span>)<br>rorse -&gt; rose (删除 <span class="hljs-string">&#x27;r&#x27;</span>)<br>rose -&gt; ros (删除 <span class="hljs-string">&#x27;e&#x27;</span>)<br></code></pre></td></tr></table></figure><p>示例 2：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：word1 = <span class="hljs-string">&quot;intention&quot;</span>, word2 = <span class="hljs-string">&quot;execution&quot;</span><br>输出：5<br>解释：<br>intention -&gt; inention (删除 <span class="hljs-string">&#x27;t&#x27;</span>)<br>inention -&gt; enention (将 <span class="hljs-string">&#x27;i&#x27;</span> 替换为 <span class="hljs-string">&#x27;e&#x27;</span>)<br>enention -&gt; exention (将 <span class="hljs-string">&#x27;n&#x27;</span> 替换为 <span class="hljs-string">&#x27;x&#x27;</span>)<br>exention -&gt; exection (将 <span class="hljs-string">&#x27;n&#x27;</span> 替换为 <span class="hljs-string">&#x27;c&#x27;</span>)<br>exection -&gt; execution (插入 <span class="hljs-string">&#x27;u&#x27;</span>)<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">minDistance</span><span class="hljs-params">(string word1, string word2)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = word<span class="hljs-number">1.l</span>ength(), m = word<span class="hljs-number">2.l</span>ength();<br><br>        <span class="hljs-keyword">if</span> (m * n == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">return</span> m + n;<br>        &#125;<br><br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">dp</span>(n<span class="hljs-number">+1</span>, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(m<span class="hljs-number">+1</span>));<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt;= n; i++)&#123;<br>            dp[i][<span class="hljs-number">0</span>] = i;<br>        &#125;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt;= m; j++)&#123;<br>            dp[<span class="hljs-number">0</span>][j] = j;<br>        &#125;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= n; i++)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= m; j++)&#123;<br>                <span class="hljs-type">int</span> ans1 = dp[i][j<span class="hljs-number">-1</span>] + <span class="hljs-number">1</span>;<br>                <span class="hljs-type">int</span> ans2 = dp[i<span class="hljs-number">-1</span>][j] + <span class="hljs-number">1</span>;<br>                <span class="hljs-type">int</span> ans3 = dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>];<br>                <span class="hljs-keyword">if</span> (word1[i<span class="hljs-number">-1</span>] != word2[j<span class="hljs-number">-1</span>])&#123;<br>                    ans3 +=<span class="hljs-number">1</span>;<br>                &#125;<br>                dp[i][j] = <span class="hljs-built_in">min</span>(ans1, <span class="hljs-built_in">min</span>(ans2, ans3));<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n][m];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="79-单词搜索"><a href="#79-单词搜索" class="headerlink" title="79. 单词搜索"></a>79. 单词搜索</h3><p>给定一个 m x n 二维字符网格 board 和一个字符串单词 word。如果 word 存在于网格中，返回 true ；否则，返回 false。<br>单词必须按照字母顺序，通过相邻的单元格内的字母构成，其中“相邻”单元格是那些水平相邻或垂直相邻的单元格。同一个单元格内的字母不允许被重复使用。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：board = [[<span class="hljs-string">&quot;A&quot;</span>,<span class="hljs-string">&quot;B&quot;</span>,<span class="hljs-string">&quot;C&quot;</span>,<span class="hljs-string">&quot;E&quot;</span>],[<span class="hljs-string">&quot;S&quot;</span>,<span class="hljs-string">&quot;F&quot;</span>,<span class="hljs-string">&quot;C&quot;</span>,<span class="hljs-string">&quot;S&quot;</span>],[<span class="hljs-string">&quot;A&quot;</span>,<span class="hljs-string">&quot;D&quot;</span>,<span class="hljs-string">&quot;E&quot;</span>,<span class="hljs-string">&quot;E&quot;</span>]], word = <span class="hljs-string">&quot;ABCCED&quot;</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">exist</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; board, string word)</span> </span>&#123;<br>        rows = board.<span class="hljs-built_in">size</span>();<br>        cols = board[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; rows; i++) &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; cols; j++) &#123;<br>                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">dfs</span>(board, word, i, j, <span class="hljs-number">0</span>)) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-type">int</span> rows, cols;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">dfs</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; board, string word, <span class="hljs-type">int</span> i, <span class="hljs-type">int</span> j, <span class="hljs-type">int</span> k)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (i &gt;= rows || i &lt; <span class="hljs-number">0</span> || j &gt;= cols || j &lt; <span class="hljs-number">0</span> || board[i][j] != word[k]) <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        <span class="hljs-keyword">if</span> (k == word.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        board[i][j] = <span class="hljs-string">&#x27;\0&#x27;</span>;<br>        <span class="hljs-type">bool</span> res = <span class="hljs-built_in">dfs</span>(board, word, i + <span class="hljs-number">1</span>, j, k + <span class="hljs-number">1</span>) || <span class="hljs-built_in">dfs</span>(board, word, i - <span class="hljs-number">1</span>, j, k + <span class="hljs-number">1</span>) || <br>                      <span class="hljs-built_in">dfs</span>(board, word, i, j + <span class="hljs-number">1</span>, k + <span class="hljs-number">1</span>) || <span class="hljs-built_in">dfs</span>(board, word, i , j - <span class="hljs-number">1</span>, k + <span class="hljs-number">1</span>);<br>        board[i][j] = word[k];<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="97-交错字符串"><a href="#97-交错字符串" class="headerlink" title="97. 交错字符串"></a>97. 交错字符串</h3><p>给定三个字符串 s1、s2、s3，请你帮忙验证 s3 是否是由 s1 和 s2 交错 组成的。<br>两个字符串 s 和 t 交错 的定义与过程如下，其中每个字符串都会被分割成若干 非空 子字符串：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">s = s1 + s2 + ... + sn<br>t = t1 + t2 + ... + tm<br>|n - m| &lt;= 1<br>交错 是 s1 + t1 + s2 + t2 + s3 + t3 + ... 或者 t1 + s1 + t2 + s2 + t3 + s3 + ...<br>注意：a + b 意味着字符串 a 和 b 连接。<br></code></pre></td></tr></table></figure><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：s1 = <span class="hljs-string">&quot;aabcc&quot;</span>, s2 = <span class="hljs-string">&quot;dbbca&quot;</span>, s3 = <span class="hljs-string">&quot;aadbbcbcac&quot;</span><br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isInterleave</span><span class="hljs-params">(string s1, string s2, string s3)</span> </span>&#123;<br>        <span class="hljs-keyword">auto</span> f = vector &lt; vector &lt;<span class="hljs-type">int</span>&gt; &gt; (s<span class="hljs-number">1.</span><span class="hljs-built_in">size</span>() + <span class="hljs-number">1</span>, vector &lt;<span class="hljs-type">int</span>&gt; (s<span class="hljs-number">2.</span><span class="hljs-built_in">size</span>() + <span class="hljs-number">1</span>, <span class="hljs-literal">false</span>));<br><br>        <span class="hljs-type">int</span> n = s<span class="hljs-number">1.</span><span class="hljs-built_in">size</span>(), m = s<span class="hljs-number">2.</span><span class="hljs-built_in">size</span>(), t = s<span class="hljs-number">3.</span><span class="hljs-built_in">size</span>();<br><br>        <span class="hljs-keyword">if</span> (n + m != t) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br><br>        f[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-literal">true</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt;= n; ++i) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt;= m; ++j) &#123;<br>                <span class="hljs-type">int</span> p = i + j - <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">if</span> (i &gt; <span class="hljs-number">0</span>) &#123;<br>                    f[i][j] |= (f[i - <span class="hljs-number">1</span>][j] &amp;&amp; s1[i - <span class="hljs-number">1</span>] == s3[p]);<br>                &#125;<br>                <span class="hljs-keyword">if</span> (j &gt; <span class="hljs-number">0</span>) &#123;<br>                    f[i][j] |= (f[i][j - <span class="hljs-number">1</span>] &amp;&amp; s2[j - <span class="hljs-number">1</span>] == s3[p]);<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> f[n][m];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="122-买卖股票的最佳时机-II"><a href="#122-买卖股票的最佳时机-II" class="headerlink" title="122. 买卖股票的最佳时机 II"></a>122. 买卖股票的最佳时机 II</h3><p>给你一个整数数组 prices ，其中 prices[i] 表示某支股票第 i 天的价格。<br>在每一天，你可以决定是否购买和&#x2F;或出售股票。你在任何时候 最多 只能持有 一股 股票。你也可以先购买，然后在 同一天 出售。<br>返回 你能获得的 最大 利润 。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：prices = [7,1,5,3,6,4]<br>输出：7<br>解释：在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。<br>     随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6 - 3 = 3 。<br>     总利润为 4 + 3 = 7 。<br></code></pre></td></tr></table></figure><p>定义状态<code>dp[i][0]</code>表示第<code>i</code>天交易完后手里没有股票的最大利润，<code>dp[i][1]</code>表示第<code>i</code>天交易完后手里持有一支股票的最大利润（<code>i</code>从<code>0</code>开始）。</p><p>考虑<code>dp[i][0]</code>的转移方程，如果这一天交易完后手里没有股票，那么可能的转移状态为前一天已经没有股票，即<code>dp[i−1][0]</code>，或者前一天结束的时候手里持有一支股票，即<code>dp[i−1][1]</code>，这时候我们要将其卖出，并获得<code>prices[i]</code>的收益。因此为了收益最大化，我们列出如下的转移方程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dp[i][0] = max(dp[i-1][0], dp[i-1][1] + prices[i])<br></code></pre></td></tr></table></figure><p>再来考虑<code>dp[i][1]</code>，按照同样的方式考虑转移状态，那么可能的转移状态为前一天已经持有一支股票，即<code>dp[i−1][1]</code>，或者前一天结束时还没有股票，即<code>dp[i−1][0]</code>，这时候我们要将其买入，并减少<code>prices[i]</code>的收益。可以列出如下的转移方程：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">dp[i][1] = max(dp[i-1][1], dp[i-1][0] - prices[i])<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; prices)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = prices.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> dp[n][<span class="hljs-number">2</span>];<br>        dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>, dp[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>] = -prices[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; ++i) &#123;<br>            dp[i][<span class="hljs-number">0</span>] = <span class="hljs-built_in">max</span>(dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>], dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">1</span>] + prices[i]);<br>            dp[i][<span class="hljs-number">1</span>] = <span class="hljs-built_in">max</span>(dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">1</span>], dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] - prices[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="123-买卖股票的最佳时机-III"><a href="#123-买卖股票的最佳时机-III" class="headerlink" title="123. 买卖股票的最佳时机 III"></a>123. 买卖股票的最佳时机 III</h3><p>给定一个数组，它的第 i 个元素是一支给定的股票在第 i 天的价格。<br>设计一个算法来计算你所能获取的最大利润。你最多可以完成 两笔 交易。<br>注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。</p><p>示例 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：prices = [3,3,5,0,0,3,1,4]<br>输出：6<br>解释：在第 4 天（股票价格 = 0）的时候买入，在第 6 天（股票价格 = 3）的时候卖出，这笔交易所能获得利润 = 3-0 = 3 。<br>     随后，在第 7 天（股票价格 = 1）的时候买入，在第 8 天 （股票价格 = 4）的时候卖出，这笔交易所能获得利润 = 4-1 = 3 。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; prices)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = prices.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> buy1 = -prices[<span class="hljs-number">0</span>], sell1 = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> buy2 = -prices[<span class="hljs-number">0</span>], sell2 = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; ++i) &#123;<br>            buy1 = <span class="hljs-built_in">max</span>(buy1, -prices[i]);<br>            sell1 = <span class="hljs-built_in">max</span>(sell1, buy1 + prices[i]);<br>            buy2 = <span class="hljs-built_in">max</span>(buy2, sell1 - prices[i]);<br>            sell2 = <span class="hljs-built_in">max</span>(sell2, buy2 + prices[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> sell2;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="188-买卖股票的最佳时机-IV"><a href="#188-买卖股票的最佳时机-IV" class="headerlink" title="188. 买卖股票的最佳时机 IV"></a>188. 买卖股票的最佳时机 IV</h3><p>给你一个整数数组 prices 和一个整数 k ，其中 prices[i] 是某支给定的股票在第 i 天的价格。<br>设计一个算法来计算你所能获取的最大利润。你最多可以完成 k 笔交易。也就是说，你最多可以买 k 次，卖 k 次。<br>注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：k = 2, prices = [2,4,1]<br>输出：2<br>解释：在第 1 天 (股票价格 = 2) 的时候买入，在第 2 天 (股票价格 = 4) 的时候卖出，这笔交易所能获得利润 = 4-2 = 2 。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(<span class="hljs-type">int</span> k, vector&lt;<span class="hljs-type">int</span>&gt;&amp; prices)</span> </span>&#123;<br>        k = <span class="hljs-built_in">min</span>&lt;<span class="hljs-type">int</span>&gt;(k, prices.<span class="hljs-built_in">size</span>() / <span class="hljs-number">2</span>) + <span class="hljs-number">1</span>;<br>        <span class="hljs-function">vector <span class="hljs-title">buy</span><span class="hljs-params">(k, INT_MIN)</span>, <span class="hljs-title">sel</span><span class="hljs-params">(k, <span class="hljs-number">0</span>)</span></span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i : prices) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt; k; j++) &#123;<br>                buy[j] = <span class="hljs-built_in">max</span>(buy[j], sel[j - <span class="hljs-number">1</span>] - i);<br>                sel[j] = <span class="hljs-built_in">max</span>(sel[j], buy[j] + i);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> sel.<span class="hljs-built_in">back</span>();<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="309-买卖股票的最佳时机含冷冻期"><a href="#309-买卖股票的最佳时机含冷冻期" class="headerlink" title="309. 买卖股票的最佳时机含冷冻期"></a>309. 买卖股票的最佳时机含冷冻期</h3><p>给定一个整数数组prices，其中第  prices[i] 表示第 i 天的股票价格 。​<br>设计一个算法计算出最大利润。在满足以下约束条件下，你可以尽可能地完成更多的交易（多次买卖一支股票）:<br>卖出股票后，你无法在第二天买入股票 (即冷冻期为 1 天)。<br>注意：你不能同时参与多笔交易（你必须在再次购买前出售掉之前的股票）。</p><p>示例 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入: prices = [1,2,3,0,2]<br>输出: 3 <br>解释: 对应的交易状态为: [买入, 卖出, 冷冻期, 买入, 卖出]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; prices)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (prices.<span class="hljs-built_in">empty</span>()) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br><br>        <span class="hljs-type">int</span> n = prices.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-comment">// f[i][0]: 手上持有股票的最大收益</span><br>        <span class="hljs-comment">// f[i][1]: 手上不持有股票，并且处于冷冻期中的累计最大收益</span><br>        <span class="hljs-comment">// f[i][2]: 手上不持有股票，并且不在冷冻期中的累计最大收益</span><br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">f</span>(n, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(<span class="hljs-number">3</span>));<br>        f[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = -prices[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; ++i) &#123;<br>            f[i][<span class="hljs-number">0</span>] = <span class="hljs-built_in">max</span>(f[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>], f[i - <span class="hljs-number">1</span>][<span class="hljs-number">2</span>] - prices[i]);<br>            f[i][<span class="hljs-number">1</span>] = f[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] + prices[i];<br>            f[i][<span class="hljs-number">2</span>] = <span class="hljs-built_in">max</span>(f[i - <span class="hljs-number">1</span>][<span class="hljs-number">1</span>], f[i - <span class="hljs-number">1</span>][<span class="hljs-number">2</span>]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(f[n - <span class="hljs-number">1</span>][<span class="hljs-number">1</span>], f[n - <span class="hljs-number">1</span>][<span class="hljs-number">2</span>]);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="714-买卖股票的最佳时机含手续费"><a href="#714-买卖股票的最佳时机含手续费" class="headerlink" title="714. 买卖股票的最佳时机含手续费"></a>714. 买卖股票的最佳时机含手续费</h3><p>给定一个整数数组 prices，其中 prices[i]表示第 i 天的股票价格 ；整数 fee 代表了交易股票的手续费用。<br>你可以无限次地完成交易，但是你每笔交易都需要付手续费。如果你已经购买了一个股票，在卖出它之前你就不能再继续购买股票了。</p><p>返回获得利润的最大值。<br>注意：这里的一笔交易指买入持有并卖出股票的整个过程，每笔交易你只需要为支付一次手续费。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：prices = [1, 3, 2, 8, 4, 9], fee = 2<br>输出：8<br>解释：能够达到的最大利润:  <br>在此处买入 prices[0] = 1<br>在此处卖出 prices[3] = 8<br>在此处买入 prices[4] = 4<br>在此处卖出 prices[5] = 9<br>总利润: ((<span class="hljs-number">8</span> - <span class="hljs-number">1</span>) - <span class="hljs-number">2</span>) + ((<span class="hljs-number">9</span> - <span class="hljs-number">4</span>) - <span class="hljs-number">2</span>) = <span class="hljs-number">8</span><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; prices, <span class="hljs-type">int</span> fee)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = prices.<span class="hljs-built_in">size</span>();<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">dp</span>(n, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(<span class="hljs-number">2</span>));<br>        dp[<span class="hljs-number">0</span>][<span class="hljs-number">0</span>] = <span class="hljs-number">0</span>, dp[<span class="hljs-number">0</span>][<span class="hljs-number">1</span>] = -prices[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; ++i) &#123;<br>            dp[i][<span class="hljs-number">0</span>] = <span class="hljs-built_in">max</span>(dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>], dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">1</span>] + prices[i] - fee);<br>            dp[i][<span class="hljs-number">1</span>] = <span class="hljs-built_in">max</span>(dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">1</span>], dp[i - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>] - prices[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n - <span class="hljs-number">1</span>][<span class="hljs-number">0</span>];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="198-打家劫舍"><a href="#198-打家劫舍" class="headerlink" title="198. 打家劫舍"></a>198. 打家劫舍</h3><p>你是一个专业的小偷，计划偷窃沿街的房屋。每间房内都藏有一定的现金，影响你偷窃的唯一制约因素就是相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警。<br>给定一个代表每个房屋存放金额的非负整数数组，计算你 不触动警报装置的情况下 ，一夜之内能够偷窃到的最高金额。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：[1,2,3,1]<br>输出：4<br>解释：偷窃 1 号房屋 (金额 = 1) ，然后偷窃 3 号房屋 (金额 = 3)。<br>     偷窃到的最高金额 = 1 + 3 = 4 。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">rob</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n)</span></span>;<br><br>        <span class="hljs-keyword">if</span>(n == <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> nums[<span class="hljs-number">0</span>];<br>        &#125;<br><br>        <span class="hljs-keyword">if</span>(n == <span class="hljs-number">2</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(nums[<span class="hljs-number">0</span>], nums[<span class="hljs-number">1</span>]);<br>        &#125;<br>        dp[<span class="hljs-number">0</span>] = nums[<span class="hljs-number">0</span>];<br>        dp[<span class="hljs-number">1</span>] = <span class="hljs-built_in">max</span>(nums[<span class="hljs-number">0</span>], nums[<span class="hljs-number">1</span>]);<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>; i &lt; n; i++)&#123;<br>            dp[i] = <span class="hljs-built_in">max</span>(dp[i<span class="hljs-number">-1</span>], dp[i<span class="hljs-number">-2</span>] + nums[i]);<br>            ret = <span class="hljs-built_in">max</span>(ret, dp[i]);<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="213-打家劫舍-II"><a href="#213-打家劫舍-II" class="headerlink" title="213. 打家劫舍 II"></a>213. 打家劫舍 II</h3><p>你是一个专业的小偷，计划偷窃沿街的房屋，每间房内都藏有一定的现金。这个地方所有的房屋都 围成一圈 ，这意味着第一个房屋和最后一个房屋是紧挨着的。同时，相邻的房屋装有相互连通的防盗系统，如果两间相邻的房屋在同一晚上被小偷闯入，系统会自动报警 。<br>给定一个代表每个房屋存放金额的非负整数数组，计算你 在不触动警报装置的情况下 ，今晚能够偷窃到的最高金额。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [2,3,2]<br>输出：3<br>解释：你不能先偷窃 1 号房屋（金额 = 2），然后偷窃 3 号房屋（金额 = 2）, 因为他们是相邻的。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">robRange</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end)</span> </span>&#123;<br>        <span class="hljs-type">int</span> first = nums[start], second = <span class="hljs-built_in">max</span>(nums[start], nums[start + <span class="hljs-number">1</span>]);<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = start + <span class="hljs-number">2</span>; i &lt;= end; i++) &#123;<br>            <span class="hljs-type">int</span> temp = second;<br>            second = <span class="hljs-built_in">max</span>(first + nums[i], second);<br>            first = temp;<br>        &#125;<br>        <span class="hljs-keyword">return</span> second;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">rob</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> length = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span> (length == <span class="hljs-number">1</span>) &#123;<br>            <span class="hljs-keyword">return</span> nums[<span class="hljs-number">0</span>];<br>        &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (length == <span class="hljs-number">2</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(nums[<span class="hljs-number">0</span>], nums[<span class="hljs-number">1</span>]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(<span class="hljs-built_in">robRange</span>(nums, <span class="hljs-number">0</span>, length - <span class="hljs-number">2</span>), <span class="hljs-built_in">robRange</span>(nums, <span class="hljs-number">1</span>, length - <span class="hljs-number">1</span>));<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="221-最大正方形"><a href="#221-最大正方形" class="headerlink" title="221. 最大正方形"></a>221. 最大正方形</h3><p>在一个由 ‘0’ 和 ‘1’ 组成的二维矩阵内，找到只包含 ‘1’ 的最大正方形，并返回其面积。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：matrix = [[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>],[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>],[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>],[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>]]<br>输出：4<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maximalSquare</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; matrix)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = matrix.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> m = matrix[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">dp</span>(n, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(m, <span class="hljs-number">0</span>));<br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">if</span> (matrix[i][<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;1&#x27;</span>)&#123;<br>                dp[i][<span class="hljs-number">0</span>] = <span class="hljs-number">1</span>;<br>                ret = <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++)&#123;<br>            <span class="hljs-keyword">if</span> (matrix[<span class="hljs-number">0</span>][i] == <span class="hljs-string">&#x27;1&#x27;</span>)&#123;<br>                dp[<span class="hljs-number">0</span>][i] = <span class="hljs-number">1</span>;<br>                ret = <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt; m; j++)&#123;<br>                <span class="hljs-keyword">if</span>(matrix[i][j] == <span class="hljs-string">&#x27;1&#x27;</span>)&#123;<br>                    dp[i][j] = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">min</span>(dp[i<span class="hljs-number">-1</span>][j], dp[i<span class="hljs-number">-1</span>][j<span class="hljs-number">-1</span>]), dp[i][j<span class="hljs-number">-1</span>]) + <span class="hljs-number">1</span>;<br>                    ret = <span class="hljs-built_in">max</span>(ret, dp[i][j]);<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret * ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="279-完全平方数"><a href="#279-完全平方数" class="headerlink" title="279. 完全平方数"></a>279. 完全平方数</h3><p>给你一个整数 n ，返回 和为 n 的完全平方数的最少数量 。<br>完全平方数 是一个整数，其值等于另一个整数的平方；换句话说，其值等于一个整数自乘的积。例如，1、4、9 和 16 都是完全平方数，而 3 和 11 不是。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：n = 12<br>输出：3 <br>解释：12 = 4 + 4 + 4<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">numSquares</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n<span class="hljs-number">+1</span>)</span></span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= n ;i++)&#123;<br>            <span class="hljs-type">int</span> q = <span class="hljs-built_in">sqrt</span>(i);<br>            <span class="hljs-keyword">if</span>(q*q == i)&#123;<br>                dp[i] = <span class="hljs-number">1</span>;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                dp[i] = i;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">1</span>; j &lt;= q; j++)&#123;<br>                    dp[i] = <span class="hljs-built_in">min</span>(dp[i], dp[j*j] + dp[i - j*j]);<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> dp[n];<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="300-最长递增子序列"><a href="#300-最长递增子序列" class="headerlink" title="300. 最长递增子序列"></a>300. 最长递增子序列</h3><p>给你一个整数数组 nums ，找到其中最长严格递增子序列的长度。<br>子序列 是由数组派生而来的序列，删除（或不删除）数组中的元素而不改变其余元素的顺序。例如，[3,6,2,7] 是数组 [0,3,1,6,2,2,7] 的子序列。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [10,9,2,5,3,7,101,18]<br>输出：4<br>解释：最长递增子序列是 [2,3,7,101]，因此长度为 4 。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">lengthOfLIS</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = (<span class="hljs-type">int</span>)nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">dp</span><span class="hljs-params">(n, <span class="hljs-number">0</span>)</span></span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>            dp[i] = <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; i; ++j) &#123;<br>                <span class="hljs-keyword">if</span> (nums[j] &lt; nums[i]) &#123;<br>                    dp[i] = <span class="hljs-built_in">max</span>(dp[i], dp[j] + <span class="hljs-number">1</span>);<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> *<span class="hljs-built_in">max_element</span>(dp.<span class="hljs-built_in">begin</span>(), dp.<span class="hljs-built_in">end</span>());<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="二叉树"><a href="#二叉树" class="headerlink" title="二叉树"></a>二叉树</h2><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-comment">//Definition for a binary tree node.</span><br> <span class="hljs-keyword">struct</span> <span class="hljs-title class_">TreeNode</span> &#123;<br>    <span class="hljs-type">int</span> val;<br>    TreeNode *left;<br>    TreeNode *right;<br>    <span class="hljs-built_in">TreeNode</span>() : <span class="hljs-built_in">val</span>(<span class="hljs-number">0</span>), <span class="hljs-built_in">left</span>(<span class="hljs-literal">nullptr</span>), <span class="hljs-built_in">right</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>    <span class="hljs-built_in">TreeNode</span>(<span class="hljs-type">int</span> x) : <span class="hljs-built_in">val</span>(x), <span class="hljs-built_in">left</span>(<span class="hljs-literal">nullptr</span>), <span class="hljs-built_in">right</span>(<span class="hljs-literal">nullptr</span>) &#123;&#125;<br>    <span class="hljs-built_in">TreeNode</span>(<span class="hljs-type">int</span> x, TreeNode *left, TreeNode *right) : <span class="hljs-built_in">val</span>(x), <span class="hljs-built_in">left</span>(left), <span class="hljs-built_in">right</span>(right) &#123;&#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="144-二叉树的前序遍历"><a href="#144-二叉树的前序遍历" class="headerlink" title="144. 二叉树的前序遍历"></a>144. 二叉树的前序遍历</h3><p>给你二叉树的根节点 root ，返回它节点值的 前序 遍历</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">frontOrder</span><span class="hljs-params">(TreeNode* root, vector&lt;<span class="hljs-type">int</span>&gt;&amp; res)</span></span>&#123;<br>        <span class="hljs-keyword">if</span> (!root)&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        res.<span class="hljs-built_in">push_back</span>(root-&gt;val);<br>        <span class="hljs-built_in">frontOrder</span>(root-&gt;left, res);<br>        <span class="hljs-built_in">frontOrder</span>(root-&gt;right, res);<br>    &#125;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">preorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        vector&lt;<span class="hljs-type">int</span>&gt; res;<br>        <span class="hljs-built_in">frontOrder</span>(root, res);<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="94-二叉树的中序遍历"><a href="#94-二叉树的中序遍历" class="headerlink" title="94. 二叉树的中序遍历"></a>94. 二叉树的中序遍历</h3><p>给定一个二叉树的根节点 root ，返回 它的 中序 遍历 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">inorder</span><span class="hljs-params">(TreeNode* root, vector&lt;<span class="hljs-type">int</span>&gt;&amp; res)</span></span>&#123;<br>        <span class="hljs-keyword">if</span> (!root)&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-built_in">inorder</span>(root-&gt;left, res);<br>        res.<span class="hljs-built_in">push_back</span>(root-&gt;val);<br>        <span class="hljs-built_in">inorder</span>(root-&gt;right, res);<br>    &#125;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">inorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        vector&lt;<span class="hljs-type">int</span>&gt; res;<br>        <span class="hljs-built_in">inorder</span>(root, res);<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="145-二叉树的后序遍历"><a href="#145-二叉树的后序遍历" class="headerlink" title="145. 二叉树的后序遍历"></a>145. 二叉树的后序遍历</h3><p>给你一棵二叉树的根节点 root ，返回其节点值的 后序遍历 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">postOrder</span><span class="hljs-params">(TreeNode* root, vector&lt;<span class="hljs-type">int</span>&gt;&amp; res)</span></span>&#123;<br>        <span class="hljs-keyword">if</span> (!root)&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-built_in">postOrder</span>(root-&gt;left, res);<br>        <span class="hljs-built_in">postOrder</span>(root-&gt;right, res);<br>        res.<span class="hljs-built_in">push_back</span>(root-&gt;val);<br>    &#125;<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">postorderTraversal</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        vector&lt;<span class="hljs-type">int</span>&gt; res;<br>        <span class="hljs-built_in">postOrder</span>(root, res);<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="95-不同的二叉搜索树-II"><a href="#95-不同的二叉搜索树-II" class="headerlink" title="95. 不同的二叉搜索树 II"></a>95. 不同的二叉搜索树 II</h3><p>给你一个整数 n ，请你生成并返回所有由 n 个节点组成且节点值从 1 到 n 互不相同的不同 二叉搜索树 。可以按 任意顺序 返回答案。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：n = 3<br>输出：[[1,null,2,null,3],[1,null,3,2],[2,1,3],[3,1,null,null,2],[3,2,null,1]]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;TreeNode*&gt; <span class="hljs-title">generateTrees</span><span class="hljs-params">(<span class="hljs-type">int</span> start, <span class="hljs-type">int</span> end)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (start &gt; end) &#123;<br>            <span class="hljs-keyword">return</span> &#123; <span class="hljs-literal">nullptr</span> &#125;;<br>        &#125;<br>        vector&lt;TreeNode*&gt; allTrees;<br>        <span class="hljs-comment">// 枚举可行根节点</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = start; i &lt;= end; i++) &#123;<br>            <span class="hljs-comment">// 获得所有可行的左子树集合</span><br>            vector&lt;TreeNode*&gt; leftTrees = <span class="hljs-built_in">generateTrees</span>(start, i - <span class="hljs-number">1</span>);<br><br>            <span class="hljs-comment">// 获得所有可行的右子树集合</span><br>            vector&lt;TreeNode*&gt; rightTrees = <span class="hljs-built_in">generateTrees</span>(i + <span class="hljs-number">1</span>, end);<br><br>            <span class="hljs-comment">// 从左子树集合中选出一棵左子树，从右子树集合中选出一棵右子树，拼接到根节点上</span><br>            <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; left : leftTrees) &#123;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; right : rightTrees) &#123;<br>                    TreeNode* currTree = <span class="hljs-keyword">new</span> <span class="hljs-built_in">TreeNode</span>(i);<br>                    currTree-&gt;left = left;<br>                    currTree-&gt;right = right;<br>                    allTrees.<span class="hljs-built_in">emplace_back</span>(currTree);<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> allTrees;<br>    &#125;<br><br>    <span class="hljs-function">vector&lt;TreeNode*&gt; <span class="hljs-title">generateTrees</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (!n) &#123;<br>            <span class="hljs-keyword">return</span> &#123;&#125;;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">generateTrees</span>(<span class="hljs-number">1</span>, n);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="96-不同的二叉搜索树"><a href="#96-不同的二叉搜索树" class="headerlink" title="96. 不同的二叉搜索树"></a>96. 不同的二叉搜索树</h3><p>给你一个整数 n ，求恰由 n 个节点组成且节点值从 1 到 n 互不相同的 二叉搜索树 有多少种？返回满足题意的二叉搜索树的种数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">numTrees</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> C = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>            C = C * <span class="hljs-number">2</span> * (<span class="hljs-number">2</span> * i + <span class="hljs-number">1</span>) / (i + <span class="hljs-number">2</span>);<br>        &#125;<br>        <span class="hljs-keyword">return</span> (<span class="hljs-type">int</span>)C;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="98-验证二叉搜索树"><a href="#98-验证二叉搜索树" class="headerlink" title="98. 验证二叉搜索树"></a>98. 验证二叉搜索树</h3><p>给你一个二叉树的根节点 root ，判断其是否是一个有效的二叉搜索树。</p><p>有效 二叉搜索树定义如下：</p><p>节点的左子树只包含 小于 当前节点的数。<br>节点的右子树只包含 大于 当前节点的数。<br>所有左子树和右子树自身必须也是二叉搜索树。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">helper</span><span class="hljs-params">(TreeNode* root, <span class="hljs-type">long</span> <span class="hljs-type">long</span> lower, <span class="hljs-type">long</span> <span class="hljs-type">long</span> upper)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (root -&gt; val &lt;= lower || root -&gt; val &gt;= upper) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">helper</span>(root -&gt; left, lower, root -&gt; val) &amp;&amp; <span class="hljs-built_in">helper</span>(root -&gt; right, root -&gt; val, upper);<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isValidBST</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">helper</span>(root, LONG_MIN, LONG_MAX);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="99-恢复二叉搜索树"><a href="#99-恢复二叉搜索树" class="headerlink" title="99. 恢复二叉搜索树"></a>99. 恢复二叉搜索树</h3><p>给你二叉搜索树的根节点 root ，该树中的 恰好 两个节点的值被错误地交换。请在不改变其结构的情况下，恢复这棵树 。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：root = [1,3,null,null,2]<br>输出：[3,1,null,null,2]<br>解释：3 不能是 1 的左孩子，因为 3 &gt; 1 。交换 1 和 3 使二叉搜索树有效。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">inorder</span><span class="hljs-params">(TreeNode* root, vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-built_in">inorder</span>(root-&gt;left, nums);<br>        nums.<span class="hljs-built_in">push_back</span>(root-&gt;val);<br>        <span class="hljs-built_in">inorder</span>(root-&gt;right, nums);<br>    &#125;<br><br>    <span class="hljs-function">pair&lt;<span class="hljs-type">int</span>,<span class="hljs-type">int</span>&gt; <span class="hljs-title">findTwoSwapped</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> index1 = <span class="hljs-number">-1</span>, index2 = <span class="hljs-number">-1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n - <span class="hljs-number">1</span>; ++i) &#123;<br>            <span class="hljs-keyword">if</span> (nums[i + <span class="hljs-number">1</span>] &lt; nums[i]) &#123;<br>                index2 = i + <span class="hljs-number">1</span>;<br>                <span class="hljs-keyword">if</span> (index1 == <span class="hljs-number">-1</span>) &#123;<br>                    index1 = i;<br>                &#125; <span class="hljs-keyword">else</span> &#123;<br>                    <span class="hljs-keyword">break</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br>        <span class="hljs-type">int</span> x = nums[index1], y = nums[index2];<br>        <span class="hljs-keyword">return</span> &#123;x, y&#125;;<br>    &#125;<br>    <br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">recover</span><span class="hljs-params">(TreeNode* r, <span class="hljs-type">int</span> count, <span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (r != <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">if</span> (r-&gt;val == x || r-&gt;val == y) &#123;<br>                r-&gt;val = r-&gt;val == x ? y : x;<br>                <span class="hljs-keyword">if</span> (--count == <span class="hljs-number">0</span>) &#123;<br>                    <span class="hljs-keyword">return</span>;<br>                &#125;<br>            &#125;<br>            <span class="hljs-built_in">recover</span>(r-&gt;left, count, x, y);<br>            <span class="hljs-built_in">recover</span>(r-&gt;right, count, x, y);<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">recoverTree</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        vector&lt;<span class="hljs-type">int</span>&gt; nums;<br>        <span class="hljs-built_in">inorder</span>(root, nums);<br>        pair&lt;<span class="hljs-type">int</span>,<span class="hljs-type">int</span>&gt; swapped= <span class="hljs-built_in">findTwoSwapped</span>(nums);<br>        <span class="hljs-built_in">recover</span>(root, <span class="hljs-number">2</span>, swapped.first, swapped.second);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="100-相同的树"><a href="#100-相同的树" class="headerlink" title="100. 相同的树"></a>100. 相同的树</h3><p>给你两棵二叉树的根节点 p 和 q ，编写一个函数来检验这两棵树是否相同。<br>如果两个树在结构上相同，并且节点具有相同的值，则认为它们是相同的。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isSameTree</span><span class="hljs-params">(TreeNode* p, TreeNode* q)</span> </span>&#123;<br>        <span class="hljs-type">bool</span> res1, res2;<br>        <span class="hljs-keyword">if</span>(!p &amp;&amp; !q)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span>((!p &amp;&amp; q) || (p &amp;&amp; !q))&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125; <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">if</span> (p-&gt;val != q-&gt;val)&#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<span class="hljs-keyword">else</span>&#123;<br>                res1 = <span class="hljs-built_in">isSameTree</span>(p-&gt;left, q-&gt;left);<br>                res2 = <span class="hljs-built_in">isSameTree</span>(p-&gt;right, q-&gt;right);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> res1 &amp;&amp; res2;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="101-对称二叉树"><a href="#101-对称二叉树" class="headerlink" title="101. 对称二叉树"></a>101. 对称二叉树</h3><p>给你一个二叉树的根节点 root ， 检查它是否轴对称。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">judge</span><span class="hljs-params">(TreeNode* left, TreeNode* right)</span></span>&#123;<br>        <span class="hljs-keyword">if</span> (!left &amp;&amp; !right)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span>(left &amp;&amp; right)&#123;<br>            <span class="hljs-built_in">return</span> (left-&gt;val == right-&gt;val) &amp;&amp; <span class="hljs-built_in">judge</span>(left-&gt;left, right-&gt;right) &amp;&amp; <span class="hljs-built_in">judge</span>(left-&gt;right, right-&gt;left);<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isSymmetric</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(!root)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-built_in">judge</span>(root-&gt;left, root-&gt;right);<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="102-二叉树的层序遍历"><a href="#102-二叉树的层序遍历" class="headerlink" title="102. 二叉树的层序遍历"></a>102. 二叉树的层序遍历</h3><p>给你二叉树的根节点 root ，返回其节点值的 层序遍历 。 （即逐层地，从左到右访问所有节点）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">levelOrder</span>(TreeNode* root) &#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; ret;<br>        <span class="hljs-keyword">if</span>(!root)&#123;<br>            <span class="hljs-keyword">return</span> ret;<br>        &#125;<br><br>        queue &lt;TreeNode*&gt; q;<br>        q.<span class="hljs-built_in">push</span>(root);<br>        <span class="hljs-keyword">while</span>(!q.<span class="hljs-built_in">empty</span>())&#123;<br>            <span class="hljs-type">int</span> cur_size = q.<span class="hljs-built_in">size</span>();<br>            vector&lt;<span class="hljs-type">int</span>&gt; lst;<br><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= cur_size; i++)&#123;<br>                TreeNode* node = q.<span class="hljs-built_in">front</span>();<br>                q.<span class="hljs-built_in">pop</span>();<br>                lst.<span class="hljs-built_in">push_back</span>(node-&gt;val);<br>                <span class="hljs-keyword">if</span>(node-&gt;left)&#123;<br>                    q.<span class="hljs-built_in">push</span>(node-&gt;left);<br>                &#125;<br><br>                <span class="hljs-keyword">if</span>(node-&gt;right)&#123;<br>                    q.<span class="hljs-built_in">push</span>(node-&gt;right);<br>                &#125;<br>            &#125;<br><br>            ret.<span class="hljs-built_in">push_back</span>(lst);<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="104-二叉树的最大深度"><a href="#104-二叉树的最大深度" class="headerlink" title="104. 二叉树的最大深度"></a>104. 二叉树的最大深度</h3><p>给定一个二叉树 root ，返回其最大深度。<br>二叉树的 最大深度 是指从根节点到最远叶子节点的最长路径上的节点数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxDepth</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">nullptr</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(<span class="hljs-built_in">maxDepth</span>(root-&gt;left), <span class="hljs-built_in">maxDepth</span>(root-&gt;right)) + <span class="hljs-number">1</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="105-从前序与中序遍历序列构造二叉树"><a href="#105-从前序与中序遍历序列构造二叉树" class="headerlink" title="105. 从前序与中序遍历序列构造二叉树"></a>105. 从前序与中序遍历序列构造二叉树</h3><p>给定两个整数数组 preorder 和 inorder ，其中 preorder 是二叉树的先序遍历， inorder 是同一棵树的中序遍历，请构造二叉树并返回其根节点。</p><p>示例 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入: preorder = [3,9,20,15,7], inorder = [9,3,15,20,7]<br>输出: [3,9,20,null,null,15,7]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    unordered_map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; index;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">TreeNode* <span class="hljs-title">myBuildTree</span><span class="hljs-params">(<span class="hljs-type">const</span> vector&lt;<span class="hljs-type">int</span>&gt;&amp; preorder, <span class="hljs-type">const</span> vector&lt;<span class="hljs-type">int</span>&gt;&amp; inorder, <span class="hljs-type">int</span> preorder_left, <span class="hljs-type">int</span> preorder_right, <span class="hljs-type">int</span> inorder_left, <span class="hljs-type">int</span> inorder_right)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (preorder_left &gt; preorder_right) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        &#125;<br>        <br>        <span class="hljs-comment">// 前序遍历中的第一个节点就是根节点</span><br>        <span class="hljs-type">int</span> preorder_root = preorder_left;<br>        <span class="hljs-comment">// 在中序遍历中定位根节点</span><br>        <span class="hljs-type">int</span> inorder_root = index[preorder[preorder_root]];<br>        <br>        <span class="hljs-comment">// 先把根节点建立出来</span><br>        TreeNode* root = <span class="hljs-keyword">new</span> <span class="hljs-built_in">TreeNode</span>(preorder[preorder_root]);<br>        <span class="hljs-comment">// 得到左子树中的节点数目</span><br>        <span class="hljs-type">int</span> size_left_subtree = inorder_root - inorder_left;<br>        <span class="hljs-comment">// 递归地构造左子树，并连接到根节点</span><br>        <span class="hljs-comment">// 先序遍历中「从 左边界+1 开始的 size_left_subtree」个元素就对应了中序遍历中「从 左边界 开始到 根节点定位-1」的元素</span><br>        root-&gt;left = <span class="hljs-built_in">myBuildTree</span>(preorder, inorder, preorder_left + <span class="hljs-number">1</span>, preorder_left + size_left_subtree, inorder_left, inorder_root - <span class="hljs-number">1</span>);<br>        <span class="hljs-comment">// 递归地构造右子树，并连接到根节点</span><br>        <span class="hljs-comment">// 先序遍历中「从 左边界+1+左子树节点数目 开始到 右边界」的元素就对应了中序遍历中「从 根节点定位+1 到 右边界」的元素</span><br>        root-&gt;right = <span class="hljs-built_in">myBuildTree</span>(preorder, inorder, preorder_left + size_left_subtree + <span class="hljs-number">1</span>, preorder_right, inorder_root + <span class="hljs-number">1</span>, inorder_right);<br>        <span class="hljs-keyword">return</span> root;<br>    &#125;<br><br>    <span class="hljs-function">TreeNode* <span class="hljs-title">buildTree</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; preorder, vector&lt;<span class="hljs-type">int</span>&gt;&amp; inorder)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = preorder.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-comment">// 构造哈希映射，帮助我们快速定位根节点</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; ++i) &#123;<br>            index[inorder[i]] = i;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">myBuildTree</span>(preorder, inorder, <span class="hljs-number">0</span>, n - <span class="hljs-number">1</span>, <span class="hljs-number">0</span>, n - <span class="hljs-number">1</span>);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="106-从中序与后序遍历序列构造二叉树"><a href="#106-从中序与后序遍历序列构造二叉树" class="headerlink" title="106. 从中序与后序遍历序列构造二叉树"></a>106. 从中序与后序遍历序列构造二叉树</h3><p>给定两个整数数组 inorder 和 postorder ，其中 inorder 是二叉树的中序遍历， postorder 是同一棵树的后序遍历，请你构造并返回这颗 二叉树 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br>    <span class="hljs-type">int</span> post_idx;<br>    unordered_map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; idx_map;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">TreeNode* <span class="hljs-title">helper</span><span class="hljs-params">(<span class="hljs-type">int</span> in_left, <span class="hljs-type">int</span> in_right, vector&lt;<span class="hljs-type">int</span>&gt;&amp; inorder, vector&lt;<span class="hljs-type">int</span>&gt;&amp; postorder)</span></span>&#123;<br>        <span class="hljs-comment">// 如果这里没有节点构造二叉树了，就结束</span><br>        <span class="hljs-keyword">if</span> (in_left &gt; in_right) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">nullptr</span>;<br>        &#125;<br><br>        <span class="hljs-comment">// 选择 post_idx 位置的元素作为当前子树根节点</span><br>        <span class="hljs-type">int</span> root_val = postorder[post_idx];<br>        TreeNode* root = <span class="hljs-keyword">new</span> <span class="hljs-built_in">TreeNode</span>(root_val);<br><br>        <span class="hljs-comment">// 根据 root 所在位置分成左右两棵子树</span><br>        <span class="hljs-type">int</span> index = idx_map[root_val];<br><br>        <span class="hljs-comment">// 下标减一</span><br>        post_idx--;<br>        <span class="hljs-comment">// 构造右子树</span><br>        root-&gt;right = <span class="hljs-built_in">helper</span>(index + <span class="hljs-number">1</span>, in_right, inorder, postorder);<br>        <span class="hljs-comment">// 构造左子树</span><br>        root-&gt;left = <span class="hljs-built_in">helper</span>(in_left, index - <span class="hljs-number">1</span>, inorder, postorder);<br>        <span class="hljs-keyword">return</span> root;<br>    &#125;<br>    <span class="hljs-function">TreeNode* <span class="hljs-title">buildTree</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; inorder, vector&lt;<span class="hljs-type">int</span>&gt;&amp; postorder)</span> </span>&#123;<br>        <span class="hljs-comment">// 从后序遍历的最后一个元素开始</span><br>        post_idx = (<span class="hljs-type">int</span>)postorder.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br><br>        <span class="hljs-comment">// 建立（元素，下标）键值对的哈希表</span><br>        <span class="hljs-type">int</span> idx = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-keyword">auto</span>&amp; val : inorder) &#123;<br>            idx_map[val] = idx++;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">helper</span>(<span class="hljs-number">0</span>, (<span class="hljs-type">int</span>)inorder.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>, inorder, postorder);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="107-二叉树的层序遍历-II"><a href="#107-二叉树的层序遍历-II" class="headerlink" title="107. 二叉树的层序遍历 II"></a>107. 二叉树的层序遍历 II</h3><p>给你二叉树的根节点 root ，返回其节点值 自底向上的层序遍历 。 （即按从叶子节点所在层到根节点所在的层，逐层从左向右遍历）</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">levelOrderBottom</span>(TreeNode* root) &#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; ret;<br>        <span class="hljs-keyword">if</span>(!root)&#123;<br>            <span class="hljs-keyword">return</span> ret;<br>        &#125;<br><br>        queue &lt;TreeNode*&gt; q;<br>        q.<span class="hljs-built_in">push</span>(root);<br>        <span class="hljs-keyword">while</span>(!q.<span class="hljs-built_in">empty</span>())&#123;<br>            <span class="hljs-type">int</span> cur_size = q.<span class="hljs-built_in">size</span>();<br>            vector&lt;<span class="hljs-type">int</span>&gt; lst;<br><br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt;= cur_size; i++)&#123;<br>                TreeNode* node = q.<span class="hljs-built_in">front</span>();<br>                q.<span class="hljs-built_in">pop</span>();<br>                lst.<span class="hljs-built_in">push_back</span>(node-&gt;val);<br>                <span class="hljs-keyword">if</span>(node-&gt;left)&#123;<br>                    q.<span class="hljs-built_in">push</span>(node-&gt;left);<br>                &#125;<br><br>                <span class="hljs-keyword">if</span>(node-&gt;right)&#123;<br>                    q.<span class="hljs-built_in">push</span>(node-&gt;right);<br>                &#125;<br>            &#125;<br><br>            ret.<span class="hljs-built_in">push_back</span>(lst);<br>        &#125;<br>        <br>        <span class="hljs-built_in">reverse</span>(ret.<span class="hljs-built_in">begin</span>(), ret.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="110-平衡二叉树"><a href="#110-平衡二叉树" class="headerlink" title="110. 平衡二叉树"></a>110. 平衡二叉树</h3><p>给定一个二叉树，判断它是否是高度平衡的二叉树。</p><p>本题中，一棵高度平衡二叉树定义为：<br>一个二叉树每个节点 的左右两个子树的高度差的绝对值不超过 1 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">height</span><span class="hljs-params">(TreeNode* root)</span></span>&#123;<br>        <span class="hljs-keyword">if</span>(!root)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-type">int</span> left_height = <span class="hljs-built_in">height</span>(root-&gt;left);<br>        <span class="hljs-type">int</span> right_height = <span class="hljs-built_in">height</span>(root-&gt;right);<br><br>        <span class="hljs-keyword">if</span>(left_height == <span class="hljs-number">-1</span> || right_height == <span class="hljs-number">-1</span> || <span class="hljs-built_in">abs</span>(left_height - right_height) &gt; <span class="hljs-number">1</span> )&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(left_height, right_height) + <span class="hljs-number">1</span>;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isBalanced</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">height</span>(root) &gt;= <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="111-二叉树的最小深度"><a href="#111-二叉树的最小深度" class="headerlink" title="111. 二叉树的最小深度"></a>111. 二叉树的最小深度</h3><p>给定一个二叉树，找出其最小深度。<br>最小深度是从根节点到最近叶子节点的最短路径上的节点数量。<br>说明：叶子节点是指没有子节点的节点。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">minDepth</span><span class="hljs-params">(TreeNode *root)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (root-&gt;left == <span class="hljs-literal">nullptr</span> &amp;&amp; root-&gt;right == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">1</span>;<br>        &#125;<br><br>        <span class="hljs-type">int</span> min_depth = INT_MAX;<br>        <span class="hljs-keyword">if</span> (root-&gt;left != <span class="hljs-literal">nullptr</span>) &#123;<br>            min_depth = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">minDepth</span>(root-&gt;left), min_depth);<br>        &#125;<br>        <span class="hljs-keyword">if</span> (root-&gt;right != <span class="hljs-literal">nullptr</span>) &#123;<br>            min_depth = <span class="hljs-built_in">min</span>(<span class="hljs-built_in">minDepth</span>(root-&gt;right), min_depth);<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> min_depth + <span class="hljs-number">1</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="112-路径总和"><a href="#112-路径总和" class="headerlink" title="112. 路径总和"></a>112. 路径总和</h3><p>给你二叉树的根节点 root 和一个表示目标和的整数 targetSum 。判断该树中是否存在 根节点到叶子节点 的路径，这条路径上所有节点值相加等于目标和 targetSum 。如果存在，返回 true ；否则，返回 false 。<br><strong>叶子节点 是指没有子节点的节点。</strong></p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">      5<br>   4     8<br> 11    13 4<br>7  2        1<br>输入：root = [5,4,8,11,null,13,4,7,2,null,null,null,1], targetSum = 22<br>输出：<span class="hljs-literal">true</span><br>解释：等于目标和的根节点到叶节点路径如上图所示。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">hasPathSum</span><span class="hljs-params">(TreeNode *root, <span class="hljs-type">int</span> sum)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (root == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (root-&gt;left == <span class="hljs-literal">nullptr</span> &amp;&amp; root-&gt;right == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> sum == root-&gt;val;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">hasPathSum</span>(root-&gt;left, sum - root-&gt;val) ||<br>               <span class="hljs-built_in">hasPathSum</span>(root-&gt;right, sum - root-&gt;val);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="113-路径总和-II"><a href="#113-路径总和-II" class="headerlink" title="113. 路径总和 II"></a>113. 路径总和 II</h3><p>给你二叉树的根节点 root 和一个整数目标和 targetSum ，找出所有 从根节点到叶子节点 路径总和等于给定目标和的路径。<br><strong>叶子节点 是指没有子节点的节点。</strong></p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><code class="hljs bash">      5<br>   4      8<br> 11    13   4<br>7  2       5 1<br>输入：root = [5,4,8,11,null,13,4,7,2,null,null,5,1], targetSum = 22<br>输出：[[5,4,11,2],[5,8,4,5]]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(TreeNode* root, <span class="hljs-type">int</span> targetSum, vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; res, vector&lt;<span class="hljs-type">int</span>&gt;&amp; path)</span></span>&#123;<br>        <span class="hljs-keyword">if</span> (!root)&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br><br>        path.<span class="hljs-built_in">push_back</span>(root-&gt;val);<br><br>        <span class="hljs-keyword">if</span> (targetSum == root-&gt;val &amp;&amp; !root-&gt;left &amp;&amp; !root-&gt;right)&#123;<br>            res.<span class="hljs-built_in">push_back</span>(path);<br>        &#125; <span class="hljs-keyword">else</span>&#123;<br>            <span class="hljs-built_in">dfs</span>(root-&gt;left, targetSum - root-&gt;val, res, path);<br>            <span class="hljs-built_in">dfs</span>(root-&gt;right, targetSum - root-&gt;val, res, path);<br>        &#125;<br><br>        path.<span class="hljs-built_in">pop_back</span>();<br>    &#125;<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">pathSum</span>(TreeNode* root, <span class="hljs-type">int</span> targetSum) &#123;<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; res;<br>        vector&lt;<span class="hljs-type">int</span>&gt; path;<br>        <span class="hljs-built_in">dfs</span>(root, targetSum, res, path);<br><br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="114-二叉树展开为链表"><a href="#114-二叉树展开为链表" class="headerlink" title="114. 二叉树展开为链表"></a>114. 二叉树展开为链表</h3><p>给你二叉树的根结点 root ，请你将它展开为一个单链表：</p><p>展开后的单链表应该同样使用 TreeNode ，其中 right 子指针指向链表中下一个结点，而左子指针始终为 null 。<br>展开后的单链表应该与二叉树 先序遍历 顺序相同。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：root = [1,2,5,3,4,null,6]<br>输出：[1,null,2,null,3,null,4,null,5,null,6]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">flatten</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        <span class="hljs-keyword">while</span>(root)&#123;<br>            <span class="hljs-keyword">if</span> (root-&gt;left)&#123;<br>                TreeNode* tmp = root-&gt;left;<br>                <span class="hljs-keyword">while</span>(tmp-&gt;right)&#123;<br>                    tmp = tmp-&gt;right;<br>                &#125;<br><br>                tmp-&gt;right = root-&gt;right;<br>                root-&gt;right = root-&gt;left;<br>                root-&gt;left = <span class="hljs-literal">nullptr</span>;<br>                root = root-&gt;right;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                root = root-&gt;right;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="124-二叉树中的最大路径和"><a href="#124-二叉树中的最大路径和" class="headerlink" title="124. 二叉树中的最大路径和"></a>124. 二叉树中的最大路径和</h3><p>二叉树中的 路径 被定义为一条节点序列，序列中每对相邻节点之间都存在一条边。同一个节点在一条路径序列中 至多出现一次 。该路径 至少包含一个 节点，且不一定经过根节点。<br>路径和 是路径中各节点值的总和。<br>给你一个二叉树的根节点 root ，返回其 最大路径和 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    <span class="hljs-type">int</span> maxSum = INT_MIN;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxGain</span><span class="hljs-params">(TreeNode* node)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (node == <span class="hljs-literal">nullptr</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <br>        <span class="hljs-comment">// 递归计算左右子节点的最大贡献值</span><br>        <span class="hljs-comment">// 只有在最大贡献值大于 0 时，才会选取对应子节点</span><br>        <span class="hljs-type">int</span> leftGain = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">maxGain</span>(node-&gt;left), <span class="hljs-number">0</span>);<br>        <span class="hljs-type">int</span> rightGain = <span class="hljs-built_in">max</span>(<span class="hljs-built_in">maxGain</span>(node-&gt;right), <span class="hljs-number">0</span>);<br><br>        <span class="hljs-comment">// 节点的最大路径和取决于该节点的值与该节点的左右子节点的最大贡献值</span><br>        <span class="hljs-type">int</span> priceNewpath = node-&gt;val + leftGain + rightGain;<br><br>        <span class="hljs-comment">// 更新答案</span><br>        maxSum = <span class="hljs-built_in">max</span>(maxSum, priceNewpath);<br><br>        <span class="hljs-comment">// 返回节点的最大贡献值</span><br>        <span class="hljs-keyword">return</span> node-&gt;val + <span class="hljs-built_in">max</span>(leftGain, rightGain);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxPathSum</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        <span class="hljs-built_in">maxGain</span>(root);<br>        <span class="hljs-keyword">return</span> maxSum;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="337-打家劫舍-III"><a href="#337-打家劫舍-III" class="headerlink" title="337. 打家劫舍 III"></a>337. 打家劫舍 III</h3><p>小偷又发现了一个新的可行窃的地区。这个地区只有一个入口，我们称之为 root 。<br>除了 root 之外，每栋房子有且只有一个“父“房子与之相连。一番侦察之后，聪明的小偷意识到“这个地方的所有房屋的排列类似于一棵二叉树”。 如果 两个直接相连的房子在同一天晚上被打劫 ，房屋将自动报警。<br>给定二叉树的 root 。返回 在不触动警报的情况下 ，小偷能够盗取的最高金额 。</p><p>示例 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入: root = [3,2,3,null,3,null,1]<br>输出: 7 <br>解释: 小偷一晚能够盗取的最高金额 3 + 3 + 1 = 7<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    map &lt;TreeNode*, <span class="hljs-type">int</span>&gt; cur, not_cur;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(TreeNode* node)</span></span>&#123;<br>        <span class="hljs-keyword">if</span>(!node)&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br><br>        <span class="hljs-built_in">dfs</span>(node-&gt;left);<br>        <span class="hljs-built_in">dfs</span>(node-&gt;right);<br><br>        cur[node] = node-&gt;val + not_cur[node-&gt;left] + not_cur[node-&gt;right];<br>        not_cur[node] = <span class="hljs-built_in">max</span>(cur[node-&gt;left], not_cur[node-&gt;left]) + <span class="hljs-built_in">max</span>(cur[node-&gt;right], not_cur[node-&gt;right]);<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">rob</span><span class="hljs-params">(TreeNode* root)</span> </span>&#123;<br>        <span class="hljs-built_in">dfs</span>(root);<br>        <span class="hljs-keyword">return</span> <span class="hljs-built_in">max</span>(cur[root], not_cur[root]);<br><br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="字符串"><a href="#字符串" class="headerlink" title="字符串"></a>字符串</h2><h3 id="28-找出字符串中第一个匹配项的下标（KMP）"><a href="#28-找出字符串中第一个匹配项的下标（KMP）" class="headerlink" title="28. 找出字符串中第一个匹配项的下标（KMP）"></a>28. 找出字符串中第一个匹配项的下标（KMP）</h3><p>给你两个字符串 haystack 和 needle ，请你在 haystack 字符串中找出 needle 字符串的第一个匹配项的下标（下标从 0 开始）。如果 needle 不是 haystack 的一部分，则返回  -1。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">strStr</span><span class="hljs-params">(string s, string p)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = s.<span class="hljs-built_in">size</span>(), m = p.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span>(m == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        <span class="hljs-comment">//设置哨兵</span><br>        s.<span class="hljs-built_in">insert</span>(s.<span class="hljs-built_in">begin</span>(),<span class="hljs-string">&#x27; &#x27;</span>);<br>        p.<span class="hljs-built_in">insert</span>(p.<span class="hljs-built_in">begin</span>(),<span class="hljs-string">&#x27; &#x27;</span>);<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">next</span><span class="hljs-params">(m + <span class="hljs-number">1</span>)</span></span>;<br>        <span class="hljs-comment">//预处理next数组</span><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">2</span>, j = <span class="hljs-number">0</span>; i &lt;= m; i++)&#123;<br>            <span class="hljs-keyword">while</span>(j <span class="hljs-keyword">and</span> p[i] != p[j + <span class="hljs-number">1</span>]) j = next[j];<br>            <span class="hljs-keyword">if</span>(p[i] == p[j + <span class="hljs-number">1</span>]) j++;<br>            next[i] = j;<br>        &#125;<br>        <span class="hljs-comment">//匹配过程</span><br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>, j = <span class="hljs-number">0</span>; i &lt;= n; i++)&#123;<br>            <span class="hljs-keyword">while</span>(j <span class="hljs-keyword">and</span> s[i] != p[j + <span class="hljs-number">1</span>]) j = next[j];<br>            <span class="hljs-keyword">if</span>(s[i] == p[j + <span class="hljs-number">1</span>]) j++;<br>            <span class="hljs-keyword">if</span>(j == m) <span class="hljs-keyword">return</span> i - m;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-number">-1</span>;<br>    &#125;<br>&#125;;<br><br></code></pre></td></tr></table></figure><h3 id="43-字符串相乘"><a href="#43-字符串相乘" class="headerlink" title="43. 字符串相乘"></a>43. 字符串相乘</h3><p>给定两个以字符串形式表示的非负整数 num1 和 num2，返回 num1 和 num2 的乘积，它们的乘积也表示为字符串形式。<br>注意：不能使用任何内置的 BigInteger 库或直接将输入转换为整数。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">multiply</span><span class="hljs-params">(string num1, string num2)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> ((num<span class="hljs-number">1.</span><span class="hljs-built_in">size</span>() == <span class="hljs-number">1</span> &amp;&amp; num1[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;0&#x27;</span>) || (num<span class="hljs-number">2.</span><span class="hljs-built_in">size</span>() == <span class="hljs-number">1</span> &amp;&amp; num2[<span class="hljs-number">0</span>] == <span class="hljs-string">&#x27;0&#x27;</span>))&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;0&quot;</span>;<br>        &#125;<br>        <span class="hljs-type">int</span> n = num<span class="hljs-number">1.</span><span class="hljs-built_in">size</span>(), m = num<span class="hljs-number">2.</span><span class="hljs-built_in">size</span>();<br>        <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">ans</span><span class="hljs-params">(n * m + <span class="hljs-number">1</span>, <span class="hljs-number">0</span>)</span></span>;<br>        string long_num, short_num;<br><br>        <span class="hljs-keyword">if</span> (n &gt; m)&#123;<br>            long_num = num1;<br>            short_num = num2;<br>        &#125; <span class="hljs-keyword">else</span> &#123;<br>            long_num = num2;<br>            short_num = num1;<br>        &#125;<br>        n = long_num.<span class="hljs-built_in">size</span>();<br>        m = short_num.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = m - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--)&#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = n - <span class="hljs-number">1</span>; j &gt;= <span class="hljs-number">0</span>; j--)&#123;<br>                <span class="hljs-type">int</span> cur = (long_num[j] - <span class="hljs-string">&#x27;0&#x27;</span>) * (short_num[i] - <span class="hljs-string">&#x27;0&#x27;</span>);<br>                ans[m<span class="hljs-number">-1</span>-i + n<span class="hljs-number">-1</span>-j] += cur;<br>            &#125;<br>        &#125;<br><br>        string ret;<br>        <span class="hljs-type">int</span> add = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; m * n + <span class="hljs-number">1</span>; i++)&#123;<br>            ret += (ans[i] + add) % <span class="hljs-number">10</span> + <span class="hljs-string">&#x27;0&#x27;</span>;<br>            add = (ans[i] + add) / <span class="hljs-number">10</span>;<br>        &#125;<br><br>        <span class="hljs-built_in">reverse</span>(ret.<span class="hljs-built_in">begin</span>(), ret.<span class="hljs-built_in">end</span>());<br><br>        string res;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; ret.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            <span class="hljs-keyword">if</span> (ret[i] != <span class="hljs-string">&#x27;0&#x27;</span>)&#123;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = i; j &lt; ret.<span class="hljs-built_in">size</span>(); j++)&#123;<br>                    res += ret[j];<br>                &#125;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            <br>        &#125;<br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="58-最后一个单词的长度"><a href="#58-最后一个单词的长度" class="headerlink" title="58. 最后一个单词的长度"></a>58. 最后一个单词的长度</h3><p>给你一个字符串 s，由若干单词组成，单词前后用一些空格字符隔开。返回字符串中 最后一个 单词的长度。<br>单词 是指仅由字母组成、不包含任何空格字符的最大子字符串。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">lengthOfLastWord</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = s.<span class="hljs-built_in">size</span>();<br>        string ret = <span class="hljs-string">&quot;&quot;</span>;<br>        <span class="hljs-type">int</span> idx = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = n - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i--)&#123;<br>            <span class="hljs-keyword">if</span> (s[i] != <span class="hljs-string">&#x27; &#x27;</span>)&#123;<br>                idx = i;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = idx; i &gt;= <span class="hljs-number">0</span>; i --)&#123;<br>            <span class="hljs-keyword">if</span> (s[i] == <span class="hljs-string">&#x27; &#x27;</span>)&#123;<br>                <span class="hljs-keyword">break</span>;<br>            &#125;<br>            ret += s[i];<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret.<span class="hljs-built_in">size</span>();<br><br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="71-简化路径"><a href="#71-简化路径" class="headerlink" title="71. 简化路径"></a>71. 简化路径</h3><p>给你一个字符串 path ，表示指向某一文件或目录的 Unix 风格 绝对路径 （以 ‘&#x2F;‘ 开头），请你将其转化为更加简洁的规范路径。</p><p>在 Unix 风格的文件系统中，一个点（.）表示当前目录本身；此外，两个点 （..） 表示将目录切换到上一级（指向父目录）；两者都可以是复杂相对路径的组成部分。任意多个连续的斜杠（即，’&#x2F;&#x2F;‘）都被视为单个斜杠 ‘&#x2F;‘。 对于此问题，任何其他格式的点（例如，’…’）均被视为文件&#x2F;目录名称。</p><p>请注意，返回的 规范路径 必须遵循下述格式：</p><p>始终以斜杠 ‘&#x2F;‘ 开头。<br>两个目录名之间必须只有一个斜杠 ‘&#x2F;‘。<br>最后一个目录名（如果存在）不能 以 ‘&#x2F;‘ 结尾。<br>此外，路径仅包含从根目录到目标文件或目录的路径上的目录（即，不含 ‘.’ 或 ‘..’）。<br>返回简化后得到的 规范路径。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：path = <span class="hljs-string">&quot;/home/&quot;</span><br>输出：<span class="hljs-string">&quot;/home&quot;</span><br>解释：注意，最后一个目录名后面没有斜杠。<br></code></pre></td></tr></table></figure><p>示例 2：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：path = <span class="hljs-string">&quot;/../&quot;</span><br>输出：<span class="hljs-string">&quot;/&quot;</span><br>解释：从根目录向上一级是不可行的，因为根目录是你可以到达的最高级。<br></code></pre></td></tr></table></figure><p>示例 3：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：path = <span class="hljs-string">&quot;/home//foo/&quot;</span><br>输出：<span class="hljs-string">&quot;/home/foo&quot;</span><br>解释：在规范路径中，多个连续斜杠需要用一个斜杠替换。<br></code></pre></td></tr></table></figure><p>示例 4：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：path = <span class="hljs-string">&quot;/a/./b/../../c/&quot;</span><br>输出：<span class="hljs-string">&quot;/c&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">simplifyPath</span><span class="hljs-params">(string path)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = path.<span class="hljs-built_in">size</span>();<br>        string ret = <span class="hljs-string">&quot;&quot;</span>, cur = <span class="hljs-string">&quot;&quot;</span>;<br>        vector&lt;string&gt; ans, strs;<br><br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>) <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;/&quot;</span>;<br><br>        <span class="hljs-comment">//截断输入</span><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">if</span> (path[i] != <span class="hljs-string">&#x27;/&#x27;</span>)&#123;<br>                cur += path[i];<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                strs.<span class="hljs-built_in">push_back</span>(cur);<br>                cur = <span class="hljs-string">&quot;&quot;</span>;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">//注意最后一个子串</span><br>        <span class="hljs-keyword">if</span> (cur.<span class="hljs-built_in">size</span>() &gt; <span class="hljs-number">0</span>) strs.<span class="hljs-built_in">push_back</span>(cur);<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; strs.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            <span class="hljs-comment">// 处理 &#x27;..&#x27;</span><br>            <span class="hljs-keyword">if</span> (strs[i].<span class="hljs-built_in">size</span>() == <span class="hljs-number">2</span> &amp;&amp; strs[i] == <span class="hljs-string">&quot;..&quot;</span>)&#123;<br>                <span class="hljs-keyword">if</span>(ans.<span class="hljs-built_in">size</span>() &gt; <span class="hljs-number">0</span>)&#123;<br>                    ans.<span class="hljs-built_in">pop_back</span>();<br>                &#125;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (strs[i] == <span class="hljs-string">&quot;&quot;</span> || strs[i] == <span class="hljs-string">&quot;.&quot;</span>)&#123;<br>                <span class="hljs-comment">// 连续的&#x27;//&#x27;会出现空子串，&#x27;.&#x27;应当忽略</span><br>                <span class="hljs-keyword">continue</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                ans.<span class="hljs-built_in">push_back</span>(strs[i]);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-comment">// 没有有效的子串则返回&#x27;/&#x27;</span><br>        <span class="hljs-keyword">if</span>(ans.<span class="hljs-built_in">size</span>() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-string">&quot;/&quot;</span>;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; ans.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            ret += <span class="hljs-string">&quot;/&quot;</span> + ans[i];<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="93-复原-IP-地址"><a href="#93-复原-IP-地址" class="headerlink" title="93. 复原 IP 地址"></a>93. 复原 IP 地址</h3><p>有效 IP 地址 正好由四个整数（每个整数位于 0 到 255 之间组成，且不能含有前导 0），整数之间用 ‘.’ 分隔。</p><p>例如：”0.1.2.201” 和 “192.168.1.1” 是 有效 IP 地址，但是 “0.011.255.245”、”192.168.1.312” 和 “<a href="mailto:&#49;&#x39;&#x32;&#x2e;&#x31;&#x36;&#x38;&#x40;&#49;&#x2e;&#x31;">&#49;&#x39;&#x32;&#x2e;&#x31;&#x36;&#x38;&#x40;&#49;&#x2e;&#x31;</a>“ 是 无效 IP 地址。<br>给定一个只包含数字的字符串 s ，用以表示一个 IP 地址，返回所有可能的有效 IP 地址，这些地址可以通过在 s 中插入 ‘.’ 来形成。你 不能 重新排序或删除 s 中的任何数字。你可以按 任何 顺序返回答案。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：s = <span class="hljs-string">&quot;25525511135&quot;</span><br>输出：[<span class="hljs-string">&quot;255.255.11.135&quot;</span>,<span class="hljs-string">&quot;255.255.111.35&quot;</span>]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">dfs</span><span class="hljs-params">(string s, vector&lt;string&gt;&amp; res, string&amp; ip, <span class="hljs-type">int</span> count)</span></span>&#123;<br>        <span class="hljs-type">int</span> n = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span>(count == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">if</span> (n &gt; <span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span> || (n &gt;= <span class="hljs-number">1</span>  &amp;&amp; n &lt;= <span class="hljs-number">3</span> &amp;&amp; (s[<span class="hljs-number">0</span>] != <span class="hljs-string">&#x27;0&#x27;</span>) &amp;&amp; <span class="hljs-built_in">stoi</span>(s) &lt;= <span class="hljs-number">255</span>))&#123;<br>                    ip += s;<br>                    res.<span class="hljs-built_in">push_back</span>(ip);<br>                &#125;<br>            &#125;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">return</span>;<br>        &#125;<br>        <br>        string next_ip;<br>        next_ip = ip + s[<span class="hljs-number">0</span>] + <span class="hljs-string">&#x27;.&#x27;</span>;<br>        <span class="hljs-built_in">dfs</span>(s.<span class="hljs-built_in">substr</span>(<span class="hljs-number">1</span>, n - <span class="hljs-number">1</span>), res, next_ip, count - <span class="hljs-number">1</span>);<br><br>        <span class="hljs-keyword">if</span>(s[<span class="hljs-number">0</span>] != <span class="hljs-string">&#x27;0&#x27;</span>)&#123;<br>            <span class="hljs-keyword">if</span> (n &gt;= <span class="hljs-number">2</span>)&#123;<br>                next_ip = ip + s.<span class="hljs-built_in">substr</span>(<span class="hljs-number">0</span>, <span class="hljs-number">2</span>) + <span class="hljs-string">&#x27;.&#x27;</span>;<br>                <span class="hljs-built_in">dfs</span>(s.<span class="hljs-built_in">substr</span>(<span class="hljs-number">2</span>, n - <span class="hljs-number">2</span>), res, next_ip, count - <span class="hljs-number">1</span>);<br>            &#125;<br>            <span class="hljs-keyword">if</span> (n &gt;= <span class="hljs-number">3</span>)&#123;<br>                <span class="hljs-keyword">if</span> (<span class="hljs-built_in">stoi</span>(s.<span class="hljs-built_in">substr</span>(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>)) &lt;= <span class="hljs-number">255</span>)&#123;<br>                    next_ip = ip + s.<span class="hljs-built_in">substr</span>(<span class="hljs-number">0</span>, <span class="hljs-number">3</span>) + <span class="hljs-string">&#x27;.&#x27;</span>;<br>                    <span class="hljs-built_in">dfs</span>(s.<span class="hljs-built_in">substr</span>(<span class="hljs-number">3</span>, n - <span class="hljs-number">3</span>), res, next_ip, count - <span class="hljs-number">1</span>);<br>                &#125;<br>            &#125;<br>        &#125;<br>    &#125;<br><br>    <span class="hljs-function">vector&lt;string&gt; <span class="hljs-title">restoreIpAddresses</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        vector&lt;string&gt; res;<br>        string ip;<br>        <span class="hljs-built_in">dfs</span>(s, res, ip, <span class="hljs-number">3</span>);<br><br>        <span class="hljs-keyword">return</span> res;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="数学"><a href="#数学" class="headerlink" title="数学"></a>数学</h2><h3 id="50-Pow-x-n"><a href="#50-Pow-x-n" class="headerlink" title="50. Pow(x, n)"></a>50. Pow(x, n)</h3><p>实现 pow(x, n) ，即计算 x 的整数 n 次幂函数（即，xn ）。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">double</span> <span class="hljs-title">quickMul</span><span class="hljs-params">(<span class="hljs-type">double</span> x, <span class="hljs-type">long</span> <span class="hljs-type">long</span> n)</span> </span>&#123;<br>        <span class="hljs-type">double</span> ans = <span class="hljs-number">1.0</span>;<br>        <span class="hljs-type">double</span> tmp = x;<br>        <span class="hljs-keyword">while</span>(n &gt; <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">if</span> (n % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>)&#123;<br>                ans *= x;<br>            &#125;<br><br>            x *= x;<br>            n /= <span class="hljs-number">2</span>;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">double</span> <span class="hljs-title">myPow</span><span class="hljs-params">(<span class="hljs-type">double</span> x, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-type">long</span> <span class="hljs-type">long</span> N = n;<br>        <span class="hljs-keyword">return</span> N &gt;= <span class="hljs-number">0</span> ? <span class="hljs-built_in">quickMul</span>(x, N) : <span class="hljs-number">1.0</span> / <span class="hljs-built_in">quickMul</span>(x, -N);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="136-只出现一次的数字"><a href="#136-只出现一次的数字" class="headerlink" title="136. 只出现一次的数字"></a>136. 只出现一次的数字</h3><p>给你一个 非空 整数数组 nums ，除了某个元素只出现一次以外，其余每个元素均出现两次。找出那个只出现了一次的元素。<br>你必须设计并实现线性时间复杂度的算法来解决此问题，且该算法只使用常量额外空间。</p><p>示例 1 ：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [2,2,1]<br>输出：1<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">singleNumber</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> ans = nums[<span class="hljs-number">0</span>];<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; nums.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            ans ^= nums[i];<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="172-阶乘后的零"><a href="#172-阶乘后的零" class="headerlink" title="172. 阶乘后的零"></a>172. 阶乘后的零</h3><p>给定一个整数 n ，返回 n! 结果中尾随零的数量。<br>提示 <code>n! = n * (n - 1) * (n - 2) * ... * 3 * 2 * 1</code></p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">trailingZeroes</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-type">int</span> ans = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span> (n) &#123;<br>            n /= <span class="hljs-number">5</span>;<br>            ans += n;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="365-水壶问题"><a href="#365-水壶问题" class="headerlink" title="365. 水壶问题"></a>365. 水壶问题</h3><p>有两个水壶，容量分别为 jug1Capacity 和 jug2Capacity 升。水的供应是无限的。确定是否有可能使用这两个壶准确得到 targetCapacity 升。<br>如果可以得到 targetCapacity 升水，最后请用以上水壶中的一或两个来盛放取得的 targetCapacity 升水。</p><p>你可以：</p><p>装满任意一个水壶<br>清空任意一个水壶<br>从一个水壶向另外一个水壶倒水，直到装满或者倒空</p><p>示例 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入: jug1Capacity = 3, jug2Capacity = 5, targetCapacity = 4<br>输出: <span class="hljs-literal">true</span><br>解释：来自著名的 <span class="hljs-string">&quot;Die Hard&quot;</span><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">canMeasureWater</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y, <span class="hljs-type">int</span> z)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (x + y &lt; z) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (x == <span class="hljs-number">0</span> || y == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span> z == <span class="hljs-number">0</span> || x + y == z;<br>        &#125;<br>        <span class="hljs-keyword">return</span> z % <span class="hljs-built_in">gcd</span>(x, y) == <span class="hljs-number">0</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="461-汉明距离"><a href="#461-汉明距离" class="headerlink" title="461. 汉明距离"></a>461. 汉明距离</h3><p>两个整数之间的 汉明距离 指的是这两个数字对应二进制位不同的位置的数目。<br>给你两个整数 x 和 y，计算并返回它们之间的汉明距离。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：x = 1, y = 4<br>输出：2<br>解释：<br>1   (0 0 0 1)<br>4   (0 1 0 0)<br>       ↑   ↑<br>上面的箭头指出了对应二进制位不同的位置。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">hammingDistance</span><span class="hljs-params">(<span class="hljs-type">int</span> x, <span class="hljs-type">int</span> y)</span> </span>&#123;<br>        <span class="hljs-type">int</span> z = x ^ y;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br><br>        <span class="hljs-keyword">while</span>(z &gt; <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">if</span> (z % <span class="hljs-number">2</span> == <span class="hljs-number">1</span>)&#123;<br>                ret += <span class="hljs-number">1</span>;<br>            &#125;<br><br>            z /= <span class="hljs-number">2</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="数组"><a href="#数组" class="headerlink" title="数组"></a>数组</h2><h3 id="48-旋转图像"><a href="#48-旋转图像" class="headerlink" title="48. 旋转图像"></a>48. 旋转图像</h3><p>给定一个 n × n 的二维矩阵 matrix 表示一个图像。请你将图像顺时针旋转 90 度。<br>你必须在 原地 旋转图像，这意味着你需要直接修改输入的二维矩阵。请不要 使用另一个矩阵来旋转图像。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">rotate</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = matrix.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n / <span class="hljs-number">2</span>; ++i) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; (n + <span class="hljs-number">1</span>) / <span class="hljs-number">2</span>; ++j) &#123;<br>                <span class="hljs-type">int</span> temp = matrix[i][j];<br>                matrix[i][j] = matrix[n - j - <span class="hljs-number">1</span>][i];<br>                matrix[n - j - <span class="hljs-number">1</span>][i] = matrix[n - i - <span class="hljs-number">1</span>][n - j - <span class="hljs-number">1</span>];<br>                matrix[n - i - <span class="hljs-number">1</span>][n - j - <span class="hljs-number">1</span>] = matrix[j][n - i - <span class="hljs-number">1</span>];<br>                matrix[j][n - i - <span class="hljs-number">1</span>] = temp;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="54-螺旋矩阵"><a href="#54-螺旋矩阵" class="headerlink" title="54. 螺旋矩阵"></a>54. 螺旋矩阵</h3><p>给你一个 m 行 n 列的矩阵 matrix ，请按照 顺时针螺旋顺序 ，返回矩阵中的所有元素。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">spiralOrder</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; matrix)</span> </span>&#123;<br>        vector &lt;<span class="hljs-type">int</span>&gt; ans;<br>        <span class="hljs-keyword">if</span>(matrix.<span class="hljs-built_in">empty</span>()) <span class="hljs-keyword">return</span> ans; <span class="hljs-comment">//若数组为空，直接返回答案</span><br>        <span class="hljs-type">int</span> u = <span class="hljs-number">0</span>; <span class="hljs-comment">//赋值上下左右边界</span><br>        <span class="hljs-type">int</span> d = matrix.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> r = matrix[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(<span class="hljs-literal">true</span>)<br>        &#123;<br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = l; i &lt;= r; ++i) ans.<span class="hljs-built_in">push_back</span>(matrix[u][i]); <span class="hljs-comment">//向右移动直到最右</span><br>            <span class="hljs-keyword">if</span>(++ u &gt; d) <span class="hljs-keyword">break</span>; <span class="hljs-comment">//重新设定上边界，若上边界大于下边界，则遍历遍历完成，下同</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = u; i &lt;= d; ++i) ans.<span class="hljs-built_in">push_back</span>(matrix[i][r]); <span class="hljs-comment">//向下</span><br>            <span class="hljs-keyword">if</span>(-- r &lt; l) <span class="hljs-keyword">break</span>; <span class="hljs-comment">//重新设定有边界</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = r; i &gt;= l; --i) ans.<span class="hljs-built_in">push_back</span>(matrix[d][i]); <span class="hljs-comment">//向左</span><br>            <span class="hljs-keyword">if</span>(-- d &lt; u) <span class="hljs-keyword">break</span>; <span class="hljs-comment">//重新设定下边界</span><br>            <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = d; i &gt;= u; --i) ans.<span class="hljs-built_in">push_back</span>(matrix[i][l]); <span class="hljs-comment">//向上</span><br>            <span class="hljs-keyword">if</span>(++ l &gt; r) <span class="hljs-keyword">break</span>; <span class="hljs-comment">//重新设定左边界</span><br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="56-合并区间"><a href="#56-合并区间" class="headerlink" title="56. 合并区间"></a>56. 合并区间</h3><p>以数组 intervals 表示若干个区间的集合，其中单个区间为 intervals[i] &#x3D; [starti, endi]。请你合并所有重叠的区间，并返回 一个不重叠的区间数组，该数组需恰好覆盖输入中的所有区间。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：intervals = [[1,3],[2,6],[8,10],[15,18]]<br>输出：[[1,6],[8,10],[15,18]]<br>解释：区间 [1,3] 和 [2,6] 重叠, 将它们合并为 [1,6].<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">merge</span>(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; intervals) &#123;<br>        <span class="hljs-keyword">if</span> (intervals.<span class="hljs-built_in">size</span>() == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span> &#123;&#125;;<br>        &#125;<br>        <span class="hljs-built_in">sort</span>(intervals.<span class="hljs-built_in">begin</span>(), intervals.<span class="hljs-built_in">end</span>());<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; merged;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; intervals.<span class="hljs-built_in">size</span>(); ++i) &#123;<br>            <span class="hljs-type">int</span> L = intervals[i][<span class="hljs-number">0</span>], R = intervals[i][<span class="hljs-number">1</span>];<br>            <span class="hljs-keyword">if</span> (!merged.<span class="hljs-built_in">size</span>() || merged.<span class="hljs-built_in">back</span>()[<span class="hljs-number">1</span>] &lt; L) &#123;<br>                merged.<span class="hljs-built_in">push_back</span>(&#123;L, R&#125;);<br>            &#125;<br>            <span class="hljs-keyword">else</span> &#123;<br>                merged.<span class="hljs-built_in">back</span>()[<span class="hljs-number">1</span>] = <span class="hljs-built_in">max</span>(merged.<span class="hljs-built_in">back</span>()[<span class="hljs-number">1</span>], R);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> merged;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="66-加一"><a href="#66-加一" class="headerlink" title="66. 加一"></a>66. 加一</h3><p>给定一个由 整数 组成的 非空 数组所表示的非负整数，在该数的基础上加一。<br>最高位数字存放在数组的首位， 数组中每个元素只存储单个数字。<br>你可以假设除了整数 0 之外，这个整数不会以零开头。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：digits = [1,2,3]<br>输出：[1,2,4]<br>解释：输入数组表示数字 123。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">plusOne</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; digits)</span> </span>&#123;<br>        <span class="hljs-built_in">reverse</span>(digits.<span class="hljs-built_in">begin</span>(), digits.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-type">int</span> n = digits.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> c = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i ++)&#123;<br>            <span class="hljs-keyword">if</span> (i == <span class="hljs-number">0</span>)&#123;<br>                digits[<span class="hljs-number">0</span>] += <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-type">int</span> cur = (digits[i] + c) % <span class="hljs-number">10</span>;<br>            c = (digits[i] + c)/ <span class="hljs-number">10</span>;<br>            digits[i] = cur;<br>        &#125;<br>        <span class="hljs-keyword">if</span> (c &gt; <span class="hljs-number">0</span>)&#123;<br>            digits.<span class="hljs-built_in">push_back</span>(c);<br>        &#125;<br>        <span class="hljs-built_in">reverse</span>(digits.<span class="hljs-built_in">begin</span>(), digits.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-keyword">return</span> digits;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="85-最大矩形"><a href="#85-最大矩形" class="headerlink" title="85. 最大矩形"></a>85. 最大矩形</h3><p>给定一个仅包含 0 和 1 、大小为 rows x cols 的二维二进制矩阵，找出只包含 1 的最大矩形，并返回其面积。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：matrix = [[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>],[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>],[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>],[<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>,<span class="hljs-string">&quot;1&quot;</span>,<span class="hljs-string">&quot;0&quot;</span>]]<br>输出：6<br>解释：最大矩形如上图所示。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maximalRectangle</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">char</span>&gt;&gt;&amp; matrix)</span> </span>&#123;<br>        <span class="hljs-type">int</span> m = matrix.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span> (m == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-type">int</span> n = matrix[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br>        vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt; <span class="hljs-built_in">left</span>(m, <span class="hljs-built_in">vector</span>&lt;<span class="hljs-type">int</span>&gt;(n, <span class="hljs-number">0</span>));<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++) &#123;<br>                <span class="hljs-keyword">if</span> (matrix[i][j] == <span class="hljs-string">&#x27;1&#x27;</span>) &#123;<br>                    left[i][j] = (j == <span class="hljs-number">0</span> ? <span class="hljs-number">0</span>: left[i][j - <span class="hljs-number">1</span>]) + <span class="hljs-number">1</span>;<br>                &#125;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; m; i++) &#123;<br>            <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> j = <span class="hljs-number">0</span>; j &lt; n; j++) &#123;<br>                <span class="hljs-keyword">if</span> (matrix[i][j] == <span class="hljs-string">&#x27;0&#x27;</span>) &#123;<br>                    <span class="hljs-keyword">continue</span>;<br>                &#125;<br>                <span class="hljs-type">int</span> width = left[i][j];<br>                <span class="hljs-type">int</span> area = width;<br>                <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> k = i - <span class="hljs-number">1</span>; k &gt;= <span class="hljs-number">0</span>; k--) &#123;<br>                    width = <span class="hljs-built_in">min</span>(width, left[k][j]);<br>                    area = <span class="hljs-built_in">max</span>(area, (i - k + <span class="hljs-number">1</span>) * width);<br>                &#125;<br>                ret = <span class="hljs-built_in">max</span>(ret, area);<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="209-长度最小的子数组"><a href="#209-长度最小的子数组" class="headerlink" title="209. 长度最小的子数组"></a>209. 长度最小的子数组</h3><p>给定一个含有 n 个正整数的数组和一个正整数 target 。<br>找出该数组中满足其总和大于等于 target 的长度最小的 连续子数组 [numsl, numsl+1, …, numsr-1, numsr] ，并返回其长度。如果不存在符合条件的子数组，返回 0 。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：target = 7, nums = [2,3,1,2,4,3]<br>输出：2<br>解释：子数组 [4,3] 是该条件下的长度最小的子数组。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">minSubArrayLen</span><span class="hljs-params">(<span class="hljs-type">int</span> target, vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> ret = n + <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> sum = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>, right = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span>(right &lt; n)&#123;<br>            sum += nums[right];<br>            <span class="hljs-keyword">while</span>(left &lt;= right &amp;&amp; sum &gt;= target)&#123;<br>                ret = <span class="hljs-built_in">min</span>(ret, right - left + <span class="hljs-number">1</span>);<br>                sum -= nums[left];<br>                left ++;<br>            &#125;<br><br>            right++;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span>(ret == n + <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="栈"><a href="#栈" class="headerlink" title="栈"></a>栈</h2><h3 id="20-有效的括号"><a href="#20-有效的括号" class="headerlink" title="20. 有效的括号"></a>20. 有效的括号</h3><p>给定一个只包括 ‘(‘，’)’，’{‘，’}’，’[‘，’]’ 的字符串 s ，判断字符串是否有效。</p><p>有效字符串需满足：</p><p>左括号必须用相同类型的右括号闭合。<br>左括号必须以正确的顺序闭合。<br>每个右括号都有一个对应的相同类型的左括号。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isValid</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = s.<span class="hljs-built_in">size</span>();<br>        stack&lt;<span class="hljs-type">char</span>&gt; st;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">if</span> (!st.<span class="hljs-built_in">empty</span>() &amp;&amp; ((st.<span class="hljs-built_in">top</span>() == <span class="hljs-string">&#x27;&#123;&#x27;</span> &amp;&amp; s[i] == <span class="hljs-string">&#x27;&#125;&#x27;</span>) || (st.<span class="hljs-built_in">top</span>() == <span class="hljs-string">&#x27;(&#x27;</span> &amp;&amp; s[i] == <span class="hljs-string">&#x27;)&#x27;</span>) || (st.<span class="hljs-built_in">top</span>() == <span class="hljs-string">&#x27;[&#x27;</span> &amp;&amp; s[i] == <span class="hljs-string">&#x27;]&#x27;</span>)))&#123;<br>                st.<span class="hljs-built_in">pop</span>();<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                st.<span class="hljs-built_in">push</span>(s[i]);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> st.<span class="hljs-built_in">empty</span>();<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="232-用栈实现队列"><a href="#232-用栈实现队列" class="headerlink" title="232. 用栈实现队列"></a>232. 用栈实现队列</h3><p>请你仅使用两个栈实现先入先出队列。队列应当支持一般队列支持的所有操作（push、pop、peek、empty）：</p><p>实现 MyQueue 类：</p><p>void push(int x) 将元素 x 推到队列的末尾<br>int pop() 从队列的开头移除并返回元素<br>int peek() 返回队列开头的元素<br>boolean empty() 如果队列为空，返回 true ；否则，返回 false<br>说明：</p><p>你 只能 使用标准的栈操作 —— 也就是只有 push to top, peek&#x2F;pop from top, size, 和 is empty 操作是合法的。<br>你所使用的语言也许不支持栈。你可以使用 list 或者 deque（双端队列）来模拟一个栈，只要是标准的栈操作即可。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">MyQueue</span> &#123;<br><span class="hljs-keyword">private</span>:<br>    stack&lt;<span class="hljs-type">int</span>&gt; inStack, outStack;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">in2out</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">while</span> (!inStack.<span class="hljs-built_in">empty</span>()) &#123;<br>            outStack.<span class="hljs-built_in">push</span>(inStack.<span class="hljs-built_in">top</span>());<br>            inStack.<span class="hljs-built_in">pop</span>();<br>        &#125;<br>    &#125;<br><br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-built_in">MyQueue</span>() &#123;&#125;<br><br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">push</span><span class="hljs-params">(<span class="hljs-type">int</span> x)</span> </span>&#123;<br>        inStack.<span class="hljs-built_in">push</span>(x);<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">pop</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (outStack.<span class="hljs-built_in">empty</span>()) &#123;<br>            <span class="hljs-built_in">in2out</span>();<br>        &#125;<br>        <span class="hljs-type">int</span> x = outStack.<span class="hljs-built_in">top</span>();<br>        outStack.<span class="hljs-built_in">pop</span>();<br>        <span class="hljs-keyword">return</span> x;<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">peek</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">if</span> (outStack.<span class="hljs-built_in">empty</span>()) &#123;<br>            <span class="hljs-built_in">in2out</span>();<br>        &#125;<br>        <span class="hljs-keyword">return</span> outStack.<span class="hljs-built_in">top</span>();<br>    &#125;<br><br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">empty</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">return</span> inStack.<span class="hljs-built_in">empty</span>() &amp;&amp; outStack.<span class="hljs-built_in">empty</span>();<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="双指针"><a href="#双指针" class="headerlink" title="双指针"></a>双指针</h2><h3 id="11-盛最多水的容器"><a href="#11-盛最多水的容器" class="headerlink" title="11. 盛最多水的容器"></a>11. 盛最多水的容器</h3><p>给定一个长度为 n 的整数数组 height。有 n 条垂线，第 i 条线的两个端点是 (i, 0) 和 (i, height[i])。<br>找出其中的两条线，使得它们与 x 轴共同构成的容器可以容纳最多的水。<br>返回容器可以储存的最大水量。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxArea</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; height)</span> </span>&#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> n = height.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>, right = n - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span> (left &lt; right)&#123;<br>            ret = <span class="hljs-built_in">max</span>(ret, <span class="hljs-built_in">min</span>(height[right], height[left]) * (right - left));<br>            <span class="hljs-keyword">if</span> (height[right] &gt; height[left])&#123;<br>                left ++;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                right --;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="26-删除有序数组中的重复项"><a href="#26-删除有序数组中的重复项" class="headerlink" title="26. 删除有序数组中的重复项"></a>26. 删除有序数组中的重复项</h3><p>给你一个 非严格递增排列 的数组 nums ，请你 原地 删除重复出现的元素，使每个元素 只出现一次 ，返回删除后数组的新长度。元素的 相对顺序 应该保持 一致。然后返回 nums 中唯一元素的个数。</p><p>考虑 nums 的唯一元素的数量为 k ，你需要做以下事情确保你的题解可以被通过：</p><p>更改数组 nums ，使 nums 的前 k 个元素包含唯一元素，并按照它们最初在 nums 中出现的顺序排列。nums 的其余元素与 nums 的大小不重要。<br>返回 k。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">removeDuplicates</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br>        <span class="hljs-type">int</span> fast = <span class="hljs-number">1</span>, slow = <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span> (fast &lt; n) &#123;<br>            <span class="hljs-keyword">if</span> (nums[fast] != nums[fast - <span class="hljs-number">1</span>]) &#123;<br>                nums[slow] = nums[fast];<br>                ++slow;<br>            &#125;<br>            ++fast;<br>        &#125;<br>        <span class="hljs-keyword">return</span> slow;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="27-移除元素"><a href="#27-移除元素" class="headerlink" title="27. 移除元素"></a>27. 移除元素</h3><p>给你一个数组 nums 和一个值 val，你需要 原地 移除所有数值等于 val 的元素，并返回移除后数组的新长度。<br>不要使用额外的数组空间，你必须仅使用 O(1) 额外空间并 原地 修改输入数组。<br>元素的顺序可以改变。你不需要考虑数组中超出新长度后面的元素。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">removeElement</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> val)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> right = <span class="hljs-number">0</span>; right &lt; n; right++) &#123;<br>            <span class="hljs-keyword">if</span> (nums[right] != val) &#123;<br>                nums[left] = nums[right];<br>                left++;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> left;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="31-下一个排列"><a href="#31-下一个排列" class="headerlink" title="31. 下一个排列"></a>31. 下一个排列</h3><p>整数数组的一个 排列  就是将其所有成员以序列或线性顺序排列。</p><p>例如，arr &#x3D; [1,2,3] ，以下这些都可以视作 arr 的排列：[1,2,3]、[1,3,2]、[3,1,2]、[2,3,1]。<br>整数数组的 下一个排列 是指其整数的下一个字典序更大的排列。更正式地，如果数组的所有排列根据其字典顺序从小到大排列在一个容器中，那么数组的 下一个排列 就是在这个有序容器中排在它后面的那个排列。如果不存在下一个更大的排列，那么这个数组必须重排为字典序最小的排列（即，其元素按升序排列）。</p><p>例如，arr &#x3D; [1,2,3] 的下一个排列是 [1,3,2]。<br>类似地，arr &#x3D; [2,3,1] 的下一个排列是 [3,1,2]。<br>而 arr &#x3D; [3,2,1] 的下一个排列是 [1,2,3] ，因为 [3,2,1] 不存在一个字典序更大的排列。<br>给你一个整数数组 nums ，找出 nums 的下一个排列。</p><p>必须 原地 修改，只允许使用额外常数空间。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">nextPermutation</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> i = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">while</span> (i &gt;= <span class="hljs-number">0</span> &amp;&amp; nums[i] &gt;= nums[i<span class="hljs-number">+1</span>])&#123;<br>            i--;<br>        &#125;<br><br>        <span class="hljs-keyword">if</span> (i &gt;= <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-type">int</span> j = nums.<span class="hljs-built_in">size</span>() - <span class="hljs-number">1</span>;<br>            <span class="hljs-keyword">while</span>(j &gt; i &amp;&amp; nums[i] &gt;= nums[j])&#123;<br>                j--;<br>            &#125;<br>            <span class="hljs-built_in">swap</span>(nums[i], nums[j]);<br>        &#125;<br>        <span class="hljs-built_in">reverse</span>(nums.<span class="hljs-built_in">begin</span>() + i + <span class="hljs-number">1</span>, nums.<span class="hljs-built_in">end</span>());<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="42-接雨水"><a href="#42-接雨水" class="headerlink" title="42. 接雨水"></a>42. 接雨水</h3><p>给定 n 个非负整数表示每个宽度为 1 的柱子的高度图，计算按此排列的柱子，下雨之后能接多少雨水。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：height = [0,1,0,2,1,0,1,3,2,1,2,1]<br>输出：6<br>解释：上面是由数组 [0,1,0,2,1,0,1,3,2,1,2,1] 表示的高度图，在这种情况下，可以接 6 个单位的雨水（蓝色部分表示雨水）<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">cal_water</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; height, <span class="hljs-type">int</span> left, <span class="hljs-type">int</span> right)</span></span>&#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-built_in">min</span>(height[left], height[right]) * (right - left - <span class="hljs-number">1</span>);<br>        <span class="hljs-type">int</span> sum = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = left + <span class="hljs-number">1</span>; i &lt;= right - <span class="hljs-number">1</span>; i++)&#123;<br>            sum += height[i];<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret - sum;<br><br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">trap</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; height)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = height.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> r = <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> max_h = height[<span class="hljs-number">0</span>], max_h_idx = <span class="hljs-number">0</span>;<br><br>        <span class="hljs-keyword">if</span> (n == <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        &#125;<br><br>        <span class="hljs-keyword">while</span>(max_h_idx &lt;= r &amp;&amp; r &lt; n)&#123;<br>            <span class="hljs-keyword">if</span> (height[r] &gt;= max_h)&#123;<br>                ret += <span class="hljs-built_in">cal_water</span>(height, max_h_idx, r);<br>                max_h = height[r];<br>                max_h_idx = r;<br>            &#125;<br><br>            r++;<br>        &#125;<br><br>        max_h = height[n<span class="hljs-number">-1</span>];<br>        max_h_idx = n<span class="hljs-number">-1</span>;<br>        r = n<span class="hljs-number">-2</span>;<br>        <span class="hljs-keyword">while</span>(r &lt;= max_h_idx &amp;&amp; r &gt;= <span class="hljs-number">0</span>)&#123;<br>            <span class="hljs-keyword">if</span> (height[r] &gt; max_h)&#123;<br>                ret += <span class="hljs-built_in">cal_water</span>(height, r, max_h_idx);<br>                max_h = height[r];<br>                max_h_idx = r;<br>            &#125;<br><br>            r--;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="75-颜色分类"><a href="#75-颜色分类" class="headerlink" title="75. 颜色分类"></a>75. 颜色分类</h3><p>给定一个包含红色、白色和蓝色、共 n 个元素的数组 nums ，原地对它们进行排序，使得相同颜色的元素相邻，并按照红色、白色、蓝色顺序排列。<br>我们使用整数 0、 1 和 2 分别表示红色、白色和蓝色。<br>必须在不使用库内置的 sort 函数的情况下解决这个问题。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [2,0,2,1,1,0]<br>输出：[0,0,1,1,2,2]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">sortColors</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br><br>        <span class="hljs-type">int</span> red = <span class="hljs-number">0</span>, blue = n - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i ++)&#123;<br>            <span class="hljs-keyword">if</span> (nums[i] == <span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-built_in">swap</span>(nums[red], nums[i]);<br>                red ++;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = n - <span class="hljs-number">1</span>; i &gt;= <span class="hljs-number">0</span>; i --)&#123;<br>            <span class="hljs-keyword">if</span> (nums[i] == <span class="hljs-number">2</span>)&#123;<br>                <span class="hljs-built_in">swap</span>(nums[blue], nums[i]);<br>                blue --;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="80-删除有序数组中的重复项-II"><a href="#80-删除有序数组中的重复项-II" class="headerlink" title="80. 删除有序数组中的重复项 II"></a>80. 删除有序数组中的重复项 II</h3><p>给你一个有序数组 nums ，请你 原地 删除重复出现的元素，使得出现次数超过两次的元素只出现两次 ，返回删除后数组的新长度。<br>不要使用额外的数组空间，你必须在 原地 修改输入数组 并在使用 O(1) 额外空间的条件下完成。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">removeDuplicates</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span> (n &lt;= <span class="hljs-number">2</span>) &#123;<br>            <span class="hljs-keyword">return</span> n;<br>        &#125;<br>        <span class="hljs-type">int</span> slow = <span class="hljs-number">2</span>, fast = <span class="hljs-number">2</span>;<br>        <span class="hljs-keyword">while</span> (fast &lt; n) &#123;<br>            <span class="hljs-keyword">if</span> (nums[slow - <span class="hljs-number">2</span>] != nums[fast]) &#123;<br>                nums[slow] = nums[fast];<br>                ++slow;<br>            &#125;<br>            ++fast;<br>        &#125;<br>        <span class="hljs-keyword">return</span> slow;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="88-合并两个有序数组"><a href="#88-合并两个有序数组" class="headerlink" title="88. 合并两个有序数组"></a>88. 合并两个有序数组</h3><p>给你两个按 非递减顺序 排列的整数数组 nums1 和 nums2，另有两个整数 m 和 n ，分别表示 nums1 和 nums2 中的元素数目。<br>请你 合并 nums2 到 nums1 中，使合并后的数组同样按 非递减顺序 排列。<br>注意：最终，合并后数组不应由函数返回，而是存储在数组 nums1 中。为了应对这种情况，nums1 的初始长度为 m + n，其中前 m 个元素表示应合并的元素，后 n 个元素为 0 ，应忽略。nums2 的长度为 n 。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums1 = [1,2,3,0,0,0], m = 3, nums2 = [2,5,6], n = 3<br>输出：[1,2,2,3,5,6]<br>解释：需要合并 [1,2,3] 和 [2,5,6] 。<br>合并结果是 [1,2,2,3,5,6] ，其中斜体加粗标注的为 nums1 中的元素。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">merge</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums1, <span class="hljs-type">int</span> m, vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums2, <span class="hljs-type">int</span> n)</span> </span>&#123;<br>        <span class="hljs-type">int</span> p1 = m - <span class="hljs-number">1</span>, p2 = n - <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> tail = m + n - <span class="hljs-number">1</span>;<br>        <span class="hljs-type">int</span> cur;<br>        <span class="hljs-keyword">while</span> (p1 &gt;= <span class="hljs-number">0</span> || p2 &gt;= <span class="hljs-number">0</span>) &#123;<br>            <span class="hljs-keyword">if</span> (p1 == <span class="hljs-number">-1</span>) &#123;<br>                cur = nums2[p2--];<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (p2 == <span class="hljs-number">-1</span>) &#123;<br>                cur = nums1[p1--];<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (nums1[p1] &gt; nums2[p2]) &#123;<br>                cur = nums1[p1--];<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                cur = nums2[p2--];<br>            &#125;<br>            nums1[tail--] = cur;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="283-移动零"><a href="#283-移动零" class="headerlink" title="283. 移动零"></a>283. 移动零</h3><p>给定一个数组 nums，编写一个函数将所有 0 移动到数组的末尾，同时保持非零元素的相对顺序。<br>请注意 ，必须在不复制数组的情况下原地对数组进行操作。</p><p>示例 1:</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入: nums = [0,1,0,3,12]<br>输出: [1,3,12,0,0]<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">void</span> <span class="hljs-title">moveZeroes</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> idx = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">if</span> (nums[i] != <span class="hljs-number">0</span>)&#123;<br>                <span class="hljs-built_in">swap</span>(nums[i], nums[idx]);<br>                idx += <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="345-反转字符串中的元音字母"><a href="#345-反转字符串中的元音字母" class="headerlink" title="345. 反转字符串中的元音字母"></a>345. 反转字符串中的元音字母</h3><p>给你一个字符串 s ，仅反转字符串中的所有元音字母，并返回结果字符串。<br>元音字母包括 ‘a’、’e’、’i’、’o’、’u’，且可能以大小写两种形式出现不止一次。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">string <span class="hljs-title">reverseVowels</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">if</span>(n == <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> s;<br>        &#125;<br><br>        set&lt;<span class="hljs-type">char</span>&gt; st = &#123;<span class="hljs-string">&#x27;a&#x27;</span>, <span class="hljs-string">&#x27;e&#x27;</span>, <span class="hljs-string">&#x27;i&#x27;</span>, <span class="hljs-string">&#x27;o&#x27;</span>, <span class="hljs-string">&#x27;u&#x27;</span>, <span class="hljs-string">&#x27;A&#x27;</span>, <span class="hljs-string">&#x27;E&#x27;</span>, <span class="hljs-string">&#x27;I&#x27;</span>, <span class="hljs-string">&#x27;O&#x27;</span>, <span class="hljs-string">&#x27;U&#x27;</span>&#125;;<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>, right = n - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span>(left &lt; right)&#123;<br>            <span class="hljs-keyword">if</span> (st.<span class="hljs-built_in">find</span>(s[left]) == st.<span class="hljs-built_in">end</span>())&#123;<br>                left ++;<br>            &#125;<br><br>            <span class="hljs-keyword">if</span> (st.<span class="hljs-built_in">find</span>(s[right]) == st.<span class="hljs-built_in">end</span>())&#123;<br>                right --;<br>            &#125;<br><br>            <span class="hljs-keyword">if</span> (st.<span class="hljs-built_in">find</span>(s[left]) != st.<span class="hljs-built_in">end</span>() &amp;&amp; st.<span class="hljs-built_in">find</span>(s[right]) != st.<span class="hljs-built_in">end</span>())&#123;<br>                <span class="hljs-built_in">swap</span>(s[left], s[right]);<br>                left ++;<br>                right --;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> s;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="455-分发饼干"><a href="#455-分发饼干" class="headerlink" title="455. 分发饼干"></a>455. 分发饼干</h3><p>假设你是一位很棒的家长，想要给你的孩子们一些小饼干。但是，每个孩子最多只能给一块饼干。<br>对每个孩子 i，都有一个胃口值 g[i]，这是能让孩子们满足胃口的饼干的最小尺寸；并且每块饼干 j，都有一个尺寸 s[j] 。如果 s[j] &gt;&#x3D; g[i]，我们可以将这个饼干 j 分配给孩子 i ，这个孩子会得到满足。你的目标是尽可能满足越多数量的孩子，并输出这个最大数值。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">findContentChildren</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; g, vector&lt;<span class="hljs-type">int</span>&gt;&amp; s)</span> </span>&#123;<br>        <span class="hljs-built_in">sort</span>(g.<span class="hljs-built_in">begin</span>(), g.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-built_in">sort</span>(s.<span class="hljs-built_in">begin</span>(), s.<span class="hljs-built_in">end</span>());<br>        <span class="hljs-type">int</span> m = g.<span class="hljs-built_in">size</span>(), n = s.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> count = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>, j = <span class="hljs-number">0</span>; i &lt; m &amp;&amp; j &lt; n; i++, j++) &#123;<br>            <span class="hljs-keyword">while</span> (j &lt; n &amp;&amp; g[i] &gt; s[j]) &#123;<br>                j++;<br>            &#125;<br>            <span class="hljs-keyword">if</span> (j &lt; n) &#123;<br>                count++;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> count;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="哈希表"><a href="#哈希表" class="headerlink" title="哈希表"></a>哈希表</h2><h3 id="1-两数之和"><a href="#1-两数之和" class="headerlink" title="1. 两数之和"></a>1. 两数之和</h3><p>给定一个整数数组 nums 和一个整数目标值 target，请你在该数组中找出 和为目标值 target  的那 两个 整数，并返回它们的数组下标。<br>你可以假设每种输入只会对应一个答案。但是，数组中同一个元素在答案里不能重复出现。<br>你可以按任意顺序返回答案。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [2,7,11,15], target = 9<br>输出：[0,1]<br>解释：因为 nums[0] + nums[1] == 9 ，返回[0, 1]。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function">vector&lt;<span class="hljs-type">int</span>&gt; <span class="hljs-title">twoSum</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        unordered_map&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; hashtable;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; nums.<span class="hljs-built_in">size</span>(); i++) &#123;<br>            <span class="hljs-keyword">auto</span> it = hashtable.<span class="hljs-built_in">find</span>(target - nums[i]);<br>            <span class="hljs-keyword">if</span> (it != hashtable.<span class="hljs-built_in">end</span>())&#123;<br>                <span class="hljs-keyword">return</span> &#123;it-&gt;second, i&#125;;<br>            &#125;<br>            hashtable[nums[i]] = i;<br>        &#125;<br>        <span class="hljs-keyword">return</span> &#123;&#125;;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="3-无重复字符的最长子串"><a href="#3-无重复字符的最长子串" class="headerlink" title="3. 无重复字符的最长子串"></a>3. 无重复字符的最长子串</h3><p>给定一个字符串 s ，请你找出其中不含有重复字符的 最长子串 的长度。</p><p>示例 1:</p><p>输入: s &#x3D; “abcabcbb”<br>输出: 3<br>解释: 因为无重复字符的最长子串是 “abc”，所以其长度为 3。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">lengthOfLongestSubstring</span><span class="hljs-params">(string s)</span> </span>&#123;<br>        <span class="hljs-keyword">if</span>(s.<span class="hljs-built_in">size</span>() == <span class="hljs-number">0</span>) <span class="hljs-keyword">return</span> <span class="hljs-number">0</span>;<br>        unordered_set&lt;<span class="hljs-type">char</span>&gt; lookup;<br>        <span class="hljs-type">int</span> maxStr = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> left = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span>(<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; s.<span class="hljs-built_in">size</span>(); i++)&#123;<br>            <span class="hljs-keyword">while</span> (lookup.<span class="hljs-built_in">find</span>(s[i]) != lookup.<span class="hljs-built_in">end</span>())&#123;<br>                lookup.<span class="hljs-built_in">erase</span>(s[left]);<br>                left ++;<br>            &#125;<br>            maxStr = <span class="hljs-built_in">max</span>(maxStr,i-left<span class="hljs-number">+1</span>);<br>            lookup.<span class="hljs-built_in">insert</span>(s[i]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> maxStr;<br>        <br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="76-最小覆盖子串"><a href="#76-最小覆盖子串" class="headerlink" title="76. 最小覆盖子串"></a>76. 最小覆盖子串</h3><p>给你一个字符串 s 、一个字符串 t 。返回 s 中涵盖 t 所有字符的最小子串。如果 s 中不存在涵盖 t 所有字符的子串，则返回空字符串 “” 。</p><p>注意：</p><p>对于 t 中重复字符，我们寻找的子字符串中该字符数量必须不少于 t 中该字符数量。<br>如果 s 中存在这样的子串，我们保证它是唯一的答案。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：s = <span class="hljs-string">&quot;ADOBECODEBANC&quot;</span>, t = <span class="hljs-string">&quot;ABC&quot;</span><br>输出：<span class="hljs-string">&quot;BANC&quot;</span><br>解释：最小覆盖子串 <span class="hljs-string">&quot;BANC&quot;</span> 包含来自字符串 t 的 <span class="hljs-string">&#x27;A&#x27;</span>、<span class="hljs-string">&#x27;B&#x27;</span> 和 <span class="hljs-string">&#x27;C&#x27;</span>。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    unordered_map &lt;<span class="hljs-type">char</span>, <span class="hljs-type">int</span>&gt; ori, cnt;<br><br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">check</span><span class="hljs-params">()</span> </span>&#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> &amp;p: ori) &#123;<br>            <span class="hljs-keyword">if</span> (cnt[p.first] &lt; p.second) &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>    &#125;<br><br>    <span class="hljs-function">string <span class="hljs-title">minWindow</span><span class="hljs-params">(string s, string t)</span> </span>&#123;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">const</span> <span class="hljs-keyword">auto</span> &amp;c: t) &#123;<br>            ++ori[c];<br>        &#125;<br><br>        <span class="hljs-type">int</span> l = <span class="hljs-number">0</span>, r = <span class="hljs-number">-1</span>;<br>        <span class="hljs-type">int</span> len = INT_MAX, ansL = <span class="hljs-number">-1</span>, ansR = <span class="hljs-number">-1</span>;<br><br>        <span class="hljs-keyword">while</span> (r &lt; <span class="hljs-built_in">int</span>(s.<span class="hljs-built_in">size</span>())) &#123;<br>            <span class="hljs-keyword">if</span> (ori.<span class="hljs-built_in">find</span>(s[++r]) != ori.<span class="hljs-built_in">end</span>()) &#123;<br>                ++cnt[s[r]];<br>            &#125;<br>            <span class="hljs-keyword">while</span> (<span class="hljs-built_in">check</span>() &amp;&amp; l &lt;= r) &#123;<br>                <span class="hljs-keyword">if</span> (r - l + <span class="hljs-number">1</span> &lt; len) &#123;<br>                    len = r - l + <span class="hljs-number">1</span>;<br>                    ansL = l;<br>                &#125;<br>                <span class="hljs-keyword">if</span> (ori.<span class="hljs-built_in">find</span>(s[l]) != ori.<span class="hljs-built_in">end</span>()) &#123;<br>                    --cnt[s[l]];<br>                &#125;<br>                ++l;<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ansL == <span class="hljs-number">-1</span> ? <span class="hljs-built_in">string</span>() : s.<span class="hljs-built_in">substr</span>(ansL, len);<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="128-最长连续序列"><a href="#128-最长连续序列" class="headerlink" title="128. 最长连续序列"></a>128. 最长连续序列</h3><p>给定一个未排序的整数数组 nums ，找出数字连续的最长序列（不要求序列元素在原数组中连续）的长度。<br>请你设计并实现时间复杂度为 O(n) 的算法解决此问题。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：nums = [100,4,200,1,3,2]<br>输出：4<br>解释：最长数字连续序列是 [1, 2, 3, 4]。它的长度为 4。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">longestConsecutive</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br>        unordered_set&lt;<span class="hljs-type">int</span>&gt; st;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i++)&#123;<br>            <span class="hljs-keyword">if</span> (st.<span class="hljs-built_in">find</span>(nums[i]) == st.<span class="hljs-built_in">end</span>())&#123;<br>                st.<span class="hljs-built_in">insert</span>(nums[i]);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-type">int</span> cur_len = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">0</span>; i &lt; n; i ++)&#123;<br>            cur_len = <span class="hljs-number">0</span>;<br>            <span class="hljs-keyword">if</span> (st.<span class="hljs-built_in">find</span>(nums[i] - <span class="hljs-number">1</span>) == st.<span class="hljs-built_in">end</span>())&#123;<br>                <span class="hljs-type">int</span> start = nums[i];<br>                <span class="hljs-keyword">while</span>(st.<span class="hljs-built_in">find</span>(start) != st.<span class="hljs-built_in">end</span>())&#123;<br>                    cur_len ++;<br>                    start ++;<br>                &#125;<br>                ret = <span class="hljs-built_in">max</span>(ret, cur_len);<br>            &#125;<br>        &#125;<br><br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="202-快乐数"><a href="#202-快乐数" class="headerlink" title="202. 快乐数"></a>202. 快乐数</h3><p>编写一个算法来判断一个数 n 是不是快乐数。</p><p>「快乐数」 定义为：</p><p>对于一个正整数，每一次将该数替换为它每个位置上的数字的平方和。<br>然后重复这个过程直到这个数变为 1，也可能是 无限循环 但始终变不到 1。<br>如果这个过程 结果为 1，那么这个数就是快乐数。<br>如果 n 是 快乐数 就返回 true ；不是，则返回 false 。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">cal</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span></span>&#123;<br>        <span class="hljs-type">int</span> ret = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> k = <span class="hljs-number">0</span>;<br>        <span class="hljs-keyword">while</span>(n != <span class="hljs-number">0</span>)&#123;<br>            k = n % <span class="hljs-number">10</span>;<br>            n = (n - k)/<span class="hljs-number">10</span>;<br>            ret += k * k;<br>        &#125;<br>        <span class="hljs-keyword">return</span> ret;<br>    &#125;<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">isHappy</span><span class="hljs-params">(<span class="hljs-type">int</span> n)</span> </span>&#123;<br>        set&lt;<span class="hljs-type">int</span>&gt; nums;<br>        <span class="hljs-type">int</span> tmp = <span class="hljs-built_in">cal</span>(n);<br>        <span class="hljs-keyword">if</span> (tmp == <span class="hljs-number">1</span>)&#123;<br>            <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        &#125;<br><br>        nums.<span class="hljs-built_in">insert</span>(tmp);<br>        <span class="hljs-keyword">while</span>(tmp != <span class="hljs-number">1</span>)&#123;<br>            tmp = <span class="hljs-built_in">cal</span>(tmp);<br>            <span class="hljs-keyword">if</span> (nums.<span class="hljs-built_in">find</span>(tmp) == nums.<span class="hljs-built_in">end</span>())&#123;<br>                nums.<span class="hljs-built_in">insert</span>(tmp);<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>        <br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="二分"><a href="#二分" class="headerlink" title="二分"></a>二分</h2><h3 id="74-搜索二维矩阵"><a href="#74-搜索二维矩阵" class="headerlink" title="74. 搜索二维矩阵"></a>74. 搜索二维矩阵</h3><p>给你一个满足下述两条属性的 m x n 整数矩阵：</p><p>每行中的整数从左到右按非严格递增顺序排列。<br>每行的第一个整数大于前一行的最后一个整数。<br>给你一个整数 target ，如果 target 在矩阵中，返回 true ；否则，返回 false。</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：matrix = [[1,3,5,7],[10,11,16,20],[23,30,34,60]], target = 3<br>输出：<span class="hljs-literal">true</span><br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">bool</span> <span class="hljs-title">searchMatrix</span><span class="hljs-params">(vector&lt;vector&lt;<span class="hljs-type">int</span>&gt;&gt;&amp; matrix, <span class="hljs-type">int</span> target)</span> </span>&#123;<br>        <span class="hljs-type">int</span> m = matrix.<span class="hljs-built_in">size</span>(), n = matrix[<span class="hljs-number">0</span>].<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> low = <span class="hljs-number">0</span>, high = m * n - <span class="hljs-number">1</span>;<br>        <span class="hljs-keyword">while</span> (low &lt;= high) &#123;<br>            <span class="hljs-type">int</span> mid = (high - low) / <span class="hljs-number">2</span> + low;<br>            <span class="hljs-type">int</span> x = matrix[mid / n][mid % n];<br>            <span class="hljs-keyword">if</span> (x &lt; target) &#123;<br>                low = mid + <span class="hljs-number">1</span>;<br>            &#125; <span class="hljs-keyword">else</span> <span class="hljs-keyword">if</span> (x &gt; target) &#123;<br>                high = mid - <span class="hljs-number">1</span>;<br>            &#125; <span class="hljs-keyword">else</span> &#123;<br>                <span class="hljs-keyword">return</span> <span class="hljs-literal">true</span>;<br>            &#125;<br>        &#125;<br>        <span class="hljs-keyword">return</span> <span class="hljs-literal">false</span>;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h3 id="162-寻找峰值"><a href="#162-寻找峰值" class="headerlink" title="162. 寻找峰值"></a>162. 寻找峰值</h3><p>峰值元素是指其值严格大于左右相邻值的元素。<br>给你一个整数数组 nums，找到峰值元素并返回其索引。数组可能包含多个峰值，在这种情况下，返回 任何一个峰值 所在位置即可。<br>你可以假设 nums[-1] &#x3D; nums[n] &#x3D; -∞ 。<br>你必须实现时间复杂度为 O(log n) 的算法来解决此问题。</p><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">findPeakElement</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; nums)</span> </span>&#123;<br>        <span class="hljs-type">int</span> n = nums.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-type">int</span> idx = <span class="hljs-built_in">rand</span>() % n;<br><br>        <span class="hljs-comment">// 辅助函数，输入下标 i，返回一个二元组 (0/1, nums[i])</span><br>        <span class="hljs-comment">// 方便处理 nums[-1] 以及 nums[n] 的边界情况</span><br>        <span class="hljs-keyword">auto</span> get = [&amp;](<span class="hljs-type">int</span> i) -&gt; pair&lt;<span class="hljs-type">int</span>, <span class="hljs-type">int</span>&gt; &#123;<br>            <span class="hljs-keyword">if</span> (i == <span class="hljs-number">-1</span> || i == n) &#123;<br>                <span class="hljs-keyword">return</span> &#123;<span class="hljs-number">0</span>, <span class="hljs-number">0</span>&#125;;<br>            &#125;<br>            <span class="hljs-keyword">return</span> &#123;<span class="hljs-number">1</span>, nums[i]&#125;;<br>        &#125;;<br><br>        <span class="hljs-keyword">while</span> (!(<span class="hljs-built_in">get</span>(idx - <span class="hljs-number">1</span>) &lt; <span class="hljs-built_in">get</span>(idx) &amp;&amp; <span class="hljs-built_in">get</span>(idx) &gt; <span class="hljs-built_in">get</span>(idx + <span class="hljs-number">1</span>))) &#123;<br>            <span class="hljs-keyword">if</span> (<span class="hljs-built_in">get</span>(idx) &lt; <span class="hljs-built_in">get</span>(idx + <span class="hljs-number">1</span>)) &#123;<br>                idx += <span class="hljs-number">1</span>;<br>            &#125;<br>            <span class="hljs-keyword">else</span> &#123;<br>                idx -= <span class="hljs-number">1</span>;<br>            &#125;<br>        &#125;<br>        <br>        <span class="hljs-keyword">return</span> idx;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure><h2 id="贪心"><a href="#贪心" class="headerlink" title="贪心"></a>贪心</h2><h3 id="122-买卖股票的最佳时机-II-1"><a href="#122-买卖股票的最佳时机-II-1" class="headerlink" title="122. 买卖股票的最佳时机 II"></a>122. 买卖股票的最佳时机 II</h3><p>给你一个整数数组 prices ，其中 prices[i] 表示某支股票第 i 天的价格。<br>在每一天，你可以决定是否购买和&#x2F;或出售股票。你在任何时候 最多 只能持有 一股 股票。你也可以先购买，然后在 同一天 出售。<br>返回 你能获得的 最大 利润 。</p><p>示例 1：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">输入：prices = [7,1,5,3,6,4]<br>输出：7<br>解释：在第 2 天（股票价格 = 1）的时候买入，在第 3 天（股票价格 = 5）的时候卖出, 这笔交易所能获得利润 = 5 - 1 = 4 。<br>     随后，在第 4 天（股票价格 = 3）的时候买入，在第 5 天（股票价格 = 6）的时候卖出, 这笔交易所能获得利润 = 6 - 3 = 3 。<br>     总利润为 4 + 3 = 7 。<br></code></pre></td></tr></table></figure><figure class="highlight cpp"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><code class="hljs cpp"><span class="hljs-keyword">class</span> <span class="hljs-title class_">Solution</span> &#123;<br><span class="hljs-keyword">public</span>:<br>    <span class="hljs-function"><span class="hljs-type">int</span> <span class="hljs-title">maxProfit</span><span class="hljs-params">(vector&lt;<span class="hljs-type">int</span>&gt;&amp; prices)</span> </span>&#123;   <br>        <span class="hljs-type">int</span> ans = <span class="hljs-number">0</span>;<br>        <span class="hljs-type">int</span> n = prices.<span class="hljs-built_in">size</span>();<br>        <span class="hljs-keyword">for</span> (<span class="hljs-type">int</span> i = <span class="hljs-number">1</span>; i &lt; n; ++i) &#123;<br>            ans += <span class="hljs-built_in">max</span>(<span class="hljs-number">0</span>, prices[i] - prices[i - <span class="hljs-number">1</span>]);<br>        &#125;<br>        <span class="hljs-keyword">return</span> ans;<br>    &#125;<br>&#125;;<br></code></pre></td></tr></table></figure>]]></content>
    
    
    <categories>
      
      <category>Interview</category>
      
    </categories>
    
    
    <tags>
      
      <tag>C/C++</tag>
      
      <tag>Algorithm</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>使用 Vercel 部署博客和设置 SSL 证书</title>
    <link href="/2023/10/25/hexo-vercel/"/>
    <url>/2023/10/25/hexo-vercel/</url>
    
    <content type="html"><![CDATA[<p>详细说明Vercel的一些高级使用方法！</p><span id="more"></span><p>参考</p><ul><li><a href="https://hexo.fluid-dev.com/posts/hexo-vercel/">Vercel 部署高级用法教程</a></li><li><a href="https://vercel.com/">vercel</a></li></ul><p>首先创建一个新的github.io仓库，推送博客。部署好后，即可点击github.io链接访问page。在原先的方案中，我使用GitHub DNS进行域名解析，在仓库的page添加domain即可。</p><p><img src="/img/vercel/github_dns.jpg" alt="Github DNS"></p><p>在无证书情况下，可以访问域名（不能用https，即www），但是经常报DNS解析有错，这样就没法使能https，解决不了证书问题。</p><p><img src="/img/vercel/github_dns_error.jpg" alt="DNS error"></p><p>解决：改用新的vercel + ssl模式，停用掉github DNS。</p><h2 id="申请免费证书"><a href="#申请免费证书" class="headerlink" title="申请免费证书"></a>申请免费证书</h2><p><img src="/img/vercel/ca.jpg" alt="CA"></p><p>申请后绑定域名，会自动增加解析：</p><p><img src="/img/vercel/ssl_dns.jpg" alt="CA 证书域名解析"></p><h2 id="Vercel-导入项目"><a href="#Vercel-导入项目" class="headerlink" title="Vercel 导入项目"></a>Vercel 导入项目</h2><p><img src="/img/vercel/prj.png" alt="导入github.io项目"></p><h2 id="设置域名"><a href="#设置域名" class="headerlink" title="设置域名"></a>设置域名</h2><p>这里填域名的时候会要求去设置域名解析，解析后就可以验证DNS</p><p><img src="/img/vercel/ali.png" alt="vercel域名解析"></p><p><img src="/img/vercel/domain.png" alt="域名"></p><h2 id="设置区域"><a href="#设置区域" class="headerlink" title="设置区域"></a>设置区域</h2><p>发现解析后需要梯子才能访问，把区域设置为香港：</p><p><img src="/img/vercel/function.png" alt="设置区域"></p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  <entry>
    <title>hexo部署博客并上传到域名上</title>
    <link href="/2019/06/29/Deploy-Blog-on-Server-and-URL/"/>
    <url>/2019/06/29/Deploy-Blog-on-Server-and-URL/</url>
    
    <content type="html"><![CDATA[<p>文章转载来自<a href="https://blog.csdn.net/qq_40147863/article/details/84942914">使用 Hexo + Github 搭建自己的博客（图文教程）</a><br>替换主题参考<a href="https://blog.csdn.net/qq_40147863/article/details/84946894">Hexo 安装和替换主题、自定义博客主题</a><br>由于github部署的博客连接较慢，因此在购买腾讯云服务器之后将博客内容部署到腾讯云上，特此记录一下过程。</p><span id="more"></span><ul><li><a href="#%E6%90%AD%E5%BB%BA%E8%BF%87%E7%A8%8B">搭建过程</a><ul><li><a href="#%E5%AE%89%E8%A3%85git-nodejs">安装git node.js</a></li><li><a href="#%E6%96%B0%E5%BB%BA%E4%BB%93%E5%BA%93">新建仓库</a></li><li><a href="#%E5%AE%89%E8%A3%85hexo">安装Hexo</a></li><li><a href="#%E4%BF%AE%E6%94%B9_configyml">修改<code>_config.yml</code></a></li><li><a href="#%E5%BB%BA%E7%AB%8Bssh%E5%AF%86%E9%92%A5">建立ssh密钥</a></li><li><a href="#%E7%BB%B4%E6%8A%A4%E8%BF%87%E7%A8%8B">维护过程</a></li></ul></li><li><a href="#github%E8%87%AA%E5%8A%A8%E6%8E%A8%E9%80%81">github自动推送</a></li><li><a href="#%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E9%83%A8%E7%BD%B2">云服务器部署</a><ul><li><a href="#%E5%88%9B%E5%BB%BAgit%E7%94%A8%E6%88%B7%E5%92%8C%E4%BB%93%E5%BA%93">创建git用户和仓库</a></li><li><a href="#%E4%BD%BF%E7%94%A8nginx%E5%8F%8D%E5%90%91%E4%BB%A3%E7%90%86">使用nginx反向代理</a></li><li><a href="#%E5%BC%80%E6%94%BE%E4%BA%91%E6%9C%8D%E5%8A%A1%E5%99%A8%E7%AB%AF%E5%8F%A3">开放云服务器端口</a></li><li><a href="#%E8%AE%BE%E7%BD%AEhexo%E4%BB%93%E5%BA%93">设置Hexo仓库</a></li><li><a href="#%E9%85%8D%E7%BD%AE%E5%9F%9F%E5%90%8D%E8%A7%A3%E6%9E%90">配置域名解析</a></li><li><a href="#%E5%9F%9F%E5%90%8D%E5%A4%87%E6%A1%88">域名备案</a></li></ul></li></ul><h2 id="搭建过程"><a href="#搭建过程" class="headerlink" title="搭建过程"></a>搭建过程</h2><h3 id="安装git-node-js"><a href="#安装git-node-js" class="headerlink" title="安装git node.js"></a>安装git node.js</h3><p>查看版本命令用  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm -v<br>node -v<br></code></pre></td></tr></table></figure><h3 id="新建仓库"><a href="#新建仓库" class="headerlink" title="新建仓库"></a>新建仓库</h3><p>新建一个repository，名称为 <code>name.github.io</code></p><h3 id="安装Hexo"><a href="#安装Hexo" class="headerlink" title="安装Hexo"></a>安装Hexo</h3><p>首先安装cnpm</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 全局安装，这样hexo才能运行</span><br>cnpm install hexo -g<br>cnpm list -g<br>cnpm uninstall -g hexo<br><br><span class="hljs-comment"># 会卡住</span><br>hexo init<br><span class="hljs-comment"># 手动安装依赖</span><br>cnpm install -f<br>hexo s<br><br><span class="hljs-comment"># 安装更多依赖</span><br>cnpm install hexo-util<br>cnpm install moment<br>cnpm install hexo-pagination<br>cnpm install @adobe/css-tools<br>cnpm install hexo-deployer-git<br>cnpm install hexo-helper-live2d<br>cnpm install live2d-widget-model-epsilon2_1<br><br><span class="hljs-comment"># or</span><br>npm install hexo -g<br>npm list -g<br>npm uninstall -g hexo<br></code></pre></td></tr></table></figure><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><code class="hljs bash">npm install hexo -g<br>hexo -v<br>hexo init<br>npm install<br>hexo g<br>hexo s  <span class="hljs-comment">#查看本地新建的hexo</span><br>npm install hexo-deployer-git --save<br></code></pre></td></tr></table></figure><h3 id="修改-config-yml"><a href="#修改-config-yml" class="headerlink" title="修改_config.yml"></a>修改<code>_config.yml</code></h3><figure class="highlight yml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs yml"><span class="hljs-attr">deploy:</span><br>  <span class="hljs-attr">type:</span> <span class="hljs-string">git</span><br>  <span class="hljs-attr">repository:</span> <span class="hljs-string">&lt;git仓库.git&gt;</span><br>  <span class="hljs-attr">branch:</span> <span class="hljs-string">master</span><br><br></code></pre></td></tr></table></figure><h3 id="建立ssh密钥"><a href="#建立ssh密钥" class="headerlink" title="建立ssh密钥"></a>建立ssh密钥</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ssh-keygen -t rsa -C <span class="hljs-string">&quot;mail@xx.com&quot;</span><br></code></pre></td></tr></table></figure><p>并将默认保存位置的<code>id_rsa.pub</code>内容存放到github网站中的SSH密钥中。</p><h3 id="维护过程"><a href="#维护过程" class="headerlink" title="维护过程"></a>维护过程</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo new post <span class="hljs-string">&quot;blog-name&quot;</span><br>hexo d -g<br></code></pre></td></tr></table></figure><h2 id="github自动推送"><a href="#github自动推送" class="headerlink" title="github自动推送"></a>github自动推送</h2><ol><li>创建<code>.github\workflows\deploy.yml</code></li><li>在仓库添加私钥，SSH_PRIVATE，找一个本地一样的私钥</li><li>注意，packages.json也要提交</li></ol><p>yaml文件内容：</p><figure class="highlight yaml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br></pre></td><td class="code"><pre><code class="hljs yaml"><span class="hljs-attr">name:</span> <span class="hljs-string">Deploy</span>                      <span class="hljs-comment"># Actions 显示的名字，随意设置</span><br><br><span class="hljs-attr">on:</span> [<span class="hljs-string">push</span>]                        <span class="hljs-comment"># 监听到 push 事件后触发</span><br><br><span class="hljs-attr">jobs:</span><br>  <span class="hljs-attr">build:</span><br><br>    <span class="hljs-attr">runs-on:</span> <span class="hljs-string">ubuntu-latest</span><br><br>    <span class="hljs-attr">steps:</span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Checkout</span>              <span class="hljs-comment"># 拉取当前执行 Actions 仓库的指定分支</span><br>      <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/checkout@v2</span><br>      <span class="hljs-attr">with:</span><br>        <span class="hljs-attr">ref:</span> <span class="hljs-string">main</span><br><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Update</span> <span class="hljs-string">Submodule</span>      <span class="hljs-comment"># 如果仓库有 submodule，在这里更新，没有则删掉此步骤</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">        git submodule init</span><br><span class="hljs-string">        git submodule update --remote</span><br><span class="hljs-string"></span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Setup</span> <span class="hljs-string">Node</span>            <span class="hljs-comment"># 安装 Node 环境</span><br>      <span class="hljs-attr">uses:</span> <span class="hljs-string">actions/setup-node@v1</span><br>      <span class="hljs-attr">with:</span><br>        <span class="hljs-attr">node-version:</span> <span class="hljs-string">&quot;14.x&quot;</span><br><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Hexo</span> <span class="hljs-string">Generate</span>         <span class="hljs-comment"># 安装 Hexo 依赖并且生成静态文件</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">        rm -f .yarnclean</span><br><span class="hljs-string">        yarn --frozen-lockfile --ignore-engines --ignore-optional --non-interactive --silent --ignore-scripts --production=false</span><br><span class="hljs-string">        rm -rf ./public</span><br><span class="hljs-string">        yarn run hexo clean</span><br><span class="hljs-string">        yarn run hexo generate</span><br><span class="hljs-string"></span><br>    <span class="hljs-bullet">-</span> <span class="hljs-attr">name:</span> <span class="hljs-string">Hexo</span> <span class="hljs-string">Deploy</span>           <span class="hljs-comment"># 部署步骤，这里以 hexo deploy 为例</span><br>      <span class="hljs-attr">env:</span><br>        <span class="hljs-attr">SSH_PRIVATE:</span> <span class="hljs-string">$&#123;&#123;</span> <span class="hljs-string">secrets.SSH_PRIVATE</span> <span class="hljs-string">&#125;&#125;</span><br>        <span class="hljs-attr">GIT_NAME:</span> <span class="hljs-string">&lt;Your</span> <span class="hljs-string">Name&gt;</span><br>        <span class="hljs-attr">GIT_EMAIL:</span> <span class="hljs-string">&lt;Your</span> <span class="hljs-string">e-mail&gt;</span><br>      <span class="hljs-attr">run:</span> <span class="hljs-string">|</span><br><span class="hljs-string">        mkdir -p ~/.ssh/</span><br><span class="hljs-string">        echo &quot;$SSH_PRIVATE&quot; | tr -d &#x27;\r&#x27; &gt; ~/.ssh/id_rsa</span><br><span class="hljs-string">        chmod 600 ~/.ssh/id_rsa</span><br><span class="hljs-string">        ssh-keyscan github.com &gt;&gt; ~/.ssh/known_hosts</span><br><span class="hljs-string">        git config --global user.name &quot;$GIT_NAME&quot;</span><br><span class="hljs-string">        git config --global user.email &quot;$GIT_EMAIL&quot;</span><br><span class="hljs-string">        yarn run hexo deploy</span><br></code></pre></td></tr></table></figure><h2 id="云服务器部署"><a href="#云服务器部署" class="headerlink" title="云服务器部署"></a>云服务器部署</h2><p>服务器安装CentOS 7操作系统，首先安装Nodejs和git：  </p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install nodejs<br>yum install git<br></code></pre></td></tr></table></figure><h3 id="创建git用户和仓库"><a href="#创建git用户和仓库" class="headerlink" title="创建git用户和仓库"></a>创建git用户和仓库</h3><figure class="highlight shell"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br></pre></td><td class="code"><pre><code class="hljs shell">adduser git<br>chmod 740 /etc/sudoers<br>vim /etc/sudoers<br>=== root    ALL=(ALL)     ALL<br>+++ git     ALL=(ALL)     ALL<br>chmod 400 /etc/sudoers<br><br>sudo passwd git<br>su git<br>mkdir ~/.ssh<br>vim ~/.ssh/authorized_keys<br><span class="hljs-meta prompt_">#</span><span class="language-bash">然后将电脑中执行 C:\Users\28236\.ssh\id_rsa.pub ,将公钥复制粘贴到authorized_keys</span><br>linux: cat ~/.ssh/id_rsa.pub<br>chmod 600 ~/.ssh/authorized_keys<br>chmod 700 ~/.ssh<br>ssh -v git@SERVER<br><span class="hljs-meta prompt_"></span><br><span class="hljs-meta prompt_"># </span><span class="language-bash">su git  切换用户进行后续操作</span><br>cd /home/git/<br>mkdir -p projects/blog # 把项目目录建立起来<br>mkdir repos &amp;&amp; cd repos<br>git init --bare blog.git # 创建仓库<br>cd blog.git/hooks<br>vim post-receive # 创建一个钩子<br>+++ #!/bin/sh<br>+++ git --work-tree=/home/git/projects/blog --git-dir=/home/git/repos/blog.git checkout -f<br>chmod +x post-receive # 添加可执行权限<br>exit # 返回到root用户<br>chown -R git:git /home/git/repos/blog.git # 给git用户添加权限<br></code></pre></td></tr></table></figure><h3 id="使用nginx反向代理"><a href="#使用nginx反向代理" class="headerlink" title="使用nginx反向代理"></a>使用nginx反向代理</h3><p>安装nginx及使用：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">yum install nginx<br>nginx -s reload  <span class="hljs-comment">#重载配置文件</span><br>nginx -s stop<br><span class="hljs-built_in">sudo</span> service nginx restart<br>systemctl <span class="hljs-built_in">enable</span> nginx.service  <span class="hljs-comment">#设置开机自启动</span><br></code></pre></td></tr></table></figure><p>配置nginx，修改&#x2F;etc&#x2F;nginx&#x2F;nginx.conf：</p><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><code class="hljs json">user root;         <span class="hljs-comment">//用户</span><br>...<br>server <span class="hljs-punctuation">&#123;</span><br>        listen       <span class="hljs-number">80</span>;<br>        # listen       <span class="hljs-punctuation">[</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">:</span><span class="hljs-punctuation">]</span><span class="hljs-punctuation">:</span><span class="hljs-number">80</span> default_server;<br>        server_name  www.&lt;domain&gt; &lt;domain&gt;;   <span class="hljs-comment">//个人域名</span><br>        root         /home/git/projects/blog;                  <span class="hljs-comment">//仓库位置</span><br><br>        # Load configuration files for the default server block.<br>        include /etc/nginx/default.d<span class="hljs-comment">/*.conf;</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">        location / &#123;</span><br><span class="hljs-comment">        &#125;</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">        error_page 404 /404.html;</span><br><span class="hljs-comment">            location = /40x.html &#123;</span><br><span class="hljs-comment">        &#125;</span><br><span class="hljs-comment"></span><br><span class="hljs-comment">        error_page 500 502 503 504 /50x.html;</span><br><span class="hljs-comment">            location = /50x.html &#123;</span><br><span class="hljs-comment">        &#125;</span><br><span class="hljs-comment">    &#125;</span><br></code></pre></td></tr></table></figure><p>保存后重新部署。在公网中尝试连接，一般来说是失败。  </p><h3 id="开放云服务器端口"><a href="#开放云服务器端口" class="headerlink" title="开放云服务器端口"></a>开放云服务器端口</h3><p>因为腾讯云服务器并没有开放端口无法外部ping通，因此需要在“安全规则中”开放端口，如下所示：  </p><p><img src="/img/Front/front1.png" alt="fig1"></p><h3 id="设置Hexo仓库"><a href="#设置Hexo仓库" class="headerlink" title="设置Hexo仓库"></a>设置Hexo仓库</h3><figure class="highlight json"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><code class="hljs json">deploy<span class="hljs-punctuation">:</span><br>    type<span class="hljs-punctuation">:</span> git<br>    repo<span class="hljs-punctuation">:</span> git@server_ip<span class="hljs-punctuation">:</span>/home/git/repos/blog.git    <br>    branch<span class="hljs-punctuation">:</span> master<br></code></pre></td></tr></table></figure><p>提交更新：</p><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">hexo d -g<br></code></pre></td></tr></table></figure><h3 id="配置域名解析"><a href="#配置域名解析" class="headerlink" title="配置域名解析"></a>配置域名解析</h3><p>例如aliyun的域名解析设置如下：  </p><p><img src="/img/Front/front2.png" alt="fig2"></p><h3 id="域名备案"><a href="#域名备案" class="headerlink" title="域名备案"></a>域名备案</h3><p>各类云服务器在绑定域名时都需要备案，否则无法使用，例如我用的阿里云域名和腾讯云服务器，就需要在腾讯云中登记公网ip绑定的域名。</p>]]></content>
    
    
    <categories>
      
      <category>Software</category>
      
    </categories>
    
    
    <tags>
      
      <tag>Hexo</tag>
      
      <tag>Linux</tag>
      
    </tags>
    
  </entry>
  
  
  
  
</search>
