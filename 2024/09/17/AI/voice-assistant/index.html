

<!DOCTYPE html>
<html lang="zh-CN" data-default-color-scheme=auto>



<head>
  <meta charset="UTF-8">
  <link rel="apple-touch-icon" sizes="76x76" href="/img/world.png">
  <link rel="icon" href="/img/world.png">
  <meta name="viewport" content="width=device-width, initial-scale=1.0, maximum-scale=5.0, shrink-to-fit=no">
  <meta http-equiv="x-ua-compatible" content="ie=edge">
  
  <meta name="theme-color" content="#3e424a">
  <meta name="author" content="Yanjing">
  <meta name="keywords" content="">
  
    <meta name="description" content="This is a project to deploy a local AI assistant. This combines FunASR,Ollama and CosyVoice.">
<meta property="og:type" content="article">
<meta property="og:title" content="A Local AI Assistant like Siri">
<meta property="og:url" content="http://yoursite.com/2024/09/17/AI/voice-assistant/index.html">
<meta property="og:site_name" content="TechOdyssey">
<meta property="og:description" content="This is a project to deploy a local AI assistant. This combines FunASR,Ollama and CosyVoice.">
<meta property="og:locale" content="zh_CN">
<meta property="og:image" content="http://yoursite.com/img/ai/assistant/siri.jpg">
<meta property="article:published_time" content="2024-09-17T17:21:04.000Z">
<meta property="article:modified_time" content="2024-10-08T13:01:04.991Z">
<meta property="article:author" content="Yanjing">
<meta property="article:tag" content="GPU">
<meta property="article:tag" content="AI">
<meta property="article:tag" content="TTS">
<meta name="twitter:card" content="summary_large_image">
<meta name="twitter:image" content="http://yoursite.com/img/ai/assistant/siri.jpg">
  
  
  
  <title>A Local AI Assistant like Siri - TechOdyssey</title>

  <link  rel="stylesheet" href="https://lib.baomitu.com/twitter-bootstrap/4.6.1/css/bootstrap.min.css" />



  <link  rel="stylesheet" href="https://lib.baomitu.com/github-markdown-css/4.0.0/github-markdown.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/hint.css/2.7.0/hint.min.css" />

  <link  rel="stylesheet" href="https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.css" />



<!-- 主题依赖的图标库，不要自行修改 -->
<!-- Do not modify the link that theme dependent icons -->

<link rel="stylesheet" href="//at.alicdn.com/t/font_1749284_hj8rtnfg7um.css">



<link rel="stylesheet" href="//at.alicdn.com/t/font_1736178_lbnruvf0jn.css">


<link  rel="stylesheet" href="/css/main.css" />


  <link id="highlight-css" rel="stylesheet" href="/css/highlight.css" />
  
    <link id="highlight-css-dark" rel="stylesheet" href="/css/highlight-dark.css" />
  



  
<link rel="stylesheet" href="/css/icon.css">



  <script id="fluid-configs">
    var Fluid = window.Fluid || {};
    Fluid.ctx = Object.assign({}, Fluid.ctx)
    var CONFIG = {"hostname":"yoursite.com","root":"/","version":"1.9.7","typing":{"enable":true,"typeSpeed":15,"cursorChar":"|","loop":false,"scope":[]},"anchorjs":{"enable":true,"element":"h1,h2,h3,h4,h5,h6","placement":"right","visible":"hover","icon":"❡"},"progressbar":{"enable":true,"height_px":3,"color":"#29d","options":{"showSpinner":false,"trickleSpeed":100}},"code_language":{"enable":true,"default":"TEXT"},"copy_btn":true,"image_caption":{"enable":true},"image_zoom":{"enable":true,"img_url_replace":["",""]},"toc":{"enable":true,"placement":"right","headingSelector":"h1,h2,h3,h4,h5,h6","collapseDepth":0},"lazyload":{"enable":true,"loading_img":"/img/loading.gif","onlypost":false,"offset_factor":2},"web_analytics":{"enable":false,"follow_dnt":true,"baidu":null,"google":{"measurement_id":null},"tencent":{"sid":null,"cid":null},"woyaola":null,"cnzz":null,"leancloud":{"app_id":null,"app_key":null,"server_url":null,"path":"window.location.pathname","ignore_local":false}},"search_path":"/local-search.xml","include_content_in_search":true};

    if (CONFIG.web_analytics.follow_dnt) {
      var dntVal = navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack;
      Fluid.ctx.dnt = dntVal && (dntVal.startsWith('1') || dntVal.startsWith('yes') || dntVal.startsWith('on'));
    }
  </script>
  <script  src="/js/utils.js" ></script>
  <script  src="/js/color-schema.js" ></script>
  


  
<meta name="generator" content="Hexo 7.3.0"></head>


<body>
  

  <header>
    

<div class="header-inner" style="height: 70vh;">
  <nav id="navbar" class="navbar fixed-top  navbar-expand-lg navbar-dark scrolling-navbar">
  <div class="container">
    <a class="navbar-brand" href="/">
      <strong>Tech Odyssey</strong>
    </a>

    <button id="navbar-toggler-btn" class="navbar-toggler" type="button" data-toggle="collapse"
            data-target="#navbarSupportedContent"
            aria-controls="navbarSupportedContent" aria-expanded="false" aria-label="Toggle navigation">
      <div class="animated-icon"><span></span><span></span><span></span></div>
    </button>

    <!-- Collapsible content -->
    <div class="collapse navbar-collapse" id="navbarSupportedContent">
      <ul class="navbar-nav ml-auto text-center">
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/" target="_self">
                <i class="iconfont icon-home-fill"></i>
                <span>Home</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/archives/" target="_self">
                <i class="iconfont icon-archive-fill"></i>
                <span>Archives</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/categories/" target="_self">
                <i class="iconfont icon-category-fill"></i>
                <span>Categories</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/tags/" target="_self">
                <i class="iconfont icon-tags-fill"></i>
                <span>Tags</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/about/" target="_self">
                <i class="iconfont icon-user-fill"></i>
                <span>About</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item">
              <a class="nav-link" href="/links/" target="_self">
                <i class="iconfont icon-link-fill"></i>
                <span>Links</span>
              </a>
            </li>
          
        
          
          
          
          
            <li class="nav-item dropdown">
              <a class="nav-link dropdown-toggle" target="_self" href="javascript:;" role="button"
                 data-toggle="dropdown" aria-haspopup="true" aria-expanded="false">
                <i class="iconfont icon-bookmark-fill"></i>
                <span>Favor</span>
              </a>
              <div class="dropdown-menu" aria-labelledby="navbarDropdown">
                
                  
                  
                  
                  <a class="dropdown-item" href="https://vercel.com/" target="_self">
                    <i class="iconfont icon-vercel"></i>
                    <span>Vercel</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="/pdf/" target="_self">
                    <i class="iconfont icon-pdf-new"></i>
                    <span>PDF</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.google.com/" target="_self">
                    <i class="iconfont icon-google-new"></i>
                    <span>Google</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.baidu.com/" target="_self">
                    <i class="iconfont icon-baidu-new"></i>
                    <span>Baidu</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://github.com" target="_self">
                    <i class="iconfont icon-github-new"></i>
                    <span>Github</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.zhihu.com" target="_self">
                    <i class="iconfont icon-zhihu-new"></i>
                    <span>Zhihu</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.bilibili.com/" target="_self">
                    <i class="iconfont icon-bilibili-new"></i>
                    <span>Bilibili</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://chat.openai.com/" target="_self">
                    <i class="iconfont icon-chatGPT"></i>
                    <span>Chatgpt</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://msdn.itellyou.cn/" target="_self">
                    <i class="iconfont icon-microsoft"></i>
                    <span>MSDN</span>
                  </a>
                
                  
                  
                  
                  <a class="dropdown-item" href="https://www.iconfont.cn/" target="_self">
                    <i class="iconfont icon-iconfont"></i>
                    <span>Ali Icon</span>
                  </a>
                
              </div>
            </li>
          
        
        
          <li class="nav-item" id="search-btn">
            <a class="nav-link" target="_self" href="javascript:;" data-toggle="modal" data-target="#modalSearch" aria-label="Search">
              <i class="iconfont icon-search"></i>
            </a>
          </li>
          
        
        
          <li class="nav-item" id="color-toggle-btn">
            <a class="nav-link" target="_self" href="javascript:;" aria-label="Color Toggle">
              <i class="iconfont icon-dark" id="color-toggle-icon"></i>
            </a>
          </li>
        
      </ul>
    </div>
  </div>
</nav>

  

<div id="banner" class="banner" parallax=true
     style="background: url('/img/back_1.jpg') no-repeat center center; background-size: cover;">
  <div class="full-bg-img">
    <div class="mask flex-center" style="background-color: rgba(0, 0, 0, 0.1)">
      <div class="banner-text text-center fade-in-up">
        <div class="h2">
          
            <span id="subtitle" data-typed-text="A Local AI Assistant like Siri"></span>
          
        </div>

        
          
  <div class="mt-3">
    
    
      <span class="post-meta">
        <i class="iconfont icon-date-fill" aria-hidden="true"></i>
        <time datetime="2024-09-17 17:21" pubdate>
          2024年9月17日 下午
        </time>
      </span>
    
  </div>

  <div class="mt-1">
    
      <span class="post-meta mr-2">
        <i class="iconfont icon-chart"></i>
        
          473 words
        
      </span>
    

    
      <span class="post-meta mr-2">
        <i class="iconfont icon-clock-fill"></i>
        
        
        
          4 mins
        
      </span>
    

    
    
  </div>


        
      </div>

      
    </div>
  </div>
</div>

</div>

  </header>

  <main>
    
      

<div class="container-fluid nopadding-x">
  <div class="row nomargin-x">
    <div class="side-col d-none d-lg-block col-lg-2">
      

    </div>

    <div class="col-lg-8 nopadding-x-md">
      <div class="container nopadding-x-md" id="board-ctn">
        <div id="board">
          <article class="post-content mx-auto">
            <h1 id="seo-header">A Local AI Assistant like Siri</h1>
            
            
              <div class="markdown-body">
                
                <p>This is a <a href="https://github.com/Jianliang-Shen/ASR-Ollama-Chattts">project</a> to deploy a local AI assistant. This combines <a href="https://github.com/modelscope/FunASR">FunASR</a>,<a href="https://github.com/ollama/ollama">Ollama</a> and <a href="https://github.com/FunAudioLLM/CosyVoice">CosyVoice</a>.</p>
<span id="more"></span>

<ul>
<li>FunASR version: 1af68ba6ffc21d4dc3bd5f01cda656def97e361c</li>
<li>CosyVoice version: 9e0b99e48e67c3a874b7d0bbdc1a6a15c35f422e</li>
</ul>
<p><img src="/img/ai/assistant/assistant.png" srcset="/img/loading.gif" lazyload alt="Architecture"></p>
<div class="note note-danger">
            <p>Current version cannot use the cosyvoice.</p>
          </div>

<h1 id="TODO"><a href="#TODO" class="headerlink" title="TODO"></a>TODO</h1><ul>
<li><input disabled="" type="checkbox"> Cosyvoice Streaming…</li>
<li><input disabled="" type="checkbox"> Solve the defect that when playing the result audio, the microphone records the input and enter the death loop.</li>
</ul>
<h1 id="Preparation"><a href="#Preparation" class="headerlink" title="Preparation"></a>Preparation</h1><h2 id="FunASR"><a href="#FunASR" class="headerlink" title="FunASR"></a>FunASR</h2><p>You need to guarantee the WSL and Windows host can share the docker, this can be opened WSL in the docker desktop.</p>
<p><img src="/img/ai/assistant/docker.png" srcset="/img/loading.gif" lazyload alt="Docker Setup"></p>
<p>Follow this tutorial to deploy FunASR: <a href="https://github.com/modelscope/FunASR/blob/main/runtime/docs/SDK_tutorial_online.md">FunASR Realtime Transcribe Service</a>.</p>
<ul>
<li><p>Download workspace and run the local Asr server:</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">curl -O https://isv-data.oss-cn-hangzhou.aliyuncs.com/ics/MaaS/ASR/shell/funasr-runtime-deploy-online-cpu-zh.sh<br><span class="hljs-built_in">sudo</span> bash funasr-runtime-deploy-online-cpu-zh.sh install --workspace ./funasr-runtime-resources<br><br><span class="hljs-comment"># Restart the container</span><br><span class="hljs-built_in">sudo</span> bash funasr-runtime-deploy-online-cpu-zh.sh restart<br></code></pre></td></tr></table></figure>
</li>
<li><p>In the container, it will download models from the modelscope. After that you should see:</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">docker ps -a<br>docker <span class="hljs-built_in">exec</span> -it &lt;contianer ID&gt; bash<br><br><span class="hljs-comment"># In container:</span><br>watch -n 0.1 <span class="hljs-string">&quot;cat FunASR/runtime/log.txt | tail -n 10&quot;</span><br></code></pre></td></tr></table></figure></li>
</ul>
<p>We need to stop recording when the mic is not active. Here the technology is called <strong>VAD</strong>.</p>
<p>We also need to judge when the users input stop, not by the mic, but the results count from FunASR server. The count of sentences(messages) sent from the ASR server increases when user is saying. When user stopped, the count will stop increasing. I set the latency to 2s, when there is no more sentences coming from the server, the thread of <code>wait_end_and_send_to_ollama</code> will block and wait the results from the Ollama server.</p>
<div class="note note-danger">
            <p>FIX: Note that when assistant is saying, the users input at the same time will be set as next input. An important feature is that user can interrupt the assistant.</p>
          </div>

<h2 id="Ollama"><a href="#Ollama" class="headerlink" title="Ollama"></a>Ollama</h2><p>Download and install ollama in windows. After that, run <code>ollama run llama3.1</code> or <code>ollama run qwen:7b</code> in the Powershell to download the model. Then start the ollama server:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ollama serve<br></code></pre></td></tr></table></figure>

<p>You can easily follow the Ollama PyPi tutorial to use ollama APIs.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> ollama<br><br><span class="hljs-comment"># Response streaming can be enabled by setting stream=True, modifying function</span><br><span class="hljs-comment"># calls to return a Python generator where each part is an object in the stream.</span><br>stream = ollama.chat(<br>    model=<span class="hljs-string">&#x27;llama3.1&#x27;</span>,<br>    messages=[&#123;<span class="hljs-string">&#x27;role&#x27;</span>: <span class="hljs-string">&#x27;user&#x27;</span>, <span class="hljs-string">&#x27;content&#x27;</span>: <span class="hljs-string">&#x27;Why is the sky blue?&#x27;</span>&#125;],<br>    stream=<span class="hljs-literal">True</span>,<br>)<br><br><span class="hljs-keyword">for</span> chunk <span class="hljs-keyword">in</span> stream:<br>    <span class="hljs-built_in">print</span>(chunk[<span class="hljs-string">&#x27;message&#x27;</span>][<span class="hljs-string">&#x27;content&#x27;</span>], end=<span class="hljs-string">&#x27;&#x27;</span>, flush=<span class="hljs-literal">True</span>)<br></code></pre></td></tr></table></figure>

<h2 id="CosyVoice"><a href="#CosyVoice" class="headerlink" title="CosyVoice"></a>CosyVoice</h2><p>Follow the tutorial: <a href="https://github.com/FunAudioLLM/CosyVoice">CosyVoice</a></p>
<ul>
<li><p>Cuda 11.8 torch and torchaudio:</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip install torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118<br></code></pre></td></tr></table></figure>
</li>
<li><p>If you want to <strong>clone audio</strong>, transform audio file recorded from windows recorder:</p>
  <div class="note note-danger">
            <p>This is a very funny feature provided by CosyVoice, for example, you can clone Trump’s voice. This is already realized several years ago, but here it supports Chinese and uses LLM. <strong>Note that you should follow the law and privacy policy, it is very significant.</strong></p>
          </div>

  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash">ffmpeg -i input.m4a output.wav<br></code></pre></td></tr></table></figure>
</li>
<li><p>ONNX Runtime Issue: <code>onnxruntime::Provider&amp; onnxruntime::ProviderLibrary::Get() [ONNXRuntimeError] : 1 : FAIL : Failed to load library libonnxruntime_providers_cuda.so with error: libcufft.so.10: cannot open shared object file: No such file or directory</code></p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install onnxruntime-gpu==1.18.1 -i https://mirrors.aliyun.com/pypi/simple/<br>pip3 install onnxruntime==1.18.1 -i https://mirrors.aliyun.com/pypi/simple/<br></code></pre></td></tr></table></figure>
</li>
<li><p>Glibc issue: <code>version GLIBCXX_3.4.29 not found</code></p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><code class="hljs bash">find ~ -name <span class="hljs-string">&quot;libstdc++.so.6*&quot;</span><br>strings .conda/envs/cosyvoice/lib/libstdc++.so.6 | grep -i <span class="hljs-string">&quot;glibcxx&quot;</span><br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">cp</span> .conda/envs/cosyvoice/lib/libstdc++.so.6.0.33 /lib/x86_64-linux-gnu<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">rm</span> /usr/lib/x86_64-linux-gnu/libstdc++.so.6<br><span class="hljs-built_in">sudo</span> <span class="hljs-built_in">ln</span> -s /usr/lib/x86_64-linux-gnu/libstdc++.so.6.0.33 /usr/lib/x86_64-linux-gnu/libstdc++.so.6<br></code></pre></td></tr></table></figure></li>
</ul>
<h3 id="Server-and-client"><a href="#Server-and-client" class="headerlink" title="Server and client"></a>Server and client</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-comment"># 安装依赖</span><br><span class="hljs-built_in">cd</span> runtime/python/grpc &amp;&amp; python3 -m grpc_tools.protoc -I. --python_out=. --grpc_python_out=. cosyvoice.proto<br><br><span class="hljs-comment"># 将文字请求发送至server，并返回语音文件 demo.wav</span><br>python3 runtime/python/grpc/server.py --port 50000 --max_conc 4 --model_dir pretrained_models/CosyVoice-300M &amp;&amp; <span class="hljs-built_in">sleep</span> infinit<br>python3 runtime/python/grpc/client.py --port 50000 --mode sft<br><br><span class="hljs-comment"># Fast API</span><br>python3 runtime/python/fastapi/server.py --port 50000 --model_dir pretrained_models/CosyVoice-300M &amp;&amp; <span class="hljs-built_in">sleep</span> infinity<br>python3 runtime/python/fastapi/client.py --port 50000 --mode sft<br></code></pre></td></tr></table></figure>

<h3 id="Cosyvoice-Docker"><a href="#Cosyvoice-Docker" class="headerlink" title="Cosyvoice Docker"></a>Cosyvoice Docker</h3><p>You can also follow the tutorial to build the container. Thus in windows, the server can be accessed from the host or any other devices in the LAN.</p>
<p>Note that there may be a <code>CUFFT_INTERNAL_ERROR</code> bug in <code>cu117</code> docker. You can update to <code>cu118</code> manually in the docker.</p>
<ul>
<li><a href="https://forums.developer.nvidia.com/t/bug-ubuntu-on-wsl2-rtx4090-related-cufft-runtime-error/230883/5">Bug: Ubuntu on WSL2 - RTX4090 related cuFFT runtime error</a></li>
<li><a href="https://github.com/pytorch/pytorch/issues/88038">CUFFT_INTERNAL_ERROR on RTX 4090</a></li>
</ul>
<p>Uninstall 11.7 pytorch cuda in the container.</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip uninstall torch torchaudio<br>pip install torch==2.0.1 torchaudio==2.0.2 --index-url https://download.pytorch.org/whl/cu118<br></code></pre></td></tr></table></figure>

<h3 id="Play-the-audio-in-python"><a href="#Play-the-audio-in-python" class="headerlink" title="Play the audio in python"></a>Play the audio in python</h3><p>After get the <code>.wav</code> files from the server, you can use <code>simpleaudio</code> python library to play the audio.</p>
<figure class="highlight py"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br></pre></td><td class="code"><pre><code class="hljs py"><span class="hljs-keyword">import</span> simpleaudio <span class="hljs-keyword">as</span> sa<br> <br><span class="hljs-comment"># Load audio file</span><br>filename = <span class="hljs-string">&#x27;demo.wav&#x27;</span><br>wave_obj = sa.WaveObject.from_wave_file(filename)<br> <br><span class="hljs-comment"># Play the audio</span><br>play_obj = wave_obj.play()<br>play_obj.wait_done()<br></code></pre></td></tr></table></figure>

<h1 id="Deploy"><a href="#Deploy" class="headerlink" title="Deploy"></a>Deploy</h1><h2 id="Windows"><a href="#Windows" class="headerlink" title="Windows"></a>Windows</h2><p>Run the script:</p>
<figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install websockets pyaudio ollama<br>python3 funasr_client.py --host <span class="hljs-string">&quot;127.0.0.1&quot;</span> --port 10095 --hotword hotword.txt --powershell 1 --llm_mode llama3.1 --llamahost <span class="hljs-string">&quot;localhost:11434&quot;</span><br></code></pre></td></tr></table></figure>

<p><img src="/img/ai/assistant/demo.png" srcset="/img/loading.gif" lazyload alt="Voice ollama"></p>
<h2 id="WSL"><a href="#WSL" class="headerlink" title="WSL"></a>WSL</h2><ul>
<li><p>If ollama runs in the Windows host, you should enable wsl to access it in LAN (For other devices, this should also be enabled). In Powershell:</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><code class="hljs bash">[Environment]::SetEnvironmentVariable(<span class="hljs-string">&#x27;OLLAMA_HOST&#x27;</span>, <span class="hljs-string">&#x27;0.0.0.0:11434&#x27;</span>, <span class="hljs-string">&#x27;Process&#x27;</span>)<br>[Environment]::SetEnvironmentVariable(<span class="hljs-string">&#x27;OLLAMA_ORIGINS&#x27;</span>, <span class="hljs-string">&#x27;*&#x27;</span>, <span class="hljs-string">&#x27;Process&#x27;</span>)<br>ollama serve<br></code></pre></td></tr></table></figure>
</li>
<li><p>Run <code>ipconfig</code> in Poweshell to get the IPv4 of Host, for example: <code>172.20.10.2</code>.</p>
</li>
<li><p>The audio may not work due to the audio card. A way to solve the problem:</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><code class="hljs bash"><span class="hljs-built_in">sudo</span> apt-get install python3-pyaudio pulseaudio portaudio19-dev<br></code></pre></td></tr></table></figure>
</li>
<li><p>Run the scripts:</p>
  <figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><code class="hljs bash">pip3 install websockets pyaudio ollama<br>python3 funasr_client.py --host <span class="hljs-string">&quot;127.0.0.1&quot;</span> --port 10095 --hotword hotword.txt --llamahost <span class="hljs-string">&quot;172.20.10.2:11434&quot;</span> --llm_model <span class="hljs-string">&quot;qwen:7b&quot;</span><br></code></pre></td></tr></table></figure></li>
</ul>
<h1 id="References"><a href="#References" class="headerlink" title="References"></a>References</h1><ul>
<li><a href="https://pypi.org/project/ollama/">Ollama PyPI</a></li>
<li><a href="https://github.com/ollama/ollama/blob/main/docs/api.md">Ollama API</a></li>
<li><a href="https://blog.csdn.net/tianya_lu/article/details/140048604">version GLIBCXX_3.4.29 not found</a></li>
</ul>

                
              </div>
            
            <hr/>
            <div>
              <div class="post-metas my-3">
  
    <div class="post-meta mr-3 d-flex align-items-center">
      <i class="iconfont icon-category"></i>
      

<span class="category-chains">
  
  
    
      <span class="category-chain">
        
  <a href="/categories/AI/" class="category-chain-item">AI</a>
  
  

      </span>
    
  
</span>

    </div>
  
  
    <div class="post-meta">
      <i class="iconfont icon-tags"></i>
      
        <a href="/tags/GPU/" class="print-no-link">#GPU</a>
      
        <a href="/tags/AI/" class="print-no-link">#AI</a>
      
        <a href="/tags/TTS/" class="print-no-link">#TTS</a>
      
    </div>
  
</div>


              

              
                <div class="post-prevnext my-3">
                  <article class="post-prev col-6">
                    
                    
                      <a href="/2024/09/18/AI-TEE/" title="异构 CPU-GPU 系统上的机密计算：调研和未来方向">
                        <i class="iconfont icon-arrowleft"></i>
                        <span class="hidden-mobile">异构 CPU-GPU 系统上的机密计算：调研和未来方向</span>
                        <span class="visible-mobile">Previous</span>
                      </a>
                    
                  </article>
                  <article class="post-next col-6">
                    
                    
                      <a href="/2024/09/13/AI/Jetson-ASR/" title="Jetson Whisper 语音识别测试">
                        <span class="hidden-mobile">Jetson Whisper 语音识别测试</span>
                        <span class="visible-mobile">Next</span>
                        <i class="iconfont icon-arrowright"></i>
                      </a>
                    
                  </article>
                </div>
              
            </div>

            
          </article>
        </div>
      </div>
    </div>

    <div class="side-col d-none d-lg-block col-lg-2">
      
  <aside class="sidebar" style="margin-left: -1rem">
    <div id="toc">
  <p class="toc-header">
    <i class="iconfont icon-list"></i>
    <span>Table of Contents</span>
  </p>
  <div class="toc-body" id="toc-body"></div>
</div>



  </aside>


    </div>
  </div>
</div>





  



  



  



  



  


  
  









    

    
      <a id="scroll-top-button" aria-label="TOP" href="#" role="button">
        <i class="iconfont icon-arrowup" aria-hidden="true"></i>
      </a>
    

    
      <div class="modal fade" id="modalSearch" tabindex="-1" role="dialog" aria-labelledby="ModalLabel"
     aria-hidden="true">
  <div class="modal-dialog modal-dialog-scrollable modal-lg" role="document">
    <div class="modal-content">
      <div class="modal-header text-center">
        <h4 class="modal-title w-100 font-weight-bold">Search</h4>
        <button type="button" id="local-search-close" class="close" data-dismiss="modal" aria-label="Close">
          <span aria-hidden="true">&times;</span>
        </button>
      </div>
      <div class="modal-body mx-3">
        <div class="md-form mb-5">
          <input type="text" id="local-search-input" class="form-control validate">
          <label data-error="x" data-success="v" for="local-search-input">Keyword</label>
        </div>
        <div class="list-group" id="local-search-result"></div>
      </div>
    </div>
  </div>
</div>

    

    
  </main>

  <footer>
    <div class="footer-inner">
  
    <div class="footer-content">
       <a href="https://hexo.io" target="_blank" rel="nofollow noopener"><span>Tech Odyssey</span></a> <a href="https://github.com/fluid-dev/hexo-theme-fluid" target="_blank" rel="nofollow noopener"><span>2019 - 2024 🇨🇳</span></a> 
    </div>
  
  
  
  
</div>

  </footer>

  <!-- Scripts -->
  
  <script  src="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.js" ></script>
  <link  rel="stylesheet" href="https://lib.baomitu.com/nprogress/0.2.0/nprogress.min.css" />

  <script>
    NProgress.configure({"showSpinner":false,"trickleSpeed":100})
    NProgress.start()
    window.addEventListener('load', function() {
      NProgress.done();
    })
  </script>


<script  src="https://lib.baomitu.com/jquery/3.6.4/jquery.min.js" ></script>
<script  src="https://lib.baomitu.com/twitter-bootstrap/4.6.1/js/bootstrap.min.js" ></script>
<script  src="/js/events.js" ></script>
<script  src="/js/plugins.js" ></script>


  <script  src="https://lib.baomitu.com/typed.js/2.0.12/typed.min.js" ></script>
  <script>
    (function (window, document) {
      var typing = Fluid.plugins.typing;
      var subtitle = document.getElementById('subtitle');
      if (!subtitle || !typing) {
        return;
      }
      var text = subtitle.getAttribute('data-typed-text');
      
        typing(text);
      
    })(window, document);
  </script>




  
    <script  src="/js/img-lazyload.js" ></script>
  




  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/tocbot/4.20.1/tocbot.min.js', function() {
    var toc = jQuery('#toc');
    if (toc.length === 0 || !window.tocbot) { return; }
    var boardCtn = jQuery('#board-ctn');
    var boardTop = boardCtn.offset().top;

    window.tocbot.init(Object.assign({
      tocSelector     : '#toc-body',
      contentSelector : '.markdown-body',
      linkClass       : 'tocbot-link',
      activeLinkClass : 'tocbot-active-link',
      listClass       : 'tocbot-list',
      isCollapsedClass: 'tocbot-is-collapsed',
      collapsibleClass: 'tocbot-is-collapsible',
      scrollSmooth    : true,
      includeTitleTags: true,
      headingsOffset  : -boardTop,
    }, CONFIG.toc));
    if (toc.find('.toc-list-item').length > 0) {
      toc.css('visibility', 'visible');
    }

    Fluid.events.registerRefreshCallback(function() {
      if ('tocbot' in window) {
        tocbot.refresh();
        var toc = jQuery('#toc');
        if (toc.length === 0 || !tocbot) {
          return;
        }
        if (toc.find('.toc-list-item').length > 0) {
          toc.css('visibility', 'visible');
        }
      }
    });
  });
</script>


  <script src=https://lib.baomitu.com/clipboard.js/2.0.11/clipboard.min.js></script>

  <script>Fluid.plugins.codeWidget();</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/anchor-js/4.3.1/anchor.min.js', function() {
    window.anchors.options = {
      placement: CONFIG.anchorjs.placement,
      visible  : CONFIG.anchorjs.visible
    };
    if (CONFIG.anchorjs.icon) {
      window.anchors.options.icon = CONFIG.anchorjs.icon;
    }
    var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
    var res = [];
    for (var item of el) {
      res.push('.markdown-body > ' + item.trim());
    }
    if (CONFIG.anchorjs.placement === 'left') {
      window.anchors.options.class = 'anchorjs-link-left';
    }
    window.anchors.add(res.join(', '));

    Fluid.events.registerRefreshCallback(function() {
      if ('anchors' in window) {
        anchors.removeAll();
        var el = (CONFIG.anchorjs.element || 'h1,h2,h3,h4,h5,h6').split(',');
        var res = [];
        for (var item of el) {
          res.push('.markdown-body > ' + item.trim());
        }
        if (CONFIG.anchorjs.placement === 'left') {
          anchors.options.class = 'anchorjs-link-left';
        }
        anchors.add(res.join(', '));
      }
    });
  });
</script>


  
<script>
  Fluid.utils.createScript('https://lib.baomitu.com/fancybox/3.5.7/jquery.fancybox.min.js', function() {
    Fluid.plugins.fancyBox();
  });
</script>


  <script>Fluid.plugins.imageCaption();</script>

  
      <script>
        if (!window.MathJax) {
          window.MathJax = {
            tex    : {
              inlineMath: { '[+]': [['$', '$']] }
            },
            loader : {
              load: ['ui/lazy']
            },
            options: {
              renderActions: {
                insertedScript: [200, () => {
                  document.querySelectorAll('mjx-container').forEach(node => {
                    let target = node.parentNode;
                    if (target.nodeName.toLowerCase() === 'li') {
                      target.parentNode.classList.add('has-jax');
                    }
                  });
                }, '', false]
              }
            }
          };
        } else {
          MathJax.startup.document.state(0);
          MathJax.texReset();
          MathJax.typeset();
          MathJax.typesetPromise();
        }

        Fluid.events.registerRefreshCallback(function() {
          if ('MathJax' in window && MathJax.startup.document && typeof MathJax.startup.document.state === 'function') {
            MathJax.startup.document.state(0);
            MathJax.texReset();
            MathJax.typeset();
            MathJax.typesetPromise();
          }
        });
      </script>
    

  <script  src="https://lib.baomitu.com/mathjax/3.2.2/es5/tex-mml-chtml.js" ></script>

  <script  src="/js/local-search.js" ></script>





<!-- 主题的启动项，将它保持在最底部 -->
<!-- the boot of the theme, keep it at the bottom -->
<script  src="/js/boot.js" ></script>


  

  <noscript>
    <div class="noscript-warning">Blog works best with JavaScript enabled</div>
  </noscript>
<!-- hexo injector body_end start --><script data-pjax src="https://unpkg.com/oh-my-live2d"></script><script>const oml2d = OML2D.loadOml2d({dockedPosition:"left",mobileDisplay:false,models:[{"path":"/live2d-models/models/umaru/model.json","position":[100,30],"scale":0.25,"stageStyle":{"width":400,"height":470}},{"path":"/live2d-models/models/kobayaxi/model.json","position":[30,0],"scale":0.3,"stageStyle":{"width":400}},{"path":"/live2d-models/models/bilibili-22/index.json","position":[0,30],"scale":0.35,"stageStyle":{"width":400}},{"path":"/live2d-models/models/bilibili-33/index.json","position":[0,30],"scale":0.35,"stageStyle":{"width":400}}],parentElement:document.body,primaryColor:"#7f6f6c",tips:{style: {"left":"calc(50%)","top":"-50px"},idleTips:{interval:150}}});</script><!-- hexo injector body_end end --></body>
</html>
